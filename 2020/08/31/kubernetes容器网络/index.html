<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"plantegg.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="kubernetes 容器网络cni 网络  cni0 is a Linux network bridge device, all veth devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in Kubernetes Net">
<meta property="og:type" content="article">
<meta property="og:title" content="kubernetes容器网络">
<meta property="og:url" content="https://plantegg.github.io/2020/08/31/kubernetes%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="kubernetes 容器网络cni 网络  cni0 is a Linux network bridge device, all veth devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in Kubernetes Net">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220115124747936.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220115132938290.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220115133500854.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/d3111417ce646ca1475def5bea01e6b9.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/9ea9041af1211b2a5b8de4e216044465.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/16fda9322e9a59c37c11629acc611bf3.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png">
<meta property="og:image" content="https://plantegg.github.io/images/oss/5c7172e2422579eb99c66e881d47bf99.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20211228203650921.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/640-5304524.">
<meta property="article:published_time" content="2020-08-31T03:30:03.000Z">
<meta property="article:modified_time" content="2025-11-16T11:58:49.539Z">
<meta property="article:author" content="twitter @plantegg">
<meta property="article:tag" content="calico">
<meta property="article:tag" content="docker">
<meta property="article:tag" content="kubernetes">
<meta property="article:tag" content="network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220115124747936.png">


<link rel="canonical" href="https://plantegg.github.io/2020/08/31/kubernetes%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://plantegg.github.io/2020/08/31/kubernetes%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/","path":"2020/08/31/kubernetes容器网络/","title":"kubernetes容器网络"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>kubernetes容器网络 | plantegg</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">plantegg</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#kubernetes-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C"><span class="nav-number">1.</span> <span class="nav-text">kubernetes 容器网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#cni-%E7%BD%91%E7%BB%9C"><span class="nav-number">1.1.</span> <span class="nav-text">cni 网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cni%EF%BC%88Container-Network-Interface%EF%BC%89"><span class="nav-number">1.1.1.</span> <span class="nav-text">cni（Container Network Interface）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#flannel-%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.</span> <span class="nav-text">flannel 网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kubernetes-calico-%E7%BD%91%E7%BB%9C"><span class="nav-number">1.3.</span> <span class="nav-text">kubernetes calico 网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#calico-ipip%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A"><span class="nav-number">1.4.</span> <span class="nav-text">calico ipip网络不通</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B1"><span class="nav-number">1.4.1.</span> <span class="nav-text">案例1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B2"><span class="nav-number">1.4.2.</span> <span class="nav-text">案例2</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#flannel%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A"><span class="nav-number">1.5.</span> <span class="nav-text">flannel网络不通</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#firewalld"><span class="nav-number">1.5.1.</span> <span class="nav-text">firewalld</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%89%E7%94%B5%E9%87%8D%E5%90%AF%E5%90%8Eflannel%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A"><span class="nav-number">1.5.2.</span> <span class="nav-text">掉电重启后flannel网络不通</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B8%85%E7%90%86"><span class="nav-number">1.6.</span> <span class="nav-text">清理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#netns"><span class="nav-number">1.7.</span> <span class="nav-text">netns</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">1.8.</span> <span class="nav-text">参考资料</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twitter @plantegg</p>
  <div class="site-description" itemprop="description">java mysql tcp performance network docker Linux</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">184</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">274</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/08/31/kubernetes%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="kubernetes容器网络 | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kubernetes容器网络
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-08-31 11:30:03" itemprop="dateCreated datePublished" datetime="2020-08-31T11:30:03+08:00">2020-08-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="kubernetes-容器网络"><a href="#kubernetes-容器网络" class="headerlink" title="kubernetes 容器网络"></a>kubernetes 容器网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni/blob/master/SPEC.md">规范</a>。<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni">containernetworking&#x2F;cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#ls -lh /opt/cni/bin/</span><br><span class="line">总用量 90M</span><br><span class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</span><br><span class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</span><br><span class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</span><br><span class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</span><br><span class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</span><br><span class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</span><br><span class="line"></span><br><span class="line">[root@hygon3 15:55 /root]</span><br><span class="line">#ls -lh /etc/cni/net.d/</span><br><span class="line">总用量 12K</span><br><span class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</span><br><span class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</span><br><span class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</span><br></pre></td></tr></table></figure>

<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C&#x2F;S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> *<strong>Pod 1 netns*</strong> <em>through the</em> *<strong>eth1*</strong> <em>interface and reaches the</em> <em><strong>root netns*</strong> <em>through the virtual interface</em> <em><strong>veth1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>veth1*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> <em><strong>Pod 6*</strong></em>’s* <em>address;</em></li>
<li><em>Package leaves</em> <em><strong>cni0*</strong> <em>and is redirected to</em> <em><strong>eth0*</strong></em>;</em></li>
<li><em>Package leaves</em> *<strong>eth0*</strong> <em>from</em> <em><strong>Master 1*</strong> <em>and reaches the</em> <em><strong>gateway*</strong></em>;</em></li>
<li><em>Package leaves the</em> *<strong>gateway*</strong> <em>and reaches the</em> *<strong>root netns*</strong> <em>through the</em> <em><strong>eth0*</strong> <em>interface on</em> <em><strong>Worker 1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>eth0*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> <em><strong>Pod 6*</strong></em>’s* <em>address;</em></li>
<li><em>Package leaves</em> *<strong>cni0*</strong> <em>and is redirected to the</em> *<strong>veth6*</strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> *<strong>root netns*</strong> <em>through</em> *<strong>veth6*</strong> <em>and reaches the</em> *<strong>Pod 6 netns*</strong> <em>though the</em> *<strong>eth6*</strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="flannel-网络"><a href="#flannel-网络" class="headerlink" title="flannel 网络"></a>flannel 网络</h2><p>假如POD1访问POD4：</p>
<ol>
<li>从POD1中出来的包先到Bridge cni0上（因为POD1对应的veth挂在了cni0上）</li>
<li>然后进入到宿主机网络，宿主机有路由 10.244.2.0&#x2F;24 via 10.244.2.0 dev flannel.1 onlink ，也就是目标ip 10.244.2.3的包交由 flannel.1 来处理</li>
<li>flanneld 进程将包封装成vxlan 丢到eth0从宿主机1离开（封装后的目标ip是192.168.2.91）</li>
<li>这个封装后的vxlan udp包正确路由到宿主机2</li>
<li>然后经由 flanneld 解包成 10.244.2.3 ，命中宿主机2上的路由：10.244.2.0&#x2F;24 dev cni0 proto kernel scope link src 10.244.2.1 ，交给cni0（<strong>这里会过宿主机iptables</strong>）</li>
<li>cni0将包送给POD4</li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115132938290.png" alt="image-20220115132938290"></p>
<p>对应宿主机查询到的ip、路由信息（和上图不是对应的）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#ip -d -4 addr show cni0</span><br><span class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer  161.46 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br><span class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">#ip -d -4 addr show flannel.1</span><br><span class="line">474: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether fe:49:64:ae:36:af brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    vxlan id 1 local 10.133.2.252 dev bond0 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br><span class="line">    inet 192.168.3.0/32 brd 192.168.3.0 scope global flannel.1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line">[root@hygon239 20:06 /root]</span><br><span class="line">#kubectl describe node hygon252 | grep -C5 -i vtep  //可以看到VetpMAC 以及对应的宿主机IP（vxlan封包后的IP）</span><br><span class="line">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    kubernetes.io/arch=amd64</span><br><span class="line">                    kubernetes.io/hostname=hygon252</span><br><span class="line">                    kubernetes.io/os=linux</span><br><span class="line">Annotations:        flannel.alpha.coreos.com/backend-data: &#123;&quot;VNI&quot;:1,&quot;VtepMAC&quot;:&quot;fe:49:64:ae:36:af&quot;&#125;</span><br><span class="line">                    flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">                    flannel.alpha.coreos.com/kube-subnet-manager: true</span><br><span class="line">                    flannel.alpha.coreos.com/public-ip: 10.133.2.252</span><br><span class="line">                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock</span><br><span class="line">                    node.alpha.kubernetes.io/ttl: 0       </span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/image-20220115133500854.png" alt="image-20220115133500854"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br><span class="line"></span><br><span class="line">#或者老版本的calico</span><br><span class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</span><br></pre></td></tr></table></figure>

<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 &#x2F;26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</span><br><span class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br><span class="line"></span><br><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了 </span><br></pre></td></tr></table></figure>

<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </span><br><span class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br></pre></td></tr></table></figure>

<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64&#x2F;26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br></pre></td></tr></table></figure>

<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128&#x2F;26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</span><br><span class="line">//同时将默认路由改到3.113</span><br><span class="line">ip route del default via 192.168.0.253 dev eth0; </span><br><span class="line">ip route add default via 192.168.3.253 dev eth1</span><br></pre></td></tr></table></figure>

<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-14 ~]# ip route</span><br><span class="line">default via 192.168.3.253 dev eth1 </span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </span><br><span class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </span><br><span class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </span><br><span class="line">blackhole 10.122.157.128/26 proto bird </span><br><span class="line">10.122.157.129 dev cali19f6ea143e3 scope link </span><br><span class="line">10.122.157.130 dev cali09e016ead53 scope link </span><br><span class="line">10.122.157.131 dev cali0ad3225816d scope link </span><br><span class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </span><br><span class="line">10.122.157.133 dev cali01cf8687c65 scope link </span><br><span class="line">10.122.157.134 dev cali65232d7ada6 scope link </span><br><span class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </span><br><span class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</span><br></pre></td></tr></table></figure>

<p>正常后的抓包, 注意这里drequest的est ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//request</span><br><span class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</span><br><span class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</span><br><span class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</span><br><span class="line">    </span><br><span class="line">//reply    </span><br><span class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</span><br><span class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</span><br><span class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</span><br></pre></td></tr></table></figure>

<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="flannel网络不通"><a href="#flannel网络不通" class="headerlink" title="flannel网络不通"></a>flannel网络不通</h2><h3 id="firewalld"><a href="#firewalld" class="headerlink" title="firewalld"></a>firewalld</h3><p>在麒麟系统的物理机上通过kubeadm setup集群，发现有的环境flannel网络不通，在宿主机上ping 其它物理机flannel.0网卡的ip，通过在对端宿主机抓包发现icmp收到后被防火墙扔掉了，抓包中可以看到错误信息：icmp unreachable - admin prohibited</p>
<p>下图中正常的icmp是直接ping 物理机ip</p>
<p><img src="/images/951413iMgBlog/image-20211228203650921.png" alt="image-20211228203650921"></p>
<blockquote>
<p>The “admin prohibited filter” seen in the tcpdump output means there is a firewall blocking a connection. It does it by sending back an ICMP packet meaning precisely that: the admin of that firewall doesn’t want those packets to get through. It could be a firewall at the destination site. It could be a firewall in between. It could be iptables on the Linux system.</p>
</blockquote>
<p>发现有问题的环境中宿主机的防火墙设置报错了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &#x27;/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATION-STAGE-1&#x27; failed: iptables: No chain/target/match by that name.</span><br><span class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &#x27;/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATION-STAGE-2&#x27; failed: iptables: No chain/target/match by that name.</span><br></pre></td></tr></table></figure>

<p>应该是因为启动docker的时候 firewalld 是运行着的</p>
<blockquote>
<p>Do you have firewalld enabled, and was it (re)started after docker was started? If so, then it’s likely that firewalld wiped docker’s IPTables rules. Restarting the docker daemon should re-create those rules.</p>
</blockquote>
<p>停掉 firewalld 服务可以解决这个问题</p>
<h3 id="掉电重启后flannel网络不通"><a href="#掉电重启后flannel网络不通" class="headerlink" title="掉电重启后flannel网络不通"></a><a target="_blank" rel="noopener" href="https://github.com/flannel-io/flannel/issues/799">掉电重启后flannel网络不通</a></h3><p>flannel能收到包，但是cni0收不到包，说明包进到了目标宿主机，但是从flannel解开udp转送到cni的时候出了问题，大概率是iptables 拦截了包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">It seems docker version &gt;=1.13 will add iptables rule like below,and it make this issue happen:</span><br><span class="line">iptables -P FORWARD DROP</span><br><span class="line"></span><br><span class="line">All you need to do is add a rule below:</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure>



<h2 id="清理"><a href="#清理" class="headerlink" title="清理"></a><a target="_blank" rel="noopener" href="https://serverfault.com/questions/247767/cannot-delete-gre-tunnel">清理</a></h2><p>cni信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/cni/net.d/*</span><br><span class="line">/var/lib/cni/ 下存放有ip分配信息</span><br></pre></td></tr></table></figure>

<p>calico创建的tunl0网卡是个tunnel，可以通过 ip tunnel show来查看，清理不掉（重启可以清理掉tunl0）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev tunl0 name tunl0_fallback</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line">/sbin/ip link set eth1 down</span><br><span class="line">/sbin/ip link set eth1 name eth123</span><br><span class="line">/sbin/ip link set eth123 up</span><br></pre></td></tr></table></figure>

<p>flannel</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link delete flannel.1</span><br><span class="line">ip link delete cni0</span><br></pre></td></tr></table></figure>



<h2 id="netns"><a href="#netns" class="headerlink" title="netns"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw">netns</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">1004  [2021-10-27 10:49:08] ip netns add ren</span><br><span class="line">1005  [2021-10-27 10:49:12] ip netns show</span><br><span class="line">1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</span><br><span class="line">1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</span><br><span class="line">1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</span><br><span class="line">1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</span><br><span class="line">1010  [2021-10-27 10:50:18] ip netns exec ren route  </span><br><span class="line">1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</span><br><span class="line">1012  [2021-10-27 10:50:39] ifconfig</span><br><span class="line">1013  [2021-10-27 10:50:51] ip link list</span><br><span class="line">1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</span><br><span class="line">1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </span><br><span class="line">1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</span><br><span class="line">1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</span><br><span class="line">1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</span><br><span class="line">1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</span><br><span class="line">1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</span><br><span class="line">1023  [2021-10-27 10:54:22] ping 172.19.0.100</span><br><span class="line">1024  [2021-10-27 10:54:35] ifconfig -a</span><br><span class="line">1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line">1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line">1027  [2021-10-27 10:55:16] ifconfig veth1_p</span><br><span class="line">1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</span><br><span class="line">1029  [2021-10-27 10:55:32] ifconfig veth1_p</span><br><span class="line">1030  [2021-10-27 10:55:38] ping 172.19.0.101</span><br><span class="line">1031  [2021-10-27 10:55:43] ping 172.19.0.100</span><br><span class="line">1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</span><br><span class="line">1033  [2021-10-27 10:55:54] ping 172.19.0.100</span><br><span class="line">1034  [2021-10-27 10:55:58] ping 172.19.0.101</span><br><span class="line">1035  [2021-10-27 10:56:08] ifconfig veth1_p</span><br><span class="line">1036  [2021-10-27 10:56:32] ping 172.19.0.101</span><br><span class="line">1037  [2021-10-27 10:57:04] ip netns exec ren route</span><br><span class="line">1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</span><br><span class="line">1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</span><br><span class="line">1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</span><br><span class="line">1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</span><br><span class="line">1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</span><br><span class="line">1043  [2021-10-27 10:58:19] ip netns exec ren route</span><br><span class="line">1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</span><br><span class="line">1045  [2021-10-27 10:58:58] ifconfig veth1_p</span><br><span class="line">1046  [2021-10-27 10:59:10] ping 172.19.0.100</span><br><span class="line">1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</span><br><span class="line"></span><br><span class="line">把网卡加入到docker0的bridge下</span><br><span class="line">1160  [2021-10-27 12:17:37] brctl show</span><br><span class="line">1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</span><br><span class="line">1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</span><br><span class="line">1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</span><br><span class="line">1164  [2021-10-27 12:18:15] brctl show</span><br><span class="line"></span><br><span class="line">btctl showmacs br0</span><br></pre></td></tr></table></figure>

<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: net/socket.c</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sock_create</span><span class="params">(<span class="type">int</span> family, <span class="type">int</span> type, <span class="type">int</span> protocol, <span class="keyword">struct</span> socket **res)</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//file: include/net/sock.h</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sock_net_set</span><span class="params">(<span class="keyword">struct</span> sock *sk, <span class="keyword">struct</span> net *net)</span></span><br><span class="line">&#123;</span><br><span class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="https://morven.life/notes/networking-3-ipip/">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/bakari/p/10564347.html">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/goldsunshine/p/10701242.html">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/docker/" rel="tag"># docker</a>
              <a href="/tags/network/" rel="tag"># network</a>
              <a href="/tags/kubernetes/" rel="tag"># kubernetes</a>
              <a href="/tags/calico/" rel="tag"># calico</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/07/03/MySQL%20JDBC%20StreamResult%20%E5%92%8C%20net_write_timeout/" rel="prev" title="MySQL JDBC StreamResult 和 net_write_timeout">
                  <i class="fa fa-angle-left"></i> MySQL JDBC StreamResult 和 net_write_timeout
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/09/16/RT%E9%83%BD%E5%8E%BB%E5%93%AA%E4%BA%86/" rel="next" title="delay ack拉高实际rt的case">
                  delay ack拉高实际rt的case <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
