<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"plantegg.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/page/12/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="twitter @plantegg">
<meta property="article:tag" content="技术,编程,博客">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://plantegg.github.io/page/12/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/12/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>plantegg</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">plantegg</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twitter @plantegg</p>
  <div class="site-description" itemprop="description">java mysql tcp performance network docker Linux</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">190</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">282</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/01/04/%E8%8E%B7%E5%8F%96%E4%B8%80%E7%9B%B4FullGC%E4%B8%8B%E7%9A%84java%E8%BF%9B%E7%A8%8BHeapDump%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/04/%E8%8E%B7%E5%8F%96%E4%B8%80%E7%9B%B4FullGC%E4%B8%8B%E7%9A%84java%E8%BF%9B%E7%A8%8BHeapDump%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7/" class="post-title-link" itemprop="url">获取一直FullGC下的java进程HeapDump的小技巧</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-01-04 17:30:03" itemprop="dateCreated datePublished" datetime="2020-01-04T17:30:03+08:00">2020-01-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="获取一直FullGC下的java进程HeapDump的小技巧"><a href="#获取一直FullGC下的java进程HeapDump的小技巧" class="headerlink" title="获取一直FullGC下的java进程HeapDump的小技巧"></a>获取一直FullGC下的java进程HeapDump的小技巧</h1><p>就是小技巧，操作步骤需要查询，随手记录</p>
<ul>
<li>找到java进程，gdb attach上去， 例如 <code>gdb -p 12345</code></li>
<li>找到这个<code>HeapDumpBeforeFullGC</code>的地址（这个flag如果为true，会在FullGC之前做HeapDump，默认是false）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p &amp;HeapDumpBeforeFullGC</span><br><span class="line">$2 = (&lt;data variable, no debug info&gt; *) 0x7f7d50fc660f &lt;HeapDumpBeforeFullGC&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>Copy 地址：0x7f7d50fc660f</li>
<li>然后把他设置为true，这样下次FGC之前就会生成一份dump文件</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) set *0x7f7d50fc660f = 1</span><br><span class="line">(gdb) quit</span><br></pre></td></tr></table></figure>

<ul>
<li>最后，等一会，等下次FullGC触发，你就有HeapDump了！<br>(如果没有指定heapdump的名字，默认是 java_pidxxx.hprof)</li>
</ul>
<p>(PS. <code>jstat -gcutil pid</code> 可以查看gc的概况)</p>
<p>(操作完成后记得gdb上去再设置回去，不然可能一直fullgc，导致把磁盘打满).</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>在jvm还有响应的时候可以： jinfo -flag +HeapDumpBeforeFullGC pid 设置HeapDumpBeforeFullGC 为true（- 为false，+-都不要为只打印值）</p>
<p>kill -3 产生coredump  存放在 kernel.core_pattern&#x3D;&#x2F;root&#x2F;core （&#x2F;etc&#x2F;sysctl.conf , 先 ulimit -c unlimited；或者 gcore id 获取coredump)</p>
<p>得到core文件后，采用 gdb -c 执行文件 core文件 进入调试模式，对于java，有以下2个技巧：</p>
<p>进入gdb调试模式后，输入如下命令： info threads，观察异常的线程，定位到异常的线程后，则可以输入如下命令：thread 线程编号，则会打印出当前java代码的工作流程。</p>
<p> 而对于这个core，亦可以用jstack jmap打印出堆信息，线程信息，具体命令：</p>
<p>  jmap -heap 执行文件 core文件   jstack -F -l 执行文件 core文件</p>
<p><strong>容器中的进程的话需要到宿主机操作，并且将容器中的 jdk文件夹复制到宿主机对应的位置。</strong></p>
<p>  <strong>ps auxff |grep 容器id -A10 找到JVM在宿主机上的进程id</strong></p>
<h2 id="coredump"><a href="#coredump" class="headerlink" title="coredump"></a>coredump</h2><p>kill -3 产生coredump  存放在 kernel.core_pattern&#x3D;&#x2F;root&#x2F;core （&#x2F;etc&#x2F;sysctl.conf , 先 ulimit -c unlimited；）</p>
<p>或者 gcore id 获取coredump</p>
<p><a target="_blank" rel="noopener" href="https://www.baeldung.com/linux/managing-core-dumps">coredump 所在位置</a>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$cat /proc/sys/kernel/core_pattern</span><br><span class="line">/home/admin/</span><br></pre></td></tr></table></figure>

<h3 id="coredump-分析"><a href="#coredump-分析" class="headerlink" title="coredump 分析"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46605905">coredump 分析</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">//打开 coredump</span><br><span class="line">$gdb /opt/taobao/java/bin/java core.24086</span><br><span class="line">[New LWP 27184]</span><br><span class="line">[New LWP 27186]</span><br><span class="line">[New LWP 24086]</span><br><span class="line">[Thread debugging using libthread_db enabled]</span><br><span class="line">Using host libthread_db library &quot;/lib64/libthread_db.so.1&quot;.</span><br><span class="line">Core was generated by `/opt/tt/java_coroutine/bin/java&#x27;.</span><br><span class="line">#0  0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">Missing separate debuginfos, use: debuginfo-install jdk-8.9.14-20200203164153.alios7.x86_64</span><br><span class="line">(gdb) info threads  //查看所有thread</span><br><span class="line">  Id   Target Id         Frame</span><br><span class="line">  583  Thread 0x7f2fa56177c0 (LWP 24086) 0x00007f2fa4fab017 in pthread_join () from /lib64/libpthread.so.0</span><br><span class="line">  582  Thread 0x7f2f695f3700 (LWP 27186) 0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">  581  Thread 0x7f2f6cbfb700 (LWP 27184) 0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">  580  Thread 0x7f2f691ef700 (LWP 27176) 0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">  579  Thread 0x7f2f698f6700 (LWP 27174) 0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">(gdb) thread apply all bt  //查看所有线程堆栈</span><br><span class="line">Thread 583 (Thread 0x7f2fa56177c0 (LWP 24086)):</span><br><span class="line">#0  0x00007f2fa4fab017 in pthread_join () from /lib64/libpthread.so.0</span><br><span class="line">#1  0x00007f2fa4b85085 in ContinueInNewThread0 (continuation=continuation@entry=0x7f2fa4b7fd70 &lt;JavaMain&gt;, stack_size=1048576, args=args@entry=0x7ffe529432d0)</span><br><span class="line">    at /ssd1/jenkins_home/workspace/ajdk.8.build.master/jdk/src/solaris/bin/java_md_solinux.c:1044</span><br><span class="line">#2  0x00007f2fa4b81877 in ContinueInNewThread (ifn=ifn@entry=0x7ffe529433d0, threadStackSize=&lt;optimized out&gt;, argc=&lt;optimized out&gt;, argv=0x7f2fa3c163a8, mode=mode@entry=1,</span><br><span class="line">    what=what@entry=0x7ffe5294be17 &quot;com.taobao.tddl.server.TddlLauncher&quot;, ret=0) at /ssd1/jenkins_home/workspace/ajdk.8.build.master/jdk/src/share/bin/java.c:2033</span><br><span class="line">#3  0x00007f2fa4b8513b in JVMInit (ifn=ifn@entry=0x7ffe529433d0, threadStackSize=&lt;optimized out&gt;, argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;, mode=mode@entry=1,</span><br><span class="line">    what=what@entry=0x7ffe5294be17 &quot;com.taobao.tddl.server.TddlLauncher&quot;, ret=ret@entry=0) at /ssd1/jenkins_home/workspace/ajdk.8.build.master/jdk/src/solaris/bin/java_md_solinux.c:1091</span><br><span class="line">#4  0x00007f2fa4b8254d in JLI_Launch (argc=0, argv=0x7f2fa3c163a8, jargc=&lt;optimized out&gt;, jargv=&lt;optimized out&gt;, appclassc=1, appclassv=0x0, fullversion=0x400885 &quot;1.8.0_232-b604&quot;,</span><br><span class="line">    dotversion=0x400881 &quot;1.8&quot;, pname=0x40087c &quot;java&quot;, lname=0x40087c &quot;java&quot;, javaargs=0 &#x27;\000&#x27;, cpwildcard=1 &#x27;\001&#x27;, javaw=0 &#x27;\000&#x27;, ergo=0)</span><br><span class="line">    at /ssd1/jenkins_home/workspace/ajdk.8.build.master/jdk/src/share/bin/java.c:304</span><br><span class="line">#5  0x0000000000400635 in main ()</span><br><span class="line"></span><br><span class="line">Thread 582 (Thread 0x7f2f695f3700 (LWP 27186)):</span><br><span class="line">#0  0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">#1  0x00007f2fa342d863 in Parker::park(bool, long) () from /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">#2  0x00007f2fa35ba3c3 in Unsafe_Park () from /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">#3  0x00007f2f9343b44a in ?? ()</span><br><span class="line">#4  0x000000008082e778 in ?? ()</span><br><span class="line">#5  0x0000000000000003 in ?? ()</span><br><span class="line">#6  0x00007f2f88e32758 in ?? ()</span><br><span class="line">#7  0x00007f2f6f532800 in ?? ()</span><br><span class="line"></span><br><span class="line">(gdb) thread apply 582 bt //查看582这个线程堆栈，LWP 27186(0x6a32)对应jstack 线程10进程id</span><br><span class="line"></span><br><span class="line">Thread 582 (Thread 0x7f2f695f3700 (LWP 27186)):</span><br><span class="line">#0  0x00007f2fa4fada35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</span><br><span class="line">#1  0x00007f2fa342d863 in Parker::park(bool, long) () from /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">#2  0x00007f2fa35ba3c3 in Unsafe_Park () from /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">#3  0x00007f2f9343b44a in ?? ()</span><br><span class="line">#35 0x00000000f26fc738 in ?? ()</span><br><span class="line">#36 0x00007f2fa51cec5b in arena_run_split_remove (arena=0x7f2f6ab09c34, chunk=0x80, run_ind=0, flag_dirty=0, flag_decommitted=&lt;optimized out&gt;, need_pages=0) at src/arena.c:398</span><br><span class="line">#37 0x00007f2f695f2980 in ?? ()</span><br><span class="line">#38 0x0000000000000001 in ?? ()</span><br><span class="line">#39 0x00007f2f88e32758 in ?? ()</span><br><span class="line">#40 0x00007f2f695f2920 in ?? ()</span><br><span class="line">#41 0x00007f2fa32f46b8 in CallInfo::set_common(KlassHandle, KlassHandle, methodHandle, methodHandle, CallInfo::CallKind, int, Thread*) ()</span><br><span class="line">   from /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">#42 0x00007f2f7d800000 in ?? ()</span><br></pre></td></tr></table></figure>



<h3 id="coredump-转-jmap-hprof"><a href="#coredump-转-jmap-hprof" class="headerlink" title="coredump 转 jmap hprof"></a>coredump 转 jmap hprof</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -dump:format=b,file=24086.hprof /opt/taobao/java/bin/java core.24086</span><br></pre></td></tr></table></figure>

<p>以上命令输入是 core.24086 这个 coredump，输出是一个 jmap 的dump 24086.hprof</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$jmap -J-d64 /opt/taobao/java/bin/java core.24086</span><br><span class="line"></span><br><span class="line">Attaching to core core.24086 from executable /opt/taobao/java/bin/java, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.232-b604</span><br><span class="line">0x0000000000400000      8K      /opt/taobao/java/bin/java</span><br><span class="line">0x00007f2fa51be000      6679K   /opt/taobao/install/ajdk-8_9_14-b604/bin/../lib/amd64/libjemalloc.so.2</span><br><span class="line">0x00007f2fa4fa2000      138K    /lib64/libpthread.so.0</span><br><span class="line">0x00007f2fa4d8c000      88K     /lib64/libz.so.1</span><br><span class="line">0x00007f2fa4b7d000      280K    /opt/taobao/install/ajdk-8_9_14-b604/bin/../lib/amd64/jli/libjli.so</span><br><span class="line">0x00007f2fa4979000      18K     /lib64/libdl.so.2</span><br><span class="line">0x00007f2fa45ab000      2105K   /lib64/libc.so.6</span><br><span class="line">0x00007f2fa43a3000      42K     /lib64/librt.so.1</span><br><span class="line">0x00007f2fa40a1000      1110K   /lib64/libm.so.6</span><br><span class="line">0x00007f2fa5406000      159K    /lib64/ld-linux-x86-64.so.2</span><br><span class="line">0x00007f2fa2af1000      17898K  /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/server/libjvm.so</span><br><span class="line">0x00007f2fa25f1000      64K     /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libverify.so</span><br><span class="line">0x00007f2fa23c2000      228K    /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libjava.so</span><br><span class="line">0x00007f2fa21af000      60K     /lib64/libnss_files.so.2</span><br><span class="line">0x00007f2fa1fa5000      47K     /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libzip.so</span><br><span class="line">0x00007f2f80ded000      96K     /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libnio.so</span><br><span class="line">0x00007f2f80bd4000      119K    /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libnet.so</span><br><span class="line">0x00007f2f7e1f6000      50K     /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libmanagement.so</span><br><span class="line">0x00007f2f75dc8000      209K    /home/admin/drds-server/lib/native/libsigar-amd64-linux.so</span><br><span class="line">0x00007f2f6d8ad000      293K    /opt/taobao/install/ajdk-8_9_14-b604/jre/lib/amd64/libsunec.so</span><br><span class="line">0x00007f2f6d697000      86K     /lib64/libgcc_s.so.1</span><br><span class="line">0x00007f2f6bdf9000      30K     /lib64/libnss_dns.so.2</span><br><span class="line">0x00007f2f6bbdf000      107K    /lib64/libresolv.so.2</span><br></pre></td></tr></table></figure>

<h3 id="coredump-生成-java-stack"><a href="#coredump-生成-java-stack" class="headerlink" title="coredump 生成 java stack"></a><a target="_blank" rel="noopener" href="https://www.javacodegeeks.com/2013/02/analysing-a-java-core-dump.html">coredump 生成 java stack</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">jstack -J-d64 /opt/taobao/java/bin/java core.24086 </span><br><span class="line"></span><br><span class="line">Attaching to core core.24086 from executable /opt/taobao/java/bin/java, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.232-b604</span><br><span class="line">Deadlock Detection:</span><br><span class="line"></span><br><span class="line">No deadlocks found.</span><br><span class="line"></span><br><span class="line">Thread 27186: (state = BLOCKED)</span><br><span class="line"> - sun.misc.Unsafe.park0(boolean, long) @bci=0 (Compiled frame; information may be imprecise)</span><br><span class="line"> - sun.misc.Unsafe.park(boolean, long) @bci=63, line=1038 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=176 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await() @bci=42, line=2047 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.LinkedBlockingQueue.take() @bci=29, line=446 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.ThreadPoolExecutor.getTask() @bci=149, line=1074 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=26, line=1134 (Compiled frame)</span><br><span class="line"> - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=624 (Compiled frame)</span><br><span class="line"> - java.lang.Thread.run() @bci=11, line=858 (Compiled frame)</span><br></pre></td></tr></table></figure>

<h3 id="gdb-coredump-with-java-symbol"><a href="#gdb-coredump-with-java-symbol" class="headerlink" title="gdb coredump with java symbol"></a><a target="_blank" rel="noopener" href="https://mail.openjdk.org/pipermail/hotspot-dev/2016-May/023255.html">gdb coredump with java symbol</a></h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/01/02/Linux%20%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/02/Linux%20%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Linux 问题总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-01-02 17:30:03" itemprop="dateCreated datePublished" datetime="2020-01-02T17:30:03+08:00">2020-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Linux-问题总结"><a href="#Linux-问题总结" class="headerlink" title="Linux 问题总结"></a>Linux 问题总结</h1><h2 id="crond文件权限的坑"><a href="#crond文件权限的坑" class="headerlink" title="crond文件权限的坑"></a>crond文件权限的坑</h2><p>crond第一次加载的时候（刚启动）会去检查文件属性，不是644的话以后都不会执行了，即使后面chmod改成了644. </p>
<p>手工随便修改一下该文件的内容就能触发自动执行了，或者重启crond, 或者 sudo service crond reload， 或者 &#x2F;etc&#x2F;cron.d&#x2F;下有任何修改都会触发crond reload配置(包含 touch )。</p>
<p>总之 crond会每分钟去检查job有没有change，有的话才触发reload，这个change看的时候change time有没有变化，不看权限的变化，仅仅是权限的变化不会触发crond reload。</p>
<p> crond会每分钟去检查一下job有没有修改，有修改的话会reload，但是这个<strong>修改不包含权限的修改</strong>。可以简单地理解这个修改是指文件的change time。</p>
<h2 id="cgroup目录报No-space-left-on-device"><a href="#cgroup目录报No-space-left-on-device" class="headerlink" title="cgroup目录报No space left on device"></a><a target="_blank" rel="noopener" href="https://rotadev.com/cgroup-no-space-left-on-device-server-fault/">cgroup目录报No space left on device</a></h2><p>可能是因为某个规则下的 cpuset.cpus 文件是空导致的</p>
<h2 id="容器中root用户执行-su-admin-切换失败"><a href="#容器中root用户执行-su-admin-切换失败" class="headerlink" title="容器中root用户执行 su - admin 切换失败"></a>容器中root用户执行 su - admin 切换失败</h2><p>问题原因：<a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/30316">https://access.redhat.com/solutions/30316</a></p>
<p><img src="/images/oss/63a4ac6669f820156bff035e7dc49ac2.png" alt="image.png"></p>
<p>如上图去掉 admin nproc限制就可以了</p>
<p>这是因为root用户的nproc是unlimited，但是admin的是65535，所以切不过去</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@i22h08323 /home/admin]</span><br><span class="line">#ulimit -u</span><br><span class="line">unlimited</span><br></pre></td></tr></table></figure>

<h2 id="容器中ulimit限制了sudo的执行"><a href="#容器中ulimit限制了sudo的执行" class="headerlink" title="容器中ulimit限制了sudo的执行"></a>容器中ulimit限制了sudo的执行</h2><p>容器启动的时候默认nofile为65535（可以通过 docker run –ulimit nofile&#x3D;655360 来设置），如果容器中的 &#x2F;etc&#x2F;security&#x2F;limits.conf 中设置的nofile大于 65535就会报错，因为容器的1号进程就是65535了，比如在容器中用root用户执行sudo ls报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#sudo ls</span><br><span class="line">sudo: pam_open_session: Permission denied</span><br><span class="line">sudo: policy plugin failed session initialization</span><br></pre></td></tr></table></figure>

<p>可以修改容器中的 ulimit 不要超过默认的65535或者修改容器的启动参数来解决。</p>
<p>子进程都会继承父进程的一些环境变量，比如 limits.conf, sudo&#x2F;su&#x2F;crond&#x2F;passwd等都会触发重新加载limits, </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -rin pam_limit /etc/pam.d //可以看到触发重新加载的场景</span><br></pre></td></tr></table></figure>

<h2 id="systemd-limits"><a href="#systemd-limits" class="headerlink" title="systemd limits"></a>systemd limits</h2><p>&#x2F;etc&#x2F;security&#x2F;limits.conf 的配置，只适用于通过PAM 认证登录用户的资源限制，它对systemd 的service 的资源限制不生效。</p>
<p>因此登录用户的限制，通过&#x2F;etc&#x2F;security&#x2F;limits.conf 与&#x2F;etc&#x2F;security&#x2F;limits.d 下的文件设置即可。</p>
<p>对于systemd service 的资源设置，则需修改全局配置，全局配置文件放在&#x2F;etc&#x2F;systemd&#x2F;system.conf 和&#x2F;etc&#x2F;systemd&#x2F;user.conf，同时也会加载两个对应目录中的所有.conf 文件&#x2F;etc&#x2F;systemd&#x2F;system.conf.d&#x2F;.conf 和&#x2F;etc&#x2F;systemd&#x2F;user.conf.d&#x2F;.conf。</p>
<h2 id="open-files-限制在1024"><a href="#open-files-限制在1024" class="headerlink" title="open files 限制在1024"></a>open files 限制在1024</h2><p>docker 容器内 nofile只有1024，检查：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/sysconfig/docker</span><br><span class="line">或者</span><br><span class="line">cat /usr/lib/systemd/system/docker.service</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br></pre></td></tr></table></figure>

<h3 id="关于ulimit的一些知识点"><a href="#关于ulimit的一些知识点" class="headerlink" title="关于ulimit的一些知识点"></a>关于ulimit的一些知识点</h3><p>参考 <a target="_blank" rel="noopener" href="https://feichashao.com/ulimit_demo/">Ulimit</a> <a target="_blank" rel="noopener" href="http://blog.yufeng.info/archives/2568">http://blog.yufeng.info/archives/2568</a></p>
<ul>
<li>limit的设定值是 per-process 的</li>
<li>在 Linux 中，每个普通进程可以调用 getrlimit() 来查看自己的 limits，也可以调用 setrlimit() 来改变自身的 soft limits</li>
<li>要改变 hard limit, 则需要进程有 CAP_SYS_RESOURCE 权限</li>
<li>进程 fork() 出来的子进程，会继承父进程的 limits 设定</li>
<li><code>ulimit</code> 是 shell 的内置命令。在执行<code>ulimit</code>命令时，其实是 shell 自身调用 getrlimit()&#x2F;setrlimit() 来获取&#x2F;改变自身的 limits. 当我们在 shell 中执行应用程序时，相应的进程就会继承当前 shell 的 limits 设定</li>
<li>shell 的初始 limits 通常是 pam_limits 设定的。顾名思义，pam_limits 是一个 PAM 模块，用户登录后，pam_limits 会给用户的 shell 设定在 limits.conf 定义的值</li>
</ul>
<p>ulimit, limits.conf 和 pam_limits模块 的关系，大致是这样的：</p>
<ol>
<li>用户进行登录，触发 pam_limits;</li>
<li>pam_limits 读取 limits.conf，相应地设定用户所获得的 shell 的 limits；</li>
<li>用户在 shell 中，可以通过 ulimit 命令，查看或者修改当前 shell 的 limits;</li>
<li>当用户在 shell 中执行程序时，该程序进程会继承 shell 的 limits 值。于是，limits 在进程中生效了</li>
</ol>
<p>判断要分配的句柄号是不是超过了 limits.conf 中 nofile 的限制。fd 是当前进程相关的，是一个从 0 开始的整数<br>结论1：soft nofile 和 fs.nr_open的作用一样，它两都是限制的单个进程的最大文件数量。区别是 soft nofile 可以按用户来配置，而 fs.nr_open 所有用户只能配一个。注意 hard nofile 一定要比 fs.nr_open 要小，否则可能导致用户无法登陆。<br>结论2：fs.file-max: 整个系统上可打开的最大文件数，但不限制 root 用户</p>
<h2 id="pam-权限报错"><a href="#pam-权限报错" class="headerlink" title="pam 权限报错"></a>pam 权限报错</h2><p><img src="/images/oss/b646979272e71e015de4a47c62b89747.png" alt="image.png"></p>
<p>从debug信息看如果是pam权限报错的话，需要将 required 改成 sufficient</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$cat /etc/pam.d/crond </span><br><span class="line">#</span><br><span class="line"># The PAM configuration file for the cron daemon</span><br><span class="line">#</span><br><span class="line">#</span><br><span class="line"># No PAM authentication called, auth modules not needed</span><br><span class="line">account    required   pam_access.so</span><br><span class="line">account    include    system-auth</span><br><span class="line">session    required   pam_loginuid.so //required 改成 sufficient</span><br><span class="line">session    include    system-auth</span><br><span class="line">auth       include    system-auth</span><br></pre></td></tr></table></figure>

<p>PAM 提供四个安全领域的特性，但是应用程序不太可能同时需要所有这些方面。例如，<code>passwd</code> 命令只需要下面列表中的第三组：</p>
<ul>
<li><code>account</code> 处理账户限制。对于有效的用户，允许他做什么？</li>
<li><code>auth</code> 处理用户识别 — 例如，通过输入用户名和密码。</li>
<li><code>password</code> 只处理与密码相关的问题，比如设置新密码。</li>
<li><code>session</code> 处理连接管理，包括日志记录。</li>
</ul>
<p>在 &#x2F;etc&#x2F;pam.d 目录中为将使用 PAM 的每个应用程序创建一个配置文件，文件名与应用程序名相同。例如，<code>login</code> 命令的配置文件是 &#x2F;etc&#x2F;pam.d&#x2F;login。</p>
<p>必须定义将应用哪些模块，创建一个动作 “堆”。PAM 运行堆中的所有模块，根据它们的结果允许或拒绝用户的请求。还必须定义检查是否是必需的。最后，<em>other</em> 文件为没有特殊规则的所有应用程序提供默认规则。</p>
<ul>
<li><code>optional</code> 模块可以成功，也可以失败；PAM 根据模块是否最终成功返回 <code>success</code> 或 <code>failure</code>。</li>
<li><code>required</code> 模块必须成功。如果失败，PAM 返回 <code>failure</code>，但是会在运行堆中的其他模块之后返回。</li>
<li><code>requisite</code> 模块也必须成功。但是，如果失败，PAM 立即返回 <code>failure</code>，不再运行其他模块。</li>
<li><code>sufficient</code> 模块在成功时导致 PAM 立即返回 <code>success</code>，不再运行其他模块。</li>
</ul>
<p>当pam安装之后有两大部分：在&#x2F;lib64&#x2F;security目录下的各种pam模块以及&#x2F;etc&#x2F;pam.d和&#x2F;etc&#x2F;pam.d目录下的针对各种服务和应用已经定义好的pam配置文件。当某一个有认证需求的应用程序需要验证的时候，一般在应用程序中就会定义负责对其认证的PAM配置文件。以vsftpd为例，在它的配置文件&#x2F;etc&#x2F;vsftpd&#x2F;vsftpd.conf中就有这样一行定义：</p>
<blockquote>
<p>pam_service_name&#x3D;vsftpd</p>
</blockquote>
<p>表示登录FTP服务器的时候进行认证是根据&#x2F;etc&#x2F;pam.d&#x2F;vsftpd文件定义的内容进行。</p>
<h3 id="PAM-认证过程"><a href="#PAM-认证过程" class="headerlink" title="PAM 认证过程"></a>PAM 认证过程</h3><p>当程序需要认证的时候已经找到相关的pam配置文件，认证过程是如何进行的？下面我们将通过解读&#x2F;etc&#x2F;pam.d&#x2F;system-auth文件予以说明。</p>
<p>首先要声明一点的是：system-auth是一个非常重要的pam配置文件，主要负责用户登录系统的认证工作。而且该文件不仅仅只是负责用户登录系统认证，其它的程序和服务通过include接口也可以调用到它，从而节省了很多重新自定义配置的工作。所以应该说该文件是系统安全的总开关和核心的pam配置文件。</p>
<p>下面是&#x2F;etc&#x2F;pam.d&#x2F;system-auth文件的全部内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$cat /etc/pam.d/system-auth</span><br><span class="line">#%PAM-1.0</span><br><span class="line"># This file is auto-generated.</span><br><span class="line"># User changes will be destroyed the next time authconfig is run.</span><br><span class="line">auth        required      pam_env.so</span><br><span class="line">auth        required      pam_faildelay.so delay=2000000</span><br><span class="line">auth        sufficient    pam_unix.so nullok try_first_pass</span><br><span class="line">auth        requisite     pam_succeed_if.so uid &gt;= 1000 quiet_success</span><br><span class="line">auth        required      pam_deny.so</span><br><span class="line"></span><br><span class="line">account     required      pam_unix.so</span><br><span class="line">account     sufficient    pam_localuser.so</span><br><span class="line">account     sufficient    pam_succeed_if.so uid &lt; 1000 quiet</span><br><span class="line">account     required      pam_permit.so</span><br><span class="line"></span><br><span class="line">password    requisite     pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type=</span><br><span class="line">password    sufficient    pam_unix.so sha512 shadow nullok try_first_pass use_authtok</span><br><span class="line">password    required      pam_deny.so</span><br><span class="line"></span><br><span class="line">session     optional      pam_keyinit.so revoke</span><br><span class="line">session     required      pam_limits.so</span><br><span class="line">-session     optional      pam_systemd.so</span><br><span class="line">session     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid</span><br><span class="line">session     required      pam_unix.so</span><br></pre></td></tr></table></figure>

<h4 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h4><p>当用户登录的时候，首先会通过auth类接口对用户身份进行识别和密码认证。所以在该过程中验证会经过几个带auth的配置项。</p>
<p>其中的第一步是通过pam_env.so模块来定义用户登录之后的环境变量， pam_env.so允许设置和更改用户登录时候的环境变量，默认情况下，若没有特别指定配置文件，将依据&#x2F;etc&#x2F;security&#x2F;pam_env.conf进行用户登录之后环境变量的设置。</p>
<p>然后通过pam_unix.so模块来提示用户输入密码，并将用户密码与&#x2F;etc&#x2F;shadow中记录的密码信息进行对比，如果密码比对结果正确则允许用户登录，而且<strong>该配置项的使用的是“sufficient”控制位，即表示只要该配置项的验证通过，用户即可完全通过认证而不用再去走下面的认证项</strong>。不过在特殊情况下，用户允许使用空密码登录系统，例如当将某个用户在&#x2F;etc&#x2F;shadow中的密码字段删除之后，该用户可以只输入用户名直接登录系统。</p>
<p>下面的配置项中，通过pam_succeed_if.so对用户的登录条件做一些限制，表示允许uid大于500的用户在通过密码验证的情况下登录，在Linux系统中，一般系统用户的uid都在500之内，所以该项即表示允许使用useradd命令以及默认选项建立的普通用户直接由本地控制台登录系统。</p>
<p>最后通过pam_deny.so模块对所有不满足上述任意条件的登录请求直接拒绝，pam_deny.so是一个特殊的模块，该模块返回值永远为否，类似于大多数安全机制的配置准则，在所有认证规则走完之后，对不匹配任何规则的请求直接拒绝。</p>
<h4 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h4><p>三个配置项主要表示通过account账户类接口来识别账户的合法性以及登录权限。</p>
<p>第一行仍然使用pam_unix.so模块来声明用户需要通过密码认证。第二行承认了系统中uid小于500的系统用户的合法性。之后对所有类型的用户登录请求都开放控制台。</p>
<h4 id="第三部分"><a href="#第三部分" class="headerlink" title="第三部分"></a>第三部分</h4><p>会通过password口令类接口来确认用户使用的密码或者口令的合法性。第一行配置项表示需要的情况下将调用pam_cracklib来验证用户密码复杂度。如果用户输入密码不满足复杂度要求或者密码错，最多将在三次这种错误之后直接返回密码错误的提示，否则期间任何一次正确的密码验证都允许登录。需要指出的是，pam_cracklib.so是一个常用的控制密码复杂度的pam模块，关于其用法举例我们会在之后详细介绍。之后带pam_unix.so和pam_deny.so的两行配置项的意思与之前类似。都表示需要通过密码认证并对不符合上述任何配置项要求的登录请求直接予以拒绝。不过用户如果执行的操作是单纯的登录，则这部分配置是不起作用的。</p>
<h4 id="第四部分"><a href="#第四部分" class="headerlink" title="第四部分"></a>第四部分</h4><p>主要将通过session会话类接口为用户初始化会话连接。其中几个比较重要的地方包括，使用pam_keyinit.so表示当用户登录的时候为其建立相应的密钥环，并在用户登出的时候予以撤销。不过该行配置的控制位使用的是optional，表示这并非必要条件。之后通过pam_limits.so限制用户登录时的会话连接资源，相关pam_limit.so配置文件是&#x2F;etc&#x2F;security&#x2F;limits.conf，默认情况下对每个登录用户都没有限制。关于该模块的配置方法在后面也会详细介绍。</p>
<h3 id="常用的PAM模块介绍"><a href="#常用的PAM模块介绍" class="headerlink" title="常用的PAM模块介绍"></a>常用的PAM模块介绍</h3><table>
<thead>
<tr>
<th>PAM模块</th>
<th>结合管理类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>pam_unix.so</td>
<td>auth</td>
<td>提示用户输入密码,并与&#x2F;etc&#x2F;shadow文件相比对.匹配返回0</td>
</tr>
<tr>
<td>pam_unix.so</td>
<td>account</td>
<td>检查用户的账号信息(包括是否过期等).帐号可用时,返回0.</td>
</tr>
<tr>
<td>pam_unix.so</td>
<td>password</td>
<td>修改用户的密码. 将用户输入的密码,作为用户的新密码更新shadow文件</td>
</tr>
<tr>
<td>pam_shells.so</td>
<td>auth、account</td>
<td>如果用户想登录系统，那么它的shell必须是在&#x2F;etc&#x2F;shells文件中之一的shell</td>
</tr>
<tr>
<td>pam_deny.so</td>
<td>account、auth、password、session</td>
<td>该模块可用于拒绝访问</td>
</tr>
<tr>
<td>pam_permit.so</td>
<td>account、auth、password、session</td>
<td>模块任何时候都返回成功.</td>
</tr>
<tr>
<td>pam_securetty.so</td>
<td>auth</td>
<td>如果用户要以root登录时,则登录的tty必须在&#x2F;etc&#x2F;securetty之中.</td>
</tr>
<tr>
<td>pam_listfile.so</td>
<td>account、auth、password、session</td>
<td>访问应用程的控制开关</td>
</tr>
<tr>
<td>pam_cracklib.so</td>
<td>password</td>
<td>这个模块可以插入到一个程序的密码栈中,用于检查密码的强度.</td>
</tr>
<tr>
<td>pam_limits.so</td>
<td>session</td>
<td>定义使用系统资源的上限，root用户也会受此限制，可以通过&#x2F;etc&#x2F;security&#x2F;limits.conf或&#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;*.conf来设定</td>
</tr>
</tbody></table>
<h2 id="debug-crond"><a href="#debug-crond" class="headerlink" title="debug crond"></a>debug crond</h2><p>先停掉 crond service，然后开启debug参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop crond</span><br><span class="line">crond -x proc //不想真正执行的话：test</span><br></pre></td></tr></table></figure>

<p>或者增加更多的debug信息， debug sudo&#x2F;sudoers , 在 &#x2F;etc&#x2F;sudo.conf 中增加了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Debug sudo /var/log/sudo_debug all@warn</span><br><span class="line">Debug sudoers.so /var/log/sudoers_debug all@debug</span><br></pre></td></tr></table></figure>

<h2 id="crond-ERROR-getpwnam-failed"><a href="#crond-ERROR-getpwnam-failed" class="headerlink" title="crond ERROR (getpwnam() failed)"></a>crond ERROR (getpwnam() failed)</h2><p><a target="_blank" rel="noopener" href="https://www.ibm.com/support/pages/cron-job-fails-error-message-getpwnam-failed-no-such-file-or-directory">报错信息</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crond[246590]: (/usr/bin/ssh) ERROR (getpwnam() failed)</span><br></pre></td></tr></table></figure>

<p>要特别注意crond格式是 时间  <strong>用户</strong>  命令</p>
<p>有时候我们可以省略用户，但是在 <strong>&#x2F;etc&#x2F;cron.d&#x2F;</strong> 中省略用户后报错如上</p>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p>把进程看做是资源分配的单位，把线程才看成一个具体的执行实体。</p>
<h2 id="deleted-文件"><a href="#deleted-文件" class="headerlink" title="deleted 文件"></a>deleted 文件</h2><p><code>lsof +L1</code> 或者<code> lsof | grep delete</code> 发现有被删除的文件，且占用大量磁盘空间</p>
<p>更多 lsof 用法：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzAwNTM5Njk3Mw==&mid=2247518966&idx=1&sn=6ebf794b9743abb04c9ed20d30c90746">https://mp.weixin.qq.com/s?__biz=MzAwNTM5Njk3Mw==&amp;mid=2247518966&amp;idx=1&amp;sn=6ebf794b9743abb04c9ed20d30c90746</a></p>
<p>lsof &#x2F;path&#x2F;file 列出打开文件的进程，也可以是路径，还可以通过参数 “+D” 来递归路径 </p>
<p>清理：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">先通过 lsof +L1 找到 deleted 文件以及 pid</span><br><span class="line">cd /proc/&#123;上一步的 pid&#125;/fd</span><br><span class="line">ll # 在列出的文件名中找到 lsof +L1 看到的文件名，记录对应的 fd 值</span><br><span class="line">cat /dev/null &gt; &#123;上一步找到的 fd &#125;</span><br></pre></td></tr></table></figure>



<h2 id="No-route-to-host"><a href="#No-route-to-host" class="headerlink" title="No route to host"></a>No route to host</h2><p>如果ping ip能通,但是curl&#x2F;telnet 访问 ip+port 报not route to host 错误,这肯定不是route问题(因为ping能通), 一般都是目标机器防火墙的问题</p>
<p>可以停掉防火墙验证,或者添加端口到防火墙:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#firewall-cmd --permanent --add-port=8090/tcp</span><br><span class="line">success</span><br><span class="line">#firewall-cmd --reload</span><br></pre></td></tr></table></figure>

<h2 id="强制重启系统"><a href="#强制重启系统" class="headerlink" title="强制重启系统"></a>强制重启系统</h2><p><img src="/images/oss/ee2e438907fa72c70d5393a651dc9113.png" alt="image.png"></p>
<h2 id="hostname"><a href="#hostname" class="headerlink" title="hostname"></a>hostname</h2><p>hostname -i 是根据机器的hostname去解析ip，如果 &#x2F;etc&#x2F;hosts里面没有指定hostname对应的ip就会走dns 流程然后libnss_myhostname 返回所有ip</p>
<p>getHostName获取的机器名如果对应的ip不是127.0.0.1，那么就用这个ip，否则就需要通过getHostByName获取所有网卡选择一个</p>
<h2 id="tsar-Floating-point-execption"><a href="#tsar-Floating-point-execption" class="headerlink" title="tsar Floating point execption"></a>tsar Floating point execption</h2><p><img src="/images/oss/72197d600425656ec9a8ed18bcc5853b.png" alt="image.png"></p>
<p>因为 &#x2F;etc&#x2F;localtime 是deleted状态</p>
<h2 id="奇怪的文件大小-sparse-file"><a href="#奇怪的文件大小-sparse-file" class="headerlink" title="奇怪的文件大小 sparse file"></a>奇怪的文件大小 <a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/259932/strange-discrepancy-of-file-sizes-from-ls">sparse file</a></h2><p><img src="/images/oss/720f618d-2911-4bfd-a63e-33399532b6e5.png" alt="img"></p>
<p>如上图 gc.log 实际为5.6M，但是通过 ls -lh 就变成74G了，但实际上总文件夹才63M。因为写文件的时候lseek了74G的地方写入5.6M的内容就看到是这个样子了，而前面lseek的74G是不需要从磁盘上分配出来的.</p>
<p><a target="_blank" rel="noopener" href="https://www.lisenet.com/2014/so-what-is-the-size-of-that-file/">而 ls -s 中的 -s就是只看实际大小</a></p>
<p><img src="/images/oss/19b5f6cc-6fc4-4ad6-854c-6164705d343a.png" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://www.systutorials.com/handling-sparse-files-on-linux/">图片来源</a></p>
<p><a target="_blank" rel="noopener" href="https://www.mankier.com/1/fallocate">回收文件中的空洞</a>：sudo fallocate -c –length 70G gc.log</p>
<p>如果文件一直打开写入中是没法回收的，因为一回收又被重新lseek到之前的末尾重新写入了！</p>
<h2 id="增加dmesg-buffer"><a href="#增加dmesg-buffer" class="headerlink" title="增加dmesg buffer"></a>增加dmesg buffer</h2><p>If dmesg does not show any information about NUMA, then increase the Ring Buffer size:<br>Boot with ‘log_buf_len&#x3D;16M’ (or some other big value). Refer the following kbase article <a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/47276">How do I increase the kernel log ring buffer size?</a> for steps on how to increase the ring buffer</p>
<h2 id="yum-源问题处理"><a href="#yum-源问题处理" class="headerlink" title="yum 源问题处理"></a>yum 源问题处理</h2><p><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/641093">Yum commands error “pycurl.so: undefined symbol”</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># yum check update</span><br><span class="line">There was a problem importing one of the Python modules</span><br><span class="line">required to run yum. The error leading to this problem was:</span><br><span class="line"></span><br><span class="line">/usr/lib64/python2.6/site-packages/pycurl.so: undefined symbol: CRYPTO_set_locking_callback</span><br><span class="line"></span><br><span class="line">Please install a package which provides this module, or</span><br><span class="line">verify that the module is installed correctly.</span><br><span class="line"></span><br><span class="line">It&#x27;s possible that the above module doesn&#x27;t match the</span><br><span class="line">current version of Python, which is:</span><br><span class="line">2.6.6 (r266:84292, Sep  4 2013, 07:46:00)</span><br><span class="line">[GCC 4.4.7 20120313 (Red Hat 4.4.7-3)]</span><br><span class="line"></span><br><span class="line">If you cannot solve this problem yourself, please go to</span><br><span class="line">the yum faq at:</span><br><span class="line">http://yum.baseurl.org/wiki/Faq</span><br></pre></td></tr></table></figure>

<ul>
<li>Check and fix the related library paths or remove 3rd party libraries, usually <code>libcurl</code> or <code>libssh2</code>. On a x86_64 system, the standard paths for those libraries are <code>/usr/lib64/libcurl.so.4</code> and <code>/usr/lib64/libssh2.so.1</code></li>
</ul>
<h2 id="软中断、系统调用和上下文切换"><a href="#软中断、系统调用和上下文切换" class="headerlink" title="软中断、系统调用和上下文切换"></a>软中断、系统调用和上下文切换</h2><p>“你可以把内核看做是不断对请求进行响应的服务器，这些请求可能来自在CPU上执行的进程，也可能来自发出中断的外部设备。老板的请求相当于中断，而顾客的请求相当于用户态进程发出的系统调用”。</p>
<p>软中断和系统调用一样，都是CPU停止掉当前用户态上下文，保存工作现场，然后陷入到内核态继续工作。二者的唯一区别是系统调用是切换到同进程的内核态上下文，而软中断是则是切换到了另外一个内核进程ksoftirqd上。</p>
<blockquote>
<p>系统调用开销是200ns起步</p>
<p>从实验数据来看，一次软中断CPU开销大约3.4us左右</p>
<p>实验结果显示进程上下文切换平均耗时 3.5us，lmbench工具显示的进程上下文切换耗时从2.7us到5.48之间</p>
<p>大约每次线程切换开销大约是3.8us左右。<strong>从上下文切换的耗时上来看，Linux线程（轻量级进程）其实和进程差别不太大</strong>。</p>
</blockquote>
<p>软中断和进程上下文切换比较起来，进程上下文切换是从用户进程A切换到了用户进程B。而软中断切换是从用户进程A切换到了内核线程ksoftirqd上。而ksoftirqd作为一个内核控制路径，其处理程序比一个用户进程要轻量，所以上下文切换开销相对比进程切换要少一些（实际数据基本差不多）。</p>
<p>系统调用只是在进程内将用户态切换到内核态，然后再切回来，而上下文切换可是直接从进程A切换到了进程B。显然这个上下文切换需要完成的工作量更大。</p>
<h3 id="软中断开销计算"><a href="#软中断开销计算" class="headerlink" title="软中断开销计算"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247483827&idx=3&sn=8b897c8d6d3038ea79bd156a0e88db10&scene=21#wechat_redirect">软中断开销计算</a></h3><ul>
<li><strong>查看软中断总耗时</strong>， 首先用top命令可以看出每个核上软中断的开销占比，是在si列（1.2%–1秒[1000ms]中的1.2%）</li>
<li><strong>查看软中断次数</strong>，再用vmstat命令可以看到软中断的次数（in列 56000）</li>
<li><strong>计算每次软中断的耗时</strong>，该机器是16核的物理实机，故可以得出每个软中断需要的CPU时间是&#x3D;12ms&#x2F;(56000&#x2F;16)次&#x3D;3.428us。从实验数据来看，一次软中断CPU开销大约3.4us左右</li>
</ul>
<h2 id="Linux-启动进入紧急模式"><a href="#Linux-启动进入紧急模式" class="headerlink" title="Linux 启动进入紧急模式"></a>Linux 启动进入紧急模式</h2><p>可能是因为磁盘挂载不上，检查 &#x2F;etc&#x2F;fstab 中需要挂载的磁盘，尝试 mount -a 是否能全部挂载，麒麟下容易出现弄丢磁盘的标签和uuid</p>
<p>否则的话debug为啥，比如检查设备标签（e2label）是否冲突之类的</p>
<h2 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/401910162">https://zhuanlan.zhihu.com/p/401910162</a></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PROCESS STATE CODES</span><br><span class="line">  Here are the different values that the s, stat and state output specifiers(header &quot;STAT&quot; or &quot;S&quot;) will display to describe the state of a process:</span><br><span class="line"> </span><br><span class="line">    D    uninterruptible sleep (usually IO)  #不可中断睡眠 不接受任何信号，因此kill对它无效，一般是磁盘io,网络io读写时出现</span><br><span class="line">    R    running or runnable (on run queue)  #可运行状态或者运行中，可运行状态表明进程所需要的资源准备就绪，待内核调度</span><br><span class="line">    S    interruptible sleep (waiting for an event to complete) #可中断睡眠，等待某事件到来而进入睡眠状态</span><br><span class="line">    T    stopped by job control signal #进程暂停状态 平常按下的ctrl+z,实际上是给进程发了SIGTSTP 信号 （kill -l可查看系统所有的信号量）</span><br><span class="line">    t    stopped by debugger during the tracing #进程被ltrace、strace attach后就是这种状态</span><br><span class="line">    W    paging (not valid since the 2.6.xx kernel) #没有用了</span><br><span class="line">    X    dead (should never be seen) #进程退出时的状态</span><br><span class="line">    Z    defunct (&quot;zombie&quot;) process, terminated but not reaped by its parent #进程退出后父进程没有正常回收，俗称僵尸进程</span><br></pre></td></tr></table></figure>

<h3 id="D状态的进程"><a href="#D状态的进程" class="headerlink" title="D状态的进程"></a><a target="_blank" rel="noopener" href="https://gohalo.me/post/linux-kernel-hang-task-panic-introduce.html">D状态的进程</a></h3><blockquote>
<p> Process D是指进程处于不可中断状态。即uninterruptible sleep，通常我们比较常遇到的就是进程自旋等到进入竞争区等，刷脏页，进程同步等</p>
<p>D： Disk sleep（task_uninterruptible)–比如，磁盘满，导致进程D，无法kill</p>
</blockquote>
<p>相关设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt;  /proc/sys/kernel/hung_task_panic  </span><br><span class="line"></span><br><span class="line">----- 处于D状态的超时时间，默认是120s</span><br><span class="line">$ cat /proc/sys/kernel/hung_task_timeout_secs</span><br><span class="line"></span><br><span class="line">----- 发现hung task之后是否触发panic操作</span><br><span class="line">$ cat /proc/sys/kernel/hung_task_panic</span><br><span class="line"></span><br><span class="line">----- 每次检查的进程数</span><br><span class="line">$ cat /proc/sys/kernel/hung_task_check_count</span><br><span class="line"></span><br><span class="line">----- 为了防止日志被刷爆，设置最多的打印次数</span><br><span class="line">$ cat /proc/sys/kernel/hung_task_warnings</span><br></pre></td></tr></table></figure>

<p>这个参数可以用来处理 D 状态进程 </p>
<p>内核在 3.10.0 版本之后提供了 hung task 机制，用来检测系统中长期处于 D 状体的进程，如果存在，则打印相关警告和进程堆栈。</p>
<p>如果配置了 <code>hung_task_panic</code> ，则会直接发起 panic 操作，然后结合 kdump 可以搜集到相关的 vmcore 文件，用于定位分析。</p>
<p>其基本原理也很简单，系统启动时会创建一个内核线程 <code>khungtaskd</code>，定期遍历系统中的所有进程，检查是否存在处于 D 状态且超过 120s 的进程，如果存在，则打印相关警告和进程堆栈，并根据参数配置决定是否发起 panic 操作。</p>
<p>查看D进程出现的原因：</p>
<p><img src="/images/951413iMgBlog/image-20230814112500971.png" alt="image-20230814112500971"></p>
<p>这个堆栈能看到进程在哪里 D 住了，但不一定是根本原因，有可能是被动进入 D 状态的</p>
<p><img src="/images/951413iMgBlog/image-20230814112742429.png" alt="image-20230814112742429"></p>
<h3 id="T-状态进程"><a href="#T-状态进程" class="headerlink" title="T 状态进程"></a>T 状态进程</h3><p>kill -CONT pid 来恢复</p>
<p>jmap -heap&#x2F;histo和大家使用-F参数是一样的，底层都是通过serviceability agent来实现的，并不是jvm attach的方式，通过sa连上去之后会挂起进程，在serviceability agent里存在bug可能<strong>导致detach的动作不会被执行</strong>，从而会让进程一直挂着，可以通过top命令验证进程是否处于T状态，如果是说明进程被挂起了，如果进程被挂起了，可以通过kill -CONT [pid]来恢复。</p>
<h2 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h2><p>『你所规划的路由必须要是你的网卡 (如 eth0) 或 IP 可以直接沟通 (broadcast) 的情况』才行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$sudo route add -net 11.164.191.0  gw 11.164.191.247 netmask 255.255.255.0 bond0</span><br><span class="line">SIOCDELRT: No such process // 从bond0没法广播到 11.164.191.247</span><br><span class="line"></span><br><span class="line">$sudo route add -net 11.164.191.0  gw 100.81.183.247 netmask 255.255.255.0 bond0.700</span><br><span class="line">SIOCADDRT: Network is unreachable //从bond0.700 没法广播到 100.81.183.247，实际目前从bond0.700没法广播到任何地方</span><br><span class="line"></span><br><span class="line">$sudo route add** **11.164.191.247** **dev** **bond0.700</span><br><span class="line"></span><br><span class="line">$sudo route add -net 11.164.191.0  **gw 100.81.183.247** netmask 255.255.255.0 bond0.700</span><br><span class="line">SIOCADDRT: Network is unreachable  //从bond0.700 没法广播到 100.81.183.247</span><br><span class="line"></span><br><span class="line">$sudo route add -net 11.164.191.0  gw 11.164.191.247 netmask 255.255.255.0 bond0</span><br><span class="line">SIOCADDRT: Network is unreachable//从bond0没法广播到 11.164.191.247但是从bond0.700可以</span><br><span class="line"></span><br><span class="line">$sudo route add -net 11.164.191.0  **gw 11.164.191.247** netmask 255.255.255.0 bond0.700</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://serverfault.com/questions/581159/unable-to-add-a-static-route-sioaddrt-network-is-unreachable">https://serverfault.com/questions/581159/unable-to-add-a-static-route-sioaddrt-network-is-unreachable</a></p>
<h2 id="linux-2-6-32内核高精度定时器带来的cpu-sy暴涨的“问题”"><a href="#linux-2-6-32内核高精度定时器带来的cpu-sy暴涨的“问题”" class="headerlink" title="linux 2.6.32内核高精度定时器带来的cpu sy暴涨的“问题”"></a>linux 2.6.32内核高精度定时器带来的cpu sy暴涨的“问题”</h2><p>在 2.6.32 以前的内核里，即使你在java里写queue.await(1ns)之类的代码，其实都是需要1ms左右才会执行的，但.32以后则可以支持ns级的调度，对于实时性要求非常非常高的性能而言，这本来是个好特性。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/timer_list | grep .resolution</span><br></pre></td></tr></table></figure>

<p>可以通过在 &#x2F;boot&#x2F;grub2&#x2F;grub.cfg 中相应的kernel行的最后增加highres&#x3D;off nohz&#x3D;off来关闭高精度（不建议这样做，最好还是程序本身做相应的修改）</p>
<h2 id="后台执行"><a href="#后台执行" class="headerlink" title="后台执行"></a>后台执行</h2><p>将任务放到后台，断开ssh后还能运行：</p>
<ol>
<li>“ctrl-Z”将当前任务挂起；</li>
<li>“disown -h”让该任务忽略 SIGHUP 信号（不会因为掉线而终止执行）；</li>
<li>“bg”让该任务在后台恢复运行。</li>
</ol>
<h2 id="Linux-进程调度"><a href="#Linux-进程调度" class="headerlink" title="Linux 进程调度"></a>Linux 进程调度</h2><p>Linux的进程调度有一个不太为人熟知的特性，叫做<strong>wakeup affinity</strong>，它的初衷是这样的：如果两个进程频繁互动，那么它们很有可能共享同样的数据，把它们放到亲缘性更近的scheduling domain有助于提高缓存和内存的访问性能，所以当一个进程唤醒另一个的时候，被唤醒的进程可能会被放到相同的CPU core或者相同的NUMA节点上。</p>
<p>这个特性缺省是打开的，它有时候很有用，但有时候却对性能有伤害作用。设想这样一个应用场景：一个主进程给成百上千个辅进程派发任务，这成百上千个辅进程被唤醒后被安排到与主进程相同的CPU core或者NUMA节点上，就会导致负载严重失衡，CPU忙的忙死、闲的闲死，造成性能下降。<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/DG1v8cUjcXpa0x2uvrRytA">https://mp.weixin.qq.com/s/DG1v8cUjcXpa0x2uvrRytA</a></p>
<h2 id="tty"><a href="#tty" class="headerlink" title="tty"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/liqiuhao/p/9031803.html">tty</a></h2><p>tty（teletype–最早的一种终端设备，远程打字机） stty 设置tty的相关参数</p>
<p>tty都在 &#x2F;dev 下，通过 ps -ax 可以看到进程的tty；通过tty 可以看到本次的终端</p>
<p>&#x2F;dev&#x2F;pty（Pseudo Terminal） 伪终端</p>
<p>&#x2F;dev&#x2F;tty 控制终端</p>
<p>远古时代tty是物理形态的存在</p>
<p><img src="/images/951413iMgBlog/v2-7aa6997d017d876543671e4113048a62_1440w.jpg" alt="img"></p>
<p>PC时代，物理上的terminal已经没有了（用虚拟的伪终端代替，pseudo tty, 简称pty），相对kernel增加了shell，这是terminal和shell容易混淆，他们的含义</p>
<p><img src="/images/951413iMgBlog/v2-63cdd117f1026c2bbf455920b29c4454_1440w.jpg" alt="img"></p>
<p>实际像如下图的工作协作:</p>
<p><img src="/images/951413iMgBlog/case3.png" alt="Diagram"></p>
<h2 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a><a target="_blank" rel="noopener" href="https://wangdoc.com/ssh/rsync.html">rsync</a></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将本地yum备份到150上的/data/yum/ 下</span><br><span class="line">rsync -arv ./yum/ root@11.167.60.150:/data/yum/</span><br><span class="line"></span><br><span class="line">走ssh的8022端口把目录备份到本地</span><br><span class="line">rsync -e &#x27;ssh -p 8022&#x27; -arv gcsql@10.2.3.4:/home/gcsql/doc/ ./</span><br><span class="line"></span><br><span class="line">rsync -arv -e &quot;ssh -i /home/admin/.ssh/id_dsa.per  &quot; root@1.1.20.24:/home/xijun.rxj/ /home/admin/bak/</span><br></pre></td></tr></table></figure>

<p><code>-a</code>、<code>--archive</code>参数表示存档模式，保存所有的元数据，比如修改时间（modification time）、权限、所有者等，并且软链接也会同步过去。</p>
<p><code>--delete</code>参数删除只存在于目标目录、不存在于源目标的文件，即保证目标目录是源目标的镜像。</p>
<p><code>-i</code>参数表示输出源目录与目标目录之间文件差异的详细情况。</p>
<p><code>--link-dest</code>参数指定增量备份的基准目录。</p>
<p><code>-n</code>参数或<code>--dry-run</code>参数模拟将要执行的操作，而并不真的执行。配合<code>-v</code>参数使用，可以看到哪些内容会被同步过去。</p>
<p><code>--partial</code>参数允许恢复中断的传输。不使用该参数时，<code>rsync</code>会删除传输到一半被打断的文件；使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。一般需要与<code>--append</code>或<code>--append-verify</code>配合使用。</p>
<p><code>--progress</code>参数表示显示进展。</p>
<p><code>-r</code>参数表示递归，即包含子目录。</p>
<p><code>-v</code>参数表示输出细节。<code>-vv</code>表示输出更详细的信息，<code>-vvv</code>表示输出最详细的信息。</p>
<h2 id="Shebang"><a href="#Shebang" class="headerlink" title="Shebang"></a>Shebang</h2><p>Shebang 的东西 <code>#!/bin/bash</code></p>
<p>对 Shebang 的处理是内核在进行。当内核加载一个文件时，会首先读取文件的前 128 个字节，根据这 128 个字节判断文件的类型，然后调用相应的加载器来加载。</p>
<h3 id="ELF（Executable-and-Linkable-Format）"><a href="#ELF（Executable-and-Linkable-Format）" class="headerlink" title="ELF（Executable and Linkable Format）"></a>ELF（Executable and Linkable Format）</h3><p>对应windows下的exe</p>
<h2 id="修改启动参数"><a href="#修改启动参数" class="headerlink" title="修改启动参数"></a>修改启动参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$cat change_kernel_parameter.sh </span><br><span class="line">#cat /sys/devices/system/cpu/vulnerabilities/*</span><br><span class="line">#grep &#x27;&#x27; /sys/devices/system/cpu/vulnerabilities/*</span><br><span class="line">#https://help.aliyun.com/document_detail/102087.html?spm=a2c4g.11186623.6.721.4a732223pEfyNC</span><br><span class="line"></span><br><span class="line">#cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">#transparent_hugepage=always</span><br><span class="line">#noibrs noibpb nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off mitigations=off</span><br><span class="line">#追加nopti nospectre_v2到内核启动参数中</span><br><span class="line">sudo sed -i &#x27;s/\(GRUB_CMDLINE_LINUX=&quot;.*\)&quot;/\1 nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off mitigations=off transparent_hugepage=always&quot;/&#x27; /etc/default/grub</span><br><span class="line"></span><br><span class="line">//从修改的 /etc/default/grub 生成 /boot/grub2/grub.cfg 配置</span><br><span class="line">sudo grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line"></span><br><span class="line">#limit the journald log to 500M</span><br><span class="line">sed -i &#x27;s/^#SystemMaxUse=$/SystemMaxUse=500M/g&#x27; /etc/systemd/journald.conf</span><br><span class="line">#重启系统</span><br><span class="line">#sudo reboot</span><br><span class="line"></span><br><span class="line">## 选择不同的kernel启动</span><br><span class="line">#sudo grep &quot;menuentry &quot; /boot/grub2/grub.cfg | grep -n menu</span><br><span class="line">##grub认的index从0开始数的</span><br><span class="line">#sudo grub2-reboot 0; sudo reboot</span><br><span class="line"></span><br><span class="line">$cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">always [madvise] never</span><br></pre></td></tr></table></figure>

<h2 id="制作启动盘"><a href="#制作启动盘" class="headerlink" title="制作启动盘"></a>制作启动盘</h2><p>Windows 上用 UltraISO 烧制，Mac 上就比较简单了，直接用 dd 就可以搞</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ diskutil list</span><br><span class="line">/dev/disk6 (external, physical):</span><br><span class="line">   #:                       TYPE NAME                    SIZE       IDENTIFIER</span><br><span class="line">   0:                                                   *31.5 GB    disk6</span><br><span class="line">                        </span><br><span class="line"># 找到 U 盘的那个设备，umount</span><br><span class="line">$ diskutil unmountDisk /dev/disk3</span><br><span class="line"></span><br><span class="line"># 用 dd 把 ISO 文件写进设备，注意这里是 rdisk3 而不是 disk3，在 BSD 中 r(IDENTIFIER)</span><br><span class="line"># 代表了 raw device，会快很多</span><br><span class="line">$ sudo dd if=/path/image.iso of=/dev/rdisk3 bs=1m</span><br><span class="line"></span><br><span class="line"># 弹出 U 盘</span><br><span class="line">$ sudo diskutil eject /dev/disk3</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://linuxiac.com/how-to-create-bootable-usb-drive-using-dd-command/">Linux 下制作步骤</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">umount /dev/sdn1</span><br><span class="line">sudo mkfs.vfat /dev/sdn1</span><br><span class="line">dd if=/polarx/uniontechos-server-20-1040d-amd64.iso of=/dev/sdn1 status=progress</span><br></pre></td></tr></table></figure>

<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>为保证服务性能应选用 performance 模式，将 CPU 频率固定工作在其支持的最高运行频率上，不进行动态调节，操作命令为 <code>cpupower frequency-set --governor performance</code>。</p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul>
<li>dmesg | tail</li>
<li>vmstat 1</li>
<li>mpstat -P ALL 1</li>
<li>pidstat 1</li>
<li>iostat -xz 1</li>
<li>free -m</li>
<li>sar -n DEV 1</li>
<li>sar -n TCP,ETCP 1</li>
</ul>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">//检查sda磁盘中哪个应用程序占用的io比较高</span><br><span class="line">pidstat -d  1</span><br><span class="line"></span><br><span class="line">//分析应用程序中哪一个线程占用的io比较高</span><br><span class="line">pidstat -dt -p 73739 1  执行两三秒即可,得到74770线程io高</span><br><span class="line"></span><br><span class="line">//分析74770这个线程在干什么</span><br><span class="line">perf trace -t 74770 -o /tmp/tmp_aa.pstrace</span><br><span class="line">cat /tmp/tmp_aa.pstrace</span><br><span class="line">  2850.656 ( 1.915 ms): futex(uaddr: 0x653ae9c4, op: WAIT|PRIVATE_FLAG, val: 1)               = 0</span><br><span class="line">  2852.572 ( 0.001 ms): futex(uaddr: 0x653ae990, op: WAKE|PRIVATE_FLAG, val: 1)               = 0</span><br><span class="line">  2852.601 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f68)             = 0</span><br><span class="line">  2852.690 ( 0.040 ms): write(fd: 159, buf: 0xd7a30020, count: 65536)                         = 65536</span><br><span class="line">  2852.796 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f68)             = 0</span><br><span class="line">  2852.798 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f58)             = 0</span><br><span class="line">  2852.939 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f38)             = 0</span><br><span class="line">  2852.950 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f68)             = 0</span><br><span class="line">  2852.977 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f68)             = 0</span><br><span class="line">  2853.029 ( 0.035 ms): write(fd: 64, buf: 0xcd51e020, count: 65536)                          = 65536</span><br><span class="line">  2853.164 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f68)             = 0</span><br><span class="line">  2853.167 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f58)             = 0</span><br><span class="line">  2853.302 ( 0.001 ms): clock_gettime(which_clock: MONOTONIC, tp: 0xfff7bd470f38)             = 0</span><br></pre></td></tr></table></figure>

<h3 id="内存——虚拟内存参数"><a href="#内存——虚拟内存参数" class="headerlink" title="内存——虚拟内存参数"></a>内存——虚拟内存参数</h3><ul>
<li><code>dirty_ratio</code> 百分比值。当脏的 page cache 总量达到系统内存总量的这一百分比后，系统将开始使用 pdflush 操作将脏的 page cache 写入磁盘。默认值为 20％，通常不需调整。对于高性能 SSD，比如 NVMe 设备来说，降低其值有利于提高内存回收时的效率。</li>
<li><code>dirty_background_ratio</code> 百分比值。当脏的 page cache 总量达到系统内存总量的这一百分比后，系统开始在后台将脏的 page cache 写入磁盘。默认值为 10％，通常不需调整。对于高性能 SSD，比如 NVMe 设备来说，设置较低的值有利于提高内存回收时的效率。</li>
</ul>
<h3 id="I-O-调度器"><a href="#I-O-调度器" class="headerlink" title="I&#x2F;O 调度器"></a>I&#x2F;O 调度器</h3><p>I&#x2F;O 调度程序确定 I&#x2F;O 操作何时在存储设备上运行以及持续多长时间。也称为 I&#x2F;O 升降机。对于 SSD 设备，宜设置为 noop。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> noop &gt; /sys/block/<span class="variable">$&#123;SSD_DEV_NAME&#125;</span>/queue/scheduler</span><br></pre></td></tr></table></figure>

<h3 id="磁盘挂载参数"><a href="#磁盘挂载参数" class="headerlink" title="磁盘挂载参数"></a>磁盘挂载参数</h3><p><code>noatime</code> 读取文件时，将禁用对元数据的更新。它还启用了 nodiratime 行为，该行为会在读取目录时禁用对元数据的更新。</p>
<h2 id="Unix-Linux关系"><a href="#Unix-Linux关系" class="headerlink" title="Unix Linux关系"></a>Unix Linux关系</h2><p><img src="/images/951413iMgBlog/image-20211210085124387.png" alt="image-20211210085124387"></p>
<p><img src="/images/951413iMgBlog/G2Xri.png" alt="img"></p>
<h3 id="linux-发行版关系"><a href="#linux-发行版关系" class="headerlink" title="linux 发行版关系"></a><a target="_blank" rel="noopener" href="https://blog.51cto.com/wangyafei/1881605">linux 发行版关系</a></h3><p><img src="/images/951413iMgBlog/5cc164f5d79a11261.jpg_fo742.jpg" alt="细数各家linux之间的区别_软件应用_什么值得买"></p>
<p>Fedora：基于Red Hat Linux，在Red Hat Linux终止发行后，红帽公司计划以Fedora来取代Red Hat Linux在个人领域的应用，而另外发行的Red Hat Enterprise Linux取代Red Hat Linux在商业应用的领域。Fedora的功能对于用户而言，它是一套功能完备、更新快速的免费操作系统，而对赞助者Red Hat公司而言，它是许多新技术的测试平台，被认为可用的技术最终会加入到Red Hat Enterprise Linux中。Fedora大约每六个月发布新版本。</p>
<p>不同发行版几乎采用了不同包管理器（SLES、Fedora、openSUSE、centos、RHEL使用rmp包管理系统，包文件以RPM为扩展名；Ubuntu系列，Debian系列使用基于DPKG包管理系统，包文件以deb为扩展名。)</p>
<p>69年Unix诞生在贝尔实验室，80年 DARPA（国防部高级计划局）请人在Unix实现全新的TCP、IP协议栈。ARPANET最先搞出以太网</p>
<p>Linux 从91年到95年处于成长期，真正大规模应用是Linux+Apache提供的WEB服务被大家大规模采用</p>
<p>rpm:  centos&#x2F;fedora&#x2F;suse</p>
<p>deb:  debian&#x2F;ubuntu&#x2F;uos(早期基于ubuntu定制，后来基于debian定制，再到最近开始直接基于kernel定制)</p>
<p>ARPANET：<strong>高等研究計劃署網路</strong>（英語：Advanced Research Projects Agency Network），通称<strong>阿帕网</strong>（英語：ARPANET）是美國<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2">國防高等研究計劃署</a>开发的世界上第一个运营的<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E5%B0%81%E5%8C%85%E4%BA%A4%E6%8F%9B">封包交换</a>网络，是全球<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91">互联网</a>的鼻祖。</p>
<p>TCP&#x2F;IP：1974年，卡恩和瑟夫带着研究成果，在IEEE期刊上，发表了一篇题为《关于分组交换的网络通信协议》的论文，正式提出TCP&#x2F;IP，用以实现计算机网络之间的互联。</p>
<p>在1983年，美国国防部高级研究计划局决定淘汰NCP协议（ARPANET最早使用的协议），TCP&#x2F;IP取而代之。</p>
<h3 id="Deepin-UOS"><a href="#Deepin-UOS" class="headerlink" title="Deepin UOS"></a>Deepin UOS</h3><p><em><strong>*Deepin 与统信 UOS 类似于红帽的 Fedora 与 RHEL 的上下游关系，Deepin 依然保持着原来的社区运营模式，而统信 UOS 则是基于社区版 Deepin 构建的商业发行版，为 Deepin 挖掘更多的商业机会和更大的商业价值，进而反哺社区，形成良性循环*</strong></em>。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kevingrace/p/8671964.html">https://www.cnblogs.com/kevingrace/p/8671964.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/ac3e7009a764">https://www.jianshu.com/p/ac3e7009a764</a></p>
<p>B 站哈工大操作系统视频地址：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1d4411v7u7?from=search&seid=2361361014547524697">https://www.bilibili.com/video/BV1d4411v7u7?from=search&amp;seid=2361361014547524697</a></p>
<p>B 站清华大学操作系统视频地址：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1js411b7vg?from=search&seid=2361361014547524697">https://www.bilibili.com/video/BV1js411b7vg?from=search&amp;seid=2361361014547524697</a></p>
<p><a target="_blank" rel="noopener" href="https://linux.cn/article-10465-1.html">Linux 工具：点的含义</a> <a target="_blank" rel="noopener" href="https://www.linux.com/training-tutorials/linux-tools-meaning-dot/">英文版</a></p>
<p><a target="_blank" rel="noopener" href="http://coolnull.com/4432.html">linux cp实现强制覆盖</a></p>
<p><a target="_blank" rel="noopener" href="https://wangdoc.com/bash/startup.html">https://wangdoc.com/bash/startup.html</a></p>
<p><a target="_blank" rel="noopener" href="https://cjting.me/2020/12/10/tiny-x64-helloworld/">编写一个最小的 64 位 Hello World</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/01/01/ipmitool%E4%BF%AE%E6%94%B9BIOS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/01/ipmitool%E4%BF%AE%E6%94%B9BIOS/" class="post-title-link" itemprop="url">ipmitool 和 BIOS</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-01-01 12:30:03" itemprop="dateCreated datePublished" datetime="2020-01-01T12:30:03+08:00">2020-01-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ipmitool-和-BIOS"><a href="#ipmitool-和-BIOS" class="headerlink" title="ipmitool 和 BIOS"></a>ipmitool 和 BIOS</h1><h2 id="什么是-IPMI"><a href="#什么是-IPMI" class="headerlink" title="什么是 IPMI"></a>什么是 IPMI</h2><p>IPMI（智能平台管理接口），Intelligent Platform Management Interface 的缩写。原本是一种<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/Intel">Intel</a>架构的企业系统的周边设备所采用的一种工业标准。IPMI亦是一个开放的免费标准，用户无需支付额外的费用即可使用此标准。</p>
<p>IPMI 能够横跨不同的操作系统、固件和硬件平台，可以智能的监视、控制和自动回报大量服务器的运作状况，以降低服务器系统成本。</p>
<p>1998年Intel、DELL、HP及NEC共同提出IPMI规格，可以透过网路远端控制温度、电压。</p>
<p>2001年IPMI从1.0版改版至1.5版，新增 PCI Management Bus等功能。</p>
<p>2004年Intel发表了IPMI 2.0的规格，能够向下相容IPMI 1.0及1.5的规格。新增了Console Redirection，并可以通过Port、Modem以及Lan远端管理伺服器，并加强了安全、VLAN 和刀锋伺服器的支援性。</p>
<p>Intel&#x2F;amd&#x2F;hygon 基本都支持 ipmitool，看起来ARM 支持的接口也许不一样</p>
<p>BMC（Baseboard Management Controller）即我们常说的带外系统，是在机器上电时即完成自身初始化，开始运行。其系统可在standby电模式下工作。所以，通过带外监控服务器硬件故障，不受OS存活状态影响，可实现7*24小时无间断监控，甚至我们可以通过带外方式，精确感知带内存活，实现OS存活监控。</p>
<p>BMC在物理形态上，由一主嵌入式芯片+系列总线+末端芯片组成的一个硬件监控&amp;控制系统，嵌入式芯片中运行嵌入式Linux操作系统，负责整个BMC系统的资源协调及用户交互，核心进程是IPMImain进程，实现了全部IPMI2.0协议的消息传递&amp;处理工作。</p>
<h2 id="ipmitool-用法"><a href="#ipmitool-用法" class="headerlink" title="ipmitool 用法"></a>ipmitool 用法</h2><p>基本步骤：</p>
<ol>
<li>查看当前值：ipmitool raw 0x3e 0x5f 0x00 0x11 （非必要，列出目前BIOS中的值）</li>
<li>打开配置开关(让BIOS进入可配置，默认不可配置)：ipmitool raw 0x3e 0x5c 0x00 0x01 0x81</li>
<li>修改某个值，比如将numa 设置为on：ipmitool raw 0x3e 0x5c 0x05 0x01 0x81</li>
<li>查看修改后的值：ipmitool raw 0x3e 0x5d 0x05 0x01 (必须要)</li>
<li>最后reboot机器新的值就会apply到BIOS中</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zygblock/article/details/53367664">ipmitool使用</a>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">         固定-不变 0x5c修改   要修改的项    长度(一搬都是01)    新的值(0x81 表示on、0x80表示off)</span><br><span class="line">ipmitool raw 0x3e 0x5c      index       0x01                value</span><br></pre></td></tr></table></figure>

<p>第1&#x2F;2个参数raw 0x3e 固定不变</p>
<p>第三个参数表示操作可以是：</p>
<ul>
<li>0x5c 修改</li>
<li>0x5f 查看BIOS中的当前值（海光是这样，intel不是）</li>
<li>0x5d 查询即将写入的值（修改后没有写入 0x5f 看到的是老值）</li>
</ul>
<p>第四个参数Index表示需要修改的配置项（具体见后表）</p>
<p>第五个参数 0x01 表示值的长度，一般固定不需要改</p>
<p>value 表示值，0x81表示enable; 0x80表示disable</p>
<h3 id="ipmitool带外设置步骤"><a href="#ipmitool带外设置步骤" class="headerlink" title="ipmitool带外设置步骤"></a><a target="_blank" rel="noopener" href="https://promisechen.github.io/kbase/ipmi.html">ipmitool</a>带外设置步骤</h3><p>1）设置valid flag：</p>
<p>ipmitool -I lan -U admin -P admin -H 192.168.1.10 raw 0x3e 0x5c 0x00 0x01 0x81</p>
<p>2） 设置对应的选项：</p>
<p>ipmitool -I lan -U admin -P admin -H 192.168.1.10 raw 0x3e 0x5c index 0x01 Data  —- index 和Data参考下述表格；</p>
<p>3）重启CN：</p>
<p>ipmitool -I lan -U admin -P admin -H 192.168.1.10 power reset</p>
<p>4）读取当前值：</p>
<p>ipmitool -I lan -U admin -P admin -H 192.168.1.10  raw 0x3e 0x5f index 0x01 </p>
<p> 如moc机型，读取CN的 Numa值：</p>
<p>ipmitool -I lan -U admin -P admin -H 192.168.1.10 raw 0x3e 0x5f 0x05 0x01 </p>
<h3 id="确认是否设置成功"><a href="#确认是否设置成功" class="headerlink" title="确认是否设置成功"></a>确认是否设置成功</h3><p>查询要写入的新值：ipmitool 0x3e 0x5d 0x00 0x11</p>
<p> 返回值，如：11 <strong>81</strong> 81 00 00 00 00 00 00 00 00 00 00 00 00 00  00 00</p>
<p>​      第一个byte 表示查询数量，表示查询0x11个设置项；</p>
<pre><code>	 第二个byte 表示index=0的值，即Configuration，必须保证是0x81，才能进行重启，否则设置不生效；
</code></pre>
<p>​      第三个byte 表示index&#x3D;1的值，即Turbo，表示要设置为0x81；</p>
<p>​      剩余byte依次类推……….</p>
<p>​      未设置新值的index对应值是00，要设置的index其对应值为Data（步骤3的设置值）；</p>
<h2 id="海光服务器修改案例"><a href="#海光服务器修改案例" class="headerlink" title="海光服务器修改案例"></a>海光服务器修改案例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">//海光+alios下 第二列为：0x5c 修改、0x5f BIOS中的查询、0x5d 查询即将写入的值 </span><br><span class="line">//0x5f 查询BIOS中的值</span><br><span class="line"></span><br><span class="line">#ipmitool raw 0x3e 0x5f 0x00 0x11</span><br><span class="line"> 11 81 81 81 81 80 81 80 81 81 80 81 81 00 00 81</span><br><span class="line"> 80 81</span><br><span class="line"> </span><br><span class="line">//还没有写入任何新值</span><br><span class="line">#ipmitool raw 0x3e 0x5d 0x00 0x11</span><br><span class="line"> 11 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br><span class="line"> 00 00 </span><br><span class="line"></span><br><span class="line">//enable numa</span><br><span class="line">#ipmitool raw 0x3e 0x5c 0x00 0x01 0x81</span><br><span class="line">#ipmitool raw 0x3e 0x5c 0x05 0x01 0x81</span><br><span class="line"></span><br><span class="line">//enable boost</span><br><span class="line">#ipmitool raw 0x3e 0x5c 0x01 0x01 0x81</span><br><span class="line"></span><br><span class="line">#ipmitool raw 0x3e 0x5d 0x01 0x01</span><br><span class="line"> 11 81 </span><br><span class="line">//关闭 SMT</span><br><span class="line">#ipmitool raw 0x3e 0x5c 0x02 0x01 0x80</span><br><span class="line"></span><br><span class="line">#ipmitool raw 0x3e 0x5d 0x02 0x01</span><br><span class="line"> 11 81 </span><br></pre></td></tr></table></figure>



<h2 id="BIOS中选项的对应关系"><a href="#BIOS中选项的对应关系" class="headerlink" title="BIOS中选项的对应关系"></a>BIOS中选项的对应关系</h2><h3 id="Intel服务器"><a href="#Intel服务器" class="headerlink" title="Intel服务器"></a>Intel服务器</h3><table>
<thead>
<tr>
<th>Name</th>
<th>Index</th>
<th>Data Length（Bytes）</th>
<th>Data （不在列表中则为无效值）</th>
</tr>
</thead>
<tbody><tr>
<td>Configuration</td>
<td>0x00</td>
<td>1</td>
<td>0x81 – valid Flag 0x82 – Restore Default Value (恢复为PRD定义的默认值)0x00  BIOS在读取设定后，会发送index&#x3D;0x00，data&#x3D;0x00的命令给BMC，BMC应清零所有参数值。</td>
</tr>
<tr>
<td>Turbo</td>
<td>0x01</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>HT</td>
<td>0x02</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>VT</td>
<td>0x03</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>EIST</td>
<td>0x04</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>Numa</td>
<td>0X05</td>
<td>1</td>
<td>0x80 – disable 0x81 - enable</td>
</tr>
<tr>
<td>Vendor Change</td>
<td>0x06</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>VT-d</td>
<td>0x07</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>SRIOV</td>
<td>0x08</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>Active Video</td>
<td>0x09</td>
<td>1</td>
<td>0x80 – Onboard0x81 – PCIe</td>
</tr>
<tr>
<td>Local HDD Boot</td>
<td>0x0A</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>Hotkey support</td>
<td>0x0B</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
</tr>
<tr>
<td>Intel Speed Select</td>
<td>0x0C</td>
<td>1</td>
<td>0x80-Disable0x81-Config 10x82-Config 2</td>
</tr>
<tr>
<td>IMS</td>
<td>0x0D</td>
<td>1</td>
<td>0x80-Disable0x81-Enable</td>
</tr>
<tr>
<td>TPM</td>
<td>0x0E</td>
<td>1</td>
<td>0x80-Disable0x81-Enabled0x83-Enable&amp;Clear TPM</td>
</tr>
<tr>
<td>Power off remove</td>
<td>0x0F</td>
<td>1</td>
<td>0x80 – disable – 响应命令0x81 – enable –不响应命令</td>
</tr>
<tr>
<td>BIOS BOOT MODE</td>
<td>0x10</td>
<td>1</td>
<td>0x80 – Legacy0x81 – UEFI</td>
</tr>
<tr>
<td>Active Cores</td>
<td>0x11</td>
<td>1</td>
<td>0x80 - Default Core Number0x81 - Active 1 Core0x82 - Active 2 Cores0x83 - Active 3 Cores…0xFE - Active 126 Cores</td>
</tr>
<tr>
<td>C   State</td>
<td>0x12</td>
<td>1</td>
<td>0x80-Disable0x81-Enable</td>
</tr>
<tr>
<td>HWPM</td>
<td>0x13</td>
<td>1</td>
<td>0x80-Disable0x81-Native   mode0x82-OOB   Mode0x83-Native   mode Without Legacy support</td>
</tr>
<tr>
<td>Intel   SgxSW Guard Extensions (SGX)</td>
<td>0x14</td>
<td>1</td>
<td>0x80-Disable0x81-Enable</td>
</tr>
<tr>
<td>SGX PRMRR Size</td>
<td>0x15</td>
<td>1</td>
<td>0X80-[00]No valid PRMRR   size    0X81-[40000000]1G0X82-[80000000]2G0X83-[100000000]4G0X84-[200000000]8G0X85-[400000000]16G0X86-[800000000]32G0X87-[1000000000]64G0X88-[2000000000]128G0X89-[4000000000]256G0X8A-[8000000000]512G</td>
</tr>
<tr>
<td>SGX Factory Reset</td>
<td>0x16</td>
<td></td>
<td>0x80-Disable0x81-Enable</td>
</tr>
<tr>
<td></td>
<td>0x17</td>
<td></td>
<td>预留</td>
</tr>
<tr>
<td>CPU0_IOU0 (IIO PCIe Br1)</td>
<td>0x18</td>
<td>1</td>
<td>0x80 – x4x4x4x4   0x81 – x4x4x8   0x82 – x8x4x4   0x83 – x8x8   0x84 – x16   0x85 - Auto</td>
</tr>
<tr>
<td>CPU0_IOU1 (IIO PCIe Br2)</td>
<td>0x19</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU0_IOU2 (IIO PCIe Br3)</td>
<td>0x1a</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU0_IOU3 (IIO PCIe Br4)</td>
<td>0x1b</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU0_IOU4 (IIO PCIe Br5)</td>
<td>0x1c</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU1_IOU0 (IIO PCIe Br1)</td>
<td>0x1d</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU1_IOU1 (IIO PCIe Br2)</td>
<td>0x1e</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU1_IOU2 (IIO PCIe Br3)</td>
<td>0x1f</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU1_IOU3 (IIO PCIe Br4)</td>
<td>0x20</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU1_IOU4 (IIO PCIe Br5)</td>
<td>0x21</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU2_IOU0 (IIO PCIe Br1)</td>
<td>0x22</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU2_IOU1 (IIO PCIe Br2)</td>
<td>0x23</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU2_IOU2 (IIO PCIe Br3)</td>
<td>0x24</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU2_IOU3 (IIO PCIe Br4)</td>
<td>0x25</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU2_IOU4 (IIO PCIe Br5)</td>
<td>0x26</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU3_IOU0 (IIO PCIe Br1)</td>
<td>0x27</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU3_IOU1 (IIO PCIe Br2)</td>
<td>0x28</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU3_IOU2 (IIO PCIe Br3)</td>
<td>0x29</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU3_IOU3 (IIO PCIe Br4)</td>
<td>0x2a</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>CPU3_IOU4 (IIO PCIe Br5)</td>
<td>0x2b</td>
<td>1</td>
<td>同上</td>
</tr>
<tr>
<td>SGXLEPUBKEYHASHx Write Enable</td>
<td>0x2C</td>
<td>1</td>
<td>0x80-Disable0x81-Enable</td>
</tr>
<tr>
<td>SubNuma</td>
<td>0x2D</td>
<td>1</td>
<td>0x80-Disabled0x81-SN2</td>
</tr>
<tr>
<td>VirtualNuma</td>
<td>0x2E</td>
<td>1</td>
<td>0x80-Disabled0x81-Enabled</td>
</tr>
<tr>
<td>TPM Priority</td>
<td>0x2F</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>TDX</td>
<td>0x30</td>
<td>1</td>
<td>0x80 - Disabled0x81 - Enabled</td>
</tr>
<tr>
<td>Select Owner EPOCH input type</td>
<td>0x31</td>
<td>1</td>
<td>0x81-Change to New Random Owner EPOCHs0x82-Manual User Defined Owner EPOCHs</td>
</tr>
<tr>
<td>Software Guard Extensions Epoch 0</td>
<td>0x32</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Software Guard Extensions Epoch 1</td>
<td>0x33</td>
<td>1</td>
<td></td>
</tr>
</tbody></table>
<h3 id="AMD服务器"><a href="#AMD服务器" class="headerlink" title="AMD服务器"></a>AMD服务器</h3><table>
<thead>
<tr>
<th>Name</th>
<th>Index</th>
<th>Data Length（Bytes）</th>
<th>Data （不在列表中则为无效值）</th>
<th>支持项目</th>
</tr>
</thead>
<tbody><tr>
<td>Configuration</td>
<td>0x00</td>
<td>1</td>
<td>0x81 – valid Flag 0x82 – Restore Default Value (恢复为PRD定义的默认值)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Core Performance Boost</td>
<td>0x01</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>SMT Mode</td>
<td>0x02</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>SVM Mode</td>
<td>0x03</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>EIST</td>
<td>0x04</td>
<td>1</td>
<td>0x80 (AMD默认支持智能调频但无此选项)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>NUMA nodes per socket</td>
<td>0X05</td>
<td>1</td>
<td>0x80 – NPS0 0x81 – NPS1 0x82 – NPS2 0x83 – NPS4 （开）0x87 – Auto(Auto为NPS1)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Vendor Change</td>
<td>0x06</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>IOMMU</td>
<td>0x07</td>
<td>1</td>
<td>0x80 – disable0x81 – enable0x8F – Auto</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>SRIOV</td>
<td>0x08</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Active Video</td>
<td>0x09</td>
<td>1</td>
<td>0x80 – Onboard0x81 – PCIe</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Local HDD Boot</td>
<td>0x0A</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Hotkey support</td>
<td>0x0B</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Intel Speed Select</td>
<td>0x0C</td>
<td>1</td>
<td>0x80 (AMD无此选项)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>IMS</td>
<td>0x0D</td>
<td>1</td>
<td>0x80 (AMD暂未做IMS功能)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>TPM</td>
<td>0x0E</td>
<td>1</td>
<td>0x80 – disable0x81 – enable0x83 – enable &amp; TPM   clear</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>Power off remove</td>
<td>0x0F</td>
<td>1</td>
<td>0x80 (AMD暂未做此功能)</td>
<td>RomeMilan</td>
</tr>
<tr>
<td>BIOS BOOT MODE</td>
<td>0x10</td>
<td>1</td>
<td>0x80 – Legacy0x81 – UEFI</td>
<td>RomeMilan</td>
</tr>
</tbody></table>
<h3 id="海光服务器"><a href="#海光服务器" class="headerlink" title="海光服务器"></a>海光服务器</h3><table>
<thead>
<tr>
<th>Name</th>
<th>Index</th>
<th>Data Length（Bytes）</th>
<th>Data （不在列表中则为无效值）</th>
<th>支持项目</th>
</tr>
</thead>
<tbody><tr>
<td>Configuration</td>
<td>0x00</td>
<td>1</td>
<td>0x81 – valid Flag 0x82 – Restore Default Value (恢复为PRD定义的默认值)</td>
<td>海光2</td>
</tr>
<tr>
<td>Core Performance Boost</td>
<td>0x01</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>SMT</td>
<td>0x02</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>SVM</td>
<td>0x03</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>P-State Control</td>
<td>0x04</td>
<td>1</td>
<td>0x80 – Performance0x81 – Normal</td>
<td>海光2</td>
</tr>
<tr>
<td>Memory Interleaving</td>
<td>0X05</td>
<td>1</td>
<td>0x80 – Socket (关numa) 0x81 - channel（8 node）</td>
<td>海光2</td>
</tr>
<tr>
<td>Vendor Change</td>
<td>0x06</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>IOMMU</td>
<td>0x07</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>SRIOV</td>
<td>0x08</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>Onboard VGA</td>
<td>0x09</td>
<td>1</td>
<td>0x80 – Onboard0x81 – PCIe</td>
<td>海光2</td>
</tr>
<tr>
<td>Local HDD Boot</td>
<td>0x0A</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>Hotkey support</td>
<td>0x0B</td>
<td>1</td>
<td>0x80 – disable0x81 – enable</td>
<td>海光2</td>
</tr>
<tr>
<td>Hygon平台没有此选项</td>
<td>0x0C</td>
<td>1</td>
<td>0x80-Disable0x81-Config 10x82-Config 2</td>
<td>不支持</td>
</tr>
<tr>
<td>Hygon平台没有此选项</td>
<td>0x0D</td>
<td>1</td>
<td>0x80-Disable0x81-Enable</td>
<td>不支持</td>
</tr>
<tr>
<td>TPM</td>
<td>0x0E</td>
<td>1</td>
<td>0x80-Disable0x81-Enabled0x83-Enable&amp;Clear TPM</td>
<td>海光2</td>
</tr>
<tr>
<td>Power off remove</td>
<td>0x0F</td>
<td>1</td>
<td>0x80 – disable – 响应命令0x81 – enable –不响应命令</td>
<td>海光2</td>
</tr>
<tr>
<td>Boot option Filter</td>
<td>0x10</td>
<td>1</td>
<td>0x80 – Legacy0x81 – UEFI</td>
<td>海光2</td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/01/01/2010%E5%88%B02020%E8%BF%9910%E5%B9%B4%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/01/2010%E5%88%B02020%E8%BF%9910%E5%B9%B4%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5%E5%BF%B5/" class="post-title-link" itemprop="url">2010到2020这10年的碎碎念念</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-01-01 00:30:03" itemprop="dateCreated datePublished" datetime="2020-01-01T00:30:03+08:00">2020-01-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/others/" itemprop="url" rel="index"><span itemprop="name">others</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="2010到2020这10年的碎碎念念"><a href="#2010到2020这10年的碎碎念念" class="headerlink" title="2010到2020这10年的碎碎念念"></a>2010到2020这10年的碎碎念念</h1><h2 id="来自网络的一些数据"><a href="#来自网络的一些数据" class="headerlink" title="来自网络的一些数据"></a>来自网络的一些数据</h2><p>这十年，中国的人均GDP从大约3300美金干到了9800美金。这意味着：更多的中国人脱贫，更多的中国人变成了中产。这是这一轮消费升级的核心原动力，没有之一。</p>
<p>这十年，中国的进出口的总额从2009年占GDP的44.86%，降至34.35%。</p>
<p>互联网从美国copy开始变成创新、走在前列，因为有庞大的存量市场</p>
<p>2010年，一个数据发生了逆势波动。那就是中国的适龄小学人口增速。在此之前从1997年后，基本呈负增长。这是因为中国80后家长开始登上历史舞台。这带动了诸多产业的蓬勃发展，比如互联网教育，当然还有学区房。</p>
<p>10年吉利收购沃尔沃，18年吉利收购戴姆勒10%的股份。</p>
<p>微信崛起、头条崛起、百度走下神坛。美团、pdd崛起</p>
<p>12年2月6号的王护士长外逃美国大使馆也让大家兴奋了，11年的郭美美红十字会事件快要被忘记了，但是也让大家对慈善事件更加警惕，倒是谅解了汶川地震的王石10块捐款事件，不过老王很快因为娶了年轻的影星田朴珺一下子人设坍塌，大家更热衷老王的负面言论了。</p>
<p>温州动车事件让高铁降速了</p>
<p>我爸是李刚、药家鑫、李天一、邓玉娇（09年），陈冠希艳照门、三鹿奶粉、汶川地震、奥运会（08年）</p>
<p>2018年：中美贸易站、问题疫苗、个税改革、中兴被美制裁，北京驱赶低端人口，鸿茅药酒，p2p暴雷，昆山反杀案，相互宝</p>
<p>2015年：雾霾、柴静纪录片《穹顶之下》，屠呦呦诺贝尔奖，放开二胎</p>
<p>2014年：东莞扫黄、马航370事件；周师傅被查、占中</p>
<p>2013年：劳教正式被废除，想起2003年的孙志刚事件废除收容制度</p>
<p>2012年：方韩之争，韩寒走下神坛</p>
<p>2011年：日本海啸地震，中国抢盐事件；郭美美，温州动车</p>
<p>2010年：google退出中国，上海世博会开幕，富士康N连跳楼事件；我爸是李刚，腾讯大战360</p>
<h2 id="自我记忆"><a href="#自我记忆" class="headerlink" title="自我记忆"></a>自我记忆</h2><p>刚看到有人在说乐清钱云会事件，一晃10年了，10年前微博开始流行改变了好多新闻、热点事件的引爆方式。</p>
<p>这十年BBS、门户慢慢在消亡，10年前大家都知道三大门户网站和天涯，现在的新网民应该知道的不多了。</p>
<p>影响最大的还是移动网络的崛起，这也取决于4G和山寨机以及后来的小米手机，真正给中国的移动互联网带来巨大的红利，注入的巨大的增长。<br>我自己对移动互联网的判断是极端错误的，即使09年我就开始用上了iphone手机，那又怎么样，看问题还是用静态的视觉观点。手机没有键盘、手机屏幕狭小，这些确实是限制，到2014年我还想不明白为什么要在手机上购物，比较、看物品图片太不方便了，结果便利性秒杀了这些不方便；只有手机的群体秒杀了办公室里的白领，最后大家都很高兴地用手机购物了，甚至PC端bug更多，更甚至有些网站不提供PC端。</p>
<p>移动网络的崛起和微信的成功也相辅相成的，在移动网络时代每个人都有自己的手机，所以账号系统的打通不再是问题，尤其是都被微信这个移动航母在吞噬，其它公司都活在微信的阴影里。</p>
<p>当然移动支付的崛起就理所当然了。</p>
<p>即使今天网上购物还是PC上要方便，那又怎么样，很多时候网上购物都是不在电脑前的零碎时间。</p>
<p>10多年前第一次看到智能手机是室友购买的多普达，20年前也是这个室友半夜里很兴奋地播报台湾大选，让我知道了台湾大选这个事情。</p>
<p>基本的价值观、世界观，没怎么改变，不应该是年龄大了僵化了，应该是掌握信息的手段和能力增强了，翻墙获取信息也很容易，基本的逻辑还在也没那么容易跑偏了。可能就是别人看到的年纪大了脑子僵化了吧，自我感觉不一定对。</p>
<p>最近10年经济发展的非常好，政府对言论的控制越来越精准，舆论引导也非常”成功”,所以网络上看到这5年和5年前基本差别很大，5年前公知是个褒义词，5年后居然成了贬义词。</p>
<p>房价自然是这10年最火的话题，07年大家开始感觉到房价上涨快、房价高，08年金融危机本来是最好的机会，结果4万亿刺激下09年年底房价开始翻倍，到10年面对翻倍了的房价政府、媒体、老百姓都在喊高，实际也只是横盘，13-14年小拉一波，16年涨价去库存再大拉一波。基本让很多人绝望了</p>
<p>这十年做的最错的事情除了没有早点买房外就是想搞点投资收入投了制造外加炒股，踩点能力太差了，虽然前5年像任志强一样一直看多房价的不多，这个5年都被现实教育了，房价也基本到头了。</p>
<p>工作上应该更早地、坚定地进入互联网、移动互联网，这10年互联网对人才的需求实在太大了，虽然最终能伴随公司成长的太少，毕竟活下来长大的公司不多。</p>
<p>Google退出中国、看着小杨同学和一些同事移民、360大战QQ、诺贝尔和平奖、华为251事件都算是自己在一些公众事情上投入比较多的。非常不舍google的离开，这些年也基本还是只用google，既是无奈中用下百度也还是觉得搜不到什么有效信息；好奇移民的想法和他们出去后的各种生活；360跟QQ大战的时候觉得腾讯的垄断太牛叉了，同时认为可能360有这种资源的话会更作恶和垄断的更厉害，至少腾讯还是在乎外面的看法和要面子的；LXB到现在也是敏感词，直到病死在软禁中，这些年敏感词越来越多，言论的控制更严厉了；华为251也是个奇葩事件了，暴露了资本家的粗野和枉法。</p>
<p>自己工作上跳槽一次，继续做一个北漂。公司对自己的方法论改变确实比较大，近距离看到了一些成功因素方面的逻辑（更有效的激励和企业文化）。</p>
<p>经历了从外企到私企，从小公司到大公司的不同，外企英语是天花板，也看到了华为所谓的狼性、在金钱激励下的狼性，和对企业文化的维护，不能否认90%以上的人工作是为了钱</p>
<p>这几年也开始习惯写技术文章来总结了，这得益于Markdown+截图表述的便利，也深刻感受到深抠，然后总结分享的方法真的很好（高斯学习方法），也体会到了抓手、触类旁通的运用。10年前在搜狐blog写过一两年的博客放弃的很快，很难一直有持续的高水平总结和输出。</p>
<p>10年前还在比较MSN和QQ谁更好（我是坚定站在QQ这边的），10年后MSN再也看不见了，QQ也有了更好的替代工具微信。用处不大的地方倒是站对了，对自己最有用的关键地方都站错了。</p>
<p>10年前差点要去豆瓣，10年后豆瓣还活着，依然倔强地保持自己的品味，这太难得了。相反十年前好用得不得了的RSS订阅，从抓虾转到google reader再到feedly好东西就是活得这么艰难。反过来公众号起来了、贴吧式微了，公众号运作新闻类是没问题的（看完就过），但是对技术类深度一点的就很不合适了，你看看一篇文章24小时内的阅读量占据了98%以上，再到后面就存亡了！但是公众号有流量，流量可以让大家跪在地上。</p>
<p>10年前啃老是被看不起的，10年后早结婚、多啃老也基本成了这10年更对的事情，结婚得买房，啃老买得更早，不对的事情变对了（结婚早没错）。</p>
<p>很成功地组织了一次同学20周年的聚会，也看到了远则亲、近则仇的现实情况，自己组织统筹能力还可以。</p>
<p>情绪控制能力太差、容易失眠。这十年爱上了羽毛球和滑雪，虽然最近几年滑雪少了。</p>
<p>体会到自小贫穷带来的一些抠门的坏习惯。</p>
<p>2015年的股票大跌让自己很痛苦，这个过程反馈出来的不愿意撒手、在股市上的鸵鸟方式，股市上总是踩不到正确的点。割肉太难，割掉的总是错误的。</p>
<p>15、16年我认为云计算不怎么样，觉得无非就是新瓶装旧酒，现在云计算不再有人质疑了，即使现在都还是亏钱。</p>
<p>当然我也质疑过外卖就是一跑腿的，确实撑不起那么大的盘子，虽然没有像团购一样消亡，基本跟共享单车一样了，主要因为我是共享单车的重度用户，而我极端不喜欢外卖，所以要站出来看问题、屁股坐在哪边会严重影响看法，也就是不够客观。</p>
<p>网约车和移动支付一起在硝烟中混战</p>
<p>电动车开始起来，主要受政府弯道超车的刺激，目前看取决于自有充电位（适合三四线城市），可是三四线城市用户舍不得花这个溢价，汽油车都还没爽够呢。</p>
<p>对世界杯不再那么关注，对AlphaGo的新闻倒是很在意了。魏则西事件牢牢地把百度钉死在耻辱柱上。</p>
<p>随着12306的发展和高铁的起来，终于过年回家的火车票不用再靠半夜排队了。</p>
<p>2019年年末行政强制安装ETC，让我想起20年前物理老师在课堂上跟我们描述的将来小汽车走高速公路再也不用停下来收费了，会自动感应，开过去就自动扣钱了。我一直对这个未来场景念念不忘，最近10年我经常问别人为什么不办ETC，这个年底看到的是行政命令下的各种抱怨。</p>
<h3 id="看到："><a href="#看到：" class="headerlink" title="看到："></a>看到：</h3><ul>
<li><p>老人、家人更不愿意听身边亲近人员的建议；</p>
</li>
<li><p>老人思维为什么固化、怎么样在自己老后不是那样固化；</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/12/24/Linux%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%EF%BC%8C%E6%80%A7%E8%83%BD%E5%88%B0%E5%BA%95%E6%8F%90%E5%8D%87%E5%A4%9A%E5%B0%91%EF%BC%9F%E6%8B%BF%E6%95%B0%E6%8D%AE%E8%AF%B4%E8%AF%9D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/24/Linux%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%EF%BC%8C%E6%80%A7%E8%83%BD%E5%88%B0%E5%BA%95%E6%8F%90%E5%8D%87%E5%A4%9A%E5%B0%91%EF%BC%9F%E6%8B%BF%E6%95%B0%E6%8D%AE%E8%AF%B4%E8%AF%9D/" class="post-title-link" itemprop="url">Linux内核版本升级，性能到底提升多少？拿数据说话</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-24 17:30:03" itemprop="dateCreated datePublished" datetime="2019-12-24T17:30:03+08:00">2019-12-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Linux内核版本升级，性能到底提升多少？"><a href="#Linux内核版本升级，性能到底提升多少？" class="headerlink" title="Linux内核版本升级，性能到底提升多少？"></a>Linux内核版本升级，性能到底提升多少？</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>X 产品在公有云售卖一直使用的2.6.32的内核，有点老并且有些内核配套工具不能用，于是想升级一下内核版本。预期新内核的性能不能比2.6.32差</p>
<p>以下不作特殊说明的话都是在相同核数的Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz下得到的数据，最后还会比较相同内核下不同机型&#x2F;CPU型号的性能差异。</p>
<p>场景都是用sysbench 100个并发跑点查。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>先说大家关心的数据，最终4.19内核性能比2.6.32好将近30%，建议大家升级新内核，不需要做任何改动，尤其是Java应用（不同场景会有差异）</strong></p>
<p>本次比较的场景是Java应用的Proxy类服务，主要瓶颈是网络消耗，类似于MaxScale。后面有一个简单的MySQL Server场景下2.6.32和4.19的比较，性能也有33%的提升。</p>
<h2 id="2-6-32性能数据"><a href="#2-6-32性能数据" class="headerlink" title="2.6.32性能数据"></a>2.6.32性能数据</h2><p>升级前先看看目前的性能数据好对比（以下各个场景都是CPU基本跑到85%）</p>
<p><img src="/images/oss/b57c5ee5fe50ceb81cbad158f7b7aeeb.png" alt="image.png"></p>
<h2 id="一波N折的4-19"><a href="#一波N折的4-19" class="headerlink" title="一波N折的4.19"></a>一波N折的4.19</h2><p>阿里云上默认买到的ALinux2 OS（4.19），同样配置跑起来后，tps只有16000，比2.6.32的22000差了不少，心里只能暗暗骂几句坑爹的货，看了下各项指标，看不出来什么问题，就像是CPU能力不行一样。如果这个时候直接找内核同学，估计他们心里会说 X 是个什么东西？是不是你们测试有问题，是不是你们配置的问题，不要来坑我，内核性能我们每次发布都在实验室里跑过了，肯定是你们的应用问题。</p>
<p>所以要找到一个公认的场景下的性能差异。幸好通过qperf发现了一些性能差异。</p>
<h3 id="通过qperf来比较差异"><a href="#通过qperf来比较差异" class="headerlink" title="通过qperf来比较差异"></a>通过qperf来比较差异</h3><p>大包的情况下性能基本差不多，小包上差别还是很明显</p>
<pre><code>qperf -t 40 -oo msg_size:1  4.19 tcp_bw tcp_lat
tcp_bw:
    bw  =  2.13 MB/sec
tcp_lat:
    latency  =  224 us
tcp_bw:
    bw  =  2.15 MB/sec
tcp_lat:
    latency  =  226 us

qperf -t 40 -oo msg_size:1  2.6.32 tcp_bw tcp_lat
tcp_bw:
    bw  =  82 MB/sec
tcp_lat:
    latency  =  188 us
tcp_bw:
    bw  =  90.4 MB/sec
tcp_lat:
    latency  =  229 us
</code></pre>
<p>这下不用担心内核同学怼回来了，拿着这个数据直接找他们，可以稳定重现。</p>
<p>经过内核同学排查后，发现默认镜像做了一些安全加固，简而言之就是CPU拿出一部分资源做了其它事情，比如旁路攻击的补丁之类的，需要关掉（因为 X 的OS只给我们自己用，上面部署的代码都是X 产品自己的代码，没有客户代码，客户也不能够ssh连上X 产品节点）</p>
<pre><code>去掉 melt、spec 能到20000， 去掉sonypatch能到21000 
</code></pre>
<p>关闭的办法在 &#x2F;etc&#x2F;default&#x2F;grub 里 GRUB_CMDLINE_LINUX 配置中增加这些参数：</p>
<pre><code>nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off mitigations=off
</code></pre>
<p>关掉之后的状态看起来是这样的：</p>
<pre><code>$sudo cat /sys/devices/system/cpu/vulnerabilities/*
Mitigation: PTE Inversion
Vulnerable; SMT Host state unknown
Vulnerable
Vulnerable
Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers
Vulnerable, STIBP: disabled
</code></pre>
<p>这块参考<a target="_blank" rel="noopener" href="https://help.aliyun.com/knowledge_detail/154567.html?spm=a2c4g.11186623.2.12.887e38843VLHkv">阿里云文档</a> 和<a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/102087.html?spm=a2c4g.11186623.6.721.4a732223pEfyNC">这个</a></p>
<p>开启漏洞补丁（性能差）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># uname -r</span><br><span class="line">4.19.91-24.8.an8.x86_64</span><br><span class="line"></span><br><span class="line"># cat /proc/cmdline</span><br><span class="line">BOOT_IMAGE=(hd0,gpt2)/vmlinuz-4.19.91-24.8.an8.x86_64 root=UUID=ac9faf02-89c6-44d8-80b2-0f8ea1084fc3 ro console=tty0 crashkernel=auto console=ttyS0,115200 crashkernel=0M-2G:0M,2G-8G:192M,8G-:256M</span><br><span class="line">[root@Anolis82 ~]# sudo cat /sys/devices/system/cpu/vulnerabilities/*</span><br><span class="line">KVM: Mitigation: Split huge pages</span><br><span class="line">Mitigation: PTE Inversion; VMX: conditional cache flushes, SMT vulnerable</span><br><span class="line">Mitigation: Clear CPU buffers; SMT vulnerable</span><br><span class="line">Mitigation: PTI</span><br><span class="line">Mitigation: Speculative Store Bypass disabled via prctl and seccomp</span><br><span class="line">Mitigation: usercopy/swapgs barriers and __user pointer sanitization</span><br><span class="line">Mitigation: Full generic retpoline, IBPB: conditional, IBRS_FW, STIBP: conditional, RSB filling</span><br><span class="line">Not affected</span><br><span class="line">Mitigation: Clear CPU buffers; SMT vulnerable</span><br></pre></td></tr></table></figure>

<p>关闭（性能好）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@Anolis82 ~]# sudo cat /sys/devices/system/cpu/vulnerabilities/*</span><br><span class="line">KVM: Vulnerable</span><br><span class="line">Mitigation: PTE Inversion; VMX: vulnerable</span><br><span class="line">Vulnerable; SMT vulnerable</span><br><span class="line">Vulnerable</span><br><span class="line">Vulnerable</span><br><span class="line">Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers</span><br><span class="line">Vulnerable, IBPB: disabled, STIBP: disabled</span><br><span class="line">Not affected</span><br><span class="line">Vulnerable</span><br><span class="line">[root@Anolis82 ~]# cat /proc/cmdline</span><br><span class="line">BOOT_IMAGE=(hd0,gpt2)/vmlinuz-4.19.91-24.8.an8.x86_64 root=UUID=ac9faf02-89c6-44d8-80b2-0f8ea1084fc3 ro console=tty0 crashkernel=auto console=ttyS0,115200 nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off mitigations=off crashkernel=0M-2G:0M,2G-8G:192M,8G-:256M</span><br></pre></td></tr></table></figure>



<h3 id="4-9版本的内核性能"><a href="#4-9版本的内核性能" class="headerlink" title="4.9版本的内核性能"></a>4.9版本的内核性能</h3><p>但是性能还是不符合预期，总是比2.6.32差点。在中间经过几个星期排查不能解决问题，陷入僵局的过程中，尝试了一下4.9内核，果然有惊喜。</p>
<p>下图中对4.9的内核版本验证发现，tps能到24000，明显比2.6.32要好，所以传说中的新内核版本性能要好看来是真的，这下坚定了升级的念头，同时也看到了兜底的方案–最差就升级到4.9</p>
<p><img src="/images/oss/2f035e145f1bc41eb4a8b8bda8ed4ea2.png" alt="image.png"></p>
<p><strong>多队列是指网卡多队列功能，也是这次升级的一个动力。看起来在没达到单核瓶颈前，网卡多队列性能反而差点，这也符合预期</strong></p>
<h3 id="继续分析为什么4-19比4-9差了这么多"><a href="#继续分析为什么4-19比4-9差了这么多" class="headerlink" title="继续分析为什么4.19比4.9差了这么多"></a>继续分析为什么4.19比4.9差了这么多</h3><p>4.9和4.19这两个内核版本隔的近，比较好对比分析内核参数差异，4.19跟2.6.32差太多，比较起来很困难。</p>
<p>最终仔细对比了两者配置的差异，发现ALinux的4.19中 transparent_hugepage 是 madvise ,这对 Java应用来说可不是太友好：</p>
<pre><code>$cat /sys/kernel/mm/transparent_hugepage/enabled
always [madvise] never
</code></pre>
<p>将其改到 always 后4.19的tps终于稳定在了28300</p>
<p><img src="/images/oss/081c08801adb36cdfd8ff62be54fce94.png" alt="image.png"></p>
<p>这个过程中花了两个月的一些其他折腾就不多说了，主要是内核补丁和transparent_hugepage导致了性能差异。</p>
<p>transparent_hugepage，在redis、mongodb、memcache等场景（很多小内存分配）是推荐关闭的，所以要根据不同的业务场景来选择开关。</p>
<p><strong>透明大页打开后在内存紧张的时候会触发sys飙高对业务会导致不可预期的抖动，同时存在已知内存泄漏的问题，我们建议是关掉的，如果需要使用，建议使用madvise方式或者hugetlbpage</strong></p>
<h2 id="一些内核版本、机型和CPU的总结"><a href="#一些内核版本、机型和CPU的总结" class="headerlink" title="一些内核版本、机型和CPU的总结"></a>一些内核版本、机型和CPU的总结</h2><p>到此终于看到不需要应用做什么改变，整体性能将近有30%的提升。 在这个测试过程中发现不同CPU对性能影响很明显，相同机型也有不同的CPU型号（性能差异在20%以上–这个太坑了）</p>
<p>性能方面 4.19&gt;4.9&gt;2.6.32</p>
<p>没有做3.10内核版本的比较</p>
<p>以下仅作为大家选择ECS的时候做参考。</p>
<h3 id="不同机型-CPU对性能的影响"><a href="#不同机型-CPU对性能的影响" class="headerlink" title="不同机型&#x2F;CPU对性能的影响"></a>不同机型&#x2F;CPU对性能的影响</h3><p>还是先说结论：</p>
<ul>
<li>CPU:内存为1:2机型的性能排序：c6-&gt;c5-&gt;sn1ne-&gt;hfc5-&gt;s1</li>
<li>CPU:内存为1:4机型的性能排序：g6-&gt;g5-&gt;sn2ne-&gt;hfg5-&gt;sn2</li>
</ul>
<p>性能差异主要来源于CPU型号的不同</p>
<pre><code>c6/g6:                  Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz
c5/g5/sn1ne/sn2ne:      Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz
</code></pre>
<p>8269比8163大概好5-10%，价格便宜一点点，8163比E5-2682好20%以上，价格便宜10%（该买什么机型你懂了吧，价格是指整个ECS，而不是单指CPU）</p>
<p>要特别注意sn1ne&#x2F;sn2ne 是8163和E5-2682 两种CPU型号随机的，如果买到的是E5-2682就自认倒霉吧</p>
<p>C5的CPU都是8163，相比sn1ne价格便宜10%，网卡性能也一样。但是8核以上的sn1ne机型就把网络性能拉开了（价格还是维持c5便宜10%），从点查场景的测试来看网络不会成为瓶颈，到16核机型网卡多队列才会需要打开。</p>
<p>顺便给一下部分机型的包月价格比较：</p>
<p><img src="/images/oss/7c8b107fb12e285c8eab2c2d136bbd4e.png" alt="image.png"></p>
<p>官方给出的CPU数据：</p>
<p><img src="/images/oss/5f57f4228621378d14ffdd124fe54626.png" alt="image.png"></p>
<h2 id="4-19内核在MySQL-Server场景下的性能比较"><a href="#4-19内核在MySQL-Server场景下的性能比较" class="headerlink" title="4.19内核在MySQL Server场景下的性能比较"></a>4.19内核在MySQL Server场景下的性能比较</h2><p>这只是sysbench点查场景粗略比较，因为本次的目标是对X 产品性能的改进</p>
<p><img src="/images/oss/4f276e93cb914b3cdd312423be63c376.png" alt="image.png"></p>
<p>（以上表格数据主要由 内核团队和我一起测试得到）</p>
<p>**重点注意2.6.32不但tps差30%，并发能力也差的比较多，如果同样用100个并发压2.6.32上的MySQL，TPS在30000左右。只有在减少并发到20个的时候压测才能达到图中最好的tps峰值：45000. **</p>
<h2 id="新内核除了性能提升外带来的便利性"><a href="#新内核除了性能提升外带来的便利性" class="headerlink" title="新内核除了性能提升外带来的便利性"></a>新内核除了性能提升外带来的便利性</h2><p>升级内核带来的性能提升只是在极端场景下才会需要，大部分时候我们希望节省开发人员的时间，提升工作效率。于是X 产品在新内核的基础上定制如下一些便利的工具。</p>
<h3 id="麻烦的网络重传率"><a href="#麻烦的网络重传率" class="headerlink" title="麻烦的网络重传率"></a>麻烦的网络重传率</h3><p>通过tsar或者其它方式发现网络重传率有点高，有可能是别的管理端口重传率高，有可能是往外连其它服务端口重传率高等，尤其是在整体流量小的情况下一点点管理端口的重传包拉升了整个机器的重传率，严重干扰了问题排查，所以需要进一步确认重传发生在哪个进程的哪个端口上，是否真正影响了我们的业务。</p>
<p>在2.6.32内核下的排查过程是：抓包，然后写脚本分析（或者下载到本地通过wireshark分析），整个过程比较麻烦，需要的时间也比较长。那么在新镜像中我们可以利用内核自带的bcc来快速得到这些信息</p>
<pre><code>sudo /usr/share/bcc/tools/tcpretrans -l
</code></pre>
<p><img src="/images/oss/c68cc22b2e6eb7dd51d8613c5e79e88c.png" alt="image.png"></p>
<p>从截图可以看到重传时间、pid、tcp四元组、状态，针对重传发生的端口和阶段（SYN_SENT握手、ESTABLISHED）可以快速推断导致重传的不同原因。</p>
<p>再也不需要像以前一样抓包、下载、写脚本分析了。</p>
<h3 id="通过perf-top直接看Java函数的CPU消耗"><a href="#通过perf-top直接看Java函数的CPU消耗" class="headerlink" title="通过perf top直接看Java函数的CPU消耗"></a>通过perf top直接看Java函数的CPU消耗</h3><p>这个大家都比较了解，不多说，主要是top的时候能够把java函数给关联上，直接看截图：</p>
<pre><code>sh ~/tools/perf-map-agent/bin/create-java-perf-map.sh pid
sudo perf top
</code></pre>
<p><img src="/images/oss/1568775788220-32745082-5155-4ecd-832a-e814a682c0df.gif"></p>
<h3 id="快速定位Java中的锁等待"><a href="#快速定位Java中的锁等待" class="headerlink" title="快速定位Java中的锁等待"></a>快速定位Java中的锁等待</h3><p>如果CPU跑不起来，可能会存在锁瓶颈，需要快速找到它们</p>
<p>如下测试中上面的11万tps是解决掉锁后得到的，下面的4万tps是没解决锁等待前的tps：</p>
<pre><code>#[ 210s] threads: 400, tps: 0.00, reads/s: 115845.43, writes/s: 0.00, response time: 7.57ms (95%)
#[ 220s] threads: 400, tps: 0.00, reads/s: 116453.12, writes/s: 0.00, response time: 7.28ms (95%)
#[ 230s] threads: 400, tps: 0.00, reads/s: 116400.31, writes/s: 0.00, response time: 7.33ms (95%)
#[ 240s] threads: 400, tps: 0.00, reads/s: 116025.35, writes/s: 0.00, response time: 7.48ms (95%)

#[ 250s] threads: 400, tps: 0.00, reads/s: 45260.97, writes/s: 0.00, response time: 29.57ms (95%)
#[ 260s] threads: 400, tps: 0.00, reads/s: 41598.41, writes/s: 0.00, response time: 29.07ms (95%)
#[ 270s] threads: 400, tps: 0.00, reads/s: 41939.98, writes/s: 0.00, response time: 28.96ms (95%)
#[ 280s] threads: 400, tps: 0.00, reads/s: 40875.48, writes/s: 0.00, response time: 29.16ms (95%)
#[ 290s] threads: 400, tps: 0.00, reads/s: 41053.73, writes/s: 0.00, response time: 29.07ms (95%)
</code></pre>
<p>下面这行命令得到如下等锁的top 10堆栈（<a target="_blank" rel="noopener" href="https://github.com/jvm-profiling-tools/async-profiler">async-profiler</a>）：</p>
<pre><code>$~/tools/async-profiler/profiler.sh -e lock -d 5 1560

--- 1687260767618 ns (100.00%), 91083 samples
 [ 0] ch.qos.logback.classic.sift.SiftingAppender
 [ 1] ch.qos.logback.core.AppenderBase.doAppend
 [ 2] ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders
 [ 3] ch.qos.logback.classic.Logger.appendLoopOnAppenders
 [ 4] ch.qos.logback.classic.Logger.callAppenders
 [ 5] ch.qos.logback.classic.Logger.buildLoggingEventAndAppend
 [ 6] ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus
 [ 7] ch.qos.logback.classic.Logger.info
 [ 8] com.*****.logger.slf4j.Slf4jLogger.info
 [ 9] com.*****.utils.logger.support.FailsafeLogger.info
 [10] com.*****.util.LogUtils.recordSql



&quot;ServerExecutor-3-thread-480&quot; #753 daemon prio=5 os_prio=0 tid=0x00007f8265842000 nid=0x26f1 waiting for monitor entry [0x00007f82270bf000]
  java.lang.Thread.State: BLOCKED (on object monitor)
	at ch.qos.logback.core.AppenderBase.doAppend(AppenderBase.java:64)
	- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)
	at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:48)
	at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:282)
	at ch.qos.logback.classic.Logger.callAppenders(Logger.java:269)
	at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:470)
	at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:424)
	at ch.qos.logback.classic.Logger.info(Logger.java:628)
	at com.****.utils.logger.slf4j.Slf4jLogger.info(Slf4jLogger.java:42)
	at com.****.utils.logger.support.FailsafeLogger.info(FailsafeLogger.java:102)
	at com.****.util.LogUtils.recordSql(LogUtils.java:115)

          ns  percent  samples  top
  ----------  -------  -------  ---
160442633302   99.99%    38366  ch.qos.logback.classic.sift.SiftingAppender
    12480081    0.01%       19  java.util.Properties
     3059572    0.00%        9  com.***.$$$.common.IdGenerator
      244394    0.00%        1  java.lang.Object
</code></pre>
<p>堆栈中也可以看到大量的：<br>	<br>	  - waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- locked &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)<br>		- waiting to lock &lt;0x00007f866dcec208&gt; (a ch.qos.logback.classic.sift.SiftingAppender)</p>
<p>当然还有很多其他爽得要死的命令，比如一键生成火焰图等，不再一一列举，可以从业务层面的需要从这次镜像升级的便利中将他们固化到镜像中，以后排查问题不再需要繁琐的安装、配置、调试过程了。</p>
<h2 id="跟内核无关的应用层的优化"><a href="#跟内核无关的应用层的优化" class="headerlink" title="跟内核无关的应用层的优化"></a>跟内核无关的应用层的优化</h2><p>到此我们基本不用任何改动得到了30%的性能提升，但是对整个应用来说，通过以上工具让我们看到了一些明显的问题，还可以从应用层面继续提升性能。</p>
<p>如上描述通过锁排序定位到logback确实会出现锁瓶颈，同时在一些客户场景中，因为网盘的抖动也带来了灾难性的影响，所以日志需要异步处理，经过异步化后tps 达到了32000，关键的是rt 95线下降明显，这个rt下降对X 产品这种Proxy类型的应用是非常重要的（经常被客户指责多了一层转发，rt增加了）。</p>
<p>日志异步化和使用协程后的性能数据：</p>
<p><img src="/images/oss/bec4e8105091bc4b8a263aef245c0ce9.png" alt="image.png"></p>
<h3 id="Wisp2-协程带来的红利"><a href="#Wisp2-协程带来的红利" class="headerlink" title="Wisp2 协程带来的红利"></a>Wisp2 协程带来的红利</h3><p>在整个测试过程中都很顺利，只是<strong>发现Wisp2在阻塞不明显的场景下，抖的厉害</strong>。简单来说就是压力比较大的话Wisp2表现很稳定，一旦压力一般（这是大部分应用场景），Wisp2表现像是一会是协程状态，一会是没开协程状态，系统的CS也变化很大。</p>
<p>比如同一测试过程中tps抖动明显，从15000到50000：</p>
<p><img src="/images/oss/1550cc74116a56220d25e1434a675d14.png" alt="image.png"></p>
<p>100个并发的时候cs很小，40个并发的时候cs反而要大很多：</p>
<p><img src="/images/oss/3f79909f89889459d1f0dfe4fa0a2f53.png" alt="image.png"></p>
<p>最终在 @梁希 同学的攻关下发布了新的jdk版本，问题基本都解决了。不但tps提升明显，rt也有很大的下降。</p>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>感谢 OS&#x2F;Ali JDK 团队对这次内核版本升级的支持。</p>
<p>最终应用不需要任何改动可以得到 30%的性能提升，经过开启协程等优化后应用有将近80%的性能提升，同时平均rt下降了到原来的60%，rt 95线下降到原来的40%。</p>
<p>快点升级你们的内核，用上协程吧。同时考虑下在你们的应用中用上X 产品。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/25378.html">https://help.aliyun.com/document_detail/25378.html</a></p>
<p><a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/55263.html">https://help.aliyun.com/document_detail/55263.html</a></p>
<p><a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/52559.html">https://help.aliyun.com/document_detail/52559.html</a> (网卡)</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/" class="post-title-link" itemprop="url">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-16 12:30:03" itemprop="dateCreated datePublished" datetime="2019-12-16T12:30:03+08:00">2019-12-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CPU/" itemprop="url" rel="index"><span itemprop="name">CPU</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Intel-PAUSE指令变化如何影响MySQL的性能"><a href="#Intel-PAUSE指令变化如何影响MySQL的性能" class="headerlink" title="Intel PAUSE指令变化如何影响MySQL的性能"></a>Intel PAUSE指令变化如何影响MySQL的性能</h1><h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p>x86、arm指令都很多，无论是应用程序员还是数据库内核研发大多时候都不需要对这些指令深入理解，但是 Pause 指令和数据库操作太紧密了，本文通过一次非常有趣的性能优化来引入对 Pause 指令的理解，期望可以事半功倍地搞清楚 CPU指令集是如何影响你的程序的。</p>
<p>文章分成两大部分，第一部分是 MySQL 集群的一次全表扫描性能优化过程； 第二部分是问题解决后的原理分析以及Pause指令的来龙去脉和优缺点以及应用场景分析。</p>
<h2 id="业务结构"><a href="#业务结构" class="headerlink" title="业务结构"></a>业务结构</h2><p>为理解方便做了部分简化：</p>
<p>client -&gt; Tomcat -&gt; LVS -&gt; MySQL（32 个 MySQLD实例集群，每个实例8Core）</p>
<h2 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h2><p>通过 client 压 Tomcat 和 MySQL 集群（对数据做分库分表），MySQL 集群是32个实例，每个业务 SQL 都需要经过 Tomcat 拆分成 256 个 SQL 发送给 32 个MySQL（每个MySQL上有8个分库），这 256 条下发给 MySQL 的 SQL 不是完全串行，但也不是完全并行，有一定的并行性。</p>
<p>业务 SQL 如下是一个简单的select sum求和，这个 SQL在每个MySQL上都很快（有索引）</p>
<pre><code>SELECT SUM(emp_arr_amt) FROM table_c WHERE INSUTYPE=&#39;310&#39; AND Revs_Flag=&#39;Z&#39; AND accrym=&#39;201910&#39; AND emp_no=&#39;1050457&#39;;
</code></pre>
<h2 id="监控指标说明"><a href="#监控指标说明" class="headerlink" title="监控指标说明"></a>监控指标说明</h2><ul>
<li>后述或者截图中的逻辑RT&#x2F;QPS是指 client 上看到的Tomcat的 RT 和 QPS； </li>
<li>RT ：response time 请求响应时间，判断性能瓶颈的唯一指标;</li>
<li>物理RT&#x2F;QPS是指Tomcat看到的MySQL  RT 和QPS（这里的 RT 是指到达Tomcat节点网卡的 RT ，所以还包含了网络消耗）</li>
</ul>
<h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><p>通过client压一个Tomcat节点+32个MySQL，QPS大概是430，Tomcat节点CPU跑满，MySQL  RT 是0.5ms，增加一个Tomcat节点，QPS大概是700，Tomcat CPU接近跑满，MySQL  RT 是0.6ms，到这里性能基本随着扩容线性增加，是符合预期的。</p>
<p>继续增加Tomcat节点来横向扩容性能，通过client压三个Tomcat节点+32个MySQL，QPS还是700，Tomcat节点CPU跑不满，MySQL  RT 是0.8ms，这就严重不符合预期了。</p>
<p>性能压测原则：</p>
<blockquote>
<p>加并发QPS不再上升说明到了某个瓶颈，哪个环节RT增加最多瓶颈就在哪里</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20221026145848312.png" alt="image-20221026145848312"></p>
<p><strong>到这里一切都还是符合我们的经验的，看起来就是 MySQL 有瓶颈（RT 增加明显）。</strong></p>
<h2 id="排查-MySQL"><a href="#排查-MySQL" class="headerlink" title="排查 MySQL"></a>排查 MySQL</h2><p>现场DBA通过监控看到MySQL CPU不到20%，没有慢查询，并且尝试用client越过所有中间环节直接压其中一个MySQL，可以将 MySQL CPU 跑满，这时的QPS大概是38000（对应上面的场景client QPS为700的时候，单个MySQL上的QPS才跑到6000) 所以排除了MySQL的嫌疑(这个推理不够严谨为后面排查埋下了大坑)。</p>
<p>那么接下来的嫌疑在网络、LVS 等中间环节上。</p>
<h2 id="LVS和网络的嫌疑"><a href="#LVS和网络的嫌疑" class="headerlink" title="LVS和网络的嫌疑"></a>LVS和网络的嫌疑</h2><p>首先通过大查询排除了带宽的问题，因为这里都是小包，pps到了72万，很自然想到了网关、LVS的限流之类的</p>
<p>pps监控，这台物理机有4个MySQL实例上，pps 9万左右，9*32&#x2F;4&#x3D;72万<br><img src="/images/oss/b84245c17e213de528f2ad8090d504f6.png" alt="image.png"></p>
<p>…………（省略巨长的分析、拉人、扯皮过程）</p>
<p>最终所有网络因素都被排除，核心证据是：做压测的时候反复从 Tomcat 上 ping 后面的MySQL，RT 跟没有压力的时候一样，也说明了网络没有问题(请思考这个 ping 的作用)。</p>
<h2 id="问题的确认"><a href="#问题的确认" class="headerlink" title="问题的确认"></a>问题的确认</h2><p>尝试在Tomcat上打开日志，并将慢 SQL 阈值设置为100ms，这个时候确实能从日志中看到大量MySQL上的慢查询，因为这个SQL需要在Tomcat上做拆分成256个SQL，同时下发，一旦有一个SQL返回慢，整个请求就因为这个短板被拖累了。平均 RT  0.8ms，但是经常有超过100ms的话对整体影响还是很大的。</p>
<p>将Tomcat记录下来的慢查询（Tomcat增加了一个唯一id下发给MySQL）到MySQL日志中查找，果然发现MySQL上确实慢了，所以到这里基本确认是MySQL的问题，终于不用再纠结是否是网络问题了。</p>
<p>同时在Tomcat进行抓包，对网卡上的 RT 进行统计分析：</p>
<p><img src="/images/oss/ffd66d9a6098979b555dfb00d3494255.png" alt="image.png"></p>
<p>上是Tomcat上抓到的每个sql的物理RT 平均值，上面是QPS 430的时候， RT  0.6ms，下面是3个server，QPS为700，但是 RT 上升到了0.9ms，基本跟Tomcat监控记录到的物理RT一致。如果MySQL上也有类似抓包计算 RT 时间的话可以快速排除网络问题。</p>
<p>网络抓包得到的 RT 数据更容易被所有人接受。尝试过在MySQL上抓包，但是因为LVS模块的原因，进出端口、ip都被修改过，所以没法分析一个流的响应时间。</p>
<h2 id="重心再次转向MySQL"><a href="#重心再次转向MySQL" class="headerlink" title="重心再次转向MySQL"></a>重心再次转向MySQL</h2><p>这个时候因为问题点基本确认，再去查看MySQL是否有问题的重心都不一样了，不再只是看看CPU和慢查询，这个问题明显更复杂一些。</p>
<blockquote>
<p>教训：CPU只是影响性能的一个因素，RT 才是结果，要追着 RT 跑，而不是只看 CPU</p>
</blockquote>
<p>通过监控发现MySQL CPU虽然一直不高，但是经常看到running thread飙到100多，很快又降下去了，看起来像是突发性的并发查询请求太多导致了排队等待，每个MySQL实例是8Core的CPU，尝试将MySQL实例扩容到16Core（只是为了验证这个问题），QPS确实可以上升到1000（没有到达理想的1400）。</p>
<p>这是Tomcat上监控到的MySQL状态：<br><img src="/images/oss/e73c1371a02106a52f8a13f89a9dd9ad.png" alt="image.png"></p>
<p>同时在MySQL机器上通过vmstat也可以看到这种飙升：<br><img src="/images/oss/4dbd9dff9deacec0e9911e3a7d025578.png" alt="image.png"></p>
<p>以上分析可以清晰看到虽然 MySQL 整体压力不大，但是似乎会偶尔来一波卡顿、running 任务飙升。</p>
<p>像这种短暂突发性的并发流量似乎监控都很难看到（基本都被平均掉了），只有一些实时性监控偶尔会采集到这种短暂突发性飙升，这也导致了一开始忽视了MySQL。</p>
<p>所以接下来的核心问题就是MySQL为什么会有这种飙升、这种飙升的影响到底是什么？</p>
<h2 id="perf-top"><a href="#perf-top" class="headerlink" title="perf top"></a>perf top</h2><p>直接用 perf 看下 MySQLD 进程，发现 ut_delay 高得不符合逻辑：</p>
<p><img src="/images/oss/cd145c494c074e01e9d2d1d5583a87a0.png" alt="image.png"></p>
<p>展开看一下，基本是在优化器中做索引命中行数的选择：</p>
<img src="/images/oss/46d5f5ee5c58d7090a71164e645ccf79.png" alt="image.png" style="zoom: 67%;" />

<p>跟直接在 MySQL 命令行中通过 show processlist看到的基本一致：</p>
<img src="/images/oss/89cccebe41a8b8461ea75586b61b929f.png" alt="image.png" style="zoom:50%;" />

<p>这是 MySQL 的优化器在对索引进行统计，统计的时候要加锁，thread running 抖动的时候通过 show processlist 看到很多 thread处于 statistics 状态。也就是高并发下加锁影响了 CPU 压不上去同时 RT 剧烈增加。</p>
<p>这里ut_delay 消耗了 28% 的 CPU 肯定太不正常了，于是将 innodb_spin_wait_delay 从 30 改成 6 后性能立即上去了，继续增加 Tomcat 节点，QPS也可以线性增加。</p>
<blockquote>
<p>耗CPU最高的调用函数栈是…<code>mutex_spin_wait</code>-&gt;<code>ut_delay</code>，属于锁等待的逻辑。InnoDB在这里用的是自旋锁，锁等待是通过调用 ut_delay 让 CPU做空循环在等锁的时候不释放CPU从而避免上下文切换，会消耗比较高的CPU。</p>
</blockquote>
<h2 id="最终的性能"><a href="#最终的性能" class="headerlink" title="最终的性能"></a>最终的性能</h2><p>调整参数 innodb_spin_wait_delay&#x3D;6 后在4个Tomcat节点下，并发40时，QPS跑到了1700，物理RT：0.7，逻辑RT：19.6，cpu：90%，这个时候只需要继续扩容 Tomcat 节点的数量就可以增加QPS<br><img src="/images/oss/48c976f989747266f9892403794996c0.png" alt="image.png"></p>
<p>再跟调整前比较一下，innodb_spin_wait_delay&#x3D;30，并发40时，QPS 500+，物理RT：2.6ms 逻辑RT：72.1ms cpu：37%<br><img src="/images/oss/fdb459972926cff371f5f5ab703790bb.png" alt="image.png"></p>
<p>再看看调整前压测的时候的vmstat和tsar –cpu，可以看到process running抖动明显<br><img src="/images/oss/4dbd9dff9deacec0e9911e3a7d025578.png" alt="image.png"></p>
<p>对比修改delay后的process running就很稳定了，即使QPS大了3倍<br><img src="/images/oss/ed46d35161ea28352acd4289a3e9ddad.png" alt="image.png"></p>
<h2 id="事后思考和分析"><a href="#事后思考和分析" class="headerlink" title="事后思考和分析"></a>事后思考和分析</h2><p>到这里问题得到了完美解决，但是不禁要问为什么？ut_delay 是怎么工作的？ 和 innodb_spin_wait_delay 以及自旋锁的关系？</p>
<h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><p>既然调整 innodb_spin_wait_delay 就能解决这个问题，那就要先分析一下 innodb_spin_wait_delay 的作用</p>
<h3 id="关于-innodb-spin-wait-delay"><a href="#关于-innodb-spin-wait-delay" class="headerlink" title="关于 innodb_spin_wait_delay"></a>关于 innodb_spin_wait_delay</h3><p>innodb通过大量的自旋锁(比如 <code>InnoDB</code> <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_mutex">mutexes</a> and <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_rw_lock">rw-locks</a>)来用高CPU消耗避免上下文切换，这是自旋锁的正确使用方式，在多核场景下，它们一起自旋抢同一个锁，容易造成<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/30684974/are-cache-line-ping-pong-and-false-sharing-the-same">cache ping-pong</a>，进而多个CPU核之间会互相使对方缓存部分无效。所以这里<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-spin_lock_polling.html">innodb通过增加 innodb_spin_wait_delay 和 Pause 配合来缓解cache ping-pong</a>，也就是本来通过CPU 高速自旋抢锁，换成了抢锁失败后 delay一下（Pause）但是不释放CPU，delay 时间到后继续抢锁，也就是把连续的自旋抢锁转换成了更稀疏的点状的抢锁（间隔的 delay是个随机数），这样不但避免了上下文切换也大大减少了cache ping-pong。</p>
<h3 id="自旋锁如何减少了cache-ping-pong"><a href="#自旋锁如何减少了cache-ping-pong" class="headerlink" title="自旋锁如何减少了cache ping-pong"></a>自旋锁如何减少了cache ping-pong</h3><p>多线程竞争锁的时候，加锁失败的线程会“忙等待”，直到它拿到锁。什么叫“忙等待”呢？它并不意味着一直执行 CAS 函数，而是会与 CPU 紧密配合 ，它通过 CPU 提供的 <code>PAUSE</code> 指令，减少循环等待时的cache ping-pong和耗电量；对于单核 CPU，忙等待并没有意义，此时它会主动把线程休眠。</p>
<h3 id="X86-PAUSE-指令"><a href="#X86-PAUSE-指令" class="headerlink" title="X86 PAUSE 指令"></a>X86 PAUSE 指令</h3><p>X86设计了Pause指令，也就是调用 Pause 指令的代码会抢着 CPU 不释放，但是CPU 会打个盹，比如 10个时钟周期，相对一次上下文切换是大几千个时钟周期。</p>
<p>这样应用一旦自旋抢锁失败可以先 Pause 一下，只是这个Pause 时间对于 MySQL 来说还不够久，所以需要增加参数 innodb_spin_wait_delay 来将休息时间放大一些。</p>
<p>在我们的这个场景下对每个 SQL的 RT 抖动非常敏感（放大256倍），所以过高的 delay 会导致部分SQL  RT  变高。</p>
<p>函数 ut_delay(ut_rnd_interval(0, srv_spin_wait_delay)) 用来执行这个delay：</p>
<pre><code>/***************************MySQL代码****************************//**
Runs an idle loop on CPU. The argument gives the desired delay
in microseconds on 100 MHz Pentium + Visual C++.
@return dummy value */
UNIV_INTERN
ulint
ut_delay(ulint delay)  //delay 是[0,innodb_spin_wait_delay)之间的一个随机数
{
        ulint   i, j;

        UT_LOW_PRIORITY_CPU();

        j = 0;

        for (i = 0; i &lt; delay * 50; i++) {  //delay 放大50倍
                j += i;
                UT_RELAX_CPU();             //调用 CPU Pause
        }

        UT_RESUME_PRIORITY_CPU();

        return(j);
}
</code></pre>
<p>innodb_spin_wait_delay的默认值为6. spin 等待延迟是一个动态全局参数，您可以在MySQL选项文件（my.cnf或my.ini）中指定该参数，或者在运行时使用SET GLOBAL 来修改。在我们的MySQL配置中默认改成了30，导致了这个问题。</p>
<h3 id="CPU-为什么要有Pause"><a href="#CPU-为什么要有Pause" class="headerlink" title="CPU 为什么要有Pause"></a>CPU 为什么要有Pause</h3><p>首先可以看到 Pause 指令的作用：</p>
<ul>
<li>避免上下文切换，应用层想要休息可能会用yield、sleep，这两操作对于CPU来说太重了(伴随上下文切换)</li>
<li>能给超线程腾出计算能力（HT共享核，但是有单独的寄存器等存储单元，CPU Pause的时候，对应的HT可以占用计算资源），比如同一个core上先跑多个Pause，同时再跑 nop 指令，这时 nop指令的 IPC基本不受Pause的影响</li>
<li>节能（CPU可以休息、但是不让出来），CPU Pause 的时候你从 top 能看到 CPU 100%，但是不耗能。</li>
</ul>
<p>所以有了 Pause 指令后能够提高超线程的利用率,节能，减少上下文切换提高自旋锁的效率。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.reddit.com/r/intel/comments/hogk2n/research_on_the_impact_of_intel_Pause_instruction/">The PAUSE instruction is first introduced</a> for Intel Pentium 4 processor to improve the performance of “spin-wait loop”. The PAUSE instruction is typically used with software threads executing on two logical processors located in the same processor core, waiting for a lock to be released. Such short wait loops tend to last between tens and a few hundreds of cycles. When the wait loop is expected to last for thousands of cycles or more, it is preferable to yield to the operating system by calling one of the OS synchronization API functions, such as WaitForSingleObject on Windows OS.</p>
<p>An Intel® processor suffers a severe performance penalty when exiting the loop because it detects a possible memory order violation. The PAUSE instruction provides a hint to the processor that the code sequence is a spin-wait loop. The processor uses this hint to avoid the memory order violation in most situations. The PAUSE instruction can improve the performance of the processors supporting Intel Hyper-Threading Technology when executing “spin-wait loops”. With Pause instruction, processors are able to avoid the memory order violation and pipeline flush, and reduce power consumption through pipeline stall.</p>
</blockquote>
<p><strong>从intel sdm手册以及实际测试验证来看，Pause 指令在执行过程中，基本不占用流水线执行资源。</strong></p>
<h3 id="Skylake-架构的8163-和-Broadwell架构-E5-2682-CPU型号的不同"><a href="#Skylake-架构的8163-和-Broadwell架构-E5-2682-CPU型号的不同" class="headerlink" title="Skylake 架构的8163 和 Broadwell架构 E5-2682 CPU型号的不同"></a>Skylake 架构的8163 和 Broadwell架构 E5-2682 CPU型号的不同</h3><p>为什么用得好好的 innodb_spin_wait_delay 参数这次就不行了呢？</p>
<p>这是因为以前业务一直使用的是 E5-2682 CPU，这次用的是新一代架构的 Skylake 8163，那这两款CPU在这里的核心差别是？</p>
<p>在Intel 64-ia-32-architectures-optimization-manual手册中提到：</p>
<blockquote>
<p>The latency of the PAUSE instruction in prior generation microarchitectures is about 10 cycles, whereas in Skylake microarchitecture it has been extended to as many as 140 cycles.</p>
<p><a target="_blank" rel="noopener" href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-302.html">The PAUSE instruction can improves the performance</a> of processors supporting Intel Hyper-Threading Technology when executing “spin-wait loops” and other routines where one thread is accessing a shared lock or semaphore in a tight polling loop. When executing a spin-wait loop, the processor can suffer a severe performance penalty when exiting the loop because it detects a possible memory order violation and flushes the core processor’s pipeline. The PAUSE instruction provides a hint to the processor that the code sequence is a spin-wait loop. The processor uses this hint to avoid the memory order violation and prevent the pipeline flush. In addition, the PAUSE instruction de-<br>pipelines the spin-wait loop to prevent it from consuming execution resources excessively and consume power needlessly. (See<a target="_blank" rel="noopener" href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-305.html"> Section 8.10.6.1, “Use the PAUSE Instruction in Spin-Wait Loops,” for more </a>information about using the PAUSE instruction with IA-32 processors supporting Intel Hyper-Threading Technology.)</p>
</blockquote>
<p>也就是**Skylake架构的CPU的PAUSE指令从之前的10 cycles 改成了 140 cycles。**这可是14倍的变化呀。</p>
<p>MySQL 使用 innodb_spin_wait_delay 控制 spin lock等待时间，等待时间时间从0*50个Pause到innodb_spin_wait_delay*50个Pause。<br>以前 innodb_spin_wait_delay 默认配置30，对于E5-2682 CPU，等待的最长时间为：<br>30 * 50 * 10&#x3D;15000 cycles，对于2.5GHz的CPU，等待时间为6us。<br>对应计算 Skylake CPU的等待时间：30 *50 *140&#x3D;210000 cycles，CPU主频也是2.5GHz，等待时间84us。</p>
<p>E5-2682 CPU型号在不同的delay参数和不同并发压力下的写入性能数据：</p>
<p><img src="/images/951413iMgBlog/image-20221026153750159.png" alt="image-20221026153750159"></p>
<p>Skylake 8163 CPU型号在不同的delay参数和不同并发压力下的写入性能数据：</p>
<p><img src="/images/951413iMgBlog/image-20221026153813774.png" alt="image-20221026153813774"></p>
<p>&#x3D;&#x3D;因为8163的cycles从10改到了140，所以可以看到delay参数对性能的影响更加陡峻。&#x3D;&#x3D;</p>
<h2 id="总结分析"><a href="#总结分析" class="headerlink" title="总结分析"></a>总结分析</h2><p>Intel CPU 架构不同使得 Pause 指令的CPU Cycles不同导致了 MySQL innodb_spin_wait_delay 在 spin lock 失败的时候（此时需要 Pause* innodb_spin_wait_delay*N）delay更久，使得调用方看到了MySQL更大的 RT ，进而导致 Tomcat Server上业务并发跑不起来，所以最终压力上不去。</p>
<p>在长链路的排查中，细化定位是哪个节点出了问题是最难的，要盯住 RT 而不是 CPU。</p>
<p>欲速则不达，做压测的时候还是要老老实实地从一个并发开始观察QPS、 RT ，然后一直增加压力到压不上去了，再看QPS、 RT 变化，然后确认瓶颈点。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1005284">https://cloud.tencent.com/developer/article/1005284</a></p>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-spin_lock_polling.html">mysql doc</a></p>
<p><a target="_blank" rel="noopener" href="http://oliveryang.net/2018/01/cache-false-sharing-debug">Cache Line 伪共享发现与优化</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikichip.org/w/images/e/eb/intel-ref-248966-037.pdf">intel spec</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/dlKC13i9Z8wjDDiU2tig6Q">Intel PAUSE指令变化影响到MySQL的性能，该如何解决？</a></p>
<p><a target="_blank" rel="noopener" href="https://topic.atatech.org/articles/173194">ARM软硬件协同设计：锁优化</a>, arm不同于x86，用的是yield来代替Pause</p>
<p><a target="_blank" rel="noopener" href="http://cr.openjdk.java.net/~dchuyko/8186670/yield/spinwait.html">http://cr.openjdk.java.net/~dchuyko/8186670/yield/spinwait.html</a></p>
<p><a target="_blank" rel="noopener" href="https://aloiskraus.wordpress.com/2018/06/16/why-skylakex-cpus-are-sometimes-50-slower-how-intel-has-broken-existing-code/">https://aloiskraus.wordpress.com/2018/06/16/why-skylakex-cpus-are-sometimes-50-slower-how-intel-has-broken-existing-code/</a> Windows+.NET 平台下的分析过程及修复方案</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8DMySQL%E7%9A%84%E6%80%A7%E8%83%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8DMySQL%E7%9A%84%E6%80%A7%E8%83%BD/" class="post-title-link" itemprop="url">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-16 12:30:03" itemprop="dateCreated datePublished" datetime="2019-12-16T12:30:03+08:00">2019-12-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CPU/" itemprop="url" rel="index"><span itemprop="name">CPU</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Intel-PAUSE指令变化如何影响MySQL的性能"><a href="#Intel-PAUSE指令变化如何影响MySQL的性能" class="headerlink" title="Intel PAUSE指令变化如何影响MySQL的性能"></a>Intel PAUSE指令变化如何影响MySQL的性能</h1><h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p>x86、arm指令都很多，无论是应用程序员还是数据库内核研发大多时候都不需要对这些指令深入理解，但是 Pause 指令和数据库操作太紧密了，本文通过一次非常有趣的性能优化来引入对 Pause 指令的理解，期望可以事半功倍地搞清楚 CPU指令集是如何影响你的程序的。</p>
<p>文章分成两大部分，第一部分是 MySQL 集群的一次全表扫描性能优化过程； 第二部分是问题解决后的原理分析以及Pause指令的来龙去脉和优缺点以及应用场景分析。</p>
<h2 id="业务结构"><a href="#业务结构" class="headerlink" title="业务结构"></a>业务结构</h2><p>为理解方便做了部分简化：</p>
<p>client -&gt; Tomcat -&gt; LVS -&gt; MySQL（32 个 MySQLD实例集群，每个实例8Core）</p>
<h2 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h2><p>业务按照 个人分库+单位分表: 32个RDS * 8个分库   * 4张分表&#x3D;1024分表， 也就是 256个分库，每个分库4张表</p>
<p>通过 client 压 Tomcat 和 MySQL 集群（对数据做分库分表），MySQL 集群是32个实例，每个业务 SQL 都需要经过 Tomcat 拆分成 256 个 SQL 发送给 32 个MySQL 实例（每个MySQL 实例上有8个分库），这 256 条下发给 MySQL 的 SQL 不是完全串行，但也不是完全并行，有一定的并行性。</p>
<p>业务 SQL 如下是一个简单的select sum求和，这个 SQL在每个MySQL上都很快（有索引）</p>
<pre><code>SELECT SUM(emp_arr_amt) FROM table_c WHERE INSUTYPE=&#39;310&#39; AND Revs_Flag=&#39;Z&#39; AND accrym=&#39;201910&#39; AND emp_no=&#39;1050457&#39;;
</code></pre>
<h2 id="监控指标说明"><a href="#监控指标说明" class="headerlink" title="监控指标说明"></a>监控指标说明</h2><ul>
<li>后述或者截图中的逻辑RT&#x2F;QPS是指 client 上看到的Tomcat的 RT 和 QPS； </li>
<li>RT ：response time 请求响应时间，判断性能瓶颈的唯一指标;</li>
<li>物理RT&#x2F;QPS是指Tomcat看到的MySQL  RT 和QPS（这里的 RT 是指到达Tomcat节点网卡的 RT ，所以还包含了网络消耗）</li>
</ul>
<h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><p>通过client压一个Tomcat节点+32个MySQL，QPS大概是430，Tomcat节点CPU跑满，MySQL  RT 是0.5ms，增加一个Tomcat节点，QPS大概是700，Tomcat CPU接近跑满，MySQL  RT 是0.6ms，到这里性能基本随着扩容线性增加，是符合预期的。</p>
<p>继续增加Tomcat节点来横向扩容性能，通过client压三个Tomcat节点+32个MySQL，QPS还是700，Tomcat节点CPU跑不满，MySQL  RT 是0.8ms，这就严重不符合预期了。</p>
<p>性能压测原则：</p>
<blockquote>
<p>加并发QPS不再上升说明到了某个瓶颈，哪个环节RT增加最多瓶颈就在哪里</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20221026145848312.png" alt="image-20221026145848312"></p>
<p><strong>到这里一切都还是符合我们的经验的，看起来就是 MySQL 有瓶颈（RT 增加明显）。</strong></p>
<h2 id="排查-MySQL"><a href="#排查-MySQL" class="headerlink" title="排查 MySQL"></a>排查 MySQL</h2><p>现场DBA通过监控看到MySQL CPU不到20%，没有慢查询，并且尝试用client越过所有中间环节直接压其中一个MySQL，可以将 MySQL CPU 跑满，这时的QPS大概是38000（对应上面的场景client QPS为700的时候，单个MySQL上的QPS才跑到6000) 所以排除了MySQL的嫌疑(这个推理不够严谨为后面排查埋下了大坑)。</p>
<p>那么接下来的嫌疑在网络、LVS 等中间环节上。</p>
<h2 id="LVS和网络的嫌疑"><a href="#LVS和网络的嫌疑" class="headerlink" title="LVS和网络的嫌疑"></a>LVS和网络的嫌疑</h2><p>首先通过大查询排除了带宽的问题，因为这里都是小包，pps到了72万，很自然想到了网关、LVS的限流之类的</p>
<p>pps监控，这台物理机有4个MySQL实例上，pps 9万左右，9*32&#x2F;4&#x3D;72万<br><img src="/images/oss/b84245c17e213de528f2ad8090d504f6.png" alt="image.png"></p>
<p>…………（省略巨长的分析、拉人、扯皮过程）</p>
<p>最终所有网络因素都被排除，核心证据是：做压测的时候反复从 Tomcat 上 ping 后面的MySQL，RT 跟没有压力的时候一样，也说明了网络没有问题(请思考这个 ping 的作用)。</p>
<h2 id="问题的确认"><a href="#问题的确认" class="headerlink" title="问题的确认"></a>问题的确认</h2><p>尝试在Tomcat上打开日志，并将慢 SQL 阈值设置为100ms，这个时候确实能从日志中看到大量MySQL上的慢查询，因为这个SQL需要在Tomcat上做拆分成256个SQL，同时下发，一旦有一个SQL返回慢，整个请求就因为这个短板被拖累了。平均 RT  0.8ms，但是经常有超过100ms的话对整体影响还是很大的。</p>
<p>将Tomcat记录下来的慢查询（Tomcat增加了一个唯一id下发给MySQL）到MySQL日志中查找，果然发现MySQL上确实慢了，所以到这里基本确认是MySQL的问题，终于不用再纠结是否是网络问题了。</p>
<p>同时在Tomcat进行抓包，对网卡上的 RT 进行统计分析：</p>
<p><img src="/images/oss/ffd66d9a6098979b555dfb00d3494255.png" alt="image.png"></p>
<p>上是Tomcat上抓到的每个sql的物理RT 平均值，上面是QPS 430的时候， RT  0.6ms，下面是3个server，QPS为700，但是 RT 上升到了0.9ms，基本跟Tomcat监控记录到的物理RT一致。如果MySQL上也有类似抓包计算 RT 时间的话可以快速排除网络问题。</p>
<p>网络抓包得到的 RT 数据更容易被所有人接受。尝试过在MySQL上抓包，但是因为LVS模块的原因，进出端口、ip都被修改过，所以没法分析一个流的响应时间。</p>
<h2 id="重心再次转向MySQL"><a href="#重心再次转向MySQL" class="headerlink" title="重心再次转向MySQL"></a>重心再次转向MySQL</h2><p>这个时候因为问题点基本确认，再去查看MySQL是否有问题的重心都不一样了，不再只是看看CPU和慢查询，这个问题明显更复杂一些。</p>
<blockquote>
<p>教训：CPU只是影响性能的一个因素，RT 才是结果，要追着 RT 跑，而不是只看 CPU</p>
</blockquote>
<p>通过监控发现MySQL CPU虽然一直不高，但是经常看到running thread飙到100多，很快又降下去了，看起来像是突发性的并发查询请求太多导致了排队等待，每个MySQL实例是8Core的CPU，尝试将MySQL实例扩容到16Core（只是为了验证这个问题），QPS确实可以上升到1000（没有到达理想的1400）。</p>
<p>这是Tomcat上监控到的MySQL状态：<br><img src="/images/oss/e73c1371a02106a52f8a13f89a9dd9ad.png" alt="image.png"></p>
<p>同时在MySQL机器上通过vmstat也可以看到这种飙升：<br><img src="/images/oss/4dbd9dff9deacec0e9911e3a7d025578.png" alt="image.png"></p>
<p>以上分析可以清晰看到虽然 MySQL 整体压力不大，但是似乎会偶尔来一波卡顿、running 任务飙升。</p>
<p>像这种短暂突发性的并发流量似乎监控都很难看到（基本都被平均掉了），只有一些实时性监控偶尔会采集到这种短暂突发性飙升，这也导致了一开始忽视了MySQL。</p>
<p>所以接下来的核心问题就是MySQL为什么会有这种飙升、这种飙升的影响到底是什么？</p>
<h2 id="perf-top"><a href="#perf-top" class="headerlink" title="perf top"></a>perf top</h2><p>直接用 perf 看下 MySQLD 进程，发现 ut_delay 高得不符合逻辑：</p>
<p><img src="/images/oss/cd145c494c074e01e9d2d1d5583a87a0.png" alt="image.png"></p>
<p>展开看一下，基本是在优化器中做索引命中行数的选择：</p>
<img src="/images/oss/46d5f5ee5c58d7090a71164e645ccf79.png" alt="image.png" style="zoom: 67%;" />

<p>跟直接在 MySQL 命令行中通过 show processlist看到的基本一致：</p>
<img src="/images/oss/89cccebe41a8b8461ea75586b61b929f.png" alt="image.png" style="zoom:50%;" />

<p>这是 MySQL 的优化器在对索引进行统计，统计的时候要加锁，thread running 抖动的时候通过 show processlist 看到很多 thread处于 statistics 状态。也就是高并发下加锁影响了 CPU 压不上去同时 RT 剧烈增加。</p>
<p>这里ut_delay 消耗了 28% 的 CPU 肯定太不正常了，于是将 innodb_spin_wait_delay 从 30 改成 6 后性能立即上去了，继续增加 Tomcat 节点，QPS也可以线性增加。</p>
<blockquote>
<p>耗CPU最高的调用函数栈是…<code>mutex_spin_wait</code>-&gt;<code>ut_delay</code>，属于锁等待的逻辑。InnoDB在这里用的是自旋锁，锁等待是通过调用 ut_delay 让 CPU做空循环在等锁的时候不释放CPU从而避免上下文切换，会消耗比较高的CPU。</p>
</blockquote>
<h2 id="最终的性能"><a href="#最终的性能" class="headerlink" title="最终的性能"></a>最终的性能</h2><p>调整参数 innodb_spin_wait_delay&#x3D;6 后在4个Tomcat节点下，并发40时，QPS跑到了1700，物理RT：0.7，逻辑RT：19.6，cpu：90%，这个时候只需要继续扩容 Tomcat 节点的数量就可以增加QPS<br><img src="/images/oss/48c976f989747266f9892403794996c0.png" alt="image.png"></p>
<p>再跟调整前比较一下，innodb_spin_wait_delay&#x3D;30，并发40时，QPS 500+，物理RT：2.6ms 逻辑RT：72.1ms cpu：37%<br><img src="/images/oss/fdb459972926cff371f5f5ab703790bb.png" alt="image.png"></p>
<p>再看看调整前压测的时候的vmstat和tsar –cpu，可以看到process running抖动明显<br><img src="/images/oss/4dbd9dff9deacec0e9911e3a7d025578.png" alt="image.png"></p>
<p>对比修改delay后的process running就很稳定了，即使QPS大了3倍<br><img src="/images/oss/ed46d35161ea28352acd4289a3e9ddad.png" alt="image.png"></p>
<h2 id="事后思考和分析"><a href="#事后思考和分析" class="headerlink" title="事后思考和分析"></a>事后思考和分析</h2><p>到这里问题得到了完美解决，但是不禁要问为什么？ut_delay 是怎么工作的？ 和 innodb_spin_wait_delay 以及自旋锁的关系？</p>
<h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><p>既然调整 innodb_spin_wait_delay 就能解决这个问题，那就要先分析一下 innodb_spin_wait_delay 的作用</p>
<h3 id="关于-innodb-spin-wait-delay"><a href="#关于-innodb-spin-wait-delay" class="headerlink" title="关于 innodb_spin_wait_delay"></a>关于 innodb_spin_wait_delay</h3><p>innodb通过大量的自旋锁(比如 <code>InnoDB</code> <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_mutex">mutexes</a> and <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_rw_lock">rw-locks</a>)来用高CPU消耗避免上下文切换，这是自旋锁的正确使用方式，在多核场景下，它们一起自旋抢同一个锁，容易造成<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/30684974/are-cache-line-ping-pong-and-false-sharing-the-same">cache ping-pong</a>，进而多个CPU核之间会互相使对方缓存部分无效。所以这里<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-spin_lock_polling.html">innodb通过增加 innodb_spin_wait_delay 和 Pause 配合来缓解cache ping-pong</a>，也就是本来通过CPU 高速自旋抢锁，换成了抢锁失败后 delay一下（Pause）但是不释放CPU，delay 时间到后继续抢锁，也就是把连续的自旋抢锁转换成了更稀疏的点状的抢锁（间隔的 delay是个随机数），这样不但避免了上下文切换也大大减少了cache ping-pong。</p>
<h3 id="自旋锁如何减少了cache-ping-pong"><a href="#自旋锁如何减少了cache-ping-pong" class="headerlink" title="自旋锁如何减少了cache ping-pong"></a>自旋锁如何减少了cache ping-pong</h3><p>多线程竞争锁的时候，加锁失败的线程会“忙等待”，直到它拿到锁。什么叫“忙等待”呢？它并不意味着一直执行 CAS 函数，而是会与 CPU 紧密配合 ，它通过 CPU 提供的 <code>PAUSE</code> 指令，减少循环等待时的cache ping-pong和耗电量；对于单核 CPU，忙等待并没有意义，此时它会主动把线程休眠。</p>
<h3 id="X86-PAUSE-指令"><a href="#X86-PAUSE-指令" class="headerlink" title="X86 PAUSE 指令"></a>X86 PAUSE 指令</h3><p>X86设计了Pause指令，也就是调用 Pause 指令的代码会抢着 CPU 不释放，但是CPU 会打个盹，比如 10个时钟周期，相对一次上下文切换是大几千个时钟周期。</p>
<p>这样应用一旦自旋抢锁失败可以先 Pause 一下，只是这个Pause 时间对于 MySQL 来说还不够久，所以需要增加参数 innodb_spin_wait_delay 来将休息时间放大一些。</p>
<p>在我们的这个场景下对每个 SQL的 RT 抖动非常敏感（放大256倍），所以过高的 delay 会导致部分SQL  RT  变高。</p>
<p>函数 ut_delay(ut_rnd_interval(0, srv_spin_wait_delay)) 用来执行这个delay：</p>
<pre><code>/***************************MySQL代码****************************/
/**Runs an idle loop on CPU. The argument gives the desired delay
in microseconds on 100 MHz Pentium + Visual C++.
@return dummy value */
UNIV_INTERN
ulint
ut_delay(ulint delay)  //delay 是[0,innodb_spin_wait_delay)之间的一个随机数
{
        ulint   i, j;
        UT_LOW_PRIORITY_CPU();
        j = 0;

        for (i = 0; i &lt; delay * 50; i++) {  //delay 放大50倍
                j += i;
                UT_RELAX_CPU();             //调用 CPU Pause
        }

        UT_RESUME_PRIORITY_CPU();
        return(j);
}
</code></pre>
<p>innodb_spin_wait_delay的默认值为6. spin 等待延迟是一个动态全局参数，可以在MySQL选项文件（my.cnf或my.ini）中指定该参数，或者在运行时使用SET GLOBAL 来修改。在我们的MySQL配置中默认改成了30，导致了这个问题。</p>
<h3 id="CPU-为什么要有Pause"><a href="#CPU-为什么要有Pause" class="headerlink" title="CPU 为什么要有Pause"></a>CPU 为什么要有Pause</h3><p>首先可以看到 Pause 指令的作用：</p>
<ul>
<li>避免上下文切换，应用层想要休息可能会用yield、sleep，这两操作对于CPU来说太重了(伴随上下文切换)</li>
<li>能给超线程腾出计算能力（HT共享核，但是有单独的寄存器等存储单元，CPU Pause的时候，对应的HT可以占用计算资源），比如同一个core上先跑多个Pause，同时再跑 nop 指令，这时 nop指令的 IPC基本不受Pause的影响</li>
<li>节能（CPU可以休息、但是不让出来），CPU Pause 的时候你从 top 能看到 CPU 100%，但是不耗能。</li>
</ul>
<p>所以有了 Pause 指令后能够提高超线程的利用率,节能，减少上下文切换提高自旋锁的效率。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.reddit.com/r/intel/comments/hogk2n/research_on_the_impact_of_intel_Pause_instruction/">The PAUSE instruction is first introduced</a> for Intel Pentium 4 processor to improve the performance of “spin-wait loop”. The PAUSE instruction is typically used with software threads executing on two logical processors located in the same processor core, waiting for a lock to be released. Such short wait loops tend to last between tens and a few hundreds of cycles. When the wait loop is expected to last for thousands of cycles or more, it is preferable to yield to the operating system by calling one of the OS synchronization API functions, such as WaitForSingleObject on Windows OS.</p>
<p>An Intel® processor suffers a severe performance penalty when exiting the loop because it detects a possible memory order violation. The PAUSE instruction provides a hint to the processor that the code sequence is a spin-wait loop. The processor uses this hint to avoid the memory order violation in most situations. The PAUSE instruction can improve the performance of the processors supporting Intel Hyper-Threading Technology when executing “spin-wait loops”. With Pause instruction, processors are able to avoid the memory order violation and pipeline flush, and reduce power consumption through pipeline stall.</p>
</blockquote>
<p><strong>从intel sdm手册以及实际测试验证来看，Pause 指令在执行过程中，基本不占用流水线执行资源。</strong></p>
<h3 id="Skylake-架构的8163-和-Broadwell架构-E5-2682-CPU型号的不同"><a href="#Skylake-架构的8163-和-Broadwell架构-E5-2682-CPU型号的不同" class="headerlink" title="Skylake 架构的8163 和 Broadwell架构 E5-2682 CPU型号的不同"></a>Skylake 架构的8163 和 Broadwell架构 E5-2682 CPU型号的不同</h3><p>为什么用得好好的 innodb_spin_wait_delay 参数这次就不行了呢？</p>
<p>这是因为以前业务一直使用的是 E5-2682 CPU，这次用的是新一代架构的 Skylake 8163，那这两款CPU在这里的核心差别是？</p>
<p>在Intel 64-ia-32-architectures-optimization-manual手册中提到：</p>
<blockquote>
<p>The latency of the PAUSE instruction in prior generation microarchitectures is about 10 cycles, whereas in Skylake microarchitecture it has been extended to as many as 140 cycles.</p>
<p><a target="_blank" rel="noopener" href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-302.html">The PAUSE instruction can improves the performance</a> of processors supporting Intel Hyper-Threading Technology when executing “spin-wait loops” and other routines where one thread is accessing a shared lock or semaphore in a tight polling loop. When executing a spin-wait loop, the processor can suffer a severe performance penalty when exiting the loop because it detects a possible memory order violation and flushes the core processor’s pipeline. The PAUSE instruction provides a hint to the processor that the code sequence is a spin-wait loop. The processor uses this hint to avoid the memory order violation and prevent the pipeline flush. In addition, the PAUSE instruction de-<br>pipelines the spin-wait loop to prevent it from consuming execution resources excessively and consume power needlessly. (See<a target="_blank" rel="noopener" href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-305.html"> Section 8.10.6.1, “Use the PAUSE Instruction in Spin-Wait Loops,” for more </a>information about using the PAUSE instruction with IA-32 processors supporting Intel Hyper-Threading Technology.)</p>
</blockquote>
<p>也就是**Skylake架构的CPU的PAUSE指令从之前的10 cycles 改成了 140 cycles。**这可是14倍的变化呀。</p>
<p>MySQL 使用 innodb_spin_wait_delay 控制 spin lock等待时间，等待时间时间从0*50个Pause到innodb_spin_wait_delay*50个Pause。<br>以前 innodb_spin_wait_delay 默认配置30，对于E5-2682 CPU，等待的最长时间为：<br>30 * 50 * 10&#x3D;15000 cycles，对于2.5GHz的CPU，等待时间为6us。<br>对应计算 Skylake CPU的等待时间：30 *50 *140&#x3D;210000 cycles，CPU主频也是2.5GHz，等待时间84us。</p>
<p>E5-2682 CPU型号在不同的delay参数和不同并发压力下的写入性能数据：</p>
<p><img src="/images/951413iMgBlog/image-20221026153750159.png" alt="image-20221026153750159"></p>
<p>Skylake 8163 CPU型号在不同的delay参数和不同并发压力下的写入性能数据：</p>
<p><img src="/images/951413iMgBlog/image-20221026153813774.png" alt="image-20221026153813774"></p>
<p>&#x3D;&#x3D;因为8163的cycles从10改到了140，所以可以看到delay参数对性能的影响更加陡峻。&#x3D;&#x3D;</p>
<h2 id="总结分析"><a href="#总结分析" class="headerlink" title="总结分析"></a>总结分析</h2><p>Intel CPU 架构不同使得 Pause 指令的CPU Cycles不同导致了 MySQL innodb_spin_wait_delay 在 spin lock 失败的时候（此时需要 Pause* innodb_spin_wait_delay*N）delay更久，使得调用方看到了MySQL更大的 RT ，进而导致 Tomcat Server上业务并发跑不起来，所以最终压力上不去。</p>
<p>在长链路的排查中，细化定位是哪个节点出了问题是最难的，要盯住 RT 而不是 CPU。</p>
<p>欲速则不达，做压测的时候还是要老老实实地从一个并发开始观察QPS、 RT ，然后一直增加压力到压不上去了，再看QPS、 RT 变化，然后确认瓶颈点。</p>
<h2 id="我想追加几个问题帮大家理解"><a href="#我想追加几个问题帮大家理解" class="headerlink" title="我想追加几个问题帮大家理解"></a>我想追加几个问题帮大家理解</h2><h3 id="为什么要有自旋锁-内核里面的spinlock"><a href="#为什么要有自旋锁-内核里面的spinlock" class="headerlink" title="为什么要有自旋锁(内核里面的spinlock)?"></a>为什么要有自旋锁(内核里面的spinlock)?</h3><p>等锁的时候可以释放CPU进入等待，这叫悲观锁，代价是释放CPU必然导致上下文切换，一次上下文切换至少需要几千个时钟周期，也就是CPU需要几千个时钟周期来完成上下文切换的工作(几千个时钟周期没有产出–真浪费)</p>
<p>或者等锁的时候不释放CPU，赌很快能等到锁，这叫乐观锁，Linux OS用的是spinlock（类似大家看到的CAS），也就是CPU不释放一直不停地检查能否拿到锁，一个时钟周期检查一次太快了(想想你去银行柜台办业务，每秒钟问一次柜员轮到你了没有！)，所以CPU工程师就在想能不能提供一条指令一直占着CPU很久，这条指令就是pause，每一个spinlock就会调用pause休息几十、几百个时钟周期后再去看看能否抢到所(柜台给你提供了沙发茶水，你坐一会再去问柜员)</p>
<h3 id="执行Pause指令的时候CPU真的休息了吗？"><a href="#执行Pause指令的时候CPU真的休息了吗？" class="headerlink" title="执行Pause指令的时候CPU真的休息了吗？"></a>执行Pause指令的时候CPU真的休息了吗？</h3><p>如果没有事情做的话，CPU是会停下来(省电)，如果开了超线程，如果一个核执行了Pause，那么对这个核的另一个超线程来说，白捡了100%的CPU，别人休息（Pause、stall）的时候正好给我用(这是超线程的本质)！</p>
<p>这也是为什么有些场景2个超线程能发挥2倍能力，有些场景2个超线程只能跑出1倍能力。</p>
<p>相对比上下文切换浪费的几千个时钟周期，Pause(spinlock)真是一点都没浪费。但如果你一直spinlock 几万、几十万个时钟周期都没等到锁还不释放也不对，这会导致其他线程调度不到CPU而饿死。一般自旋一段时间后都会放弃CPU转为上下文切换，所以MySQL 加了参数 innodb_spin_wait_delay 来控制spinlock的长短。</p>
<h3 id="并发高导致自旋锁效率低？"><a href="#并发高导致自旋锁效率低？" class="headerlink" title="并发高导致自旋锁效率低？"></a>并发高导致自旋锁效率低？</h3><p>如果并发高，都抢同一个锁，这里的效率会随着并发的增加而降低，不展开了，记住这个结论，类似太多人在柜台问轮到自己没有，留给柜员办业务的时间反而少了！</p>
<h2 id="ARM"><a href="#ARM" class="headerlink" title="ARM"></a><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/70810121/why-does-hintspin-loop-use-isb-on-aarch64">ARM</a></h2><p>ARM 指令集中有 nop 来让流水线空转一个时钟周期，汇编里面的 yield 命令底层就是执行 nop 来达到目的，但是这还不够好，在64位的ARM 指令集里面增加了 <a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/ddi0596/2021-06/Base-Instructions/ISB--Instruction-Synchronization-Barrier-">ISB (instruction synchronization barrier)</a> 来<a target="_blank" rel="noopener" href="https://github.com/rust-lang/rust/commit/c064b6560b7ce0adeb9bbf5d7dcf12b1acb0c807">实现类似 Pause 的作用</a> ：</p>
<blockquote>
<p>On arm64 we have seen on several databases that ISB (instruction synchronization barrier) is better to use than yield in a spin loop. The yield instruction is a nop. The isb instruction puts the processor to sleep for some short time. isb is a good equivalent to the pause instruction on x86.</p>
</blockquote>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a><a target="_blank" rel="noopener" href="https://github.com/rust-lang/rust/commit/c064b6560b7ce0adeb9bbf5d7dcf12b1acb0c807">对比</a></h3><p>Below is an experiment that shows the effects of yield and isb on Arm64 and the<br>time of a pause instruction on x86 Intel processors.  The micro-benchmarks use<br><a target="_blank" rel="noopener" href="https://github.com/google/benchmark.git">https://github.com/google/benchmark.git</a></p>
<p>测试代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cat a.cc</span><br><span class="line">static void BM_scalar_increment(benchmark::State&amp; state) &#123;</span><br><span class="line">  int i = 0;</span><br><span class="line">  for (auto _ : state)</span><br><span class="line">    benchmark::DoNotOptimize(i++);</span><br><span class="line">&#125;</span><br><span class="line">BENCHMARK(BM_scalar_increment);</span><br><span class="line">static void BM_yield(benchmark::State&amp; state) &#123;</span><br><span class="line">  for (auto _ : state)</span><br><span class="line">    asm volatile(&quot;yield&quot;::);</span><br><span class="line">&#125;</span><br><span class="line">BENCHMARK(BM_yield);</span><br><span class="line">static void BM_isb(benchmark::State&amp; state) &#123;</span><br><span class="line">  for (auto _ : state)</span><br><span class="line">    asm volatile(&quot;isb&quot;::);</span><br><span class="line">&#125;</span><br><span class="line">BENCHMARK(BM_isb);</span><br><span class="line">BENCHMARK_MAIN();</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ g++ -o run a.cc -O2 -lbenchmark -lpthread</span><br><span class="line">$ ./run</span><br><span class="line">--------------------------------------------------------------</span><br><span class="line">Benchmark                    Time             CPU   Iterations</span><br><span class="line">--------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">AWS Graviton2 (Neoverse-N1) processor:</span><br><span class="line">BM_scalar_increment      0.485 ns        0.485 ns   1000000000</span><br><span class="line">BM_yield                 0.400 ns        0.400 ns   1000000000</span><br><span class="line">BM_isb                    13.2 ns         13.2 ns     52993304</span><br><span class="line"></span><br><span class="line">AWS Graviton (A-72) processor:</span><br><span class="line">BM_scalar_increment      0.897 ns        0.874 ns    801558633</span><br><span class="line">BM_yield                 0.877 ns        0.875 ns    800002377</span><br><span class="line">BM_isb                    13.0 ns         12.7 ns     55169412</span><br><span class="line"></span><br><span class="line">Apple Arm64 M1 processor:</span><br><span class="line">BM_scalar_increment      0.315 ns        0.315 ns   1000000000</span><br><span class="line">BM_yield                 0.313 ns        0.313 ns   1000000000</span><br><span class="line">BM_isb                    9.06 ns         9.06 ns     77259282</span><br><span class="line"></span><br><span class="line">static void BM_pause(benchmark::State&amp; state) &#123;</span><br><span class="line">  for (auto _ : state)</span><br><span class="line">    asm volatile(&quot;pause&quot;::);</span><br><span class="line">&#125;</span><br><span class="line">BENCHMARK(BM_pause);</span><br><span class="line"></span><br><span class="line">Intel Skylake processor:</span><br><span class="line">BM_scalar_increment      0.295 ns        0.295 ns   1000000000</span><br><span class="line">BM_pause                  41.7 ns         41.7 ns     16780553</span><br><span class="line"></span><br><span class="line">Tested on Graviton2 aarch64-linux with `./x.py test`.</span><br></pre></td></tr></table></figure>

<p>依照如上测试结果可以看出在 ARM 指令集下一次 yield 基本耗费一个时钟周期，但是一次 isb 需要 20-30 个时钟周期，而在intel Skylate 下一次Pause 需要140个时钟周期</p>
<p>所以MySQL 的 <a target="_blank" rel="noopener" href="https://bugs.mysql.com/bug.php?id=100664#:~:text=better%20user%20experience.-,isb,-%3A%0AThe%20pause%20instruction">aarch64 版本在2020年也终于进行了改进</a> </p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1005284">https://cloud.tencent.com/developer/article/1005284</a></p>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-spin_lock_polling.html">mysql doc</a></p>
<p><a target="_blank" rel="noopener" href="http://oliveryang.net/2018/01/cache-false-sharing-debug">Cache Line 伪共享发现与优化</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikichip.org/w/images/e/eb/intel-ref-248966-037.pdf">intel spec</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/dlKC13i9Z8wjDDiU2tig6Q">Intel PAUSE指令变化影响到MySQL的性能，该如何解决？</a></p>
<p><a target="_blank" rel="noopener" href="https://topic.atatech.org/articles/173194">ARM软硬件协同设计：锁优化</a>, arm不同于x86，用的是yield、ISB 来代替Pause</p>
<p><a target="_blank" rel="noopener" href="http://cr.openjdk.java.net/~dchuyko/8186670/yield/spinwait.html">http://cr.openjdk.java.net/~dchuyko/8186670/yield/spinwait.html</a></p>
<p><a target="_blank" rel="noopener" href="https://aloiskraus.wordpress.com/2018/06/16/why-skylakex-cpus-are-sometimes-50-slower-how-intel-has-broken-existing-code/">https://aloiskraus.wordpress.com/2018/06/16/why-skylakex-cpus-are-sometimes-50-slower-how-intel-has-broken-existing-code/</a> Windows+.NET 平台下的分析过程及修复方案</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/12/09/epoll%E7%9A%84LT%E5%92%8CET/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/09/epoll%E7%9A%84LT%E5%92%8CET/" class="post-title-link" itemprop="url">epoll的LT和ET</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-09 12:30:03" itemprop="dateCreated datePublished" datetime="2019-12-09T12:30:03+08:00">2019-12-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-29 15:19:06" itemprop="dateModified" datetime="2025-11-29T15:19:06+08:00">2025-11-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="epoll的LT和ET"><a href="#epoll的LT和ET" class="headerlink" title="epoll的LT和ET"></a>epoll的LT和ET</h1><ul>
<li><p>LT水平触发(翻译为 条件触发 更合适） </p>
<blockquote>
<p>如果事件来了，不管来了几个，只要仍然有未处理的事件，epoll都会通知你。比如来了，打印一行通知，但是不去处理事件，那么会不停滴打印通知。水平触发模式的 epoll 的扩展性很差。</p>
</blockquote>
</li>
<li><p>ET边沿触发 </p>
<blockquote>
<p>  如果事件来了，不管来了几个，你若不处理或者没有处理完，除非下一个事件到来，否则epoll将不会再通知你。 比如事件来了，打印一行通知，但是不去处理事件，那么不再通知，除非下个事件来了</p>
</blockquote>
</li>
</ul>
<p>LT比ET会多一次重新加入就绪队列的动作，也就是意味着一定有一次poll不到东西，效率是有影响但是队列长度有限所以基本可以不用考虑。但是LT编程方式上要简单多了，所以LT也是默认的。</p>
<p>举个 🌰：你有急事打电话找人，如果对方一直不接，那你只有一直打，直到他接电话为止，这就是 lt 模式；如果不急，电话打过去对方不接，那就等有空再打，这就是 et 模式。</p>
<p><img src="/images/951413iMgBlog/1732793220279-61c6e613-481e-4c90-bd01-80bbb9851cc9.png" alt="img"></p>
<h3 id="条件触发的问题：不必要的唤醒"><a href="#条件触发的问题：不必要的唤醒" class="headerlink" title="条件触发的问题：不必要的唤醒"></a>条件触发的问题：不必要的唤醒</h3><ol>
<li>内核：收到一个新建连接的请求</li>
<li>内核：由于 “惊群效应” ，唤醒两个正在 epoll_wait() 的线程 A 和线程 B</li>
<li>线程A：epoll_wait() 返回</li>
<li>线程B：epoll_wait() 返回</li>
<li>线程A：执行 accept() 并且成功</li>
<li>线程B：执行 accept() 失败，accept() 返回 EAGAIN</li>
</ol>
<h3 id="边缘触发的问题：不必要的唤醒以及饥饿"><a href="#边缘触发的问题：不必要的唤醒以及饥饿" class="headerlink" title="边缘触发的问题：不必要的唤醒以及饥饿"></a>边缘触发的问题：不必要的唤醒以及饥饿</h3><p>不必要的唤醒：</p>
<ol>
<li>内核：收到第一个连接请求。线程 A 和 线程 B 两个线程都在 epoll_wait() 上等待。由于采用边缘触发模式，所以只有一个线程会收到通知。这里假定线程 A 收到通知</li>
<li>线程A：epoll_wait() 返回</li>
<li>线程A：调用 accpet() 并且成功</li>
<li>内核：此时 accept queue 为空，所以将边缘触发的 socket 的状态从可读置成不可读</li>
<li>内核：收到第二个建连请求</li>
<li>内核：此时，由于线程 A 还在执行 accept() 处理，只剩下线程 B 在等待 epoll_wait()，于是唤醒线程 B</li>
<li>线程A：继续执行 accept() 直到返回 EAGAIN</li>
<li>线程B：执行 accept()，并返回 EAGAIN，此时线程 B 可能有点困惑(“明明通知我有事件，结果却返回 EAGAIN”)</li>
<li>线程A：再次执行 accept()，这次终于返回 EAGAIN</li>
</ol>
<p>饥饿：</p>
<ol>
<li>内核：接收到两个建连请求。线程 A 和 线程 B 两个线程都在等在 epoll_wait()。由于采用边缘触发模式，只有一个线程会被唤醒，我们这里假定线程 A 先被唤醒</li>
<li>线程A：epoll_wait() 返回</li>
<li>线程A：调用 accpet() 并且成功</li>
<li>内核：收到第三个建连请求。由于线程 A 还没有处理完(没有返回 EAGAIN)，当前 socket 还处于可读的状态，由于是边缘触发模式，所有不会产生新的事件</li>
<li>线程A：继续执行 accept() 希望返回 EAGAIN 再进入 epoll_wait() 等待，然而它又 accept() 成功并处理了一个新连接</li>
<li>内核：又收到了第四个建连请求</li>
<li>线程A：又继续执行 accept()，结果又返回成功</li>
</ol>
<p>ET的话会要求应用一直要把消息处理完毕，比如nginx用ET模式，来了一个上传大文件并压缩的任务，会造成这么一个循环：</p>
<blockquote>
<p>nginx读数据（未读完）-&gt;Gzip(需要时间，套接字又有数据过来)-&gt;读数据（未读完）-&gt;Gzip …..</p>
</blockquote>
<p>新的accpt进来，因为前一个nginx worker已经被唤醒并且还在read(这个时候内核因为accept queue为空所以已经将socket设置成不可读），所以即使其它worker 被唤醒，看到的也是一个不可读的socket，所以很快因为EAGAIN返回了。</p>
<p>这样就会造成nginx的这个worker假死了一样。如果上传速度慢，这个循环无法持续存在，也就是一旦读完nginx切走（再有数据进来等待下次触发），不会造成假死。</p>
<p>JDK中的NIO是条件触发（level-triggered），不支持ET。netty，nginx和redis默认是边缘触发（edge-triggered），netty因为JDK不支持ET，所以自己实现了Netty-native的抽象，不依赖JDK来提供ET。</p>
<p>边缘触发会比条件触发更高效一些，因为边缘触发不会让同一个文件描述符多次被处理,比如有些文件描述符已经不需要再读写了,但是在条件触发下每次都会返回,而边缘触发只会返回一次。</p>
<p>如果设置边缘触发,则必须将对应的文件描述符设置为非阻塞模式并且循环读取数据。否则会导致程序的效率大大下降或丢消息。</p>
<p>poll和epoll默认采用的都是条件触发,只是epoll可以修改成边缘触发。条件触发同时支持block和non-block，使用更简单一些。</p>
<h3 id="epoll-LT惊群的发生"><a href="#epoll-LT惊群的发生" class="headerlink" title="epoll LT惊群的发生"></a>epoll LT惊群的发生</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 否则会阻塞在IO系统调用，导致没有机会再epoll</span></span><br><span class="line">set_socket_nonblocking(sd);</span><br><span class="line">epfd = epoll_create(<span class="number">64</span>);</span><br><span class="line">event.data.fd = sd;</span><br><span class="line">epoll_ctl(epfd, EPOLL_CTL_ADD, sd, &amp;event);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    epoll_wait(epfd, events, <span class="number">64</span>, xx);</span><br><span class="line">    ... <span class="comment">// 危险区域！如果有共享同一个epfd的进程/线程调用epoll_wait，它们也将会被唤醒！</span></span><br><span class="line">    <span class="comment">// 这个accept将会有多个进程/线程调用，如果并发请求数很少，那么将仅有几个进程会成功：</span></span><br><span class="line">    <span class="comment">// 1. 假设accept队列中有n个请求，则仅有n个进程能成功，其它将全部返回EAGAIN (Resource temporarily unavailable)</span></span><br><span class="line">    <span class="comment">// 2. 如果n很大(即增加请求负载)，虽然返回EAGAIN的比率会降低，但这些进程也并不一定取到了epoll_wait返回当下的那个预期的请求。</span></span><br><span class="line">    csd = accept(sd, &amp;in_addr, &amp;in_len); </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再看一遍LT的描述“如果事件来了，不管来了几个，只要仍然有未处理的事件，epoll都会通知你。”，显然，epoll_wait刚刚取到事件的时候的时候，不可能马上就调用accept去处理，事实上，逻辑在epoll_wait函数调用的ep_poll中还没返回的，这个时候，显然符合“仍然有未处理的事件”这个条件，显然这个时候为了实现这个语义，需要做的就是通知别的同样阻塞在同一个epoll句柄睡眠队列上的进程！在实现上，这个语义由两点来保证：</p>
<p>保证1：在LT模式下，“就绪链表”上取出的epi上报完事件后会重新加回“就绪链表”；<br>保证2：如果“就绪链表”不为空，且此时有进程阻塞在同一个epoll句柄的睡眠队列上，则唤醒它。</p>
<p>epoll LT模式下有进程被不必要唤醒，这一点并不是内核无意而为之的，内核肯定是知道这件事的，这个并不像之前accept惊群那样算是内核的一个缺陷。epoll LT模式只是提供了一种模式，误用这种模式将会造成类似惊群那样的效应。但是不管怎么说，为了讨论上的方便，后面我们姑且将这种效应称作epoll LT惊群吧。</p>
<h3 id="epoll-ET模式可以解决上面的问题，但是带来了新的麻烦"><a href="#epoll-ET模式可以解决上面的问题，但是带来了新的麻烦" class="headerlink" title="epoll ET模式可以解决上面的问题，但是带来了新的麻烦"></a>epoll ET模式可以解决上面的问题，但是带来了新的麻烦</h3><p>由于epi entry的callback即ep_poll_callback所做的事情仅仅是将该epi自身加入到epoll句柄的“就绪链表”，同时唤醒在epoll句柄睡眠队列上的task，所以这里并不对事件的细节进行计数，比如说，<strong>如果ep_poll_callback在将一个epi加入“就绪链表”之前发现它已经在“就绪链表”了，那么就不会再次添加，因此可以说，一个epi可能pending了多个事件，注意到这点非常重要！</strong></p>
<p>一个epi上pending多个事件，这个在LT模式下没有任何问题，因为获取事件的epi总是会被重新添加回“就绪链表”，那么如果还有事件，在下次check的时候总会取到。然而对于ET模式，仅仅将epi从“就绪链表”删除并将事件本身上报后就返回了，因此如果该epi里还有事件，则只能等待再次发生事件，进而调用ep_poll_callback时将该epi加入“就绪队列”。这意味着什么？</p>
<p>这意味着，应用程序，即epoll_wait的调用进程必须自己在获取事件后将其处理干净后方可再次调用epoll_wait，否则epoll_wait不会返回，而是必须等到下次产生事件的时候方可返回。这会导致事件堆积，所以一般会死循环一直拉取事件，直到拉取不到了再返回。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="https://www.atatech.org/articles/157349">Epoll is fundamentally broken</a> </p>
<p><a target="_blank" rel="noopener" href="https://idea.popcount.org/2017-02-20-epoll-is-fundamentally-broken-12">Epoll is fundamentally broken 1&#x2F;2</a> </p>
<p><a target="_blank" rel="noopener" href="https://wenfh2020.com/2021/11/21/question-nginx-epoll-et/">https://wenfh2020.com/2021/11/21/question-nginx-epoll-et/</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/12/09/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0-2019V2%E7%89%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/09/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0-2019V2%E7%89%88/" class="post-title-link" itemprop="url">如何在工作中学习-2019V2版</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-09 12:30:03" itemprop="dateCreated datePublished" datetime="2019-12-09T12:30:03+08:00">2019-12-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E5%B7%A7/" itemprop="url" rel="index"><span itemprop="name">技巧</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="如何在工作中学习-2019V2版"><a href="#如何在工作中学习-2019V2版" class="headerlink" title="如何在工作中学习-2019V2版"></a>如何在工作中学习-2019V2版</h1><p><a href="/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">2018版简单一些，可以看这里</a>，2019版加入了一些新的理解和案例，目的是想要让文章中所说的不是空洞的口号，而是可以具体执行的命令，拉平对读者的要求。</p>
<blockquote>
<p>先说一件值得思考的事情：高考的时候大家都是一样的教科书，同一个教室，同样的老师辅导，时间精力基本差不多，可是最后别人考的是清华北大或者一本，而你的实力只能考个三本，为什么？ 当然这里主要是智商的影响，那么其他因素呢？智商解决的问题能不能后天用其他方式来补位一下？</p>
</blockquote>
<p>学习的闭环：先了解知识，再实战演练，然后总结复盘。很多时候只是停留在知识学习层面，没有实践，或者实践后没有思考复盘优化，都导致无法深入的理解掌握知识点(from: 瑾妤)</p>
<h2 id="关键问题点"><a href="#关键问题点" class="headerlink" title="关键问题点"></a>关键问题点</h2><h3 id="为什么你的知识积累不了？"><a href="#为什么你的知识积累不了？" class="headerlink" title="为什么你的知识积累不了？"></a>为什么你的知识积累不了？</h3><p>有些知识看过就忘、忘了再看，实际碰到问题还是联系不上这个知识，这其实是知识的积累出了问题，没有深入的理解自然就不能灵活运用，也就谈不上解决问题了。这跟大家一起看相同的高考教科书但是高考结果不一样是一个原因。问题出在了理解上，每个人的理解能力不一样（智商），绝大多数人对知识的理解要靠不断地实践（做题）来巩固。</p>
<h3 id="同样实践效果不一样？"><a href="#同样实践效果不一样？" class="headerlink" title="同样实践效果不一样？"></a>同样实践效果不一样？</h3><p>同样工作一年碰到了10个问题（或者说做了10套高考模拟试卷），但是结果不一样，那是因为在实践过程中方法不够好。或者说你对你为什么做对了、为什么做错了没有去复盘</p>
<p>假如碰到一个问题，身边的同事解决了，而我解决不了。那么我就去想这个问题他是怎么解决的，他看到这个问题后的逻辑和思考是怎么样的，有哪些知识指导了他这么逻辑推理，这些知识哪些我也知道但是我没有想到这么去运用推理（说明我对这个知识理解的不到位导致灵活运用缺乏）；这些知识中又有哪些是我不知道的（知识缺乏，没什么好说的快去Google什么学习下–有场景案例和目的加持，学习理解起来更快）。</p>
<p>等你把这个问题基本按照你同事掌握的知识和逻辑推理想明白后，需要再去琢磨一下他的逻辑推理解题思路中有没有不对的，有没有啰嗦的地方，有没有更直接的方式（对知识更好地运用）。</p>
<p>我相信每个问题都这么去实践的话就不应该再抱怨灵活运用、举一反三，同时知识也积累下来了，这种场景下积累到的知识是不会那么容易忘记的。</p>
<p>这就是向身边的牛人学习，同时很快超过他的办法。这就是为什么高考前你做了10套模拟题还不如其他人做一套的效果好</p>
<p><strong>知识+逻辑 基本等于你的能力</strong>，知识让你知道那个东西，逻辑让你把东西和问题联系起来</p>
<p><strong>这里的问题你可以理解成方案、架构、设计等</strong></p>
<h3 id="系统化的知识哪里来？"><a href="#系统化的知识哪里来？" class="headerlink" title="系统化的知识哪里来？"></a>系统化的知识哪里来？</h3><p>知识之间是可以联系起来的并且像一颗大树一样自我生长，但是当你都没理解透彻，自然没法产生联系，也就不能够自我生长了。</p>
<p>真正掌握好的知识点会慢慢生长连接最终组成一张大网</p>
<p>但是我们最容易陷入的就是掌握的深度、系统化（工作中碎片时间过多，学校里缺少时间）不够，所以一个知识点每次碰到花半个小时学习下来觉得掌握了，但是3个月后就又没印象了。总是感觉自己在懵懵懂懂中，或者一个领域学起来总是不得要领，根本的原因还是在于：宏观整体大图了解不够（缺乏体系，每次都是盲人摸象）；关键知识点深度不够，理解不透彻，这些关键点就是这个领域的骨架、支点、抓手。缺了抓手自然不能生长，缺了宏观大图容易误入歧途。</p>
<p>我们有时候发现自己在某个领域学起来特别快，但是换个领域就总是不得要领，问题出在了上面，即使花再多时间也是徒然。这也就是为什么学霸看两个小时的课本比你看两天效果还好，感受下来还觉得别人好聪明，是不是智商比我高啊。</p>
<p>所以新进入一个领域的时候要去找他的大图和抓手。</p>
<p>好的同事总是能很轻易地把这个大图交给你，再顺便给你几个抓手，你就基本入门了，这就是培训的魅力，这种情况肯定比自学效率高多了。但是目前绝大部分的培训都做不到这点</p>
<h3 id="好的逻辑又怎么来？"><a href="#好的逻辑又怎么来？" class="headerlink" title="好的逻辑又怎么来？"></a>好的逻辑又怎么来？</h3><p>实践、复盘</p>
<h2 id="讲个前同事的故事"><a href="#讲个前同事的故事" class="headerlink" title="讲个前同事的故事"></a>讲个前同事的故事</h2><p>有一个前同事是5Q过来的，负责技术（所有解决不了的问题都找他），这位同学从chinaren出道，跟着王兴一块创业5Q，5Q在学校靠鸡腿打下大片市场，最后被陈一舟的校内收购（据说被收购后5Q的好多技术都走了，最后王兴硬是呆在校内网把合约上的所有钱都拿到了）。这位同学让我最佩服的解决问题的能力，好多问题其实他也不一定就擅长，但是他就是有本事通过Help、Google不停地验证尝试就把一个不熟悉的问题给解决了，这是我最羡慕的能力，在后面的职业生涯中一直不停地往这个方面尝试。</p>
<h3 id="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"><a href="#应用刚启动连接到数据库的时候比较慢，但又不是慢查询" class="headerlink" title="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"></a>应用刚启动连接到数据库的时候比较慢，但又不是慢查询</h3><ol>
<li><p>这位同学的解决办法是通过tcpdump来分析网络包，看网络包的时间戳和网络包的内容，然后找到了具体卡在了哪里。</p>
</li>
<li><p>如果是专业的DBA可能会通过show processlist 看具体连接在做什么，比如看到这些连接状态是 <strong>authentication</strong> 状态，然后再通过Google或者对这个状态的理解知道创建连接的时候MySQL需要反查IP、域名这里比较耗时，通过配置参数 <strong>skip-name-resolve</strong> 跳过去就好了。</p>
</li>
<li><p>如果是MySQL的老司机，一上来就知道连接慢的话跟 <strong>skip-name-resolve</strong> 关系最大。</p>
<p> 在我眼里这三种方式都解决了问题，最后一种最快但是纯靠积累和经验，换个问题也许就不灵了；第一种方式是最牛逼和通用的，只需要最少的知识就把问题解决了。</p>
</li>
</ol>
<p>我当时跟着他从sudo、ls等linux命令开始学起。当然我不会轻易去打搅他问他，每次碰到问题我尽量让他在我的电脑上来操作，解决后我再自己复盘，通过history调出他的所有操作记录，看他在我的电脑上用Google搜啥了，然后一个个去学习分析他每个动作，去想他为什么搜这个关键字，复盘完还有不懂的再到他面前跟他面对面的讨论他为什么要这么做，指导他这么做的知识和逻辑又是什么。</p>
<h2 id="如何向身边的同学学习"><a href="#如何向身边的同学学习" class="headerlink" title="如何向身边的同学学习"></a>如何向身边的同学学习</h2><h3 id="钉钉提问的技巧"><a href="#钉钉提问的技巧" class="headerlink" title="钉钉提问的技巧"></a>钉钉提问的技巧</h3><p>我进现在的公司的时候是个网络小白，但是业务需要我去解决这些问题，于是我就经常在钉钉上找内部的专家来帮请教一些问题，首先要感谢他们的耐心，同时我觉得跟他们提问的时候的方法大家可以参考一下。</p>
<p>首先，没有客套直奔主题把问题描述清楚，钉钉消息本来就不是即时的，就不要问在不在、能不能问个问题、你好（因为这些问题会浪费他一次切换，真要客套把 你好 写在问题前面在一条消息中发出去）。</p>
<p>其次，我会截图把现象接下来，关键部分红框标明。如果是内部机器还会帮对方申请登陆账号，打通ssh登陆，然后把ssh登陆命令和触发截图现象命令的文字一起钉钉发过去。也就是对方收到我的消息，看到截图的问题后，他只要复制粘贴我发给他的文字信息就看到现象了。为什么要帮他申请账号，有时候账号要审批，要找人，对方不知道到哪里申请等等；这么复杂对方干脆就装作没看见你的消息好了。</p>
<p>为什么还要把ssh登陆命令、重现文字命令发给他呢，怕他敲错啊，敲错了还得来问你，一来一回时间都浪费了。你也许会说我截图上有重现命令啊，那么凭什么他帮你解决问题他还要瞪大眼睛看你的截图把你的命令抄下来？比如容器ID一长串，你是截图了，结果他把b抄成6了，重现不了，还得问你，又是几个来回……</p>
<p>提完问题后有三种情况：抱歉，我也不知道；这个问题你要问问谁，他应该知道；沉默</p>
<p>没关系钉钉的优势是复制粘贴方便，你就换个人再问，可能问到第三个人终于搞定了。那么我会回来把结果告诉前面我问过的同学，即使他是沉默的那个。因为我骚扰过人家，要回来填这个坑，另外也许他真的不知道，那么同步给他也可以帮到他。结果就是他觉得我很靠谱，信任度就建立好了，下次再有问题会更卖力地一起来解决。</p>
<h4 id="一些不好的"><a href="#一些不好的" class="headerlink" title="一些不好的"></a>一些不好的</h4><p>有个同学看了我的文章（晚上11点看的），马上发了钉钉消息过来问文章中用到的工具是什么。我还没睡觉但是躺床上看东西，有钉钉消息提醒，但没有切过去回复（不想中断我在看的东西）。5分钟后这个同学居然钉了我一下，我当时是很震惊的，这是你平时学习，不是我的产品出了故障，现在晚上11点。</p>
<p>提问题的时间要考虑对方大概率在电脑前，打字快。否则要紧的话就提选择题类型的问题</p>
<p>问题要尽量是封闭的，比如钉钉上不适合问的问题：</p>
<ul>
<li>为什么我们应用的TPS压不上去，即使CPU还有很多空闲（不好的原因：太开放，原因太多，对方要打字2000才能给你解释清楚各种可能的原因，你要不是他老板就不要这样问了）</li>
<li>用多条消息来描述一个问题，一次没把问题描述清楚，需要对方中断多次</li>
</ul>
<h2 id="场景式学习、体感的来源、面对问题学习"><a href="#场景式学习、体感的来源、面对问题学习" class="headerlink" title="场景式学习、体感的来源、面对问题学习"></a>场景式学习、体感的来源、面对问题学习</h2><p>前面提到的对知识的深入理解这有点空，如何才能做到深入理解？</p>
<h3 id="举个学习TCP三次握手例子"><a href="#举个学习TCP三次握手例子" class="headerlink" title="举个学习TCP三次握手例子"></a>举个学习TCP三次握手例子</h3><p>经历稍微丰富点的工程师都觉得TCP三次握手看过很多次、很多篇文章了，但是文章写得再好似乎当时理解了，但是总是过几个月就忘了或者一看就懂，过一阵子被人一问就模模糊糊了，或者两个为什么就答不上了，自己都觉得自己的回答是在猜或者不确定</p>
<p>为什么会这样呢？而学其它知识就好通畅多了，我觉得这里最主要的是我们对TCP缺乏体感，比如没有几个工程师去看过TCP握手的代码，也没法想象真正的TCP握手是如何在电脑里运作的（打电话能给你一些类似的体感，但是细节覆盖面不够）。</p>
<p>如果这个时候你一边学习的时候一边再用wireshark抓包看看三次握手具体在干什么，比抽象的描述实在多了，你能看到具体握手的一来一回，并且看到一来一回带了哪些内容，这些内容又是用来做什么、为什么要带，这个时候你再去看别人讲解的理论顿时会觉得好理解多了，以后也很难忘记。</p>
<p>但是这里很多人执行能力不强，想去抓包，但是觉得要下载安装wireshark，要学习wireshark就放弃了。只看不动手当然是最舒适的，但是这个最舒适给了你在学习的假象，没有结果。</p>
<p>这是不是跟你要解决一个难题非常像，这个难题需要你去做很多事，比如下载源代码（翻不了墙，放弃）；比如要编译（还要去学习那些编译参数，放弃）；比如要搭建环境（太琐屑，放弃）。你看这中间九九八十一难你放弃了一难都取不了真经。这也是为什么同样学习、同样的问题，他能学会，他能解决，你不可以。</p>
<h3 id="再来看一个解决问题的例子"><a href="#再来看一个解决问题的例子" class="headerlink" title="再来看一个解决问题的例子"></a>再来看一个解决问题的例子</h3><p><a target="_blank" rel="noopener" href="https://www.atatech.org/articles/73174">会员系统双11优化这个问题</a>对我来说，我是个外来者，完全不懂这里面的部署架构、业务逻辑。但是在问题的关键地方（会员认为自己没问题–压力测试正常的；淘宝API更是认为自己没问题，alimonitor监控显示正常），结果就是会员的同学说我们没有问题，淘宝API肯定有问题，然后就不去思考自己这边可能出问题的环节了。思想上已经甩包了，那么即使再去review流程、环节也就不会那么仔细，自然更是发现不了问题了。</p>
<p>但是我的经验告诉我要有证据地甩包，或者说拿着证据优雅地甩包，这迫使我去找更多的细节证据（证据要给力哦，不能让人家拍回来）。如果我是这么说的，这个问题在淘宝API这里，你看理由是…………，我做了这些实验，看到了这些东东。那么淘宝API那边想要证明我的理由错了就会更积极地去找一些数据。</p>
<p>事实上我就是做这些实验找证据过程中发现了会员的问题，这就是态度、执行力、知识、逻辑能力综合下来拿到的一个结果。我最不喜欢的一句话就是我的程序没问题，因为我的逻辑是这样的，不会错的。你当然不会写你知道的错误逻辑，程序之所以有错误都是在你的逻辑、意料之外的东西。有很多次一堆人电话会议中扯皮的时候，我一般把电话静音了，直接上去人肉一个个过对方的逻辑，一般来说电话会议还没有结束我就给出来对方逻辑之外的东西。</p>
<h3 id="场景式学习"><a href="#场景式学习" class="headerlink" title="场景式学习"></a>场景式学习</h3><p>我带2岁的小朋友看刷牙的画本的时候，小朋友理解不了喝口水含在嘴里咕噜咕噜不要咽下去，然后刷牙的时候就都喝下去了。我讲到这里的时候立马放下书把小朋友带到洗手间，先开始我自己刷牙了，示范一下什么是咕噜咕噜（放心，他还是理解不了的，但是至少有点感觉了，水在口里会响，然后水会吐出来）。示范完然后辅导他刷牙，喝水的时候我和他一起直接低着头，喝水然后立马水吐出来了，让他理解了到嘴里的东西不全是吞下去的。然后喝水晃脑袋，有点声音了（离咕噜咕噜不远了）。训练几次后小朋友就理解了咕噜咕噜，也学会了咕噜咕噜。这就是场景式学习的魅力。</p>
<p>很多年前我有一次等电梯，边上还有一个老太太，一个年轻的妈妈带着一个4、5岁的娃。应该是刚从外面玩了回来，妈妈在教育娃娃刚刚在外面哪里做错了，那个小朋友也是气嘟嘟地。进了电梯后都不说话，小朋友就开始踢电梯。这个时候那个年轻的妈妈又想开始教育小朋友了。这时老太太教育这个妈妈说，这是小朋友不高兴，做出的反抗，就是想要用这个方式抗议刚刚的教育或者挑逗起妈妈的注意。这个时候要忽视他，不要去在意，他踢几下后（虽然没有公德这么小懂不了这么多）脚也疼还没人搭理他这个动作，就觉得真没劲，可能后面他都不踢电梯了，觉得这是一个非常无聊还挨疼的事情。那么我在这个场景下立马反应过来，这就是很多以前我对一些小朋友的行为不理解的原因啊，这比书上看到的深刻多了。就是他们生气了在那里做妖挑逗你骂他、打他或者激怒你来吸引大人的注意力。</p>
<h2 id="钉子式学习方法和系统性学习方法"><a href="#钉子式学习方法和系统性学习方法" class="headerlink" title="钉子式学习方法和系统性学习方法"></a>钉子式学习方法和系统性学习方法</h2><p>系统性就是想掌握MySQL，那么搞几本MySQL专著和MySQL 官方DOC看下来，一般课程设计的好的话还是比较容易普遍性地掌握下来，绝大部分时候都是这种学习方法，可是问题在于在种方式下学完后当时看着似乎理解了，但是很容易忘记，一片一片地系统性的忘记。还是一般人对知识的理解没那么容易真正理解。</p>
<p>钉子式的学习方式，就是在一大片知识中打入几个桩，反复演练将这个桩不停地夯实，夯温，做到在这个知识点上用通俗的语言跟小白都能讲明白，然后在这几个桩中间发散像星星之火燎原一样把整个一片知识都掌握下来。这种学习方法的缺点就是很难找到一片知识点的这个点，然后没有很好整合的话知识过于零散。</p>
<p>我们常说的一个人很聪明，就是指系统性的看看书就都理解了，是真的理解那种，还能灵活运用，但是大多数普通人就不是这样的，看完书似乎理解了，实际几周后基本都忘记了，真正实践需要用的时候还是用不好。</p>
<p>实际这两种学习方法要互相结合，对普通人来讲钉子式学习方法更好一些，掌握几个钉子后再系统性地学习也容易多了；对非常聪明的人来说系统性地学习效率更高一些。</p>
<h3 id="举个Open-SSH的例子"><a href="#举个Open-SSH的例子" class="headerlink" title="举个Open-SSH的例子"></a>举个Open-SSH的例子</h3><p>为了做通 SSH 的免密登陆，大家都需要用到 ssh-keygen&#x2F;ssh-copy-id， 如果我们把这两个命令当一个小的钉子的话，会去了解ssh-keygen做了啥（生成了密钥对），或者ssh-copy-id 的时候报错了（原来是需要秘钥对），然后将 ssh-keygen 生成的pub key复制到server的~&#x2F;.ssh&#x2F;authorized_keys 中。</p>
<p>然后你应该会对这个原理要有一些理解（更大的钉子），于是理解了密钥对，和ssh验证的流程，顺便学会怎么看ssh debug信息，那么接下来网络上各种ssh攻略、各种ssh卡顿的解决都是很简单的事情了。</p>
<p>比如你通过SSH可以解决这些问题：</p>
<ul>
<li>免密登陆</li>
<li>ssh卡顿</li>
<li>怎么去掉ssh的时候需要手工多输入yes</li>
<li>怎么样一次登录，多次复用</li>
<li>我的ssh怎么很快就断掉了</li>
<li>我怎么样才能一次通过跳板机ssh到目标机器</li>
<li>我怎么样通过ssh科学上网</li>
<li>我的ansible（底层批量命令都是基于ssh）怎么这么多问题，到底是为什么</li>
<li>我的git怎么报网络错误了</li>
<li>xshell我怎么配置不好</li>
<li>https为什么需要随机数加密，还需要签名</li>
<li>…………</li>
</ul>
<p>这些问题都是一步步在扩大ssh的外延，让这个钉子变成一个巨大的桩。</p>
<p>然后就会学习到一些<a href="/2018/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82SSH--SSH%E8%8A%B1%E5%BC%8F%E7%8E%A9%E6%B3%95/">高级一些的ssh配置</a>，比如干掉ssh的时候经常要yes一下(StrictHostKeyChecking&#x3D;no), 或者怎么配置一下ssh就不会断线了（ServerAliveInterval&#x3D;15），或者将 ssh跳板机-&gt;ssh server的过程做成 ssh server一步就可以了(ProxyCommand)，进而发现用 ssh的ProxyCommand很容易科学上网了，或者git有问题的时候轻而易举地把ssh debug打开，对git进行debug了……</p>
<p>这基本都还是ssh的本质范围，像ansible、git在底层都是依赖ssh来通讯的，你会发现学、调试xshell、ansible和git简直太容易了。</p>
<p>另外理解了ssh的秘钥对，也就理解了非对称加密，同时也很容易理解https流程（SSL），同时知道对称和非对称加密各自的优缺点，SSL为什么需要用到这两种加密算法了。</p>
<p>你看一个简单日常的知识我们只要沿着它用钉子精神，深挖细挖你就会发现知识之间的连接，这个小小的知识点成为你知识体系的一根结实的柱子。</p>
<p>我见过太多年老的工程师、年轻的工程师，天天在那里ssh 密码，ssh 跳板机，ssh 目标机，一小会ssh断了，重来一遍；或者ssh后卡住了，等吧……</p>
<p>在这个问题上表现得没有求知欲、没有探索精神、没有一次把问题搞定的魄力，所以就习惯了，然后年轻的工程师也变成了年老的工程师 :)</p>
<h2 id="空洞的口号"><a href="#空洞的口号" class="headerlink" title="空洞的口号"></a>空洞的口号</h2><p>很多文章都会教大家：举一反三、灵活运用、活学活用、多做多练。但是只有这些口号是没法落地的，落地的基本原则就是前面提到的，却总是被忽视了。</p>
<h2 id="什么是工程效率，什么是知识效率"><a href="#什么是工程效率，什么是知识效率" class="headerlink" title="什么是工程效率，什么是知识效率"></a>什么是工程效率，什么是知识效率</h2><p>有些人纯看理论就能掌握好一门技能，还能举一反三，这是知识效率，这种人非常少；</p>
<p>大多数普通人都是看点知识然后结合实践来强化理论，要经过反反复复才能比较好地掌握一个知识，这就是工程效率，讲究技巧、工具来达到目的。</p>
<p>肯定知识效率最牛逼，但是拥有这种技能的人毕竟非常少（天生的高智商吧）。从小我们周边那种不怎么学的学霸型基本都是这类，这种学霸都还能触类旁通非常快的掌握一个新知识，非常气人。剩下的绝大部分只能拼时间+方法+总结等也能掌握一些知识</p>
<p>非常遗憾我就是工程效率型，只能羡慕那些知识效率型的学霸。但是这事又不能独立看待有些人在某些方向上是工程效率型，有些方向就又是知识效率型（有一种知识效率型是你掌握的实在太多也就比较容易触类旁通了，这算灰色知识效率型）</p>
<p>使劲挖掘自己在知识效率型方面的能力吧，两者之间当然没有明显的界限，知识积累多了逻辑训练好了在别人看来你的智商就高了</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>高质量学习+反思和输出，才能建立自己的知识脉络和体系。</p>
<p>①学习力-学习总结能力；</p>
<p>②输出力-逻辑思维和沟通表达能力；</p>
<p>③反思力-自省和修正能力；</p>
<p>某个领域的知识体系犹如一棵大树的根、干、枝、叶。</p>
<p>①损之又损得其道，为其根</p>
<p>②基本的方法论，为其干</p>
<p>③领域的通用知识，为其枝</p>
<p>④与业务绑定的特定知识，为其叶</p>
<p>在这个之上，你所取得的成就，为其花和果</p>
<p>学习能力+思考能力+行动能力&#x3D;结果</p>
<p>最好的学习方法：带着问题、场景学习（目标明确）</p>
<h2 id="为什么看电影注意力特别好，做正事注意力集中不了"><a href="#为什么看电影注意力特别好，做正事注意力集中不了" class="headerlink" title="为什么看电影注意力特别好，做正事注意力集中不了"></a>为什么看电影注意力特别好，做正事注意力集中不了</h2><p>首先接受这个现实，医学上把这叫作注意力缺失症，基本所有人都有这种毛病，因为做正事比较枯燥、困难，让人不舒服，集中不了注意力，逃避很正常！</p>
<p>改善方法：做笔记、收集素材、写作</p>
<h2 id="极易被手机、微博、朋友圈干扰"><a href="#极易被手机、微博、朋友圈干扰" class="headerlink" title="极易被手机、微博、朋友圈干扰"></a>极易被手机、微博、朋友圈干扰</h2><p>意志力—还没有好办法</p>
<h2 id="改变条件反射，多逻辑思考"><a href="#改变条件反射，多逻辑思考" class="headerlink" title="改变条件反射，多逻辑思考"></a>改变条件反射，多逻辑思考</h2><p>有科学家通过研究，发现一个人一天的行为中，5%是非习惯性的，用思考脑的逻辑驱动，95%是习惯性的，用反射脑的直觉驱动，决定我们一生的，永远是95%的反射脑（习惯），而不是5%的思考脑（逻辑）</p>
<p>互联网+手机时代：浏览信息的时间多了，自己思考和琢磨的时间少了，专注在无效事情上的时间多了，专注在自我成长上的时间少了。</p>
<h2 id="容易忘记"><a href="#容易忘记" class="headerlink" title="容易忘记"></a>容易忘记</h2><p>学东西当时感觉很好，但是过几周基本都忘记了</p>
<p>这很正常，主要还是理解不够，理解不够也正常，这就是普通人的智商和理解能力。</p>
<p>改善：做笔记，利用碎片时间回顾</p>
<p>总结成系统性的文章，知识体系化，不会再忘记了。</p>
<h2 id="执行力和自律"><a href="#执行力和自律" class="headerlink" title="执行力和自律"></a>执行力和自律</h2><p>执行力和自律在我们的工作和生活中出现的频率非常高，因为这是我们成长或做成事时必须要有的2个关键词，但是很长一段时间里，对于提升执行力，疑惑很大。同时在工作场景中可能会被老板多次要求提升执行力，抽象又具体，但往往只有提升执行力的要求没有如何提升的方法和认知，这是普遍点到即止的现象，普遍提升不了执行力的现象。</p>
<p>“要有执行力”就是一句空话，谁都想，但是臣妾做不到。</p>
<p>人生由成长（学习）和享受（比如看电影、刷朋友圈）构成，成长太艰难，享受就很自然符合人性</p>
<p>怎么办？</p>
<pre><code>划重点：执行力就是想明白，然后一步一步做下去。
</code></pre>
<h2 id="跳出舒适区"><a href="#跳出舒适区" class="headerlink" title="跳出舒适区"></a>跳出舒适区</h2><p>重复、没有进步的时候就是舒适区，人性就是喜欢适合自己、符合自己技能的环境，解决问题容易；对陌生区域有恐惧感。</p>
<p>有时候是缺机会和场景驱动自我去学习，要找到从舒适到陌生区域的交融点，慢慢跨出去。<br>比如从自己熟悉的知识体系中入手，从已有的抓手和桩开始突击不清楚的问题，也就是横向、纵向多深挖，自然恐惧区就越来越小了，舒适区慢慢在扩张</p>
<h2 id="养成写文章的习惯非常重要"><a href="#养成写文章的习惯非常重要" class="headerlink" title="养成写文章的习惯非常重要"></a>养成写文章的习惯非常重要</h2><p>对自我碎片知识的总结、加深理解的良机，将知识体系化、结构化，形成知识体系中的抓手、桩。</p>
<p>缺的不是鸡汤，而是勺子，勺子就是具体的步骤，可以复制，对人、人性要求很低的动作。</p>
<p>生活本质是生产（工作学习成长）和消费(娱乐、刷朋友圈等)，消费总是符合人性的，当是对自己的适当奖励，不要把自己搞成机器人</p>
<p>可以做的是生产的时候效率更高</p>
<h2 id="知识分两种"><a href="#知识分两种" class="headerlink" title="知识分两种"></a>知识分两种</h2><p>一种是通用知识（不是说对所有人通用，而是说在一个专业领域去到哪个公司都能通用）；另外一种是跟业务公司绑定的特定知识</p>
<p>通用知识没有任何疑问碰到后要非常饥渴地扑上去掌握他们（受益终生，这还有什么疑问吗？）。对于特定知识就要看你对业务需要掌握的深度了，肯定也是需要掌握一些的，特定知识掌握好的一般在公司里混的也会比较好</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2019/11/24/%E5%88%B0%E5%BA%95%E6%98%AF%E8%B0%81reset%E4%BA%86%E4%BD%A0%E7%9A%84%E8%BF%9E%E6%8E%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/24/%E5%88%B0%E5%BA%95%E6%98%AF%E8%B0%81reset%E4%BA%86%E4%BD%A0%E7%9A%84%E8%BF%9E%E6%8E%A5/" class="post-title-link" itemprop="url">到底是谁reset了你的连接</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-11-24 17:30:03" itemprop="dateCreated datePublished" datetime="2019-11-24T17:30:03+08:00">2019-11-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TCP/" itemprop="url" rel="index"><span itemprop="name">TCP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="到底是谁reset了你的连接"><a href="#到底是谁reset了你的连接" class="headerlink" title="到底是谁reset了你的连接"></a>到底是谁reset了你的连接</h1><p>通过一个案例展示TCP连接是如何被reset的，以及identification、ttl都可以帮我们干点啥。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>用户经常连不上服务，经过抓包发现是链路上连接被reset了，需要定位到是哪个设备发起的reset</p>
<p>比如：</p>
<ol>
<li>用户用navicat从自己访问云上的MySQL的时候，点开数据库总是报错（不是稳定报错，有一定的概率报错）</li>
<li>某家居客户通过专线访问云上MySQL，总是被reset( 内网ip地址重复–都是192.168.*， 导致连接被reset)</li>
</ol>
<blockquote>
<p><strong>进程被kill、异常退出时，针对它打开的连接，内核就会发送 RST 报文来关闭</strong>。RST 的全称是 Reset 复位的意思，它可以不走四次挥手强制关闭连接，但当报文延迟或者重复传输时，这种方式会导致数据错乱，所以这是不得已而为之的关闭连接方案。当然还有其它场景也会触发reset</p>
</blockquote>
<h2 id="抓包"><a href="#抓包" class="headerlink" title="抓包"></a>抓包</h2><p>在 Navicat 机器上抓包如下：</p>
<p><img src="/images/oss/83b07725d92b9e4d3eb4a504cf83cc09.png" alt="image.png"></p>
<p>从抓包可以清楚看到 Navicat 发送 Use Database后收到了 MySQL（来自3306端口）的Reset重接连接命令，所以连接强行中断，然后 Navicat报错了。注意图中红框中的 Identification 两次都是13052，先留下不表，这是个线索。</p>
<p><img src="/images/oss/53b5dc8e0a90ed9ad641caf38399141b.png" alt="image.png"></p>
<h2 id="MySQL-Server上抓包"><a href="#MySQL-Server上抓包" class="headerlink" title="MySQL Server上抓包"></a>MySQL Server上抓包</h2><p>特别说明下，MySQL上抓到的不是跟Navicat上抓到的同一次报错，所以报错的端口等会不一样</p>
<p><img src="/images/oss/70287488290b38cd4753d9fce0bee945.png" alt="image.png"></p>
<p>从这个图中可以清楚看到reset是从 Navicat 客户端发过来的，并且 Use Database被拦截了，没有发到MySQL上。</p>
<p>从这里基本可以判断是客户的防火墙之类的中间设备监控到了关键字之类的触发了防火墙向两边发送了reset，导致了 Navicat 报错。</p>
<h3 id="如果连接已经断开"><a href="#如果连接已经断开" class="headerlink" title="如果连接已经断开"></a>如果连接已经断开</h3><p>如果连接已经断开后还收到Client的请求包，因为连接在Server上是不存在的，这个时候Server收到这个包后也会发一个reset回去，这个reset的特点是identification是0.</p>
<h2 id="到底是谁动了这个连接呢？"><a href="#到底是谁动了这个连接呢？" class="headerlink" title="到底是谁动了这个连接呢？"></a>到底是谁动了这个连接呢？</h2><h3 id="得帮客户解决问题"><a href="#得帮客户解决问题" class="headerlink" title="得帮客户解决问题"></a>得帮客户解决问题</h3><p>虽然原因很清楚，但是客户说连本地 MySQL就没这个问题，连你的云上MySQL就这样，你让我们怎么用？你们得帮我们找到是哪个设备。</p>
<p>这不废话么，连本地没经过这么多防火墙、网关当然没事了。但是客户第一，不能这么说，得找到问题所在。</p>
<h2 id="Identification-和-TTL"><a href="#Identification-和-TTL" class="headerlink" title="Identification 和 TTL"></a>Identification 和 TTL</h2><h3 id="线索一-Identification"><a href="#线索一-Identification" class="headerlink" title="线索一 Identification"></a>线索一 Identification</h3><p>还记得第一个截图中的两个相同的identification 13052吧，让我们来看看基础知识：</p>
<p><img src="/images/oss/eed9ba1f9ba492ed8954ae7f39e72803.png" alt="image.png"></p>
<p>（摘自 TCP卷一），简单来说这个 identification 用来标识一个连接中的每个包，这个序号按包的个数依次递增，通信双方是两个不同的序列。<strong>主要是用于ip packet的reassemble</strong>。</p>
<p>所以如果这个reset是MySQL发出来的话，因为MySQL发出的前一个包的 identification 是23403，所以这个必须是23404，实际上居然是13502（而且还和Navicat发出的 Use Database包是同一个 identification），这是非常不对的。</p>
<p>所以可以大胆猜测，这里有个中间设备收到 Use Database后触发了不放行的逻辑，于是冒充 Navicat给 MySQL Server发了reset包，src ip&#x2F;src port&#x2F;seq等都直接用Navicat的，identification也用Navicat的，所以 MySQL Server收到的 Reset看起来很正常（啥都是对的，没留下一点冒充的痕迹）。</p>
<p>但是这个中间设备还要冒充MySQL Server给 Navicat 也发个reset，有点难为中间设备了，这个时候中间设备手里只有 Navicat 发出来的包， src ip&#x2F;src port&#x2F;seq 都比较好反过来，但是 identification 就不好糊弄了，手里只有 Navicat的，因为 Navicat和MySQL Server是两个序列的 identification，这下中间设备搞不出来MySQL Server的identification，怎么办？ 只能糊弄了，就随手用 Navicat 自己的 identification填回去了（所以看到这么个奇怪的 identification）</p>
<p><strong>identification不对不影响实际连接被reset，也就是验证包的时候不会判断identification的正确性。</strong></p>
<h3 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h3><p>identification基本撇清了MySQL的嫌疑，还得进一步找到是哪个机器，我们先来看一个基础知识 TTL(Time-to-Live):</p>
<p><img src="/images/oss/ed8c624b704b0c94da2ca76a37b39916.png" alt="image.png"></p>
<p>然后我们再看看 Navicat收到的这个reset包的ttl是63，而正常的MySQL Server回过来的包是47，而发出的第一个包初始ttl是64，所以这里可以很清楚地看到在Navicat 下一跳发出的这个reset</p>
<p><img src="/images/oss/b288a740f9f10007485e37fd339051f8.png" alt="image.png"></p>
<p>既然是下一跳干的直接拿这个包的src mac地址，然后到内网中找这个内网设备就可以了，最终找到是一个锐捷的防火墙。</p>
<p>如果不是下一跳可以通过 traceroute&#x2F;mtr 来找到这个设备的ip</p>
<h2 id="某家居的reset"><a href="#某家居的reset" class="headerlink" title="某家居的reset"></a>某家居的reset</h2><p><img src="/images/oss/1573793438383-3a05c4da-1443-4fcf-8b59-b93bc2a246de.png" alt="undefined"> </p>
<p>从图中可以清楚看到都是3306收到ttl为62的reset，正常ttl是61，所以推定reset来自client的下一跳上。</p>
<h2 id="某ISV-vpn环境reset"><a href="#某ISV-vpn环境reset" class="headerlink" title="某ISV vpn环境reset"></a>某ISV vpn环境reset</h2><p>client通过公网到server有几十跳，偶尔会出现连接被reset。反复重现发现只要是： select * from table1 ; 就一定reset，但是select * from table1 limit 1 之有极低的概率会被reset，reset的概率跟查询结果的大小比较相关。</p>
<p>于是在server和client上同时抓到了一次完整的reset</p>
<p>如下图红框 Server正常发出了一个大小为761的response包，id 51101，注意seq号，另外通过上下文知道server client之间的rt是15ms左右（15ms后 server收到了一个reset id为0）</p>
<p><img src="/images/oss/89f584899a5e5e00ba5c2b16707ed24a.png" alt="image.png"></p>
<p>下图是client收到的 id 51101号包，seq也正常，只是原来的response内容被替换成了reset，可以推断是中间环节检测到id 51101号包触发了某个条件，然后向server、client同时发出了reset，server收到的reset包是id 是0（伪造出来的），client收到的reset包还是51101，可以判断出是51101号包触发的reset，中间环节披着51101号包的外衣将response替换成了reset，这种双向reset基本是同时发出，从server和client的接收时间来看，这个中间环节挨着client，同时server收到的reset 的id是0，结合ttl等综合判断client侧的防火墙发出了这个reset</p>
<p><img src="/images/oss/ec1f04befe56823668b4d1f831bd3ea4.png"></p>
<p>最终排查后client端</p>
<blockquote>
<p>公司部分网络设置了一些拦截措施，然后现在把这次项目中涉及到的服务器添加到了白名单中，现在运行正常了</p>
</blockquote>
<h3 id="扩展一下"><a href="#扩展一下" class="headerlink" title="扩展一下"></a>扩展一下</h3><p>假如这里不是下一跳，而是隔了几跳发过来的reset，那么这个src mac地址就不是发reset设备的mac了，那该怎么办呢？</p>
<p>可以根据中间的跳数(TTL)，再配合 traceroute 来找到这个设备的ip</p>
<h2 id="SLB-reset"><a href="#SLB-reset" class="headerlink" title="SLB reset"></a>SLB reset</h2><p>如果连接闲置15分钟(900秒)后，SLB会给两端发送reset，设置的ttl为102（102年，下图经过3跳后到达RS 节点所以看到的是99），identification 为31415（π）</p>
<p><img src="/images/951413iMgBlog/image-20220722161729776.png" alt="image-20220722161729776"></p>
<h2 id="被忽略的reset"><a href="#被忽略的reset" class="headerlink" title="被忽略的reset"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/YWzuKBK3TMclejeN2ziAvQ">被忽略的reset</a></h2><p>不是收到reset就一定释放连接，OS还是会验证一下这个reset 包的有效性，主要是通过reset包的seq是否落在接收窗口内来验证，当然五元组一定要对。</p>
<p><img src="/images/951413iMgBlog/640-20220224102640374.png" alt="Image"></p>
<p>但是对于SLB来说，收到reset就会clean 连接的session（SLB没做合法性验证），一般等session失效后（10秒）</p>
<h2 id="SLB主动reset的话"><a href="#SLB主动reset的话" class="headerlink" title="SLB主动reset的话"></a>SLB主动reset的话</h2><p>ttl是102, identification是31415，探活reset不是这样的。</p>
<p>如下图就是SLB发出来的reset packet</p>
<p><img src="/images/oss/9de70216-188c-4ca4-898f-0fa88e853c18.png" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>基础知识很重要，但是知道ttl、identification到会用ttl、identification是两个不同的层次。只是看书的话未必会有很深的印象，实际也不一定会灵活使用。</p>
<p>平时不要看那么多书，会用才是关键。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/YWzuKBK3TMclejeN2ziAvQ">TCP中并不是所有的RST都有效</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/11/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/13/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
