<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1">






<meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/page/3/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="plantegg">
<meta name="twitter:description" content="java mysql tcp performance network docker Linux">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/page/3/">





  <title>plantegg - java tcp mysql performance network docker Linux</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/10/10/Nginx性能测试/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/10/10/Nginx性能测试/" itemprop="url">Nginx 性能测试</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-10-10T12:30:03+08:00">
                2022-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Nginx-性能测试"><a href="#Nginx-性能测试" class="headerlink" title="Nginx 性能测试"></a>Nginx 性能测试</h1><p>压测工具选择 wrk ，apache ab压nginx单核没问题，多核的话 ab 自己先到瓶颈。另外默认关闭 access.log 避免 osq(osq 优化的自旋锁)。</p>
<h2 id="Nginx-官方测试数据"><a href="#Nginx-官方测试数据" class="headerlink" title="Nginx 官方测试数据"></a><a href="https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/" target="_blank" rel="noopener">Nginx 官方测试数据</a></h2><p>普通测试数据参考官方数据，不再多做测试</p>
<h3 id="RPS-for-HTTP-Requests"><a href="#RPS-for-HTTP-Requests" class="headerlink" title="RPS for HTTP Requests"></a>RPS for HTTP Requests</h3><p>The table and graph below show the number of HTTP requests for varying numbers of CPUs and varying request sizes, in kilobytes (KB).</p>
<table>
<thead>
<tr>
<th align="center">CPUs</th>
<th align="center">0 KB</th>
<th align="center">1 KB</th>
<th align="center">10 KB</th>
<th align="center">100 KB</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">145,551</td>
<td align="center">74,091</td>
<td align="center">54,684</td>
<td align="center">33,125</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">249,293</td>
<td align="center">131,466</td>
<td align="center">102,069</td>
<td align="center">62,554</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">543,061</td>
<td align="center">261,269</td>
<td align="center">207,848</td>
<td align="center">88,691</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">1,048,421</td>
<td align="center">524,745</td>
<td align="center">392,151</td>
<td align="center">91,640</td>
</tr>
<tr>
<td align="center">16</td>
<td align="center">2,001,846</td>
<td align="center">972,382</td>
<td align="center">663,921</td>
<td align="center">91,623</td>
</tr>
<tr>
<td align="center">32</td>
<td align="center">3,019,182</td>
<td align="center">1,316,362</td>
<td align="center">774,567</td>
<td align="center">91,640</td>
</tr>
<tr>
<td align="center">36</td>
<td align="center">3,298,511</td>
<td align="center">1,309,358</td>
<td align="center">764,744</td>
<td align="center">91,655</td>
</tr>
</tbody></table>
<p><a href="https://www.nginx.com/wp-content/uploads/2017/08/NGINX-HTTP-RPS.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/NGINX-HTTP-RPS.png" alt="img"></a></p>
<h3 id="RPS-for-HTTPS-Requests"><a href="#RPS-for-HTTPS-Requests" class="headerlink" title="RPS for HTTPS Requests"></a>RPS for HTTPS Requests</h3><p>HTTPS RPS is lower than HTTP RPS for the same provisioned bare‑metal hardware because the data encryption and decryption necessary to secure data transmitted between machines is computationally expensive.</p>
<p>Nonetheless, continued advances in Intel architecture – resulting in servers with faster processors and better memory management – mean that the performance of software for CPU‑bound encryption tasks continually improves compared to dedicated hardware encryption devices.</p>
<p>Though RPS for HTTPS are roughly one‑quarter less than for HTTP at the 16‑CPU mark, “throwing hardware at the problem” – in the form of additional CPUs – is more effective than for HTTP, for the more commonly used file sizes and all the way up to 36 CPUs.</p>
<table>
<thead>
<tr>
<th align="center">CPUs</th>
<th align="center">0 KB</th>
<th align="center">1 KB</th>
<th align="center">10 KB</th>
<th align="center">100 KB</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">71,561</td>
<td align="center">40,207</td>
<td align="center">23,308</td>
<td align="center">4,830</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">151,325</td>
<td align="center">85,139</td>
<td align="center">48,654</td>
<td align="center">9,871</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">324,654</td>
<td align="center">178,395</td>
<td align="center">96,808</td>
<td align="center">19,355</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">647,213</td>
<td align="center">359,576</td>
<td align="center">198,818</td>
<td align="center">38,900</td>
</tr>
<tr>
<td align="center">16</td>
<td align="center">1,262,999</td>
<td align="center">690,329</td>
<td align="center">383,860</td>
<td align="center">77,427</td>
</tr>
<tr>
<td align="center">32</td>
<td align="center">2,197,336</td>
<td align="center">1,207,959</td>
<td align="center">692,804</td>
<td align="center">90,430</td>
</tr>
<tr>
<td align="center">36</td>
<td align="center">2,175,945</td>
<td align="center">1,239,624</td>
<td align="center">733,745</td>
<td align="center">89,842</td>
</tr>
</tbody></table>
<h2 id="参考配置参数"><a href="#参考配置参数" class="headerlink" title="参考配置参数"></a>参考配置参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">user nginx;</span><br><span class="line">worker_processes 4;</span><br><span class="line">worker_cpu_affinity 00000000000000000000000000001111;</span><br><span class="line"></span><br><span class="line"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    use epoll;</span><br><span class="line">    accept_mutex off;</span><br><span class="line">    worker_connections 102400;</span><br><span class="line">&#125;</span><br><span class="line">http &#123;</span><br><span class="line">    access_log off;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    sendfile_max_chunk 512k;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    keepalive_timeout   60;</span><br><span class="line">    keepalive_requests 100000000000;</span><br><span class="line"></span><br><span class="line">		#在 nginx.conf 中增加以下开销能提升短连接 RPS</span><br><span class="line">    open_file_cache max=10240000 inactive=60s;</span><br><span class="line">    open_file_cache_valid 80s;</span><br><span class="line">    open_file_cache_min_uses 1;</span><br><span class="line"></span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</span><br><span class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</span><br><span class="line">    # for more information.</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name  _;</span><br><span class="line">        root         /apt/uos.aarch;</span><br><span class="line"></span><br><span class="line">        # Load configuration files for the default server block.</span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        location /&#123;</span><br><span class="line">                #root /polarx/apt/uos.aarch;</span><br><span class="line">                index index.html;</span><br><span class="line">                autoindex on;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">        		#return 200 &apos;a&apos;;</span><br><span class="line">        		#root   /usr/share/nginx/html;</span><br><span class="line">        		#index  index.html index.htm;</span><br><span class="line">        		#autoindex 目录文件浏览模式</span><br><span class="line">        		autoindex on;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">            location = /40x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">            location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="https-配置"><a href="#https-配置" class="headerlink" title="https 配置"></a>https 配置</h3><p>解开https默认配置注释 &#x2F;&#x2F; sed -i “57,81s&#x2F;#(.*)&#x2F;\1&#x2F;“ &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># Settings for a TLS enabled server.</span><br><span class="line">#</span><br><span class="line">#    server &#123;</span><br><span class="line">#        listen       443 ssl http2 default_server;</span><br><span class="line">#        listen       [::]:443 ssl http2 default_server;</span><br><span class="line">#        server_name  _;</span><br><span class="line">#        root         /usr/share/nginx/html;</span><br><span class="line">#</span><br><span class="line">#        ssl_certificate &quot;/etc/pki/nginx/server.crt&quot;;</span><br><span class="line">#        ssl_certificate_key &quot;/etc/pki/nginx/private/server.key&quot;;</span><br><span class="line">#        ssl_session_cache shared:SSL:1m;</span><br><span class="line">#        ssl_session_timeout  10m;</span><br><span class="line">#        ssl_ciphers HIGH:!aNULL:!MD5;</span><br><span class="line">#        ssl_prefer_server_ciphers on;</span><br><span class="line">#</span><br><span class="line">#        # Load configuration files for the default server block.</span><br><span class="line">#        include /etc/nginx/default.d/*.conf;</span><br><span class="line">#</span><br><span class="line">#        location / &#123;</span><br><span class="line">#        &#125;</span><br><span class="line">#</span><br><span class="line">#        error_page 404 /404.html;</span><br><span class="line">#            location = /40x.html &#123;</span><br><span class="line">#        &#125;</span><br><span class="line">#</span><br><span class="line">#        error_page 500 502 503 504 /50x.html;</span><br><span class="line">#            location = /50x.html &#123;</span><br><span class="line">#        &#125;</span><br><span class="line">#    &#125;</span><br></pre></td></tr></table></figure>

<p>生成秘钥文件和配置https</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mkdir /etc/pki/nginx/  /etc/pki/nginx/private -p</span><br><span class="line">openssl genrsa -des3 -out server.key 2048  #会有两次要求输入密码,输入同一个即可</span><br><span class="line">openssl rsa -in server.key -out server.key</span><br><span class="line">openssl req -new -key server.key -out server.csr</span><br><span class="line">openssl req -new -x509 -key server.key -out server.crt -days 3650</span><br><span class="line">openssl req -new -x509 -key server.key -out ca.crt -days 3650</span><br><span class="line">openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt</span><br><span class="line"></span><br><span class="line">cp server.crt /etc/pki/nginx/</span><br><span class="line">cp server.key /etc/pki/nginx/private</span><br><span class="line"></span><br><span class="line">启动nginx</span><br><span class="line">systemctl start nginx</span><br></pre></td></tr></table></figure>

<h3 id="创建ecdsa-P256-秘钥和证书"><a href="#创建ecdsa-P256-秘钥和证书" class="headerlink" title="创建ecdsa P256 秘钥和证书"></a>创建ecdsa P256 秘钥和证书</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -x509 -sha256 -nodes -days 365 -newkey ec:&lt;(openssl ecparam -name prime256v1) -keyout ecdsa.key -out ecdsa.crt -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=Example Inc./OU=Web Security/CN=example1.com&quot;</span><br></pre></td></tr></table></figure>

<h3 id="https-长连接"><a href="#https-长连接" class="headerlink" title="https 长连接"></a>https 长连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrk -t 32 -c 1000 -d 30 --latency https://$serverIP:443</span><br></pre></td></tr></table></figure>

<h3 id="https-短连接"><a href="#https-短连接" class="headerlink" title="https 短连接"></a>https 短连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrk -t 32 -c 1000 -d 30  -H &apos;Connection: close&apos;  --latency https://$serverIP:443</span><br></pre></td></tr></table></figure>

<h2 id="不同-CPU-型号下-Nginx-静态页面的处理能力"><a href="#不同-CPU-型号下-Nginx-静态页面的处理能力" class="headerlink" title="不同 CPU 型号下 Nginx 静态页面的处理能力"></a>不同 CPU 型号下 Nginx 静态页面的处理能力</h2><p>对比不同 CPU 型号下 Nginx 静态页面的处理能力。静态文件下容易出现 同一文件上的 自旋锁（OSQ），null 测试场景表示直接返回，不读取文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrk -t12 -c400 -d30s http://100.81.131.221:18082/index.html //参数可以调整，目标就是将 CPU 压满</span><br></pre></td></tr></table></figure>

<p>软中断在 node0 上，intel E5和 M的对比，在M上访问单个文件锁竞争太激烈，改成请求直接 return 后多核能保持较好的线性能力（下表中 null标识）</p>
<table>
<thead>
<tr>
<th align="center">CPUs(括号中为core序号)</th>
<th align="center">E5-2682</th>
<th>E5-2682 null</th>
<th>M</th>
<th align="center">M  null</th>
<th>AMD 7t83 null</th>
<th>AMD 7t83</th>
<th>ft s2500  on null</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1(0)</td>
<td align="center">69282&#x2F;61500.77</td>
<td>118694&#x2F;106825</td>
<td>74091</td>
<td align="center">135539&#x2F;192691</td>
<td>190568</td>
<td>87190</td>
<td>35064</td>
</tr>
<tr>
<td align="center">2(1,2)</td>
<td align="center">130648 us 31%</td>
<td>233947</td>
<td>131466</td>
<td align="center"></td>
<td>365315</td>
<td></td>
<td></td>
</tr>
<tr>
<td align="center">2(1对HT)</td>
<td align="center">94158 34%</td>
<td>160114</td>
<td></td>
<td align="center"></td>
<td>217783</td>
<td></td>
<td></td>
</tr>
<tr>
<td align="center">4(0-3)</td>
<td align="center">234884&#x2F;211897</td>
<td>463033&#x2F;481010</td>
<td></td>
<td align="center">499507&#x2F;748880</td>
<td>730189</td>
<td>323591</td>
<td></td>
</tr>
<tr>
<td align="center">8(0-7)</td>
<td align="center">467658&#x2F;431308</td>
<td>923348&#x2F;825002</td>
<td></td>
<td align="center">1015744&#x2F;1529721</td>
<td>1442115</td>
<td>650780</td>
<td></td>
</tr>
<tr>
<td align="center">8(0-15)</td>
<td align="center"></td>
<td>1689722&#x2F;1363031</td>
<td></td>
<td align="center">1982448&#x2F;3047778</td>
<td>2569314</td>
<td>915399</td>
<td></td>
</tr>
</tbody></table>
<p>测试说明：</p>
<ul>
<li>压测要将多个核打满，有时候因为软中断的挤占会导致部分核打不满</li>
<li>要考虑软中断对CPU使用的挤占&#x2F;以及软中断跨node的影响</li>
<li>测试结果两组数字的话，前者为nginx、软中断分别在不同的node</li>
<li>E5&#x2F;M 软中断绑 node1，测试结果的两组数据表示软中断和nginx跨node和同node（同 node时软中断和nginx尽量错开）</li>
<li>null 指的是 nginx 直接返回 200，不从文件读取html，保证没有文件锁</li>
<li>AMD 软中断总是能跟着绑核的nginx进程跑</li>
<li>压测要将多个核打满，有时候因为软中断的挤占会导致部分核打不满</li>
</ul>
<p>M是裸金属ECS，moc卡插在Die1上，所以软中断默认绑在 Die1 上，测试强行将软中断绑定到 Die0 实际测试结果和绑定在 Die1 性能一样，猜测改了驱动将网络包的描述符没有按硬件绑死而是跟软中断就近分配。</p>
<h2 id="sendfile-和-tcp-nopush"><a href="#sendfile-和-tcp-nopush" class="headerlink" title="sendfile 和 tcp_nopush"></a>sendfile 和 tcp_nopush</h2><h3 id="tcp-nopush-对性能的影响"><a href="#tcp-nopush-对性能的影响" class="headerlink" title="tcp_nopush 对性能的影响"></a>tcp_nopush 对性能的影响</h3><p>M上，返回很小的 html页面，如果 tcp_nopush&#x3D;on 性能能有20%的提升，并且开启后 si% 使用率从10%降到了0. Tcp_nodelay&#x3D;on 就基本对性能没啥影响</p>
<blockquote>
<p>TCP_NOPUSH 是 FreeBSD 的一个 socket 选项，对应 Linux 的 TCP_CORK，Nginx 里统一用 <code>tcp_nopush</code> 来控制它。启用它之后，数据包会累计到一定大小之后才会发送，减小了额外开销，提高网络效率。</p>
<p>To keep everything logical, Nginx tcp_nopush activates the TCP_CORK option in the Linux TCP stack since the TCP_NOPUSH one exists on FreeBSD only.</p>
</blockquote>
<p>nginx on M 8核，http 长连接，访问极小的静态页面（AMD 上测试也是 sendfile off 性能要好30%左右）</p>
<table>
<thead>
<tr>
<th></th>
<th>tcp_nopush on</th>
<th>tcp_nopush off</th>
</tr>
</thead>
<tbody><tr>
<td>sendfile on</td>
<td>46万(PPS 44万)</td>
<td>37万（PPS 73万）</td>
</tr>
<tr>
<td>sendfile off</td>
<td>49万(PPS 48万)</td>
<td>49万（PPS 48万)</td>
</tr>
</tbody></table>
<p>问题：为什么 sendfile off 性能反而好？（PPS 明显低了）</p>
<p>答：一次请求Nginx要回复header+body, header在用户态内存，body走sendfile在内核态内存，nginx没有机会合并header+body, sendfile on后导致每次请求要回复两个tcp包。而 sendfile off的时候虽然有用户态内核态切换、copy，但是有机会把 header&#x2F;body 合并成一个tcp包</p>
<p>从抓包来看，sendfile on的时候每次 http get都是回复两个包：1) http 包头（len：288）2）http body(len: 58) </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221008100922349.png" alt="image-20221008100922349"></p>
<p>sendfile off的时候每次 http get都是回复一个包： http 包头+body（len：292&#x3D;288+4）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221008100808480.png" alt="image-20221008100808480"></p>
<p>在这个小包场景，如果sendfile&#x3D;off 后，回包在http层面就已经合并从1个了，导致内核没机会再次 cork（合并包）；如果sendfile&#x3D;on 则是每次请求回复两个tcp包，如果设置了  nopush 会在内核层面合并一次。</p>
<p>如果不是访问磁盘上的静态页面，而是直接 return某个内存的内容的话，sendfile on&#x2F;off 对性能没有影响，原理也如上，不需要访问磁盘，也就没有机会分两个包发送包头和body了。</p>
<h3 id="分析参考数据"><a href="#分析参考数据" class="headerlink" title="分析参考数据"></a>分析参考数据</h3><p>以下数据都是变换不同的 sendfile、tcp_nopush等组合来观察QPS、setsockopt、PPS来分析这些参数起了什么作用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">//tcp_nopush off; QPS 37万  很明显 pps 比46万高了将近1倍，这是因为 tcp_cork 合并了小包</span><br><span class="line">//nginx 创建连接设置的 sock opt</span><br><span class="line">#cat strace.log.88206</span><br><span class="line">08:31:19.632581 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0 &lt;0.000013&gt;</span><br><span class="line"></span><br><span class="line">#tsar --traffic --live -i1</span><br><span class="line">Time              ---------------------traffic--------------------</span><br><span class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</span><br><span class="line">30/09/22-07:00:22  52.9M  122.8M  748.2K  726.8K    0.00    0.00</span><br><span class="line">30/09/22-07:00:23  52.9M  122.7M  748.1K  726.2K    0.00    0.00</span><br><span class="line">30/09/22-07:00:24  53.0M  122.9M  749.2K  727.2K    0.00    0.00</span><br><span class="line">30/09/22-07:00:25  53.0M  122.8M  749.3K  726.6K    0.00    0.00</span><br><span class="line">30/09/22-07:00:26  52.9M  122.8M  748.2K  727.1K    0.00    0.00</span><br><span class="line">30/09/22-07:00:27  53.1M  123.0M  750.5K  728.0K    0.00    0.00</span><br><span class="line"></span><br><span class="line">//tcp_nopush      on; QPS 46万</span><br><span class="line">#tsar --traffic --live -i1</span><br><span class="line">Time              ---------------------traffic--------------------</span><br><span class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</span><br><span class="line">30/09/22-07:00:54  40.2M  127.6M  447.6K  447.6K    0.00    0.00</span><br><span class="line">30/09/22-07:00:55  40.2M  127.5M  447.1K  447.1K    0.00    0.00</span><br><span class="line">30/09/22-07:00:56  40.1M  127.4M  446.8K  446.8K    0.00    0.00</span><br><span class="line"></span><br><span class="line">//sendfile on ,tcp_nopush on, quickack on; QPS 46万</span><br><span class="line">#ip route change 172.16.0.0/24 dev eth0 quickack 1</span><br><span class="line"></span><br><span class="line">#ip route</span><br><span class="line">default via 172.16.0.253 dev eth0</span><br><span class="line">169.254.0.0/16 dev eth0 scope link metric 1002</span><br><span class="line">172.16.0.0/24 dev eth0 scope link quickack 1</span><br><span class="line">192.168.5.0/24 dev docker0 proto kernel scope link src 192.168.5.1</span><br><span class="line"></span><br><span class="line">//nginx 创建连接设置的 sock opt </span><br><span class="line">#cat strace.log.85937</span><br><span class="line">08:27:44.702111 setsockopt(3, SOL_TCP, TCP_CORK, [1], 4) = 0 &lt;0.000011&gt;</span><br><span class="line">08:27:44.702353 setsockopt(3, SOL_TCP, TCP_CORK, [0], 4) = 0 &lt;0.000013&gt;</span><br><span class="line"></span><br><span class="line">#tsar --traffic -i1 --live</span><br><span class="line">Time              ---------------------traffic--------------------</span><br><span class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</span><br><span class="line">08/10/22-03:27:23  40.7M  152.9M  452.6K  905.2K    0.00    0.00</span><br><span class="line">08/10/22-03:27:24  40.7M  152.9M  452.6K  905.2K    0.00    0.00</span><br><span class="line">08/10/22-03:27:25  40.6M  152.8M  452.3K  904.5K    0.00    0.00</span><br><span class="line">08/10/22-03:27:26  40.6M  152.7M  452.1K  904.1K    0.00    0.00</span><br><span class="line">08/10/22-03:27:27  40.6M  152.7M  452.0K  904.0K    0.00    0.00</span><br><span class="line">08/10/22-03:27:28  40.7M  153.1M  453.2K  906.5K    0.00    0.00</span><br><span class="line"></span><br><span class="line">//sendfile on , quickack on; QPS 42万</span><br><span class="line">#tsar --traffic -i1 --live</span><br><span class="line">Time              ---------------------traffic--------------------</span><br><span class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</span><br><span class="line">08/10/22-04:02:53  57.9M  158.7M  812.3K    1.2M    0.00    0.00</span><br><span class="line">08/10/22-04:02:54  58.3M  159.6M  817.3K    1.2M    0.00    0.00</span><br><span class="line">08/10/22-04:02:55  58.2M  159.4M  816.0K    1.2M    0.00    0.00</span><br></pre></td></tr></table></figure>

<p><a href="https://thoughts.t37.net/nginx-optimization-understanding-sendfile-tcp-nodelay-and-tcp-nopush-c55cdd276765" target="_blank" rel="noopener">This behavior is confirmed in a comment from the TCP stack source about TCP_CORK</a>:</p>
<blockquote>
<p>When set indicates to always queue non-full frames. Later the user clears this option and we transmit any pending partial frames in the queue. This is meant to be used alongside sendfile() to get properly filled frames when the user (for example) must write out headers with a write() call first and then use sendfile to send out the data parts. TCP_CORK can be set together with TCP_NODELAY and it is stronger than TCP_NODELAY.</p>
</blockquote>
<h3 id="perf-top-数据"><a href="#perf-top-数据" class="headerlink" title="perf top 数据"></a>perf top 数据</h3><p>以下都是 sendfile on的时候变换 tcp_nopush 参数得到的不同 perf 数据</p>
<p>tcp_nopush&#x3D;off：(QPS 37万)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220930143920567.png" alt="image-20220930143920567"></p>
<p>tcp_nopush&#x3D;on：(QPS 46万)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220930143419304.png" alt="image-20220930143419304"></p>
<p>对比一下，在sendfile on的时候，用不同的push 参数对应的 tcp 栈</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221009093842151.png" alt="image-20221009093842151"></p>
<h2 id="Nginx-在16核后再增加核数性能提升很少的分析"><a href="#Nginx-在16核后再增加核数性能提升很少的分析" class="headerlink" title="Nginx 在16核后再增加核数性能提升很少的分析"></a>Nginx 在16核后再增加核数性能提升很少的分析</h2><p>16核 perf top</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916174106821.png" alt="image-20220916174106821"></p>
<p>32核 perf top</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916174234039.png" alt="image-20220916174234039"></p>
<p>从以上两个perf top 对比可以看到内核锁消耗增加非常明显</p>
<p>这是因为<a href="https://www.cnblogs.com/LoyenWang/p/12826811.html" target="_blank" rel="noopener">读写文件锁 osq_lock</a> ，比如nginx需要写日志访问 access.log，需要加锁</p>
<p><code>osq(optimistci spinning queue)</code>是基于MCS算法的一个具体实现，osq_lock 是Linux 中对MCS的实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">        return 200 &apos;&lt;!DOCTYPE html&gt;&lt;h2&gt;null!&lt;/h2&gt;\n&apos;; #直接内存返回，不读磁盘文件，避免文件锁</span><br><span class="line">        # because default content-type is application/octet-stream,</span><br><span class="line">    		# browser will offer to &quot;save the file&quot;...</span><br><span class="line">    		# if you want to see reply in browser, uncomment next line </span><br><span class="line">    		# add_header Content-Type text/plain;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="ARM下这个瓶颈更明显"><a href="#ARM下这个瓶颈更明显" class="headerlink" title="ARM下这个瓶颈更明显"></a>ARM下这个瓶颈更明显</h3><p>M上用40-64 core 并发的时候 perf top都是如下图，40 core以上网络瓶颈，pps 达到620万（离ECS规格承诺的1200万还很远），CPU压不起来了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#tsar --traffic -i1 --live</span><br><span class="line">Time              ---------------------traffic--------------------</span><br><span class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</span><br><span class="line">16/09/22-12:41:07 289.4M  682.8M    3.2M    3.2M    0.00    0.00</span><br><span class="line">16/09/22-12:41:08 285.5M  674.4M    3.1M    3.1M    0.00    0.00</span><br><span class="line">16/09/22-12:41:09 285.0M  672.6M    3.1M    3.1M    0.00    0.00</span><br><span class="line">16/09/22-12:41:10 287.5M  678.3M    3.1M    3.1M    0.00    0.00</span><br><span class="line">16/09/22-12:41:11 289.2M  682.0M    3.2M    3.2M    0.00    0.00</span><br><span class="line">16/09/22-12:41:12 290.1M  685.1M    3.2M    3.2M    0.00    0.00</span><br><span class="line">16/09/22-12:41:13 288.3M  680.4M    3.1M    3.1M    0.00    0.00</span><br><span class="line"></span><br><span class="line">#ethtool -l eth0</span><br><span class="line">Channel parameters for eth0:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:		0</span><br><span class="line">TX:		0</span><br><span class="line">Other:		0</span><br><span class="line">Combined:	32  //所以用不满64 core，依据上面的测试数据推算64队列的话那么基本可以跑到1200万pps</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:		0</span><br><span class="line">TX:		0</span><br><span class="line">Other:		0</span><br><span class="line">Combined:	32</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916202347245.png" alt="image-20220916202347245"></p>
<h3 id="文件锁的竞争"><a href="#文件锁的竞争" class="headerlink" title="文件锁的竞争"></a>文件锁的竞争</h3><p>Nginx 在M 上使用 16 core的时候完全压不起来，都是内核态锁竞争，16core QPS 不到23万，线性能力很差（单核68000）</p>
<p>从下图可以看到 sys 偏高，真正用于 us 的 CPU 太少，而内核态 CPU 消耗过高的是 osq_lock(写日志文件锁相关)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916151006533.png" alt="image-20220916151006533"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916151310488.png" alt="image-20220916151310488"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1663329200304-4f4b615b-8507-47c8-87ff-7e92939f12bc.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220916151613388.png" alt="image-20220916151613388"></p>
<p>16核对应的perf状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Performance counter stats for process id &apos;49643&apos;:</span><br><span class="line"></span><br><span class="line">      2479.448740      task-clock (msec)         #    0.994 CPUs utilized</span><br><span class="line">              233      context-switches          #    0.094 K/sec</span><br><span class="line">                0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">                0      page-faults               #    0.000 K/sec</span><br><span class="line">    3,389,330,461      cycles                    #    1.367 GHz</span><br><span class="line">    1,045,248,301      stalled-cycles-frontend   #   30.84% frontend cycles idle</span><br><span class="line">    1,378,321,174      stalled-cycles-backend    #   40.67% backend  cycles idle</span><br><span class="line">    3,877,095,782      instructions              #    1.14  insns per cycle</span><br><span class="line">                                                 #    0.36  stalled cycles per insn</span><br><span class="line">  &lt;not supported&gt;      branches</span><br><span class="line">        2,128,918      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">      2.493168013 seconds time elapsed</span><br></pre></td></tr></table></figure>

<h2 id="软中断和-nginx-所在-node-关系"><a href="#软中断和-nginx-所在-node-关系" class="headerlink" title="软中断和 nginx 所在 node 关系"></a>软中断和 nginx 所在 node 关系</h2><p>以下两种情况的软中断都绑在 32-47 core上</p>
<p>软中断和 nginx 在同一个node，这时基本看不到多少 si% </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220919180725510.png" alt="image-20220919180725510"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220919180758887.png" alt="image-20220919180758887"></p>
<p>软中断和 nginx 跨node（性能相当于同node的70-80%）, 软中断几乎快打满 8 个核了，同时性能还差</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220919180916190.png" alt="image-20220919180916190"></p>
<h3 id="网络描述符、数据缓冲区，设备的关系"><a href="#网络描述符、数据缓冲区，设备的关系" class="headerlink" title="网络描述符、数据缓冲区，设备的关系"></a>网络描述符、数据缓冲区，设备的关系</h3><p>网络描述符的内存分配跟着设备走（设备插在哪个node 就就近在本 node 分配描述符的内存）， 数据缓冲区内存跟着队列(中断)走， 如果队列绑定到DIE0， 而设备在DIE1上，这样在做DMA通信时， 会产生跨 DIE 的交织访问.</p>
<h2 id="Nginx处理HTTP的生命周期"><a href="#Nginx处理HTTP的生命周期" class="headerlink" title="Nginx处理HTTP的生命周期"></a><strong>Nginx处理HTTP的生命周期</strong></h2><p>Nginx将HTTP处理分成了11个阶段。下面的阶段，按顺序执行</p>
<table>
<thead>
<tr>
<th><strong>阶段名称</strong></th>
<th><strong>阶段作用</strong></th>
<th><strong>涉及的模块Moduel</strong></th>
<th><strong>Moduel作用</strong></th>
</tr>
</thead>
<tbody><tr>
<td>POST_READ</td>
<td>接收到完整的http头部后处理的阶段，在uri重写之前。一般跳过</td>
<td>realip</td>
<td>读取客户端真实IP信息，用于限流等</td>
</tr>
<tr>
<td>SERVER_RERITE</td>
<td>location匹配前，修改uri的阶段，用于重定向，location块外的重写指令（多次执行）</td>
<td>rewrite</td>
<td>重定向</td>
</tr>
<tr>
<td>FIND_CONFIG</td>
<td>uri寻找匹配的location块配置项（多次执行）</td>
<td>find_config</td>
<td>根据URI寻找匹配的localtion块配置</td>
</tr>
<tr>
<td>REWRITE</td>
<td>找到location块后再修改uri，location级别的uri重写阶段（多次执行）</td>
<td>rewrite</td>
<td>重定向</td>
</tr>
<tr>
<td>POST_WRITE</td>
<td>防死循环，跳转到对应阶段</td>
<td>&#x2F;</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>PREACCESS</td>
<td>权限预处理</td>
<td>limt_conn</td>
<td>限制处理请求的速率，还可以设置桶的大小，是否延迟等参数</td>
</tr>
<tr>
<td>limit_req</td>
<td>限制连接和请求数</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ACCESS</td>
<td>判断是否允许这个请求进入</td>
<td>auth_basic</td>
<td>实现简单的用户名、密码登录</td>
</tr>
<tr>
<td>access</td>
<td>支持配置allow\deny等指令</td>
<td></td>
<td></td>
</tr>
<tr>
<td>auth_request</td>
<td>将请求转发到第三方认证服务器上</td>
<td></td>
<td></td>
</tr>
<tr>
<td>POST_ACCESS</td>
<td>向用户发送拒绝服务的错误码，用来响应上一阶段的拒绝</td>
<td>&#x2F;</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>PRECONTENT</td>
<td>服务器响应内容之前向响应内容添加一些额外的内容。</td>
<td>try_files</td>
<td>匹配配置的多个url地址</td>
</tr>
<tr>
<td>mirrors</td>
<td>复制一个相同的子请求，例如生产流量复制</td>
<td></td>
<td></td>
</tr>
<tr>
<td>CONTENT</td>
<td>内容生成阶段，该阶段产生响应，并发送到客户端</td>
<td>concat</td>
<td>如果访问多个小文件，可在一次请求上返回多个小文件内容</td>
</tr>
<tr>
<td>random_index，index, auto_index</td>
<td>显示location下目录或目录下的index.html文件的配置</td>
<td></td>
<td></td>
</tr>
<tr>
<td>static</td>
<td>通过absolute_redirect等指令设置重定向的Location等</td>
<td></td>
<td></td>
</tr>
<tr>
<td>LOG</td>
<td>记录访问日志</td>
<td>log</td>
<td>配置日志格式，存储位置等</td>
</tr>
</tbody></table>
<p>也可以通过源码ngx_module.c 中，查看到ngx_module_name，其中包含了在编译 Nginx 的时候的 with 指令所包含的所有模块，它们之间的顺序非常关键，在数组中顺序是相反的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20231117103535342.png" alt="image-20231117103535342"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要考虑软中断、以及网卡软中断队列数量对性能的影响</p>
<p>sendfile不一定导致性能变好了</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>完善的Nginx在AWS Graviton上的测试报告<a href="https://armkeil.blob.core.windows.net/developer/Files/pdf/white-paper/guidelines-for-deploying-nginx-plus-on-aws.pdf" target="_blank" rel="noopener">https://armkeil.blob.core.windows.net/developer/Files/pdf/white-paper/guidelines-for-deploying-nginx-plus-on-aws.pdf</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/07/03/MySQL8.0的一些数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/07/03/MySQL8.0的一些数据/" itemprop="url">MySQL 8.0新特性和性能数据</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-07-03T17:30:03+08:00">
                2022-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MySQL-8-0新特性和性能数据"><a href="#MySQL-8-0新特性和性能数据" class="headerlink" title="MySQL 8.0新特性和性能数据"></a>MySQL 8.0新特性和性能数据</h1><h2 id="MySQL-8-0带来了很多新特性"><a href="#MySQL-8-0带来了很多新特性" class="headerlink" title="MySQL 8.0带来了很多新特性"></a>MySQL 8.0带来了很多新特性</h2><p>针对性能方面介绍全在这个PPT（ <a href="http://dimitrik.free.fr/Presentations/MySQL_Perf-OOW2018-dim.pdf%EF%BC%89%E9%87%8C%E9%9D%A2%E4%BA%86%EF%BC%9A" target="_blank" rel="noopener">http://dimitrik.free.fr/Presentations/MySQL_Perf-OOW2018-dim.pdf）里面了：</a></p>
<p>IO_Bound 下性能提升简直非常明显，之前主要是fil_system的锁导致IO的并发上不去，见图1。</p>
<p>因为优化了redo的写入模式，采用了事件的模型，所以写入场景有较好的提升 。</p>
<p>utf8mb4在点查询场景优势不明显，在distinct range查询下有30%提升。</p>
<p>内存只读场景略有提升。</p>
<p>还有傲腾对SSD的数据，不过Intel都放弃了，就不说了。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><h3 id="page-size"><a href="#page-size" class="headerlink" title="page size"></a>page size</h3><p>MySQL的页都是16K, 当查询的行不在内存中时需要按照16K为单位从磁盘读取页,而文件系统中的页是4k，也就是一次数据库请求需要有4次磁盘IO，如过查询比较随机，每次只需要一个页中的几行数据，存在很大的读放大。</p>
<p>那么我们是否可以把MySQL的页设置为4K来减少读放大呢？</p>
<p>在5.7里收益不大，因为每次IO存在 fil_system 的锁，导致IO的并发上不去</p>
<p>8.0中总算优化了这个场景，测试细节可以参考<a href="http://dimitrik.free.fr/blog/archives/2018/05/mysql-performance-1m-iobound-qps-with-80-ga-on-intel-optane-ssd.html" target="_blank" rel="noopener">这篇</a></p>
<p>16K VS 4K 性能对比（4K接近翻倍）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1547605552845-d406952d-9857-462d-a666-1694b19fbedb.png" alt="img"></p>
<p>4K会带来的问题：顺序insert慢了10%（因为fsync更多了）；DDL更慢；二级索引更多的场景下4K性能较差；大BP下，刷脏代价大。</p>
<h3 id="REDO的优化"><a href="#REDO的优化" class="headerlink" title="REDO的优化"></a><strong>REDO的优化</strong></h3><p>redo的优化似乎是8.0读写性能优于以往的主要原因</p>
<p>redo的模型改成了事件驱动，而不是通过争抢锁实现，专用的flush线程刷完IO后通知用户线程，并且会根据IO的rt自动调整每次flush的data大小，如果io延迟很低，就大量小IO，如果IO延迟高，就用大io刷，也就说redo的刷写能力完全取决于IO的吞吐</p>
<p>但是事件驱动的方式在小并发下性能没有单线程锁的方式高效，这块已经优化了，需要自己测下效果</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220810150929638.png" alt="image-20220810150929638"></p>
<h2 id="Innodb-相关数据"><a href="#Innodb-相关数据" class="headerlink" title="Innodb 相关数据"></a>Innodb 相关数据</h2><p><strong>innodb_row_read</strong>：行读，点查峰值大约在800W左右，列表查大约在1200W左右。<br><strong>innodb_buffer_pool_read_requests</strong>：逻辑读，峰值800W左右。<br><strong>innodb_bp_hit</strong>：innodb bp缓存命中率，比较优秀的命中率一般在99.8%+。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MySQL 8.0优化总结，从官方给出的数据来看，可以总结如下</p>
<ul>
<li>只读场景没有什么优化</li>
<li><a href="https://yuque.antfin-inc.com/frodo/lyul32/qcggx4#b329a99a" target="_blank" rel="noopener">utf8mb4的性能提升比较明显</a></li>
<li>优化了fil_system，<a href="https://yuque.antfin-inc.com/frodo/lyul32/qcggx4#26583664" target="_blank" rel="noopener">MySQL 可以尝试使用4K的页</a></li>
<li>8.0使用新硬件能够获得较好的收益，多socket, optane</li>
<li>由于redo的优化以及<a href="https://mysqlserverteam.com/contention-aware-transaction-scheduling-arriving-in-innodb-to-boost-performance/" target="_blank" rel="noopener">新的热点检查算法</a>，关闭binlog下，读写混合的场景性能比5.7好很多，但是生产环境无法关闭binlog，默认的字符集也不是latin，所以具体的数据需要单独测试，官方数据只能参考</li>
<li>Double Write的问题需要在高并发，低命中率下才会触发，生产环境遇到的不多，该问题预计下个版本就修复了</li>
<li>生产环境需要关闭UNDO Auto-Truncate </li>
<li>binlog的问题在8.0比较明显，暂时没有解法</li>
<li>另外innodb_flush_method&#x3D;O_DIRECT_NO_FSYNC 在8.0.14版本后可以保障应用的稳定性了</li>
</ul>
<blockquote>
<p>Prior to 8.0.14, the <code>O_DIRECT_NO_FSYNC</code> setting is not recommended for use on Linux systems. It may cause the operating system to hang due to file system metadata becoming unsynchronized. As of MySQL 8.0.14, <code>InnoDB</code> calls <code>fsync()</code> after creating a new file, after increasing file size, and after closing a file, which permits <code>O_DIRECT_NO_FSYNC</code> mode to be safely used on EXT4 and XFS file systems. The <code>fsync()</code> system call is still skipped after each write operation.</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/06/05/上下文切换开销/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/06/05/上下文切换开销/" itemprop="url">上下文切换的代价</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-06-05T17:30:00+08:00">
                2022-06-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="上下文切换的代价"><a href="#上下文切换的代价" class="headerlink" title="上下文切换的代价"></a>上下文切换的代价</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>进程切换、软中断、内核态用户态切换、CPU超线程切换</p>
<p>内核态用户态切换：还是在一个线程中，只是由用户态进入内核态为了安全等因素需要更多的指令，系统调用具体多做了啥请看：<a href="https://github.com/torvalds/linux/blob/v5.2/arch/x86/entry/entry_64.S#L145" target="_blank" rel="noopener">https://github.com/torvalds/linux/blob/v5.2/arch/x86/entry/entry_64.S#L145</a></p>
<p>软中断：比如网络包到达，触发ksoftirqd(每个核一个)进程来处理，是进程切换的一种</p>
<p>进程切换是里面最重的，少不了上下文切换，代价还有进程阻塞唤醒调度。另外进程切换有主动让出CPU的切换、也有时间片用完后被切换</p>
<p>CPU超线程切换：最轻，发生在CPU内部，OS、应用都无法感知</p>
<p>多线程调度下的热点火焰图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/7ece6c553c78927c7886f70c09d7e15b.png" alt="image.png"></p>
<p>上下文切换后还会因为调度的原因导致线程卡顿更久</p>
<p>Linux 内核进程调度时间片一般是HZ的倒数，HZ在编译的时候一般设置为1000，倒数也就是1ms，也就是每个进程的时间片是1ms（早年是10ms–HZ 为100的时候），如果进程1阻塞让出CPU进入调度队列，这个时候调度队列前还有两个进程2&#x2F;3在排队，也就是最差会在2ms后才轮到1被调度执行。负载决定了排队等待调度队列的长短，如果轮到调度的进程已经ready那么性能没有浪费，反之如果轮到被调度但是没有ready（比如网络回包没到达）相当浪费了一次调度</p>
<blockquote>
<p><code>sched_min_granularity_ns</code> is the most prominent setting. In the original <a href="https://elixir.bootlin.com/linux/v2.6.25/source/Documentation/scheduler/sched-design-CFS.txt#L82" target="_blank" rel="noopener">sched-design-CFS.txt</a> this was described as the only “tunable” setting, “to tune the scheduler from ‘desktop’ (low latencies) to ‘server’ (good batching) workloads.”</p>
<p>In other words, we can change this setting to reduce overheads from context-switching, and therefore improve throughput at the cost of responsiveness (“latency”).</p>
<p>The CFS setting as mimicking the previous build-time setting, <a href="https://elixir.bootlin.com/linux/v2.6.25/source/kernel/Kconfig.hz" target="_blank" rel="noopener">CONFIG_HZ</a>. In the first version of the CFS code, the default value was 1 ms, equivalent to 1000 Hz for “desktop” usage. Other supported values of CONFIG_HZ were 250 Hz (the default), and 100 Hz for the “server” end. 100 Hz was also useful when running Linux on very slow CPUs, this was one of the reasons given <a href="https://lwn.net/Articles/56378/" target="_blank" rel="noopener">when CONFIG_HZ was first added as an build setting on X86</a>.</p>
</blockquote>
<p>或者参数调整：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#sysctl -a |grep -i sched_ |grep -v cpu</span><br><span class="line">kernel.sched_autogroup_enabled = 0</span><br><span class="line">kernel.sched_cfs_bandwidth_slice_us = 5000</span><br><span class="line">kernel.sched_cfs_bw_burst_enabled = 1</span><br><span class="line">kernel.sched_cfs_bw_burst_onset_percent = 0</span><br><span class="line">kernel.sched_child_runs_first = 0</span><br><span class="line">kernel.sched_latency_ns = 24000000</span><br><span class="line">kernel.sched_migration_cost_ns = 500000</span><br><span class="line">kernel.sched_min_granularity_ns = 3000000</span><br><span class="line">kernel.sched_nr_migrate = 32</span><br><span class="line">kernel.sched_rr_timeslice_ms = 100</span><br><span class="line">kernel.sched_rt_period_us = 1000000</span><br><span class="line">kernel.sched_rt_runtime_us = 950000</span><br><span class="line">kernel.sched_schedstats = 1</span><br><span class="line">kernel.sched_tunable_scaling = 1</span><br><span class="line">kernel.sched_wakeup_granularity_ns = 4000000</span><br></pre></td></tr></table></figure>

<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="How-long-does-it-take-to-make-a-context-switch"><a href="#How-long-does-it-take-to-make-a-context-switch" class="headerlink" title="How long does it take to make a context switch?"></a><a href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="noopener">How long does it take to make a context switch?</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">model name : Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">2 physical CPUs, 26 cores/CPU, 2 hardware threads/core = 104 hw threads total</span><br><span class="line">-- No CPU affinity --</span><br><span class="line">10000000 system calls in 1144720626ns (114.5ns/syscall)</span><br><span class="line">2000000 process context switches in 6280519812ns (3140.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 6417846724ns (3208.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 147035970ns (73.5ns/ctxsw)</span><br><span class="line">-- With CPU affinity --</span><br><span class="line">10000000 system calls in 1109675081ns (111.0ns/syscall)</span><br><span class="line">2000000 process context switches in 4204573541ns (2102.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 2740739815ns (1370.4ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 474815006ns (237.4ns/ctxsw)</span><br><span class="line">-- With CPU affinity to CPU 0 --</span><br><span class="line">10000000 system calls in 1039827099ns (104.0ns/syscall)</span><br><span class="line">2000000 process context switches in 5622932975ns (2811.5ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 5697704164ns (2848.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 143474146ns (71.7ns/ctxsw)</span><br><span class="line">----------</span><br><span class="line">model name : Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</span><br><span class="line">2 physical CPUs, 16 cores/CPU, 2 hardware threads/core = 64 hw threads total</span><br><span class="line">-- No CPU affinity --</span><br><span class="line">10000000 system calls in 772827735ns (77.3ns/syscall)</span><br><span class="line">2000000 process context switches in 4009838007ns (2004.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 5234823470ns (2617.4ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 193276269ns (96.6ns/ctxsw)</span><br><span class="line">-- With CPU affinity --</span><br><span class="line">10000000 system calls in 746578449ns (74.7ns/syscall)</span><br><span class="line">2000000 process context switches in 3598569493ns (1799.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 2475733882ns (1237.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 381484302ns (190.7ns/ctxsw)</span><br><span class="line">-- With CPU affinity to CPU 0 --</span><br><span class="line">10000000 system calls in 746674401ns (74.7ns/syscall)</span><br><span class="line">2000000 process context switches in 4129856807ns (2064.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 4226458450ns (2113.2ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 193047255ns (96.5ns/ctxsw)</span><br><span class="line">---------</span><br><span class="line">model name : Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</span><br><span class="line">2 physical CPUs, 24 cores/CPU, 2 hardware threads/core = 96 hw threads total</span><br><span class="line">-- No CPU affinity --</span><br><span class="line">10000000 system calls in 765013680ns (76.5ns/syscall)</span><br><span class="line">2000000 process context switches in 5906908170ns (2953.5ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 6741875538ns (3370.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 173271254ns (86.6ns/ctxsw)</span><br><span class="line">-- With CPU affinity --</span><br><span class="line">10000000 system calls in 764139687ns (76.4ns/syscall)</span><br><span class="line">2000000 process context switches in 4040915457ns (2020.5ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 2327904634ns (1164.0ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 378847082ns (189.4ns/ctxsw)</span><br><span class="line">-- With CPU affinity to CPU 0 --</span><br><span class="line">10000000 system calls in 762375921ns (76.2ns/syscall)</span><br><span class="line">2000000 process context switches in 5827318932ns (2913.7ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 6360562477ns (3180.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 173019064ns (86.5ns/ctxsw)</span><br><span class="line">--------ECS</span><br><span class="line">model name : Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">1 physical CPUs, 2 cores/CPU, 2 hardware threads/core = 4 hw threads total</span><br><span class="line">-- No CPU affinity --</span><br><span class="line">10000000 system calls in 561242906ns (56.1ns/syscall)</span><br><span class="line">2000000 process context switches in 3025706345ns (1512.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 3333843503ns (1666.9ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 145410372ns (72.7ns/ctxsw)</span><br><span class="line">-- With CPU affinity --</span><br><span class="line">10000000 system calls in 586742944ns (58.7ns/syscall)</span><br><span class="line">2000000 process context switches in 2369203084ns (1184.6ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 1929627973ns (964.8ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 335827569ns (167.9ns/ctxsw)</span><br><span class="line">-- With CPU affinity to CPU 0 --</span><br><span class="line">10000000 system calls in 630259940ns (63.0ns/syscall)</span><br><span class="line">2000000 process context switches in 3027444795ns (1513.7ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 3172677638ns (1586.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 144168251ns (72.1ns/ctxsw)</span><br><span class="line">---------kupeng 920</span><br><span class="line">2 physical CPUs, 96 cores/CPU, 1 hardware threads/core = 192 hw threads total</span><br><span class="line">-- No CPU affinity --</span><br><span class="line">10000000 system calls in 1216730780ns (121.7ns/syscall)</span><br><span class="line">2000000 process context switches in 4653366132ns (2326.7ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 4689966324ns (2345.0ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 167871167ns (83.9ns/ctxsw)</span><br><span class="line">-- With CPU affinity --</span><br><span class="line">10000000 system calls in 1220106854ns (122.0ns/syscall)</span><br><span class="line">2000000 process context switches in 3420506934ns (1710.3ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 2962106029ns (1481.1ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 543325133ns (271.7ns/ctxsw)</span><br><span class="line">-- With CPU affinity to CPU 0 --</span><br><span class="line">10000000 system calls in 1216466158ns (121.6ns/syscall)</span><br><span class="line">2000000 process context switches in 2797948549ns (1399.0ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 3119316050ns (1559.7ns/ctxsw)</span><br><span class="line">2000000  thread context switches in 167728516ns (83.9ns/ctxsw)</span><br></pre></td></tr></table></figure>

<p>测试代码仓库：<a href="https://github.com/tsuna/contextswitch" target="_blank" rel="noopener">https://github.com/tsuna/contextswitch</a></p>
<p>Source code: <a href="https://github.com/tsuna/contextswitch/blob/master/timectxsw.c" target="_blank" rel="noopener">timectxsw.c</a> Results:</p>
<ul>
<li>Intel 5150: ~4300ns&#x2F;context switch</li>
<li>Intel E5440: ~3600ns&#x2F;context switch</li>
<li>Intel E5520: ~4500ns&#x2F;context switch</li>
<li>Intel X5550: ~3000ns&#x2F;context switch</li>
<li>Intel L5630: ~3000ns&#x2F;context switch</li>
<li>Intel E5-2620: ~3000ns&#x2F;context switch</li>
</ul>
<p>如果绑核后上下文切换能提速在66-45%之间</p>
<p>系统调用代价</p>
<p>Source code: <a href="https://github.com/tsuna/contextswitch/blob/master/timesyscall.c" target="_blank" rel="noopener">timesyscall.c</a> Results:</p>
<ul>
<li>Intel 5150: 105ns&#x2F;syscall</li>
<li>Intel E5440: 87ns&#x2F;syscall</li>
<li>Intel E5520: 58ns&#x2F;syscall</li>
<li>Intel X5550: 52ns&#x2F;syscall</li>
<li>Intel L5630: 58ns&#x2F;syscall</li>
<li>Intel E5-2620: 67ns&#x2F;syscall</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s/uq5s5vwk5vtPOZ30sfNsOg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uq5s5vwk5vtPOZ30sfNsOg</a> 进程&#x2F;线程切换究竟需要多少开销？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">创建两个进程并在它们之间传送一个令牌。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。如此往返传送一定的次数，然后统计他们的平均单次切换时间开销</span></span><br><span class="line"><span class="comment">代码来自：https://www.jianshu.com/p/be3250786a91</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/time.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;      //pipe()  </span></span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> x, i, fd[<span class="number">2</span>], p[<span class="number">2</span>];  </span><br><span class="line">    <span class="keyword">char</span> send    = <span class="string">'s'</span>;  </span><br><span class="line">    <span class="keyword">char</span> receive;  </span><br><span class="line">    pipe(fd);  </span><br><span class="line">    pipe(p);  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">tv</span>;</span>  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sched_param</span> <span class="title">param</span>;</span>  </span><br><span class="line">    param.sched_priority = <span class="number">0</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> ((x = fork()) == <span class="number">-1</span>); </span><br><span class="line">    <span class="keyword">if</span> (x==<span class="number">0</span>) &#123;  </span><br><span class="line">        sched_setscheduler(getpid(), SCHED_FIFO, &amp;param);  </span><br><span class="line">        gettimeofday(&amp;tv, <span class="literal">NULL</span>);  </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Before Context Switch Time%u s, %u us\n"</span>, tv.tv_sec, tv.tv_usec);  </span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;  </span><br><span class="line">            read(fd[<span class="number">0</span>], &amp;receive, <span class="number">1</span>);  </span><br><span class="line">            write(p[<span class="number">1</span>], &amp;send, <span class="number">1</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span> &#123;  </span><br><span class="line">        sched_setscheduler(getpid(), SCHED_FIFO, &amp;param);  </span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;  </span><br><span class="line">            write(fd[<span class="number">1</span>], &amp;send, <span class="number">1</span>);  </span><br><span class="line">            read(p[<span class="number">0</span>], &amp;receive, <span class="number">1</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">        gettimeofday(&amp;tv, <span class="literal">NULL</span>);  </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"After Context SWitch Time%u s, %u us\n"</span>, tv.tv_sec, tv.tv_usec);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>平均每次上下文切换耗时3.5us左右</p>
<h2 id="软中断开销计算"><a href="#软中断开销计算" class="headerlink" title="软中断开销计算"></a>软中断开销计算</h2><p>下面的计算方法比较糙，仅供参考。压力越大，一次软中断需要处理的网络包数量就越多，消耗的时间越长。如果包数量太少那么测试干扰就太严重了，数据也不准确。</p>
<p>测试机将收发队列设置为1，让所有软中断交给一个core来处理。</p>
<p>无压力时 interrupt大概4000，然后故意跑压力，CPU跑到80%，通过vmstat和top查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$vmstat 1 </span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">19  0      0 174980 151840 3882800    0    0     0    11    1    1  1  0 99  0  0</span><br><span class="line">11  0      0 174820 151844 3883668    0    0     0     0 30640 113918 59 22 20  0  0</span><br><span class="line"> 9  0      0 175952 151852 3884576    0    0     0   224 29611 108549 57 22 21  0  0</span><br><span class="line">11  0      0 171752 151852 3885636    0    0     0  3452 30682 113874 57 22 21  0  0</span><br></pre></td></tr></table></figure>

<p>top看到 si% 大概为20%，也就是一个核25000个interrupt需要消耗 20% 的CPU, 说明这些软中断消耗了200毫秒</p>
<p>200*1000微秒&#x2F;25000&#x3D;200&#x2F;25&#x3D;8微秒，8000纳秒 – 偏高</p>
<p>降低压力CPU 跑到55% si消耗12%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 6  0      0 174180 152076 3884360    0    0     0     0 25314 119681 40 17 43  0  0</span><br><span class="line"> 1  0      0 172600 152080 3884308    0    0     0   252 24971 116407 40 17 43  0  0</span><br><span class="line"> 4  0      0 174664 152080 3884540    0    0     0  3536 25164 118175 39 18 42  0  0</span><br></pre></td></tr></table></figure>

<p>120*1000微秒&#x2F;(21000)&#x3D;5.7微秒， 5700纳秒 – 偏高</p>
<p>降低压力（4核CPU只压到15%）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 0  0      0 183228 151788 3876288    0    0     0     0 15603 42460  6  3 91  0  0</span><br><span class="line"> 0  0      0 181312 151788 3876032    0    0     0     0 15943 43129  7  2 91  0  0</span><br><span class="line"> 1  0      0 181728 151788 3876544    0    0     0  3232 15790 42409  7  3 90  0  0</span><br><span class="line"> 0  0      0 181584 151788 3875956    0    0     0     0 15728 42641  7  3 90  0  0</span><br><span class="line"> 1  0      0 179276 151792 3876848    0    0     0   192 15862 42875  6  3 91  0  0</span><br><span class="line"> 0  0      0 179508 151796 3876424    0    0     0     0 15404 41899  7  2 91  0  0</span><br></pre></td></tr></table></figure>

<p>单核11000 interrupt，对应 si CPU 2.2%</p>
<p>22*1000&#x2F;11000&#x3D; 2微秒 2000纳秒 略微靠谱</p>
<h2 id="超线程切换开销"><a href="#超线程切换开销" class="headerlink" title="超线程切换开销"></a>超线程切换开销</h2><p>最小，基本可以忽略，1ns以内</p>
<h2 id="lmbench测试工具"><a href="#lmbench测试工具" class="headerlink" title="lmbench测试工具"></a>lmbench测试工具</h2><p>lmbench的lat_ctx等，单位是微秒，压力小的时候一次进程的上下文是1540纳秒</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@plantegg 13:19 /root/lmbench3]</span><br><span class="line"><span class="meta">#</span><span class="bash">taskset -c 4 ./bin/lat_ctx -P 2 -W warmup -s 64 2  //CPU 打满</span></span><br><span class="line">"size=64k ovr=3.47</span><br><span class="line">2 7.88</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">taskset -c 4 ./bin/lat_ctx -P 1 -W warmup -s 64 2</span></span><br><span class="line">"size=64k ovr=3.46</span><br><span class="line">2 1.54</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">taskset -c 4-5 ./bin/lat_ctx  -W warmup -s 64 2</span></span><br><span class="line">"size=64k ovr=3.44</span><br><span class="line">2 3.11</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">taskset -c 4-7 ./bin/lat_ctx -P 2 -W warmup -s 64 2  //CPU 打到50%</span></span><br><span class="line">"size=64k ovr=3.48</span><br><span class="line">2 3.14</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">taskset -c 4-15 ./bin/lat_ctx -P 3 -W warmup -s 64 2</span></span><br><span class="line">"size=64k ovr=3.46</span><br><span class="line">2 3.18</span><br></pre></td></tr></table></figure>

<h2 id="协程对性能的影响"><a href="#协程对性能的影响" class="headerlink" title="协程对性能的影响"></a>协程对性能的影响</h2><p>将WEB服务改用协程调度后，TPS提升50%（30000提升到45000），而contextswitch数量从11万降低到8000（无压力的cs也有4500）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 5  0      0 3831480 153136 3819244    0    0     0     0 23599 6065 79 19  2  0  0</span><br><span class="line"> 4  0      0 3829208 153136 3818824    0    0     0   160 23324 7349 80 18  2  0  0</span><br><span class="line"> 4  0      0 3833320 153140 3818672    0    0     0     0 24567 8213 80 19  2  0  0</span><br><span class="line"> 4  0      0 3831880 153140 3818532    0    0     0     0 24339 8350 78 20  2  0  0</span><br><span class="line"> </span><br><span class="line">[  99s] threads: 60, tps: 0.00, reads/s: 44609.77, writes/s: 0.00, response time: 2.05ms (95%)</span><br><span class="line">[ 100s] threads: 60, tps: 0.00, reads/s: 46538.27, writes/s: 0.00, response time: 1.99ms (95%)</span><br><span class="line">[ 101s] threads: 60, tps: 0.00, reads/s: 46061.84, writes/s: 0.00, response time: 2.01ms (95%)</span><br><span class="line">[ 102s] threads: 60, tps: 0.00, reads/s: 46961.05, writes/s: 0.00, response time: 1.94ms (95%)</span><br><span class="line">[ 103s] threads: 60, tps: 0.00, reads/s: 46224.15, writes/s: 0.00, response time: 2.00ms (95%)</span><br><span class="line">[ 104s] threads: 60, tps: 0.00, reads/s: 46556.93, writes/s: 0.00, response time: 1.98ms (95%)</span><br><span class="line">[ 105s] threads: 60, tps: 0.00, reads/s: 45965.12, writes/s: 0.00, response time: 1.97ms (95%)</span><br><span class="line">[ 106s] threads: 60, tps: 0.00, reads/s: 46369.96, writes/s: 0.00, response time: 2.01ms (95%)</span><br><span class="line"></span><br><span class="line">//4core 机器下</span><br><span class="line"> PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 11588 admin     20   0   12.9g   6.9g  22976 R 95.7 45.6   0:33.07 Root-Worke //四个协程把CPU基本跑满</span><br><span class="line"> 11586 admin     20   0   12.9g   6.9g  22976 R 93.7 45.6   0:34.29 Root-Worke</span><br><span class="line"> 11587 admin     20   0   12.9g   6.9g  22976 R 93.7 45.6   0:32.58 Root-Worke</span><br><span class="line"> 11585 admin     20   0   12.9g   6.9g  22976 R 92.0 45.6   0:33.25 Root-Worke</span><br></pre></td></tr></table></figure>

<p>没开协程CPU有20%闲置打不上去，开了协程后CPU 跑到95%</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>进程上下文切换需要几千纳秒（不同CPU型号会有差异）</li>
<li>如果做taskset 那么上下文切换会减少50%的时间（避免了L1、L2 Miss等）</li>
<li>线程比进程上下文切换略快10%左右</li>
<li>测试数据和实际运行场景相关很大，比较难以把控，CPU竞争太激烈容易把等待调度时间计入；如果CPU比较闲体现不出cache miss等导致的时延加剧</li>
<li>系统调用相对进程上下文切换就很轻了，大概100ns以内</li>
<li>函数调用更轻，大概几个ns，压栈跳转</li>
<li>CPU的超线程调度和函数调用差不多，都是几个ns可以搞定</li>
</ul>
<p>看完这些数据再想想协程是在做什么、为什么效率高就很自然的了</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/05/05/Netty和Disruptor的cache_line对齐实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/05/05/Netty和Disruptor的cache_line对齐实践/" itemprop="url">Netty和Disruptor的cache_line对齐实践</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-05-05T18:20:03+08:00">
                2022-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Netty和Disruptor的cache-line对齐实践"><a href="#Netty和Disruptor的cache-line对齐实践" class="headerlink" title="Netty和Disruptor的cache_line对齐实践"></a>Netty和Disruptor的cache_line对齐实践</h1><p>原理先看这篇：<a href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line%E5%92%8C%E6%80%A7%E8%83%BD/">CPU 性能和Cache Line</a></p>
<p>写这篇文章的起因是这个 <a href="https://mp.weixin.qq.com/s/vkCskOVSpzxt3Umzc_GYrQ" target="_blank" rel="noopener">记一次 Netty PR 的提交</a>，然后我去看了下这次提交，发现Netty的这部分代码有问题、这次提交也有问题</p>
<h2 id="什么是-cache-line"><a href="#什么是-cache-line" class="headerlink" title="什么是 cache_line"></a>什么是 cache_line</h2><p>CPU从内存中读取数据的时候是一次读一个cache_line到 cache中以提升效率，一般情况下cache_line的大小是64 byte，也就是每次读取64byte到CPU cache中，按照热点逻辑这个cache line中的数据大概率会被访问到。</p>
<h3 id="cache-失效"><a href="#cache-失效" class="headerlink" title="cache 失效"></a>cache 失效</h3><p>假设CPU的两个核 A 和 B, 都在各自本地 Cache Line 里有同一个变量1的拷贝时，此时该 Cache Line 处于 Shared 状态。当 核A 在本地修改了变量2，除去把本地变量所属的 Cache Line 置为 Modified 状态以外，还必须在另一个 核B 读另一个变量2前，对该变量所在的 B 处理器本地 Cache Line 发起 Invaidate 操作，标记 B 处理器的那条 Cache Line 为 Invalidate 状态。随后，若处理器 B 在对变量做读写操作时，如果遇到这个标记为 Invalidate 的状态的 Cache Line，即会引发 Cache Miss，从而将内存中最新的数据拷贝到 Cache Line 里，然后处理器 B 再对此 Cache Line 对变量做读写操作。</p>
<p>上面这个过程也叫false-share, 即伪共享，因为变量1、2不是真的关联共享，本来变量1失效不应该导致变量2失效，但是因为cache line机制的存在导致 变量2也失效了，所以这里变量1、2叫false-share</p>
<h2 id="Disruptor中对cache-line的使用"><a href="#Disruptor中对cache-line的使用" class="headerlink" title="Disruptor中对cache_line的使用"></a>Disruptor中对cache_line的使用</h2><p>Disruptor中为了保护下面的那几个final 成员变量，前后都加了 p1-p7就是为了避免这4个final成员不要和别的变量放到同一个cache line中。</p>
<p>重点留意下面代码中的p1-p7这几个没有用的long变量，实际使用来占位，占住实际变量前后的位置，这样避免这些变量被其他变量的修改而失效。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">abstract class RingBufferPad</span><br><span class="line">&#123;</span><br><span class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">abstract class RingBufferFields&lt;E&gt; extends RingBufferPad</span><br><span class="line">&#123;</span><br><span class="line">    ......    </span><br><span class="line">    private final long indexMask;</span><br><span class="line">    private final Object[] entries;</span><br><span class="line">    protected final int bufferSize;</span><br><span class="line">    protected final Sequencer sequencer;</span><br><span class="line">    ......    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">    ......    </span><br><span class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结果如下图所示绿色部分很好地被保护起来一定是独占一个cache line，本来绿色部分都是final，也就是你理解成只读的，不会更改了，这样不会因为共享cache line的变量被修改导致他们所在的cache失效（完全没必要）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1620984677390-81694fd0-0323-4052-98d1-32be39a02248-4505908.png" alt="image.png"></p>
<p>队列大部分时候都是空的（head挨着tail），也就导致head 和 tail在一个cache line中，读和写会造成没必要的cache ping-pong，一般可以通过将head 和 tail 中间填充其它内容来实现错开到不同的cache line中</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1577093636588-6b58c36c-1617-4f2c-aba9-156c52972689-1744256.png" alt="image"></p>
<p>数组(RingBuffer)基本能保证元素在内存中是连续的，但是Queue（链表）就不一定了，连续的话更利于CPU cache</p>
<h2 id="Netty中cache-line的对齐"><a href="#Netty中cache-line的对齐" class="headerlink" title="Netty中cache line的对齐"></a>Netty中cache line的对齐</h2><p><a href="https://github.com/arthur-zhang/netty/blob/e8250372cafe4cf5435a1dbc4c8e400072fb9791/common/src/main/java/io/netty/util/internal/InternalThreadLocalMap.java" target="_blank" rel="noopener">注意下图12行</a>的代码，重点也请注意下11行的注释</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// String-related thread-locals</span><br><span class="line">private StringBuilder stringBuilder;</span><br><span class="line">private Map&lt;Charset, CharsetEncoder&gt; charsetEncoderCache;</span><br><span class="line">private Map&lt;Charset, CharsetDecoder&gt; charsetDecoderCache;</span><br><span class="line"></span><br><span class="line">// ArrayList-related thread-locals</span><br><span class="line">private ArrayList&lt;Object&gt; arrayList;</span><br><span class="line"></span><br><span class="line">private BitSet cleanerFlags;</span><br><span class="line"></span><br><span class="line">/** @deprecated These padding fields will be removed in the future. */</span><br><span class="line">public long rp1, rp2, rp3, rp4, rp5, rp6, rp7, rp8;</span><br><span class="line"></span><br><span class="line">static &#123;</span><br><span class="line">    STRING_BUILDER_INITIAL_SIZE =</span><br><span class="line">            SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.initialSize&quot;, 1024);</span><br><span class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.initialSize: &#123;&#125;&quot;, STRING_BUILDER_INITIAL_SIZE);</span><br><span class="line"></span><br><span class="line">    STRING_BUILDER_MAX_SIZE = SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.maxSize&quot;, 1024 * 4);</span><br><span class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.maxSize: &#123;&#125;&quot;, STRING_BUILDER_MAX_SIZE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一看这里也和Disruptor一样想保护某个变量尽量少失效，可是这个实现我看不出来想要保护哪个变量，因为这种保护办法只对齐了一边，还有一边是和别的变量共享cache line。</p>
<p>另外这个代码之前是9个long rp来对齐，这个<a href="https://github.com/netty/netty/pull/12309" target="_blank" rel="noopener">PR</a>改成了8个，9个就实在是迷惑了（9个long占72bytes了）对齐也是64bytes就好了</p>
<p>还是按照11行注释所说去掉这个对齐的rp吧，要不明确要保护哪些变量，前后夹击真正保护起来，并且做好对比测试</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Netty的这段代码纸上谈兵更多一点，Donald E. Knuth 告诉我们不要提前优化</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/03/15/记一次听风扇声音来定位性能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/03/15/记一次听风扇声音来定位性能/" itemprop="url">听风扇声音来定位性能瓶颈</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-03-15T17:30:03+08:00">
                2022-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="记一次听风扇声音来定位性能瓶颈"><a href="#记一次听风扇声音来定位性能瓶颈" class="headerlink" title="记一次听风扇声音来定位性能瓶颈"></a>记一次听风扇声音来定位性能瓶颈</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在一次POC测试过程中，测试机构提供了两台Intel压力机来压我们的集群</p>
<ul>
<li>压力机1：两路共72core intel 5XXX系列 CPU，主频2.2GHz， 128G内存</li>
<li>压力机2：四路共196core intel 8XXX系列 CPU，主频2.5GHz， 256G内存 （8系列比5系列 CPU的性能要好、要贵）</li>
</ul>
<p>从CPU硬件指标来看压力机2都是碾压压力机1，但是实际测试是压力机2只能跑到接近压力机1的能力，两台机器CPU基本都跑满，并且都是压测进程消耗了90%以上的CPU，内核态消耗不到5%CPU</p>
<p>所以接下来需要在调试我们集群性能前先把测试机优化好，才能把压力打上来。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>测试机构提供的机器上没有任何工具来评估CPU性能，也无法安装，只能<strong>仔细听196core机器的CPU风扇声音更小，说明196core的CPU出工不出力，大概是流水线在频繁地Stall</strong>（不管你信不信反正我是信的）</p>
<p>进一步分析，首先看到 业务消耗了90%以上的CPU，内核态消耗不到5%CPU，两台机器都是这样，这说明 196core 只跑出了 72core的水平，一定是CPU效率出了问题，top看到的CPU占用率不完全是全力在运算，其实cpu 流水线stall也是占用CPU的。</p>
<p>这个分析理论请参考我的文章<a href="https://plantegg.github.io/2021/05/16/Perf%20IPC%E4%BB%A5%E5%8F%8ACPU%E5%88%A9%E7%94%A8%E7%8E%87/">《Perf IPC以及CPU性能》</a></p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>通过stream测试读写内存的带宽和时延，得到如下数据：</p>
<p>72core机器，  本路时延1.1，跨路时延1.4，因为是2路所以有50%的概率跨路，性能下降30%</p>
<p>196core机器，本路时延1.2，跨路时延1.85，因为是4路所以有75%的概率跨路，性能下降50%</p>
<p>从以上测试数据可以明显看到虽然196core机器拥有更强的单核能力以及更多的核数，但是因为访问内存太慢严重拖累了CPU运算能力，导致大部分时间CPU都在等待内存，这里CPU和内存的速度差了2个数量级，所以内存延时才是整体的瓶颈。</p>
<p>测试数据和方法请参考我的文章<a href="https://plantegg.github.io/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">《AMD Zen CPU 架构以及不同CPU性能大PK》</a></p>
<p>有了这个数据心里非常有底问题在哪里了，但是还要想清楚怎么解释给测试机构他们才会信服，因为第一次解释他们直接说不可能，怎么会196core打不过72core呢，再说从来没有集群是测试机构196core压力机打不满的，这台压力机用了几年从来没有人说过这个问题 :(</p>
<h2 id="内存信息"><a href="#内存信息" class="headerlink" title="内存信息"></a>内存信息</h2><p>接下来需要拿到更详细的硬件信息来说服测试机构了。</p>
<p>通过dmidecode 获取两台机器内存的速度，分别是2100（196core） VS 2900（72core），同时系统也吐出了内存延时分别是 0.5ns VS 0.3 ns，这两个时间对比很直观，普通人也能看懂。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">//以下硬件信息是从家里机器上获取，并非测试机构提供的机器，测试机构提供的机器不让拍照和采集</span><br><span class="line">#dmidecode -t memory</span><br><span class="line"># dmidecode 3.2</span><br><span class="line">Getting SMBIOS data from sysfs.</span><br><span class="line">SMBIOS 3.2.1 present.</span><br><span class="line"># SMBIOS implementations newer than version 3.2.0 are not</span><br><span class="line"># fully supported by this version of dmidecode.</span><br><span class="line"></span><br><span class="line">Handle 0x0033, DMI type 16, 23 bytes </span><br><span class="line">Physical Memory Array</span><br><span class="line">	Location: System Board Or Motherboard</span><br><span class="line">	Use: System Memory</span><br><span class="line">	Error Correction Type: Multi-bit ECC</span><br><span class="line">	Maximum Capacity: 2 TB  //最大支持2T</span><br><span class="line">	Error Information Handle: 0x0032</span><br><span class="line">	Number Of Devices: 32   //32个插槽</span><br><span class="line">	</span><br><span class="line">	Handle 0x0041, DMI type 17, 84 bytes</span><br><span class="line">Memory Device</span><br><span class="line">	Array Handle: 0x0033</span><br><span class="line">	Error Information Handle: 0x0040</span><br><span class="line">	Total Width: 72 bits</span><br><span class="line">	Data Width: 64 bits</span><br><span class="line">	Size: 32 GB</span><br><span class="line">	Form Factor: DIMM</span><br><span class="line">	Set: None</span><br><span class="line">	Locator: CPU0_DIMMA0</span><br><span class="line">	Bank Locator: P0 CHANNEL A</span><br><span class="line">	Type: DDR4</span><br><span class="line">	Type Detail: Synchronous Registered (Buffered)</span><br><span class="line">	Speed: 2933 MT/s                    //dmmi 内存插槽支持最大速度 ?</span><br><span class="line">	Manufacturer: SK Hynix</span><br><span class="line">	Serial Number: 220F9EC0</span><br><span class="line">	Asset Tag: Not Specified</span><br><span class="line">	Part Number: HMAA4GR7AJR8N-WM</span><br><span class="line">	Rank: 2</span><br><span class="line">	Configured Memory Speed: 2100 MT/s  //内存实际运行速度</span><br><span class="line">	Minimum Voltage: 1.2 V</span><br><span class="line">	Maximum Voltage: 1.2 V</span><br><span class="line">	Configured Voltage: 1.2 V</span><br><span class="line">	Memory Technology: DRAM</span><br><span class="line">	Memory Operating Mode Capability: Volatile memory</span><br><span class="line">	Module Manufacturer ID: Bank 1, Hex 0xAD</span><br><span class="line">	Non-Volatile Size: None</span><br><span class="line">	Volatile Size: 32 GB</span><br><span class="line">	</span><br><span class="line">	#lshw</span><br><span class="line">	*-bank:19  //主板插槽槽位</span><br><span class="line">             description: DIMM DDR4 Synchronous Registered (Buffered) 2933 MHz (0.3 ns) </span><br><span class="line">             product: HMAA4GR7AJR8N-WM</span><br><span class="line">             vendor: SK Hynix</span><br><span class="line">             physical id: 13</span><br><span class="line">             serial: 220F9F63</span><br><span class="line">             slot: CPU1_DIMMB0</span><br><span class="line">             size: 32GiB  //实际所插内存大小</span><br><span class="line">             width: 64 bits</span><br><span class="line">             clock: 2933MHz (0.3ns)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>In <code>dmidecode</code>’s output for memory, “Speed” is the highest speed supported by the DIMM, as determined by <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="noopener">JEDEC</a> SPD information. “Configured Clock Speed” is the speed at which it is currently running (as set up during boot).</p>
</blockquote>
<p>Dimm（双列直插式存储模块（dual In-line memory module））： DIMM是内存条印刷电路板正反面均有金手指与主板上的内存条槽接触，这种结构被称为DIMM。于是内存条也有人叫DIMM条，主板上的内存槽也有人称为DIMM槽。</p>
<p>大多数主板设计为易于用户安装和更换DIMM，通常只需打开侧边卡扣，将DIMM垂直插入插槽，然后关闭卡扣即可固定内存模块。正确安装DIMM时通常会有轻微的“点击”声，表示模块已经正确位于插槽中。</p>
<p>DIMM 代表物理上的一根内存条，下图中三根内存条共享一个channel连到 CPU</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/05-05_DPC_Bandwidth_Impact.svg" alt="05-05_DPC_Bandwidth_Impact"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220705104403314.png" alt="image-20220705104403314"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/8f04a1f57fe07692327b9269ba484ce4.jpg" alt="img"></p>
<h2 id="最终的运行方案"><a href="#最终的运行方案" class="headerlink" title="最终的运行方案"></a>最终的运行方案</h2><p>给196core的机器换上新的2933 MHz (0.3 ns)的内存条，速度一下子就上去了。</p>
<p>然后在196core的机器上起4个压力进程，每个进程分担25%的压力，避免跨路访问内存导致时延从1.2掉到1.8，实际测试也是只用196core中的48core性能和用全部196core是一样的，所以这里一定要起多个进程做内存亲和性绑定，充分使用全部196core。</p>
<p><strong>最终整机196core机器的打压能力达到了原来的3.6倍左右。</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>程序员要保护好听力，关键时刻可能会用上 :)</p>
<p>你说196core机器用了这么强的CPU但是为什么搭配那么差的内存以及主板，我也不知道，大概是有人拿回扣吧。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://frankdenneman.nl/2016/07/13/numa-deep-dive-4-local-memory-optimization/" target="_blank" rel="noopener">NUMA DEEP DIVE PART 4: LOCAL MEMORY OPTIMIZATION</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/25/ssd_san和sas磁盘性能比较/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/25/ssd_san和sas磁盘性能比较/" itemprop="url">ssd/san/sas/磁盘/光纤性能比较</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-25T17:30:03+08:00">
                2022-01-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ssd-x2F-san-x2F-sas-x2F-磁盘-x2F-光纤-x2F-RAID性能比较"><a href="#ssd-x2F-san-x2F-sas-x2F-磁盘-x2F-光纤-x2F-RAID性能比较" class="headerlink" title="ssd&#x2F;san&#x2F;sas&#x2F;磁盘&#x2F;光纤&#x2F;RAID性能比较"></a>ssd&#x2F;san&#x2F;sas&#x2F;磁盘&#x2F;光纤&#x2F;RAID性能比较</h1><p>本文汇总HDD、SSD、SAN、LVM、软RAID等一些性能数据</p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>正好有机会用到一个san存储设备，跑了一把性能数据，记录一下</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/d57a004c846e193126ca01398e394319.png" alt="image.png"></p>
<p>所使用的测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=1000G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br></pre></td></tr></table></figure>

<p>ssd（Solid State Drive）和san的比较是在同一台物理机上，所以排除了其他因素的干扰。</p>
<p>简要的结论： </p>
<ul>
<li><p>本地ssd性能最好、sas机械盘(RAID10)性能最差</p>
</li>
<li><p>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</p>
</li>
<li><p>从rt来看 ssd:san:sas 大概是 1:3:15</p>
</li>
<li><p>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</p>
</li>
</ul>
<h2 id="NVMe-SSD-和-HDD的性能比较"><a href="#NVMe-SSD-和-HDD的性能比较" class="headerlink" title="NVMe SSD 和 HDD的性能比较"></a>NVMe SSD 和 HDD的性能比较</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/d64a0f78ebf471ac69d447ecb46d90f1.png" alt="image.png"></p>
<p>表中性能差异比上面测试还要大，SSD 的随机 IO 延迟比传统硬盘快百倍以上，一般在微妙级别；IO 带宽也高很多倍，可以达到每秒几个 GB；随机 IOPS 更是快了上千倍，可以达到几十万。</p>
<p><strong>HDD只有一个磁头，并发没有意义，但是SSD支持高并发写入读取。SSD没有磁头、不需要旋转，所以随机读取和顺序读取基本没有差别。</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1ab661ee2d3a71f54bae3ecf62982e7e.png" alt="img"></p>
<p>从上图可以看出如果是随机读写HDD性能极差，但是如果是顺序读写HDD和SDD、内存差异就不那么大了。</p>
<h2 id="磁盘类型查看"><a href="#磁盘类型查看" class="headerlink" title="磁盘类型查看"></a>磁盘类型查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$cat /sys/block/vda/queue/rotational</span><br><span class="line">1  //1表示旋转，非ssd，0表示ssd</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line">lsblk -d -o name,rota,size,label,uuid</span><br></pre></td></tr></table></figure>

<h2 id="fio测试"><a href="#fio测试" class="headerlink" title="fio测试"></a>fio测试</h2><p>以下是两块测试的SSD磁盘测试前的基本情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/dev/sda	240.06G  SSD_SATA  //sata</span><br><span class="line">/dev/sfd0n1	3200G	 SSD_PCIE  //PCIE</span><br><span class="line"></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        49G   29G   18G  63% / </span><br><span class="line">/dev/sfdv0n1p1  2.0T  803G  1.3T  40% /data</span><br><span class="line"></span><br><span class="line"># cat /sys/block/sda/queue/rotational </span><br><span class="line">0</span><br><span class="line"># cat /sys/block/sfdv0n1/queue/rotational </span><br><span class="line">0</span><br><span class="line"></span><br><span class="line">#测试前的iostat状态</span><br><span class="line"># iostat -d sfdv0n1 sda3 1 -x</span><br><span class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda3              0.00    10.67    1.24   18.78     7.82   220.69    22.83     0.03    1.64    1.39    1.66   0.08   0.17</span><br><span class="line">sfdv0n1           0.00     0.21    9.91  841.42   128.15  8237.10    19.65     0.93    0.04    0.25    0.04   1.05  89.52</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda3              0.00    15.00    0.00   17.00     0.00   136.00    16.00     0.03    2.00    0.00    2.00   1.29   2.20</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 11158.00     0.00 54448.00     9.76     1.03    0.02    0.00    0.02   0.09 100.00</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda3              0.00     5.00    0.00   18.00     0.00   104.00    11.56     0.01    0.61    0.00    0.61   0.61   1.10</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 10970.00     0.00 53216.00     9.70     1.02    0.03    0.00    0.03   0.09 100.10</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda3              0.00     0.00    0.00   24.00     0.00   100.00     8.33     0.01    0.58    0.00    0.58   0.08   0.20</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 11206.00     0.00 54476.00     9.72     1.03    0.03    0.00    0.03   0.09  99.90</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda3              0.00    14.00    0.00   21.00     0.00   148.00    14.10     0.01    0.48    0.00    0.48   0.33   0.70</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 10071.00     0.00 49028.00     9.74     1.02    0.03    0.00    0.03   0.10  99.80</span><br></pre></td></tr></table></figure>

<h3 id="NVMe-SSD测试数据"><a href="#NVMe-SSD测试数据" class="headerlink" title="NVMe SSD测试数据"></a>NVMe SSD测试数据</h3><p>对一块ssd进行如下测试(挂载在&#x2F;data 目录)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file (1 file / 16384MiB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=63.8MiB/s][r=0,w=16.3k IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=258871: Tue Feb 23 14:12:23 2021</span><br><span class="line">  write: IOPS=18.9k, BW=74.0MiB/s (77.6MB/s)(4441MiB/60001msec)</span><br><span class="line">    slat (usec): min=4, max=6154, avg=48.82, stdev=56.38</span><br><span class="line">    clat (nsec): min=1049, max=12360k, avg=3326362.62, stdev=920683.43</span><br><span class="line">     lat (usec): min=68, max=12414, avg=3375.52, stdev=928.97</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[ 1483],  5.00th=[ 1811], 10.00th=[ 2114], 20.00th=[ 2376],</span><br><span class="line">     | 30.00th=[ 2704], 40.00th=[ 3130], 50.00th=[ 3523], 60.00th=[ 3785],</span><br><span class="line">     | 70.00th=[ 3949], 80.00th=[ 4080], 90.00th=[ 4293], 95.00th=[ 4490],</span><br><span class="line">     | 99.00th=[ 5604], 99.50th=[ 5997], 99.90th=[ 7111], 99.95th=[ 7832],</span><br><span class="line">     | 99.99th=[ 9634]</span><br><span class="line">   bw (  KiB/s): min=61024, max=118256, per=99.98%, avg=75779.58, stdev=12747.95, samples=120</span><br><span class="line">   iops        : min=15256, max=29564, avg=18944.88, stdev=3186.97, samples=120</span><br><span class="line">  lat (usec)   : 2=0.01%, 100=0.01%, 250=0.01%, 500=0.01%, 750=0.02%</span><br><span class="line">  lat (usec)   : 1000=0.06%</span><br><span class="line">  lat (msec)   : 2=7.40%, 4=66.19%, 10=26.32%, 20=0.01%</span><br><span class="line">  cpu          : usr=5.23%, sys=46.71%, ctx=846953, majf=0, minf=6</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=0,1136905,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=74.0MiB/s (77.6MB/s), 74.0MiB/s-74.0MiB/s (77.6MB/s-77.6MB/s), io=4441MiB (4657MB), run=60001-60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sfdv0n1: ios=0/1821771, merge=0/7335, ticks=0/39708, in_queue=78295, util=100.00%</span><br></pre></td></tr></table></figure>

<p>如上测试iops为：18944，测试期间的iostat，测试中一直有mysql在导入数据，所以测试开始前util就已经100%了，并且w&#x2F;s到了13K左右</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># iostat -d sfdv0n1 3 -x</span><br><span class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.18    3.45  769.17   102.83  7885.16    20.68     0.93    0.04    0.26    0.04   1.16  89.46</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 13168.67     0.00 66244.00    10.06     1.05    0.03    0.00    0.03   0.08 100.10</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 12822.67     0.00 65542.67    10.22     1.04    0.02    0.00    0.02   0.08 100.07</span><br><span class="line"></span><br><span class="line">//增加压力</span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 27348.33     0.00 214928.00    15.72     1.27    0.02    0.00    0.02   0.04 100.17</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     1.00    0.00 32661.67     0.00 271660.00    16.63     1.32    0.02    0.00    0.02   0.03 100.37</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 31645.00     0.00 265988.00    16.81     1.33    0.02    0.00    0.02   0.03 100.37</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00   574.00    0.00 31961.67     0.00 271094.67    16.96     1.36    0.02    0.00    0.02   0.03 100.13</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sfdv0n1           0.00     0.00    0.00 27656.33     0.00 224586.67    16.24     1.28    0.02    0.00    0.02   0.04 100.37</span><br></pre></td></tr></table></figure>

<p>从iostat看出，测试开始前util已经100%（因为ssd，util失去参考意义），w&#x2F;s 13K左右，压力跑起来后w&#x2F;s能到30K，svctm、await均保持稳定</p>
<p>如下测试中direct&#x3D;1和direct&#x3D;0的write avg iops分别为42K、16K</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=16G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=507MiB/s,w=216MiB/s][r=130k,w=55.2k IOPS][eta 00m:00s] </span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=415921: Tue Feb 23 14:34:33 2021</span><br><span class="line">   read: IOPS=99.8k, BW=390MiB/s (409MB/s)(11.2GiB/29432msec)</span><br><span class="line">    slat (nsec): min=1043, max=917837, avg=4273.86, stdev=3792.17</span><br><span class="line">    clat (usec): min=2, max=4313, avg=459.80, stdev=239.61</span><br><span class="line">     lat (usec): min=4, max=4328, avg=464.16, stdev=241.81</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  251],  5.00th=[  277], 10.00th=[  289], 20.00th=[  310],</span><br><span class="line">     | 30.00th=[  326], 40.00th=[  343], 50.00th=[  363], 60.00th=[  400],</span><br><span class="line">     | 70.00th=[  502], 80.00th=[  603], 90.00th=[  750], 95.00th=[  881],</span><br><span class="line">     | 99.00th=[ 1172], 99.50th=[ 1401], 99.90th=[ 3032], 99.95th=[ 3359],</span><br><span class="line">     | 99.99th=[ 3785]</span><br><span class="line">   bw (  KiB/s): min=182520, max=574856, per=99.24%, avg=395975.64, stdev=119541.78, samples=58</span><br><span class="line">   iops        : min=45630, max=143714, avg=98993.90, stdev=29885.42, samples=58</span><br><span class="line">  write: IOPS=42.8k, BW=167MiB/s (175MB/s)(4915MiB/29432msec)</span><br><span class="line">    slat (usec): min=3, max=263, avg= 9.34, stdev= 4.35</span><br><span class="line">    clat (usec): min=14, max=2057, avg=402.26, stdev=140.67</span><br><span class="line">     lat (usec): min=19, max=2070, avg=411.72, stdev=142.67</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  237],  5.00th=[  281], 10.00th=[  293], 20.00th=[  314],</span><br><span class="line">     | 30.00th=[  330], 40.00th=[  343], 50.00th=[  359], 60.00th=[  379],</span><br><span class="line">     | 70.00th=[  404], 80.00th=[  457], 90.00th=[  586], 95.00th=[  717],</span><br><span class="line">     | 99.00th=[  930], 99.50th=[ 1004], 99.90th=[ 1254], 99.95th=[ 1385],</span><br><span class="line">     | 99.99th=[ 1532]</span><br><span class="line">   bw (  KiB/s): min=78104, max=244408, per=99.22%, avg=169671.52, stdev=51142.10, samples=58</span><br><span class="line">   iops        : min=19526, max=61102, avg=42417.86, stdev=12785.51, samples=58</span><br><span class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 50=0.02%, 100=0.04%</span><br><span class="line">  lat (usec)   : 250=1.02%, 500=73.32%, 750=17.28%, 1000=6.30%</span><br><span class="line">  lat (msec)   : 2=1.83%, 4=0.19%, 10=0.01%</span><br><span class="line">  cpu          : usr=15.84%, sys=83.31%, ctx=13765, majf=0, minf=7</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=2936000,1258304,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=390MiB/s (409MB/s), 390MiB/s-390MiB/s (409MB/s-409MB/s), io=11.2GiB (12.0GB), run=29432-29432msec</span><br><span class="line">  WRITE: bw=167MiB/s (175MB/s), 167MiB/s-167MiB/s (175MB/s-175MB/s), io=4915MiB (5154MB), run=29432-29432msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sfdv0n1: ios=795793/1618341, merge=0/11, ticks=218710/27721, in_queue=264935, util=100.00%</span><br><span class="line">[root@nu4d01142 data]# </span><br><span class="line">[root@nu4d01142 data]# fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=6G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=124MiB/s,w=53.5MiB/s][r=31.7k,w=13.7k IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=437523: Tue Feb 23 14:37:54 2021</span><br><span class="line">   read: IOPS=38.6k, BW=151MiB/s (158MB/s)(4300MiB/28550msec)</span><br><span class="line">    slat (nsec): min=1205, max=1826.7k, avg=13253.36, stdev=17173.87</span><br><span class="line">    clat (nsec): min=236, max=5816.8k, avg=1135969.25, stdev=337142.34</span><br><span class="line">     lat (nsec): min=1977, max=5831.2k, avg=1149404.84, stdev=341232.87</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  461],  5.00th=[  627], 10.00th=[  717], 20.00th=[  840],</span><br><span class="line">     | 30.00th=[  938], 40.00th=[ 1029], 50.00th=[ 1123], 60.00th=[ 1221],</span><br><span class="line">     | 70.00th=[ 1319], 80.00th=[ 1434], 90.00th=[ 1565], 95.00th=[ 1680],</span><br><span class="line">     | 99.00th=[ 1893], 99.50th=[ 1975], 99.90th=[ 2671], 99.95th=[ 3261],</span><br><span class="line">     | 99.99th=[ 3851]</span><br><span class="line">   bw (  KiB/s): min=119304, max=216648, per=100.00%, avg=154273.07, stdev=29925.10, samples=57</span><br><span class="line">   iops        : min=29826, max=54162, avg=38568.25, stdev=7481.30, samples=57</span><br><span class="line">  write: IOPS=16.5k, BW=64.6MiB/s (67.7MB/s)(1844MiB/28550msec)</span><br><span class="line">    slat (usec): min=3, max=3565, avg=21.07, stdev=22.23</span><br><span class="line">    clat (usec): min=14, max=9983, avg=1164.21, stdev=459.66</span><br><span class="line">     lat (usec): min=21, max=10011, avg=1185.57, stdev=463.28</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  498],  5.00th=[  619], 10.00th=[  709], 20.00th=[  832],</span><br><span class="line">     | 30.00th=[  930], 40.00th=[ 1020], 50.00th=[ 1123], 60.00th=[ 1237],</span><br><span class="line">     | 70.00th=[ 1336], 80.00th=[ 1450], 90.00th=[ 1598], 95.00th=[ 1713],</span><br><span class="line">     | 99.00th=[ 2311], 99.50th=[ 3851], 99.90th=[ 5932], 99.95th=[ 6456],</span><br><span class="line">     | 99.99th=[ 7701]</span><br><span class="line">   bw (  KiB/s): min=50800, max=92328, per=100.00%, avg=66128.47, stdev=12890.64, samples=57</span><br><span class="line">   iops        : min=12700, max=23082, avg=16532.07, stdev=3222.66, samples=57</span><br><span class="line">  lat (nsec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</span><br><span class="line">  lat (usec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=0.02%, 50=0.03%</span><br><span class="line">  lat (usec)   : 100=0.04%, 250=0.18%, 500=1.01%, 750=11.05%, 1000=25.02%</span><br><span class="line">  lat (msec)   : 2=61.87%, 4=0.62%, 10=0.14%</span><br><span class="line">  cpu          : usr=10.87%, sys=61.98%, ctx=218415, majf=0, minf=7</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=1100924,471940,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=151MiB/s (158MB/s), 151MiB/s-151MiB/s (158MB/s-158MB/s), io=4300MiB (4509MB), run=28550-28550msec</span><br><span class="line">  WRITE: bw=64.6MiB/s (67.7MB/s), 64.6MiB/s-64.6MiB/s (67.7MB/s-67.7MB/s), io=1844MiB (1933MB), run=28550-28550msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sfdv0n1: ios=536103/822037, merge=0/1442, ticks=66507/17141, in_queue=99429, util=100.00%</span><br></pre></td></tr></table></figure>

<h3 id="SATA-SSD测试数据"><a href="#SATA-SSD测试数据" class="headerlink" title="SATA SSD测试数据"></a>SATA SSD测试数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># cat /sys/block/sda/queue/rotational </span><br><span class="line">0</span><br><span class="line"># lsblk -d -o name,rota</span><br><span class="line">NAME     ROTA</span><br><span class="line">sda         0</span><br><span class="line">sfdv0n1     0</span><br></pre></td></tr></table></figure>

<p>-direct&#x3D;0 -buffered&#x3D;0读写iops分别为15.8K、6.8K 比ssd差了不少（都是direct&#x3D;0），如果direct、buffered都是1的话，ESSD性能很差，读写iops分别为4312、1852</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"># fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file (1 file / 2048MiB)</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=68.7MiB/s,w=29.7MiB/s][r=17.6k,w=7594 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=13261: Tue Feb 23 14:42:41 2021</span><br><span class="line">   read: IOPS=15.8k, BW=61.8MiB/s (64.8MB/s)(1432MiB/23172msec)</span><br><span class="line">    slat (nsec): min=1266, max=7261.0k, avg=7101.88, stdev=20655.54</span><br><span class="line">    clat (usec): min=167, max=27670, avg=2832.68, stdev=1786.18</span><br><span class="line">     lat (usec): min=175, max=27674, avg=2839.93, stdev=1784.42</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  437],  5.00th=[  668], 10.00th=[  873], 20.00th=[  988],</span><br><span class="line">     | 30.00th=[ 1401], 40.00th=[ 2442], 50.00th=[ 2835], 60.00th=[ 3195],</span><br><span class="line">     | 70.00th=[ 3523], 80.00th=[ 4047], 90.00th=[ 5014], 95.00th=[ 5866],</span><br><span class="line">     | 99.00th=[ 8160], 99.50th=[ 9372], 99.90th=[13829], 99.95th=[15008],</span><br><span class="line">     | 99.99th=[23725]</span><br><span class="line">   bw (  KiB/s): min=44183, max=149440, per=99.28%, avg=62836.17, stdev=26590.84, samples=46</span><br><span class="line">   iops        : min=11045, max=37360, avg=15709.02, stdev=6647.72, samples=46</span><br><span class="line">  write: IOPS=6803, BW=26.6MiB/s (27.9MB/s)(616MiB/23172msec)</span><br><span class="line">    slat (nsec): min=1566, max=11474k, avg=8460.17, stdev=38221.51</span><br><span class="line">    clat (usec): min=77, max=24047, avg=2789.68, stdev=2042.55</span><br><span class="line">     lat (usec): min=80, max=24054, avg=2798.29, stdev=2040.85</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  265],  5.00th=[  433], 10.00th=[  635], 20.00th=[  840],</span><br><span class="line">     | 30.00th=[  979], 40.00th=[ 2212], 50.00th=[ 2671], 60.00th=[ 3130],</span><br><span class="line">     | 70.00th=[ 3523], 80.00th=[ 4228], 90.00th=[ 5342], 95.00th=[ 6456],</span><br><span class="line">     | 99.00th=[ 9241], 99.50th=[10421], 99.90th=[13960], 99.95th=[15533],</span><br><span class="line">     | 99.99th=[23725]</span><br><span class="line">   bw (  KiB/s): min=18435, max=63112, per=99.26%, avg=27012.57, stdev=11299.42, samples=46</span><br><span class="line">   iops        : min= 4608, max=15778, avg=6753.11, stdev=2824.87, samples=46</span><br><span class="line">  lat (usec)   : 100=0.01%, 250=0.23%, 500=3.14%, 750=5.46%, 1000=15.27%</span><br><span class="line">  lat (msec)   : 2=11.47%, 4=43.09%, 10=20.88%, 20=0.44%, 50=0.01%</span><br><span class="line">  cpu          : usr=3.53%, sys=18.08%, ctx=47448, majf=0, minf=6</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=61.8MiB/s (64.8MB/s), 61.8MiB/s-61.8MiB/s (64.8MB/s-64.8MB/s), io=1432MiB (1502MB), run=23172-23172msec</span><br><span class="line">  WRITE: bw=26.6MiB/s (27.9MB/s), 26.6MiB/s-26.6MiB/s (27.9MB/s-27.9MB/s), io=616MiB (646MB), run=23172-23172msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sda: ios=359202/155123, merge=299/377, ticks=946305/407820, in_queue=1354596, util=99.61%</span><br><span class="line">  </span><br><span class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][95.5%][r=57.8MiB/s,w=25.7MiB/s][r=14.8k,w=6568 IOPS][eta 00m:01s] </span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26167: Tue Feb 23 14:44:40 2021</span><br><span class="line">   read: IOPS=16.9k, BW=65.9MiB/s (69.1MB/s)(1432MiB/21730msec)</span><br><span class="line">    slat (nsec): min=1312, max=4454.2k, avg=8489.99, stdev=15763.97</span><br><span class="line">    clat (usec): min=201, max=18856, avg=2679.38, stdev=1720.02</span><br><span class="line">     lat (usec): min=206, max=18860, avg=2688.03, stdev=1717.19</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  635],  5.00th=[  832], 10.00th=[  914], 20.00th=[  971],</span><br><span class="line">     | 30.00th=[ 1090], 40.00th=[ 2114], 50.00th=[ 2704], 60.00th=[ 3064],</span><br><span class="line">     | 70.00th=[ 3392], 80.00th=[ 3851], 90.00th=[ 4817], 95.00th=[ 5735],</span><br><span class="line">     | 99.00th=[ 7767], 99.50th=[ 8979], 99.90th=[13698], 99.95th=[15139],</span><br><span class="line">     | 99.99th=[16581]</span><br><span class="line">   bw (  KiB/s): min=45168, max=127528, per=100.00%, avg=67625.19, stdev=26620.82, samples=43</span><br><span class="line">   iops        : min=11292, max=31882, avg=16906.28, stdev=6655.20, samples=43</span><br><span class="line">  write: IOPS=7254, BW=28.3MiB/s (29.7MB/s)(616MiB/21730msec)</span><br><span class="line">    slat (nsec): min=1749, max=3412.2k, avg=9816.22, stdev=14501.05</span><br><span class="line">    clat (usec): min=97, max=23473, avg=2556.02, stdev=1980.53</span><br><span class="line">     lat (usec): min=107, max=23477, avg=2566.01, stdev=1977.65</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  277],  5.00th=[  486], 10.00th=[  693], 20.00th=[  824],</span><br><span class="line">     | 30.00th=[  881], 40.00th=[ 1205], 50.00th=[ 2442], 60.00th=[ 2868],</span><br><span class="line">     | 70.00th=[ 3326], 80.00th=[ 3949], 90.00th=[ 5080], 95.00th=[ 6128],</span><br><span class="line">     | 99.00th=[ 8717], 99.50th=[10159], 99.90th=[14484], 99.95th=[15926],</span><br><span class="line">     | 99.99th=[18744]</span><br><span class="line">   bw (  KiB/s): min=19360, max=55040, per=100.00%, avg=29064.05, stdev=11373.59, samples=43</span><br><span class="line">   iops        : min= 4840, max=13760, avg=7266.00, stdev=2843.41, samples=43</span><br><span class="line">  lat (usec)   : 100=0.01%, 250=0.17%, 500=1.66%, 750=3.74%, 1000=22.57%</span><br><span class="line">  lat (msec)   : 2=12.66%, 4=40.62%, 10=18.20%, 20=0.38%, 50=0.01%</span><br><span class="line">  cpu          : usr=4.17%, sys=22.27%, ctx=14314, majf=0, minf=7</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=65.9MiB/s (69.1MB/s), 65.9MiB/s-65.9MiB/s (69.1MB/s-69.1MB/s), io=1432MiB (1502MB), run=21730-21730msec</span><br><span class="line">  WRITE: bw=28.3MiB/s (29.7MB/s), 28.3MiB/s-28.3MiB/s (29.7MB/s-29.7MB/s), io=616MiB (646MB), run=21730-21730msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sda: ios=364744/157621, merge=779/473, ticks=851759/352008, in_queue=1204024, util=99.61%</span><br><span class="line"></span><br><span class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.9MiB/s,w=7308KiB/s][r=4081,w=1827 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=31560: Tue Feb 23 14:46:10 2021</span><br><span class="line">   read: IOPS=4312, BW=16.8MiB/s (17.7MB/s)(1011MiB/60001msec)</span><br><span class="line">    slat (usec): min=63, max=14320, avg=216.76, stdev=430.61</span><br><span class="line">    clat (usec): min=5, max=778861, avg=10254.92, stdev=22345.40</span><br><span class="line">     lat (usec): min=1900, max=782277, avg=10472.16, stdev=22657.06</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</span><br><span class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</span><br><span class="line">     | 70.00th=[    8], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</span><br><span class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  132], 99.95th=[  197],</span><br><span class="line">     | 99.99th=[  760]</span><br><span class="line">   bw (  KiB/s): min=  168, max=29784, per=100.00%, avg=17390.92, stdev=10932.90, samples=119</span><br><span class="line">   iops        : min=   42, max= 7446, avg=4347.71, stdev=2733.21, samples=119</span><br><span class="line">  write: IOPS=1852, BW=7410KiB/s (7588kB/s)(434MiB/60001msec)</span><br><span class="line">    slat (usec): min=3, max=666432, avg=23.59, stdev=2745.39</span><br><span class="line">    clat (msec): min=3, max=781, avg=10.14, stdev=20.50</span><br><span class="line">     lat (msec): min=3, max=781, avg=10.16, stdev=20.72</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</span><br><span class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</span><br><span class="line">     | 70.00th=[    7], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</span><br><span class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  131], 99.95th=[  157],</span><br><span class="line">     | 99.99th=[  760]</span><br><span class="line">   bw (  KiB/s): min=   80, max=12328, per=100.00%, avg=7469.53, stdev=4696.69, samples=119</span><br><span class="line">   iops        : min=   20, max= 3082, avg=1867.34, stdev=1174.19, samples=119</span><br><span class="line">  lat (usec)   : 10=0.01%</span><br><span class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=94.64%, 20=1.78%, 50=0.11%</span><br><span class="line">  lat (msec)   : 100=1.80%, 250=1.63%, 500=0.01%, 750=0.02%, 1000=0.01%</span><br><span class="line">  cpu          : usr=2.51%, sys=10.98%, ctx=260210, majf=0, minf=7</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=258768,111147,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=16.8MiB/s (17.7MB/s), 16.8MiB/s-16.8MiB/s (17.7MB/s-17.7MB/s), io=1011MiB (1060MB), run=60001-60001msec</span><br><span class="line">  WRITE: bw=7410KiB/s (7588kB/s), 7410KiB/s-7410KiB/s (7588kB/s-7588kB/s), io=434MiB (455MB), run=60001-60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sda: ios=258717/89376, merge=0/735, ticks=52540/564186, in_queue=616999, util=90.07%</span><br></pre></td></tr></table></figure>

<h3 id="ESSD磁盘测试数据"><a href="#ESSD磁盘测试数据" class="headerlink" title="ESSD磁盘测试数据"></a>ESSD磁盘测试数据</h3><p>这是一块虚拟的阿里云网络盘，不能算完整意义的SSD（承诺IOPS 4200），数据仅供参考，磁盘概况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$df -lh</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/vda1        99G   30G   65G  32% /</span><br><span class="line"></span><br><span class="line">$cat /sys/block/vda/queue/rotational</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<p>测试数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=10.8MiB/s,w=11.2MiB/s][r=2757,w=2876 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25641: Tue Feb 23 16:35:19 2021</span><br><span class="line">   read: IOPS=2136, BW=8545KiB/s (8750kB/s)(501MiB/60001msec)</span><br><span class="line">    slat (usec): min=190, max=830992, avg=457.20, stdev=3088.80</span><br><span class="line">    clat (nsec): min=1792, max=1721.3M, avg=14657528.60, stdev=63188988.75</span><br><span class="line">     lat (usec): min=344, max=1751.1k, avg=15115.20, stdev=65165.80</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</span><br><span class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1028], 99.95th=[ 1167],</span><br><span class="line">     | 99.99th=[ 1653]</span><br><span class="line">   bw (  KiB/s): min=   56, max=12648, per=100.00%, avg=8598.92, stdev=5289.40, samples=118</span><br><span class="line">   iops        : min=   14, max= 3162, avg=2149.73, stdev=1322.35, samples=118</span><br><span class="line">  write: IOPS=2137, BW=8548KiB/s (8753kB/s)(501MiB/60001msec)</span><br><span class="line">    slat (usec): min=2, max=181, avg= 6.67, stdev= 7.22</span><br><span class="line">    clat (usec): min=628, max=1721.1k, avg=14825.32, stdev=65017.66</span><br><span class="line">     lat (usec): min=636, max=1721.1k, avg=14832.10, stdev=65018.10</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</span><br><span class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1045], 99.95th=[ 1200],</span><br><span class="line">     | 99.99th=[ 1687]</span><br><span class="line">   bw (  KiB/s): min=   72, max=13304, per=100.00%, avg=8602.99, stdev=5296.31, samples=118</span><br><span class="line">   iops        : min=   18, max= 3326, avg=2150.75, stdev=1324.08, samples=118</span><br><span class="line">  lat (usec)   : 2=0.01%, 500=0.01%, 750=0.01%</span><br><span class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=37.85%, 20=61.53%, 50=0.10%</span><br><span class="line">  lat (msec)   : 100=0.06%, 250=0.03%, 500=0.01%, 750=0.03%, 1000=0.25%</span><br><span class="line">  lat (msec)   : 2000=0.14%</span><br><span class="line">  cpu          : usr=0.70%, sys=4.01%, ctx=135029, majf=0, minf=4</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=128180,128223,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=8545KiB/s (8750kB/s), 8545KiB/s-8545KiB/s (8750kB/s-8750kB/s), io=501MiB (525MB), run=60001-60001msec</span><br><span class="line">  WRITE: bw=8548KiB/s (8753kB/s), 8548KiB/s-8548KiB/s (8753kB/s-8753kB/s), io=501MiB (525MB), run=60001-60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vda: ios=127922/87337, merge=0/237, ticks=55122/4269885, in_queue=2209125, util=94.29%</span><br><span class="line"></span><br><span class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9680KiB/s,w=9712KiB/s][r=2420,w=2428 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25375: Tue Feb 23 16:33:03 2021</span><br><span class="line">   read: IOPS=2462, BW=9849KiB/s (10.1MB/s)(577MiB/60011msec)</span><br><span class="line">    slat (nsec): min=1558, max=10663k, avg=5900.28, stdev=46286.64</span><br><span class="line">    clat (usec): min=290, max=93493, avg=13054.57, stdev=4301.89</span><br><span class="line">     lat (usec): min=332, max=93497, avg=13060.60, stdev=4301.68</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[ 1844],  5.00th=[10159], 10.00th=[10290], 20.00th=[10421],</span><br><span class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</span><br><span class="line">     | 70.00th=[18482], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</span><br><span class="line">     | 99.00th=[19530], 99.50th=[19792], 99.90th=[29492], 99.95th=[30278],</span><br><span class="line">     | 99.99th=[43779]</span><br><span class="line">   bw (  KiB/s): min= 9128, max=30392, per=100.00%, avg=9850.12, stdev=1902.00, samples=120</span><br><span class="line">   iops        : min= 2282, max= 7598, avg=2462.52, stdev=475.50, samples=120</span><br><span class="line">  write: IOPS=2465, BW=9864KiB/s (10.1MB/s)(578MiB/60011msec)</span><br><span class="line">    slat (usec): min=2, max=10586, avg= 6.92, stdev=67.34</span><br><span class="line">    clat (usec): min=240, max=69922, avg=12902.33, stdev=4307.92</span><br><span class="line">     lat (usec): min=244, max=69927, avg=12909.37, stdev=4307.03</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[ 1729],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</span><br><span class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</span><br><span class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</span><br><span class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[21103], 99.95th=[35390],</span><br><span class="line">     | 99.99th=[50594]</span><br><span class="line">   bw (  KiB/s): min= 8496, max=31352, per=100.00%, avg=9862.92, stdev=1991.48, samples=120</span><br><span class="line">   iops        : min= 2124, max= 7838, avg=2465.72, stdev=497.87, samples=120</span><br><span class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</span><br><span class="line">  lat (msec)   : 2=1.70%, 4=0.41%, 10=1.25%, 20=96.22%, 50=0.34%</span><br><span class="line">  lat (msec)   : 100=0.01%</span><br><span class="line">  cpu          : usr=0.89%, sys=4.09%, ctx=206337, majf=0, minf=4</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=147768,147981,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=9849KiB/s (10.1MB/s), 9849KiB/s-9849KiB/s (10.1MB/s-10.1MB/s), io=577MiB (605MB), run=60011-60011msec</span><br><span class="line">  WRITE: bw=9864KiB/s (10.1MB/s), 9864KiB/s-9864KiB/s (10.1MB/s-10.1MB/s), io=578MiB (606MB), run=60011-60011msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vda: ios=147515/148154, merge=0/231, ticks=1922378/1915751, in_queue=3780605, util=98.46%</span><br><span class="line">  </span><br><span class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=132KiB/s,w=148KiB/s][r=33,w=37 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25892: Tue Feb 23 16:37:41 2021</span><br><span class="line">   read: IOPS=1987, BW=7949KiB/s (8140kB/s)(467MiB/60150msec)</span><br><span class="line">    slat (usec): min=192, max=599873, avg=479.26, stdev=2917.52</span><br><span class="line">    clat (usec): min=15, max=1975.6k, avg=16004.22, stdev=76024.60</span><br><span class="line">     lat (msec): min=5, max=2005, avg=16.48, stdev=78.00</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</span><br><span class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   19], 99.50th=[  317], 99.90th=[ 1133], 99.95th=[ 1435],</span><br><span class="line">     | 99.99th=[ 1871]</span><br><span class="line">   bw (  KiB/s): min=   32, max=12672, per=100.00%, avg=8034.08, stdev=5399.63, samples=119</span><br><span class="line">   iops        : min=    8, max= 3168, avg=2008.52, stdev=1349.91, samples=119</span><br><span class="line">  write: IOPS=1984, BW=7937KiB/s (8127kB/s)(466MiB/60150msec)</span><br><span class="line">    slat (usec): min=2, max=839634, avg=18.39, stdev=2747.10</span><br><span class="line">    clat (msec): min=5, max=1975, avg=15.64, stdev=73.06</span><br><span class="line">     lat (msec): min=5, max=1975, avg=15.66, stdev=73.28</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</span><br><span class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   18], 99.50th=[  153], 99.90th=[ 1116], 99.95th=[ 1435],</span><br><span class="line">     | 99.99th=[ 1921]</span><br><span class="line">   bw (  KiB/s): min=   24, max=13160, per=100.00%, avg=8021.18, stdev=5405.12, samples=119</span><br><span class="line">   iops        : min=    6, max= 3290, avg=2005.29, stdev=1351.28, samples=119</span><br><span class="line">  lat (usec)   : 20=0.01%</span><br><span class="line">  lat (msec)   : 10=36.51%, 20=62.63%, 50=0.21%, 100=0.12%, 250=0.05%</span><br><span class="line">  lat (msec)   : 500=0.02%, 750=0.02%, 1000=0.19%, 2000=0.26%</span><br><span class="line">  cpu          : usr=0.62%, sys=4.04%, ctx=125974, majf=0, minf=3</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=119533,119347,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=7949KiB/s (8140kB/s), 7949KiB/s-7949KiB/s (8140kB/s-8140kB/s), io=467MiB (490MB), run=60150-60150msec</span><br><span class="line">  WRITE: bw=7937KiB/s (8127kB/s), 7937KiB/s-7937KiB/s (8127kB/s-8127kB/s), io=466MiB (489MB), run=60150-60150msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vda: ios=119533/108186, merge=0/214, ticks=54093/4937255, in_queue=2525052, util=93.99%</span><br><span class="line">  </span><br><span class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9644KiB/s,w=9792KiB/s][r=2411,w=2448 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26139: Tue Feb 23 16:39:43 2021</span><br><span class="line">   read: IOPS=2455, BW=9823KiB/s (10.1MB/s)(576MiB/60015msec)</span><br><span class="line">    slat (nsec): min=1619, max=18282k, avg=5882.81, stdev=71214.52</span><br><span class="line">    clat (usec): min=281, max=64630, avg=13055.68, stdev=4233.17</span><br><span class="line">     lat (usec): min=323, max=64636, avg=13061.69, stdev=4232.79</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[ 2040],  5.00th=[10290], 10.00th=[10421], 20.00th=[10421],</span><br><span class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</span><br><span class="line">     | 70.00th=[18220], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</span><br><span class="line">     | 99.00th=[19530], 99.50th=[20055], 99.90th=[28967], 99.95th=[29754],</span><br><span class="line">     | 99.99th=[30540]</span><br><span class="line">   bw (  KiB/s): min= 8776, max=27648, per=100.00%, avg=9824.29, stdev=1655.78, samples=120</span><br><span class="line">   iops        : min= 2194, max= 6912, avg=2456.05, stdev=413.95, samples=120</span><br><span class="line">  write: IOPS=2458, BW=9835KiB/s (10.1MB/s)(576MiB/60015msec)</span><br><span class="line">    slat (usec): min=2, max=10681, avg= 6.79, stdev=71.30</span><br><span class="line">    clat (usec): min=221, max=70411, avg=12909.50, stdev=4312.40</span><br><span class="line">     lat (usec): min=225, max=70414, avg=12916.40, stdev=4312.05</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[ 1909],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</span><br><span class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</span><br><span class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</span><br><span class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[28705], 99.95th=[40109],</span><br><span class="line">     | 99.99th=[60031]</span><br><span class="line">   bw (  KiB/s): min= 8568, max=28544, per=100.00%, avg=9836.03, stdev=1737.29, samples=120</span><br><span class="line">   iops        : min= 2142, max= 7136, avg=2458.98, stdev=434.32, samples=120</span><br><span class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</span><br><span class="line">  lat (msec)   : 2=1.03%, 4=1.10%, 10=0.98%, 20=96.43%, 50=0.38%</span><br><span class="line">  lat (msec)   : 100=0.01%</span><br><span class="line">  cpu          : usr=0.82%, sys=4.32%, ctx=212008, majf=0, minf=4</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=147386,147564,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=9823KiB/s (10.1MB/s), 9823KiB/s-9823KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</span><br><span class="line">  WRITE: bw=9835KiB/s (10.1MB/s), 9835KiB/s-9835KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vda: ios=147097/147865, merge=0/241, ticks=1916703/1915836, in_queue=3791443, util=98.68%</span><br></pre></td></tr></table></figure>

<p>各类型云盘的性能比较如下表所示。</p>
<table>
<thead>
<tr>
<th align="left">性能类别</th>
<th align="left">ESSD AutoPL云盘（邀测）</th>
<th align="left">ESSD PL-X云盘（邀测）</th>
<th align="left">ESSD云盘 PL3</th>
<th align="left">ESSD云盘 PL0</th>
<th align="left">ESSD云盘 PL1</th>
<th align="left">ESSD云盘 PL0</th>
<th>SSD云盘</th>
<th>高效云盘</th>
<th>普通云盘</th>
</tr>
</thead>
<tbody><tr>
<td align="left">单盘容量范围（GiB）</td>
<td align="left">40~32,768</td>
<td align="left">40~32,768</td>
<td align="left">1261~32,768</td>
<td align="left">461~32,768</td>
<td align="left">20~32,768</td>
<td align="left">40~32,768</td>
<td>20~32,768</td>
<td>20~32,768</td>
<td>5~2,000</td>
</tr>
<tr>
<td align="left">最大IOPS</td>
<td align="left">100,000</td>
<td align="left">3,000,000</td>
<td align="left">1,000,000</td>
<td align="left">100,000</td>
<td align="left">50,000</td>
<td align="left">10,000</td>
<td>25,000</td>
<td>5,000</td>
<td>数百</td>
</tr>
<tr>
<td align="left">最大吞吐量（MB&#x2F;s）</td>
<td align="left">1,131</td>
<td align="left">12,288</td>
<td align="left">4,000</td>
<td align="left">750</td>
<td align="left">350</td>
<td align="left">180</td>
<td>300</td>
<td>140</td>
<td>30~40</td>
</tr>
<tr>
<td align="left">单盘IOPS性能计算公式</td>
<td align="left">min{1,800+50*容量, 50,000}</td>
<td align="left">预配置IOPS</td>
<td align="left">min{1,800+50*容量, 1,000,000}</td>
<td align="left">min{1,800+50*容量, 100,000}</td>
<td align="left">min{1,800+50*容量, 50,000}</td>
<td align="left">min{ 1,800+12*容量, 10,000 }</td>
<td>min{1,800+30*容量, 25,000}</td>
<td>min{1,800+8*容量, 5,000}</td>
<td>无</td>
</tr>
<tr>
<td align="left">单盘吞吐量性能计算公式（MB&#x2F;s）</td>
<td align="left">min{120+0.5*容量, 350}</td>
<td align="left">4 KB*预配置IOPS&#x2F;1024</td>
<td align="left">min{120+0.5*容量, 4,000}</td>
<td align="left">min{120+0.5*容量, 750}</td>
<td align="left">min{120+0.5*容量, 350}</td>
<td align="left">min{100+0.25*容量, 180}</td>
<td>min{120+0.5*容量, 300}</td>
<td>min{100+0.15*容量, 140}</td>
<td>无</td>
</tr>
<tr>
<td align="left">单路随机写平均时延（ms），Block Size&#x3D;4K</td>
<td align="left">0.2</td>
<td align="left">0.03</td>
<td align="left">0.2</td>
<td align="left">0.2</td>
<td align="left">0.2</td>
<td align="left">0.3~0.5</td>
<td>0.5~2</td>
<td>1~3</td>
<td>5~10</td>
</tr>
<tr>
<td align="left">API参数取值</td>
<td align="left">cloud_auto</td>
<td align="left">cloud_plx</td>
<td align="left">cloud_essd</td>
<td align="left">cloud_essd</td>
<td align="left">cloud_essd</td>
<td align="left">cloud_essd</td>
<td>cloud_ssd</td>
<td>cloud_efficiency</td>
<td>cloud</td>
</tr>
</tbody></table>
<h4 id="ESSD-PL3-测试"><a href="#ESSD-PL3-测试" class="headerlink" title="ESSD(PL3) 测试"></a>ESSD(PL3) 测试</h4><blockquote>
<p>阿里云ESSD（Enhanced SSD）云盘结合25 GE网络和RDMA技术，为您提供单盘高达100万的随机读写能力和单路低时延性能。本文介绍了ESSD云盘的性能级别、适用场景及性能上限，提供了选择不同ESSD云盘性能级别时的参考信息。</p>
</blockquote>
<p>测试结论：读能力非常差(不到写的10%)，写能力能符合官方标称的IOPS，但是写IOPS抖动极大，会长时间IOPS 跌0，但最终IOPS还是会达到目标IOPS。</p>
<p>测试命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br></pre></td></tr></table></figure>

<p>ESSD 是aliyun 购买的 ESSD PL3，LVM是海光物理机下两块本地NVMe SSD做的LVM，测试基于ext4文件系统，阿里云官方提供ESSD的 IOPS 性能数据是裸盘（不含文件系统的）</p>
<table>
<thead>
<tr>
<th></th>
<th>本地LVM</th>
<th>ESSD PL3</th>
<th>PL2+倚天</th>
</tr>
</thead>
<tbody><tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -buffered&#x3D;1 read</td>
<td>bw&#x3D;36636KB&#x2F;s, iops&#x3D;9159<br>nvme0n1:util&#x3D;42.31%<br>nvme1n1: util&#x3D;41.63%</td>
<td>IOPS&#x3D;3647, BW&#x3D;14.2MiB&#x2F;s<br>util&#x3D;88.08%</td>
<td>IOPS&#x3D;458k, BW&#x3D;1789MiB&#x2F;s<br>util&#x3D;96.69%</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -buffered&#x3D;1 randwrite</td>
<td>bw&#x3D;383626KB&#x2F;s, iops&#x3D;95906<br>nvme0n1:util&#x3D;37.16%<br>nvme1n1: util&#x3D;33.58%</td>
<td>IOPS&#x3D;104k, BW&#x3D;406MiB&#x2F;s<br>util&#x3D;39.06%</td>
<td>IOPS&#x3D;37.4k, BW&#x3D;146MiB&#x2F;s<br>util&#x3D;94.03%</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -buffered&#x3D;1 randrw rwmixread&#x3D;70</td>
<td>write: bw&#x3D;12765KB&#x2F;s, iops&#x3D;3191<br>read : bw&#x3D;29766KB&#x2F;s, iops&#x3D;7441<br>nvme0n1:util&#x3D;35.18%<br>nvme1n1: util&#x3D;35.04%</td>
<td>write:IOPS&#x3D;1701, BW&#x3D;6808KiB&#x2F;s<br>read: IOPS&#x3D;3962, BW&#x3D;15.5MiB&#x2F;s<br> nvme7n1: util&#x3D;99.35%</td>
<td>write:IOPS&#x3D;1826, BW&#x3D;7306KiB&#x2F;s<br>read:IOPS&#x3D;4254, BW&#x3D;16.6MiB&#x2F;s<br>util&#x3D;98.99%</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0 read</td>
<td>bw&#x3D;67938KB&#x2F;s, iops&#x3D;16984<br>nvme0n1:util&#x3D;43.17%<br>nvme1n1: util&#x3D;39.18%</td>
<td>IOPS&#x3D;4687, BW&#x3D;18.3MiB&#x2F;s<br>util&#x3D;99.75%</td>
<td>read: IOPS&#x3D;145k, BW&#x3D;565MiB&#x2F;s<br>util&#x3D;98.88%</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0 write</td>
<td>bw&#x3D;160775KB&#x2F;s, iops&#x3D;40193<br>nvme0n1:util&#x3D;28.66%<br>nvme1n1: util&#x3D;21.67%</td>
<td>IOPS&#x3D;7153, BW&#x3D;27.9MiB&#x2F;s<br>util&#x3D;99.85%</td>
<td>write: IOPS&#x3D;98.0k, BW&#x3D;387MiB&#x2F;s<br>util&#x3D;99.88%</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0 randrw rwmixread&#x3D;70</td>
<td>write: bw&#x3D;23087KB&#x2F;s, iops&#x3D;5771<br>read : bw&#x3D;53849KB&#x2F;s, iops&#x3D;13462</td>
<td>write:IOPS&#x3D;1511, BW&#x3D;6045KiB&#x2F;s<br>read: IOPS&#x3D;3534, BW&#x3D;13.8MiB&#x2F;s</td>
<td>write: IOPS&#x3D;29.4k, BW&#x3D;115MiB&#x2F;s<br>read: IOPS&#x3D;68.6k, BW&#x3D;268MiB&#x2F;s<br>util&#x3D;99.88%</td>
</tr>
</tbody></table>
<p>结论：</p>
<ul>
<li>ESSD只要有随机读性能就很差,纯读是本地盘（LVM）的40%，纯写和本地盘差不多</li>
<li>direct 读是本地盘的四分之一</li>
<li>direct 写是本地盘的六分之一，写16K Page差距缩小到五分之一（5749&#x2F;25817）</li>
<li>intel direct 写本地intel SSDPE2KX040T8 iops&#x3D;55826（比海光好40%，海光是memblaze）</li>
<li>ESSD 带 buffer 读写抖动很大</li>
<li>ESSD 出现过多次卡死，表现就是磁盘不响应任何操作，大概N分钟后恢复，原因未知</li>
</ul>
<p>PL3单盘IOPS性能计算公式  min{1800+50*容量, 1000000}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=566MiB/s][r=0,w=145k IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2416234: Thu Apr  7 17:03:07 2022</span><br><span class="line">  write: IOPS=96.2k, BW=376MiB/s (394MB/s)(22.0GiB/60000msec)</span><br><span class="line">    slat (usec): min=2, max=530984, avg= 8.27, stdev=1104.96</span><br><span class="line">    clat (usec): min=2, max=944103, avg=599.25, stdev=9230.93</span><br><span class="line">     lat (usec): min=7, max=944111, avg=607.60, stdev=9308.81</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[   392],  5.00th=[   400], 10.00th=[   404], 20.00th=[   408],</span><br><span class="line">     | 30.00th=[   412], 40.00th=[   416], 50.00th=[   420], 60.00th=[   424],</span><br><span class="line">     | 70.00th=[   433], 80.00th=[   441], 90.00th=[   457], 95.00th=[   482],</span><br><span class="line">     | 99.00th=[   627], 99.50th=[   766], 99.90th=[  1795], 99.95th=[  4228],</span><br><span class="line">     | 99.99th=[488637]</span><br><span class="line">   bw (  KiB/s): min=  168, max=609232, per=100.00%, avg=422254.17, stdev=257181.75, samples=108</span><br><span class="line">   iops        : min=   42, max=152308, avg=105563.63, stdev=64295.48, samples=108</span><br><span class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</span><br><span class="line">  lat (usec)   : 500=96.35%, 750=3.11%, 1000=0.26%</span><br><span class="line">  lat (msec)   : 2=0.19%, 4=0.03%, 10=0.02%, 250=0.01%, 500=0.03%</span><br><span class="line">  lat (msec)   : 750=0.01%, 1000=0.01%</span><br><span class="line">  cpu          : usr=13.56%, sys=60.78%, ctx=1455, majf=0, minf=9743</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=0,5771972,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=376MiB/s (394MB/s), 376MiB/s-376MiB/s (394MB/s-394MB/s), io=22.0GiB (23.6GB), run=60000-60000msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vdb: ios=0/1463799, merge=0/7373, ticks=0/2011879, in_queue=2011879, util=27.85%</span><br><span class="line">  </span><br><span class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randread -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [r(1)][100.0%][r=15.9MiB/s,w=0KiB/s][r=4058,w=0 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2441598: Thu Apr  7 17:05:10 2022</span><br><span class="line">   read: IOPS=3647, BW=14.2MiB/s (14.9MB/s)(855MiB/60001msec)</span><br><span class="line">    slat (usec): min=183, max=10119, avg=239.01, stdev=110.20</span><br><span class="line">    clat (usec): min=2, max=54577, avg=15170.17, stdev=1324.10</span><br><span class="line">     lat (usec): min=237, max=55110, avg=15409.34, stdev=1338.09</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[13960],  5.00th=[14091], 10.00th=[14222], 20.00th=[14484],</span><br><span class="line">     | 30.00th=[14615], 40.00th=[14746], 50.00th=[14877], 60.00th=[15139],</span><br><span class="line">     | 70.00th=[15270], 80.00th=[15533], 90.00th=[16057], 95.00th=[16712],</span><br><span class="line">     | 99.00th=[20317], 99.50th=[22152], 99.90th=[26346], 99.95th=[30802],</span><br><span class="line">     | 99.99th=[52691]</span><br><span class="line">   bw (  KiB/s): min= 6000, max=17272, per=100.00%, avg=16511.28, stdev=1140.64, samples=105</span><br><span class="line">   iops        : min= 1500, max= 4318, avg=4127.81, stdev=285.16, samples=105</span><br><span class="line">  lat (usec)   : 4=0.01%, 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</span><br><span class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=98.91%, 50=1.05%</span><br><span class="line">  lat (msec)   : 100=0.02%</span><br><span class="line">  cpu          : usr=0.18%, sys=17.18%, ctx=219041, majf=0, minf=4215</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=218835,0,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=14.2MiB/s (14.9MB/s), 14.2MiB/s-14.2MiB/s (14.9MB/s-14.9MB/s), io=855MiB (896MB), run=60001-60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vdb: ios=218343/7992, merge=0/8876, ticks=50566/3749, in_queue=54315, util=88.08%  </span><br><span class="line"> </span><br><span class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.7MiB/s,w=7031KiB/s][r=4007,w=1757 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2641414: Thu Apr  7 17:21:10 2022</span><br><span class="line">   read: IOPS=3962, BW=15.5MiB/s (16.2MB/s)(929MiB/60001msec)</span><br><span class="line">    slat (usec): min=182, max=7194, avg=243.23, stdev=116.87</span><br><span class="line">    clat (usec): min=2, max=235715, avg=11020.01, stdev=3366.61</span><br><span class="line">     lat (usec): min=253, max=235991, avg=11263.40, stdev=3375.49</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</span><br><span class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   36],</span><br><span class="line">     | 99.99th=[  234]</span><br><span class="line">   bw (  KiB/s): min=10808, max=17016, per=100.00%, avg=15977.89, stdev=895.35, samples=118</span><br><span class="line">   iops        : min= 2702, max= 4254, avg=3994.47, stdev=223.85, samples=118</span><br><span class="line">  write: IOPS=1701, BW=6808KiB/s (6971kB/s)(399MiB/60001msec)</span><br><span class="line">    slat (usec): min=3, max=221631, avg=10.16, stdev=693.59</span><br><span class="line">    clat (usec): min=486, max=235772, avg=11029.42, stdev=3590.93</span><br><span class="line">     lat (usec): min=493, max=235780, avg=11039.67, stdev=3659.04</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</span><br><span class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</span><br><span class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</span><br><span class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   37],</span><br><span class="line">     | 99.99th=[  234]</span><br><span class="line">   bw (  KiB/s): min= 4480, max= 7728, per=100.00%, avg=6862.60, stdev=475.79, samples=118</span><br><span class="line">   iops        : min= 1120, max= 1932, avg=1715.64, stdev=118.97, samples=118</span><br><span class="line">  lat (usec)   : 4=0.01%, 500=0.01%, 750=0.01%</span><br><span class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=20.77%, 20=78.89%, 50=0.31%</span><br><span class="line">  lat (msec)   : 100=0.01%, 250=0.02%</span><br><span class="line">  cpu          : usr=0.65%, sys=7.20%, ctx=239089, majf=0, minf=8292</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=237743,102115,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">   READ: bw=15.5MiB/s (16.2MB/s), 15.5MiB/s-15.5MiB/s (16.2MB/s-16.2MB/s), io=929MiB (974MB), run=60001-60001msec</span><br><span class="line">  WRITE: bw=6808KiB/s (6971kB/s), 6808KiB/s-6808KiB/s (6971kB/s-6971kB/s), io=399MiB (418MB), run=60001-60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vdb: ios=237216/118960, merge=0/8118, ticks=55191/148225, in_queue=203416, util=99.35%</span><br><span class="line">  </span><br><span class="line">[essd_pl3]# fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=64</span><br><span class="line">fio-3.7</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=28.3MiB/s][r=0,w=7249 IOPS][eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2470117: Fri Apr  8 15:35:20 2022</span><br><span class="line">  write: IOPS=7222, BW=28.2MiB/s (29.6MB/s)(846MiB/30001msec)</span><br><span class="line">    clat (usec): min=115, max=7155, avg=137.29, stdev=68.48</span><br><span class="line">     lat (usec): min=115, max=7156, avg=137.36, stdev=68.49</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  121],  5.00th=[  123], 10.00th=[  125], 20.00th=[  126],</span><br><span class="line">     | 30.00th=[  127], 40.00th=[  129], 50.00th=[  130], 60.00th=[  133],</span><br><span class="line">     | 70.00th=[  135], 80.00th=[  139], 90.00th=[  149], 95.00th=[  163],</span><br><span class="line">     | 99.00th=[  255], 99.50th=[  347], 99.90th=[  668], 99.95th=[  947],</span><br><span class="line">     | 99.99th=[ 3589]</span><br><span class="line">   bw (  KiB/s): min=23592, max=30104, per=99.95%, avg=28873.29, stdev=1084.49, samples=59</span><br><span class="line">   iops        : min= 5898, max= 7526, avg=7218.32, stdev=271.12, samples=59</span><br><span class="line">  lat (usec)   : 250=98.95%, 500=0.81%, 750=0.17%, 1000=0.03%</span><br><span class="line">  lat (msec)   : 2=0.02%, 4=0.02%, 10=0.01%</span><br><span class="line">  cpu          : usr=0.72%, sys=5.08%, ctx=216767, majf=0, minf=148</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=0,216677,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=28.2MiB/s (29.6MB/s), 28.2MiB/s-28.2MiB/s (29.6MB/s-29.6MB/s), io=846MiB (888MB), run=30001-30001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  vdb: ios=0/219122, merge=0/3907, ticks=0/29812, in_queue=29812, util=99.52% </span><br><span class="line">  </span><br><span class="line">[root@hygon8 14:44 /polarx/lvm]</span><br><span class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/157.2MB/0KB /s] [0/40.3K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=3486352: Fri Apr  8 14:45:43 2022</span><br><span class="line">  write: io=4710.4MB, bw=160775KB/s, iops=40193, runt= 30001msec</span><br><span class="line">    clat (usec): min=18, max=4164, avg=22.05, stdev= 7.33</span><br><span class="line">     lat (usec): min=19, max=4165, avg=22.59, stdev= 7.36</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[   20],  5.00th=[   20], 10.00th=[   21], 20.00th=[   21],</span><br><span class="line">     | 30.00th=[   21], 40.00th=[   21], 50.00th=[   21], 60.00th=[   22],</span><br><span class="line">     | 70.00th=[   22], 80.00th=[   22], 90.00th=[   23], 95.00th=[   25],</span><br><span class="line">     | 99.00th=[   36], 99.50th=[   40], 99.90th=[   62], 99.95th=[   99],</span><br><span class="line">     | 99.99th=[  157]</span><br><span class="line">    bw (KB  /s): min=147568, max=165400, per=100.00%, avg=160803.12, stdev=2704.22</span><br><span class="line">    lat (usec) : 20=0.08%, 50=99.70%, 100=0.17%, 250=0.04%, 500=0.01%</span><br><span class="line">    lat (usec) : 750=0.01%, 1000=0.01%</span><br><span class="line">    lat (msec) : 2=0.01%, 10=0.01%</span><br><span class="line">  cpu          : usr=6.95%, sys=31.18%, ctx=1205994, majf=0, minf=1573</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=1205849/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=4710.4MB, aggrb=160774KB/s, minb=160774KB/s, maxb=160774KB/s, mint=30001msec, maxt=30001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    dm-2: ios=0/1204503, merge=0/0, ticks=0/15340, in_queue=15340, util=50.78%, aggrios=0/603282, aggrmerge=0/463, aggrticks=0/8822, aggrin_queue=0, aggrutil=28.66%</span><br><span class="line">  nvme0n1: ios=0/683021, merge=0/474, ticks=0/9992, in_queue=0, util=28.66%</span><br><span class="line">  nvme1n1: ios=0/523543, merge=0/452, ticks=0/7652, in_queue=0, util=21.67%</span><br><span class="line">  </span><br><span class="line">[root@x86.170 /polarx/lvm]</span><br><span class="line">#/usr/sbin/nvme list</span><br><span class="line">Node             SN                   Model                                    Namespace Usage                      Format           FW Rev</span><br><span class="line">---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------</span><br><span class="line">/dev/nvme0n1     BTLJ932205P44P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</span><br><span class="line">/dev/nvme1n1     BTLJ932207H04P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</span><br><span class="line">/dev/nvme2n1     BTLJ932205AS4P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</span><br><span class="line">[root@x86.170 /polarx/lvm]</span><br><span class="line">#fio  -bs=4k  -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/240.2MB/0KB /s] [0/61.5K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=11516: Fri Apr  8 15:44:36 2022</span><br><span class="line">  write: io=7143.3MB, bw=243813KB/s, iops=60953, runt= 30001msec</span><br><span class="line">    clat (usec): min=10, max=818, avg=14.96, stdev= 4.14</span><br><span class="line">     lat (usec): min=10, max=818, avg=15.14, stdev= 4.15</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[   11],  5.00th=[   12], 10.00th=[   12], 20.00th=[   14],</span><br><span class="line">     | 30.00th=[   15], 40.00th=[   15], 50.00th=[   15], 60.00th=[   15],</span><br><span class="line">     | 70.00th=[   15], 80.00th=[   16], 90.00th=[   16], 95.00th=[   16],</span><br><span class="line">     | 99.00th=[   20], 99.50th=[   32], 99.90th=[   78], 99.95th=[   84],</span><br><span class="line">     | 99.99th=[  105]</span><br><span class="line">    bw (KB  /s): min=236768, max=246424, per=99.99%, avg=243794.17, stdev=1736.82</span><br><span class="line">    lat (usec) : 20=98.96%, 50=0.73%, 100=0.29%, 250=0.01%, 500=0.01%</span><br><span class="line">    lat (usec) : 750=0.01%, 1000=0.01%</span><br><span class="line">  cpu          : usr=10.65%, sys=42.66%, ctx=1828699, majf=0, minf=7</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=1828662/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=7143.3MB, aggrb=243813KB/s, minb=243813KB/s, maxb=243813KB/s, mint=30001msec, maxt=30001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    dm-0: ios=0/1823575, merge=0/0, ticks=0/13666, in_queue=13667, util=45.56%, aggrios=0/609558, aggrmerge=0/2, aggrticks=0/4280, aggrin_queue=4198, aggrutil=14.47%</span><br><span class="line">  nvme0n1: ios=0/609144, merge=0/6, ticks=0/4438, in_queue=4353, util=14.47%</span><br><span class="line">  nvme1n1: ios=0/609470, merge=0/0, ticks=0/4186, in_queue=4109, util=13.65%</span><br><span class="line">  nvme2n1: ios=0/610060, merge=0/0, ticks=0/4216, in_queue=4134, util=13.74%</span><br></pre></td></tr></table></figure>

<h3 id="倚天-PL3-VS-SSD"><a href="#倚天-PL3-VS-SSD" class="headerlink" title="倚天 PL3 VS SSD"></a>倚天 PL3 VS SSD</h3><p>测试环境倚天裸金属，4.18 CentOS fio-3.7</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>参数</th>
<th>nvme SSD单盘</th>
<th>PL3+倚天裸金属</th>
</tr>
</thead>
<tbody><tr>
<td>randread</td>
<td>fio -bs&#x3D;4k -buffered&#x3D;1</td>
<td>IOPS&#x3D;17.7K</td>
<td>IOPS&#x3D;2533</td>
</tr>
<tr>
<td>randread</td>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0</td>
<td>IOPS&#x3D;269k</td>
<td>IOPS&#x3D;24k</td>
</tr>
<tr>
<td>randwrite</td>
<td>fio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0</td>
<td>IOPS&#x3D;68.5k</td>
<td>IOPS&#x3D;3275</td>
</tr>
<tr>
<td>randwrite</td>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -buffered&#x3D;1</td>
<td>IOPS&#x3D;253k</td>
<td>IOPS&#x3D;250k</td>
</tr>
<tr>
<td>randrw</td>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -buffered&#x3D;1 rwmixread&#x3D;70</td>
<td>write:IOPS&#x3D;8815, read:IOPS&#x3D;20.5K</td>
<td>write:IOPS&#x3D;1059，read:IOPS&#x3D;2482</td>
</tr>
<tr>
<td>randrw</td>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0 rwmixread&#x3D;70</td>
<td>write:IOPS&#x3D;8754, read: IOPS&#x3D;20.4K</td>
<td>write: IOPS&#x3D;940, read: IOPS&#x3D;2212</td>
</tr>
</tbody></table>
<p>测试命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -ioengine=libaio -bs=4k -buffered=1  -thread -rw=randrw -rwmixread=70  -size=16G -filename=./fio.test -name=&quot;essd-pl3&quot; -iodepth=64 -runtime=30</span><br></pre></td></tr></table></figure>

<h3 id="HDD性能测试数据"><a href="#HDD性能测试数据" class="headerlink" title="HDD性能测试数据"></a>HDD性能测试数据</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/0868d560-067f-4302-bc60-bffc3d4460ed.png" alt="img"></p>
<p>从上图可以看到这个磁盘的IOPS 读 935 写 400，读rt 10731nsec 大约10us, 写 17us。如果IOPS是1000的话，rt应该是1ms，实际比1ms小两个数量级，<del>应该是cache、磁盘阵列在起作用。</del></p>
<p>SATA硬盘，10K转</p>
<p>万转机械硬盘组成RAID5阵列，在顺序条件最好的情况下，带宽可以达到1GB&#x2F;s以上，平均延时也非常低，最低只有20多us。但是在随机IO的情况下，机械硬盘的短板就充分暴露了，零点几兆的带宽，将近5ms的延迟，IOPS只有200左右。其原因是因为</p>
<ul>
<li>随机访问直接让RAID卡缓存成了个摆设</li>
<li>磁盘不能并行工作，因为我的机器RAID宽度Strip Size为128 KB</li>
<li>机械轴也得在各个磁道之间跳来跳去。</li>
</ul>
<p>理解了磁盘顺序IO时候的几十M甚至一个GB的带宽，随机IO这个真的是太可怜了。</p>
<p>从上面的测试数据中我们看到了机械硬盘在顺序IO和随机IO下的巨大性能差异。在顺序IO情况下，磁盘是最擅长的顺序IO,再加上Raid卡缓存命中率也高。这时带宽表现有几十、几百M，最好条件下甚至能达到1GB。IOPS这时候能有2-3W左右。到了随机IO的情形下，机械轴也被逼的跳来跳去寻道，RAID卡缓存也失效了。带宽跌到了1MB以下，最低只有100K，IOPS也只有可怜巴巴的200左右。</p>
<h2 id="测试数据总结"><a href="#测试数据总结" class="headerlink" title="测试数据总结"></a>测试数据总结</h2><table>
<thead>
<tr>
<th></th>
<th>-direct&#x3D;1 -buffered&#x3D;1</th>
<th>-direct&#x3D;0 -buffered&#x3D;1</th>
<th>-direct&#x3D;1 -buffered&#x3D;0</th>
<th>-direct&#x3D;0 -buffered&#x3D;0</th>
</tr>
</thead>
<tbody><tr>
<td>NVMe SSD</td>
<td>R&#x3D;10.6k W&#x3D;4544</td>
<td>R&#x3D;10.8K W&#x3D;4642</td>
<td>R&#x3D;99.8K W&#x3D;42.8K</td>
<td>R&#x3D;38.6k W&#x3D;16.5k</td>
</tr>
<tr>
<td>SATA SSD</td>
<td>R&#x3D;4312 W&#x3D;1852</td>
<td>R&#x3D;5389 W&#x3D;2314</td>
<td>R&#x3D;16.9k W&#x3D;7254</td>
<td>R&#x3D;15.8k W&#x3D;6803</td>
</tr>
<tr>
<td>ESSD</td>
<td>R&#x3D;2149 W&#x3D;2150</td>
<td>R&#x3D;1987 W&#x3D;1984</td>
<td>R&#x3D;2462 W&#x3D;2465</td>
<td>R&#x3D;2455 W&#x3D;2458</td>
</tr>
</tbody></table>
<p>看起来，<strong>对于SSD如果buffered为1的话direct没啥用，如果buffered为0那么direct为1性能要好很多</strong></p>
<p><strong>SATA SSD的IOPS比NVMe性能差很多</strong>。</p>
<p>SATA SSD当-buffered&#x3D;1参数下SATA SSD的latency在7-10us之间。 </p>
<p>NVMe SSD以及SATA SSD当buffered&#x3D;0的条件下latency均为2-3us,  NVMe SSD latency参考文章第一个表格， 和本次NVMe测试结果一致.  </p>
<p>ESSD的latency基本是13-16us。</p>
<p>以上NVMe SSD测试数据是在测试过程中还有mysql在全力导入数据的情况下，用fio测试所得。所以空闲情况下测试结果会更好。</p>
<h3 id="网上测试数据参考"><a href="#网上测试数据参考" class="headerlink" title="网上测试数据参考"></a><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="noopener">网上测试数据参考</a></h3><p>我们来一起看一下具体的数据。首先来看NVＭe如何减小了协议栈本身的时间消耗，我们用<em>blktrace</em>工具来分析一组传输在应用程序层、操作系统层、驱动层和硬件层消耗的时间和占比，来了解AHCI和NVMe协议的性能区别：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/v2-8b37f236d5c754efabe17aa9706f99a3_720w.jpg" alt="img"></p>
<p>硬盘HDD作为一个参考基准，它的时延是非常大的，达到14ms，而AHCI SATA为125us，NVMe为111us。我们从图中可以看出，NVMe相对AHCI，协议栈及之下所占用的时间比重明显减小，应用程序层面等待的时间占比很高，这是因为SSD物理硬盘速度不够快，导致应用空转。NVMe也为将来Optane硬盘这种低延迟介质的速度提高留下了广阔的空间。</p>
<h2 id="对比LVM-、RAID0和-一块NVMe-SSD"><a href="#对比LVM-、RAID0和-一块NVMe-SSD" class="headerlink" title="对比LVM 、RAID0和 一块NVMe SSD"></a>对比LVM 、RAID0和 一块NVMe SSD</h2><p>曙光H620-G30A机型下测试</p>
<p>各拿两块nvme，分别作LVM和RAID0，另外单独拿一块nvme直接读写，条带用的是4块nvme做的，然后比较顺序、随机读写，测试结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>RAID0（2块盘）</th>
<th>NVMe</th>
<th>LVM</th>
<th>RAID0（4块盘）</th>
<th>线性（4块 linear）</th>
</tr>
</thead>
<tbody><tr>
<td>dd write bs&#x3D;1M count&#x3D;10240 conv&#x3D;fsync</td>
<td>10.9秒</td>
<td>23秒</td>
<td>24.6秒</td>
<td>10.9秒</td>
<td>11.9秒</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k  -buffered&#x3D;1</td>
<td>bw&#x3D;346744KB&#x2F;s, iops&#x3D;86686 <br> nvme6n1: util&#x3D;38.43%<br> nvme7n1: util&#x3D;38.96%</td>
<td>bw&#x3D;380816KB&#x2F;s, iops&#x3D;95203<br>nvme2n1: util&#x3D;68.31%</td>
<td>bw&#x3D;175704KB&#x2F;s, iops&#x3D;43925<br>nvme0n1:util&#x3D;29.60%<br>nvme1n1: util&#x3D;25.64%</td>
<td>bw&#x3D;337495KB&#x2F;s, iops&#x3D;84373<br> nvme6n1: util&#x3D;20.93%<br> nvme5n1: util&#x3D;21.30%<br> nvme4n1: util&#x3D;21.12%<br> nvme7n1: util&#x3D;20.95%</td>
<td>bw&#x3D;329721KB&#x2F;s, iops&#x3D;82430<br> nvme0n1: util&#x3D;67.22%<br> nvme3n1: util&#x3D;0%<br>线性每次只写一块盘</td>
</tr>
<tr>
<td>fio -ioengine&#x3D;libaio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0</td>
<td>bw&#x3D;121556KB&#x2F;s, iops&#x3D;30389 <br> nvme6n1: util&#x3D;18.70%<br> nvme7n1: util&#x3D;18.91%</td>
<td>bw&#x3D;126215KB&#x2F;s, iops&#x3D;31553<br>nvme2n1: util&#x3D;37.27%</td>
<td>bw&#x3D;117192KB&#x2F;s, iops&#x3D;29297<br>nvme0n1:util&#x3D;21.16%<br>nvme1n1: util&#x3D;13.35%</td>
<td>bw&#x3D;119145KB&#x2F;s, iops&#x3D;29786<br> nvme6n1: util&#x3D;9.19%<br> nvme5n1: util&#x3D;9.45%<br> nvme4n1: util&#x3D;9.45%<br> nvme7n1: util&#x3D;9.30%</td>
<td>bw&#x3D;116688KB&#x2F;s, iops&#x3D;29171<br> nvme0n1: util&#x3D;37.87%<br> nvme3n1: util&#x3D;0%<br>线性每次只写一块盘</td>
</tr>
<tr>
<td>fio -bs&#x3D;4k -direct&#x3D;1 -buffered&#x3D;0</td>
<td>bw&#x3D;104107KB&#x2F;s, iops&#x3D;26026 <br> nvme6n1: util&#x3D;15.55%<br> nvme7n1: util&#x3D;15.00%</td>
<td>bw&#x3D;105115KB&#x2F;s, iops&#x3D;26278<br>nvme2n1: util&#x3D;31.25%</td>
<td>bw&#x3D;101936KB&#x2F;s, iops&#x3D;25484<br>nvme0n1:util&#x3D;17.76%<br>nvme1n1: util&#x3D;12.07%</td>
<td>bw&#x3D;102517KB&#x2F;s, iops&#x3D;25629<br> nvme6n1: util&#x3D;8.13%<br> nvme5n1: util&#x3D;7.65%<br> nvme4n1: util&#x3D;7.57%<br> nvme7n1: util&#x3D;7.75%</td>
<td>bw&#x3D;87280KB&#x2F;s, iops&#x3D;21820<br> nvme0n1: util&#x3D;31.27%<br> nvme3n1: util&#x3D;0%<br>线性每次只写一块盘</td>
</tr>
</tbody></table>
<ul>
<li>整体看 nvme 最好(顺序写除外)，raid0性能接近nvme，LVM最差</li>
<li>顺序写raid0是nvme、LVM的两倍</li>
<li>随机读写带buffered的话 nvme最好，raid0略差（猜测是软件消耗），LVM只有前两者的一半</li>
<li>关掉buffered 三者性能下降都很大，最终差异变小</li>
<li>raid0下两块盘非常均衡，LVM下两块盘负载差异比较大</li>
<li>性能不在单块盘到了瓶颈，当阵列中盘数变多后，软件实现的LVM、RAID性能都有下降</li>
<li>开buffer对性能提升非常大</li>
<li>每次测试前都会echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches ; rm -f .&#x2F;fio.test ;测试跑多次，取稳定值</li>
</ul>
<h3 id="顺序读写"><a href="#顺序读写" class="headerlink" title="顺序读写"></a>顺序读写</h3><p>然后同时做dd写入测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time taskset -c 0 dd if=/dev/zero of=./tempfile2 bs=1M count=40240 &amp;</span><br></pre></td></tr></table></figure>

<p>下图上面两块nvme做的LVM，下面两块nvme做成RAID0，同时开始测试，可以看到RAID0的两块盘写入速度更快</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211231205730735.png" alt="image-20211231205730735"></p>
<p>测试结果</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211231205842753.png" alt="image-20211231205842753"></p>
<p>实际单独写一块nvme也比写两块nvme做的LVM要快一倍，对dd这样的顺序读写，软RAID0还是能提升一倍速度的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@hygon33 14:02 /nvme]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</span><br><span class="line">记录了10240+0 的读入</span><br><span class="line">记录了10240+0 的写出</span><br><span class="line">10737418240字节（11 GB，10 GiB）已复制，23.0399 s，466 MB/s</span><br><span class="line"></span><br><span class="line">real	0m23.046s</span><br><span class="line">user	0m0.004s</span><br><span class="line">sys	0m8.033s</span><br><span class="line"></span><br><span class="line">[root@hygon33 14:08 /nvme]</span><br><span class="line">#cd ../md0/</span><br><span class="line"></span><br><span class="line">[root@hygon33 14:08 /md0]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</span><br><span class="line">记录了10240+0 的读入</span><br><span class="line">记录了10240+0 的写出</span><br><span class="line">10737418240字节（11 GB，10 GiB）已复制，10.9632 s，979 MB/s</span><br><span class="line"></span><br><span class="line">real	0m10.967s</span><br><span class="line">user	0m0.004s</span><br><span class="line">sys	0m10.899s</span><br><span class="line"></span><br><span class="line">[root@hygon33 14:08 /md0]</span><br><span class="line">#cd /polarx/</span><br><span class="line"></span><br><span class="line">[root@hygon33 14:08 /polarx]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</span><br><span class="line">记录了10240+0 的读入</span><br><span class="line">记录了10240+0 的写出</span><br><span class="line">10737418240字节（11 GB，10 GiB）已复制，24.6481 s，436 MB/s</span><br><span class="line"></span><br><span class="line">real	0m24.653s</span><br><span class="line">user	0m0.008s</span><br><span class="line">sys	0m24.557s</span><br></pre></td></tr></table></figure>

<h3 id="随机读写"><a href="#随机读写" class="headerlink" title="随机读写"></a>随机读写</h3><p>SSD单独的随机读IOPS大概是随机写IOPS的10%, 应该是因为write有cache</p>
<p>RAID0是使用mdadm做的软raid，系统层面还是有消耗，没法和RAID卡硬件比较</p>
<p>左边是一块nvme，中间是两块nvme做了LVM，右边是两块nvme做RAID0，看起来速度差不多，一块nvme似乎要好一点点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220101104145331.png" alt="image-20220101104145331"></p>
<p>从观察来看，RAID0的两块盘读写、iops都非常均衡，LVM的两块盘</p>
<p>三个测试分开跑，独立nvme性能最好，LVM最差并且不均衡</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220101110016074.png" alt="image-20220101110016074"></p>
<p>三个测试分开跑，去掉 aio，性能都只有原来的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220101110708888.png" alt="image-20220101110708888"></p>
<p>修改fio参数，用最快的 direct&#x3D;0 buffered&#x3D;1 aio 结论是raid0最快，直接写nvme略慢，LVM只有raid0的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">[root@hygon33 13:43 /md0]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [98.1% done] [0KB/394.3MB/0KB /s] [0/101K/0 iops] [eta 00m:01s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21016: Sat Jan  1 13:45:25 2022</span><br><span class="line">  write: io=16384MB, bw=329974KB/s, iops=82493, runt= 50844msec</span><br><span class="line">    slat (usec): min=3, max=1496, avg= 9.00, stdev= 2.76</span><br><span class="line">    clat (usec): min=5, max=2272, avg=764.73, stdev=101.63</span><br><span class="line">     lat (usec): min=10, max=2282, avg=774.19, stdev=103.15</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  510],  5.00th=[  612], 10.00th=[  644], 20.00th=[  684],</span><br><span class="line">     | 30.00th=[  700], 40.00th=[  716], 50.00th=[  772], 60.00th=[  820],</span><br><span class="line">     | 70.00th=[  844], 80.00th=[  860], 90.00th=[  884], 95.00th=[  908],</span><br><span class="line">     | 99.00th=[  932], 99.50th=[  940], 99.90th=[  988], 99.95th=[ 1064],</span><br><span class="line">     | 99.99th=[ 1336]</span><br><span class="line">    bw (KB  /s): min=277928, max=490720, per=99.84%, avg=329447.45, stdev=40386.54</span><br><span class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</span><br><span class="line">    lat (usec) : 500=0.17%, 750=48.67%, 1000=51.08%</span><br><span class="line">    lat (msec) : 2=0.08%, 4=0.01%</span><br><span class="line">  cpu          : usr=17.79%, sys=81.97%, ctx=113, majf=0, minf=5526</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=16384MB, aggrb=329974KB/s, minb=329974KB/s, maxb=329974KB/s, mint=50844msec, maxt=50844msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    md0: ios=0/2883541, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/1232592, aggrmerge=0/219971, aggrticks=0/44029, aggrin_queue=0, aggrutil=38.91%</span><br><span class="line">  nvme6n1: ios=0/1228849, merge=0/219880, ticks=0/43940, in_queue=0, util=37.19%</span><br><span class="line">  nvme7n1: ios=0/1236335, merge=0/220062, ticks=0/44119, in_queue=0, util=38.91%</span><br><span class="line">  </span><br><span class="line">[root@hygon33 13:46 /nvme]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/314.3MB/0KB /s] [0/80.5K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21072: Sat Jan  1 13:47:32 2022</span><br><span class="line">  write: io=16384MB, bw=309554KB/s, iops=77388, runt= 54198msec</span><br><span class="line">    slat (usec): min=3, max=88800, avg= 9.83, stdev=44.88</span><br><span class="line">    clat (usec): min=5, max=89662, avg=815.09, stdev=381.75</span><br><span class="line">     lat (usec): min=27, max=89748, avg=825.38, stdev=385.05</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  470],  5.00th=[  612], 10.00th=[  652], 20.00th=[  684],</span><br><span class="line">     | 30.00th=[  716], 40.00th=[  756], 50.00th=[  796], 60.00th=[  836],</span><br><span class="line">     | 70.00th=[  876], 80.00th=[  932], 90.00th=[ 1012], 95.00th=[ 1096],</span><br><span class="line">     | 99.00th=[ 1272], 99.50th=[ 1368], 99.90th=[ 1688], 99.95th=[ 1912],</span><br><span class="line">     | 99.99th=[ 3920]</span><br><span class="line">    bw (KB  /s): min=247208, max=523840, per=99.99%, avg=309507.85, stdev=34709.01</span><br><span class="line">    lat (usec) : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%, 500=1.73%</span><br><span class="line">    lat (usec) : 750=37.71%, 1000=49.60%</span><br><span class="line">    lat (msec) : 2=10.91%, 4=0.03%, 10=0.01%, 100=0.01%</span><br><span class="line">  cpu          : usr=16.00%, sys=79.36%, ctx=138668, majf=0, minf=5522</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=16384MB, aggrb=309554KB/s, minb=309554KB/s, maxb=309554KB/s, mint=54198msec, maxt=54198msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    dm-0: ios=77/1587455, merge=0/0, ticks=184/244940, in_queue=245124, util=98.23%, aggrios=77/1584444, aggrmerge=0/5777, aggrticks=183/193531, aggrin_queue=76, aggrutil=81.60%</span><br><span class="line">  sda: ios=77/1584444, merge=0/5777, ticks=183/193531, in_queue=76, util=81.60%</span><br><span class="line">  </span><br><span class="line">[root@hygon33 13:50 /polarx]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/293.2MB/0KB /s] [0/75.1K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=22787: Sat Jan  1 13:51:16 2022</span><br><span class="line">  write: io=10270MB, bw=175269KB/s, iops=43817, runt= 60001msec</span><br><span class="line">    slat (usec): min=4, max=2609, avg=19.43, stdev=19.84</span><br><span class="line">    clat (usec): min=4, max=6420, avg=1438.87, stdev=483.15</span><br><span class="line">     lat (usec): min=17, max=6718, avg=1458.80, stdev=490.29</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  700],  5.00th=[  788], 10.00th=[  852], 20.00th=[  964],</span><br><span class="line">     | 30.00th=[ 1080], 40.00th=[ 1208], 50.00th=[ 1368], 60.00th=[ 1560],</span><br><span class="line">     | 70.00th=[ 1752], 80.00th=[ 1944], 90.00th=[ 2128], 95.00th=[ 2224],</span><br><span class="line">     | 99.00th=[ 2416], 99.50th=[ 2480], 99.90th=[ 2672], 99.95th=[ 3248],</span><br><span class="line">     | 99.99th=[ 5088]</span><br><span class="line">    bw (KB  /s): min=109992, max=308016, per=99.40%, avg=174219.83, stdev=56844.59</span><br><span class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</span><br><span class="line">    lat (usec) : 500=0.01%, 750=2.87%, 1000=20.63%</span><br><span class="line">    lat (msec) : 2=59.43%, 4=17.03%, 10=0.03%</span><br><span class="line">  cpu          : usr=9.11%, sys=57.07%, ctx=762410, majf=0, minf=1769</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=2629079/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=10270MB, aggrb=175269KB/s, minb=175269KB/s, maxb=175269KB/s, mint=60001msec, maxt=60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    dm-2: ios=1/3185487, merge=0/0, ticks=0/86364, in_queue=86364, util=46.24%, aggrios=0/1576688, aggrmerge=0/16344, aggrticks=0/40217, aggrin_queue=0, aggrutil=29.99%</span><br><span class="line">  nvme0n1: ios=0/1786835, merge=0/16931, ticks=0/44447, in_queue=0, util=29.99%</span><br><span class="line">  nvme1n1: ios=1/1366541, merge=0/15758, ticks=0/35987, in_queue=0, util=25.44%</span><br></pre></td></tr></table></figure>

<p>将RAID0从两块nvme改成四块后，整体性能略微下降</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/99756KB/0KB /s] [0/24.1K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=30608: Sat Jan  1 12:09:29 2022</span><br><span class="line">  write: io=5733.9MB, bw=97857KB/s, iops=24464, runt= 60001msec</span><br><span class="line">    clat (usec): min=29, max=2885, avg=37.95, stdev=12.19</span><br><span class="line">     lat (usec): min=30, max=2886, avg=38.49, stdev=12.20</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[   32],  5.00th=[   33], 10.00th=[   34], 20.00th=[   35],</span><br><span class="line">     | 30.00th=[   36], 40.00th=[   36], 50.00th=[   37], 60.00th=[   37],</span><br><span class="line">     | 70.00th=[   38], 80.00th=[   39], 90.00th=[   40], 95.00th=[   49],</span><br><span class="line">     | 99.00th=[   65], 99.50th=[   76], 99.90th=[  109], 99.95th=[  125],</span><br><span class="line">     | 99.99th=[  203]</span><br><span class="line">    bw (KB  /s): min=92968, max=108344, per=99.99%, avg=97846.18, stdev=2085.73</span><br><span class="line">    lat (usec) : 50=95.20%, 100=4.61%, 250=0.18%, 500=0.01%, 750=0.01%</span><br><span class="line">    lat (usec) : 1000=0.01%</span><br><span class="line">    lat (msec) : 2=0.01%, 4=0.01%</span><br><span class="line">  cpu          : usr=4.67%, sys=56.35%, ctx=1467919, majf=0, minf=1144</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=1467872/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=5733.9MB, aggrb=97856KB/s, minb=97856KB/s, maxb=97856KB/s, mint=60001msec, maxt=60001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    md0: ios=0/1553786, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/370860, aggrmerge=0/17733, aggrticks=0/6539, aggrin_queue=0, aggrutil=8.41%</span><br><span class="line">  nvme6n1: ios=0/369576, merge=0/17648, ticks=0/6439, in_queue=0, util=7.62%</span><br><span class="line">  nvme5n1: ios=0/370422, merge=0/17611, ticks=0/6600, in_queue=0, util=7.72%</span><br><span class="line">  nvme4n1: ios=0/371559, merge=0/18092, ticks=0/6511, in_queue=0, util=8.41%</span><br><span class="line">  nvme7n1: ios=0/371886, merge=0/17584, ticks=0/6606, in_queue=0, util=8.17%</span><br></pre></td></tr></table></figure>

<h3 id="raid6测试"><a href="#raid6测试" class="headerlink" title="raid6测试"></a>raid6测试</h3><p>raid6开buffer性能比raid0还要好10-20%，实际是将刷盘延迟异步在做，如果用-buffer&#x3D;0 raid6的性能只有raid0的一半</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220105173206915.png" alt="image-20220105173206915"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">[root@hygon33 17:19 /md6]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/424.9MB/0KB /s] [0/109K/0 iops] [eta 00m:00s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=117679: Wed Jan  5 17:21:13 2022</span><br><span class="line">  write: io=16384MB, bw=432135KB/s, iops=108033, runt= 38824msec</span><br><span class="line">    slat (usec): min=4, max=7289, avg= 6.06, stdev= 5.28</span><br><span class="line">    clat (usec): min=3, max=7973, avg=584.23, stdev=45.35</span><br><span class="line">     lat (usec): min=10, max=7986, avg=590.77, stdev=45.75</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  548],  5.00th=[  556], 10.00th=[  564], 20.00th=[  572],</span><br><span class="line">     | 30.00th=[  580], 40.00th=[  580], 50.00th=[  580], 60.00th=[  588],</span><br><span class="line">     | 70.00th=[  588], 80.00th=[  596], 90.00th=[  604], 95.00th=[  612],</span><br><span class="line">     | 99.00th=[  636], 99.50th=[  660], 99.90th=[  796], 99.95th=[  820],</span><br><span class="line">     | 99.99th=[  916]</span><br><span class="line">    bw (KB  /s): min=423896, max=455400, per=99.97%, avg=432015.17, stdev=6404.92</span><br><span class="line">    lat (usec) : 4=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</span><br><span class="line">    lat (usec) : 500=0.01%, 750=99.78%, 1000=0.21%</span><br><span class="line">    lat (msec) : 2=0.01%, 4=0.01%, 10=0.01%</span><br><span class="line">  cpu          : usr=21.20%, sys=78.56%, ctx=57, majf=0, minf=1769</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=16384MB, aggrb=432135KB/s, minb=432135KB/s, maxb=432135KB/s, mint=38824msec, maxt=38824msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    md6: ios=0/162790, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=83058/153522, aggrmerge=1516568/962072, aggrticks=29792/16802, aggrin_queue=2425, aggrutil=44.71%</span><br><span class="line">  nvme0n1: ios=83410/144109, merge=1517412/995022, ticks=31218/16718, in_queue=2416, util=43.62%</span><br><span class="line">  nvme3n1: ios=83301/162626, merge=1517086/927594, ticks=24190/17067, in_queue=2364, util=34.14%</span><br><span class="line">  nvme2n1: ios=81594/144341, merge=1514750/992273, ticks=32204/16646, in_queue=2504, util=44.71%</span><br><span class="line">  nvme1n1: ios=83929/163013, merge=1517025/933399, ticks=31559/16780, in_queue=2416, util=42.83%</span><br><span class="line"></span><br><span class="line">[root@hygon33 17:21 /md6]</span><br><span class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</span><br><span class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</span><br><span class="line">fio-2.2.8</span><br><span class="line">Starting 1 thread</span><br><span class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</span><br><span class="line">Jobs: 1 (f=0): [w(1)] [22.9% done] [0KB/51034KB/0KB /s] [0/12.8K/0 iops] [eta 03m:25s]</span><br><span class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=164871: Wed Jan  5 17:25:17 2022</span><br><span class="line">  write: io=3743.6MB, bw=63887KB/s, iops=15971, runt= 60003msec</span><br><span class="line">    slat (usec): min=11, max=123152, avg=29.39, stdev=283.93</span><br><span class="line">    clat (usec): min=261, max=196197, avg=3975.22, stdev=3526.29</span><br><span class="line">     lat (usec): min=300, max=196223, avg=4005.13, stdev=3554.65</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    3],  5.00th=[    3], 10.00th=[    4], 20.00th=[    4],</span><br><span class="line">     | 30.00th=[    4], 40.00th=[    4], 50.00th=[    4], 60.00th=[    4],</span><br><span class="line">     | 70.00th=[    5], 80.00th=[    5], 90.00th=[    5], 95.00th=[    6],</span><br><span class="line">     | 99.00th=[    7], 99.50th=[    7], 99.90th=[   39], 99.95th=[   88],</span><br><span class="line">     | 99.99th=[  167]</span><br><span class="line">    bw (KB  /s): min=41520, max=78176, per=100.00%, avg=64093.14, stdev=6896.65</span><br><span class="line">    lat (usec) : 500=0.02%, 750=0.03%, 1000=0.02%</span><br><span class="line">    lat (msec) : 2=0.73%, 4=64.28%, 10=34.72%, 20=0.06%, 50=0.08%</span><br><span class="line">    lat (msec) : 100=0.02%, 250=0.05%</span><br><span class="line">  cpu          : usr=4.11%, sys=48.69%, ctx=357564, majf=0, minf=2653</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</span><br><span class="line">     issued    : total=r=0/w=958349/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: io=3743.6MB, aggrb=63886KB/s, minb=63886KB/s, maxb=63886KB/s, mint=60003msec, maxt=60003msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    md6: ios=0/1022450, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=262364/764703, aggrmerge=430291/192464, aggrticks=38687/55432, aggrin_queue=317, aggrutil=42.63%</span><br><span class="line">  nvme0n1: ios=262282/759874, merge=430112/209613, ticks=43304/55197, in_queue=324, util=42.63%</span><br><span class="line">  nvme3n1: ios=260535/771153, merge=430415/176326, ticks=25263/55664, in_queue=280, util=26.11%</span><br><span class="line">  nvme2n1: ios=263663/758974, merge=430349/208189, ticks=42754/55761, in_queue=280, util=42.14%</span><br><span class="line">  nvme1n1: ios=262976/768813, merge=430289/175731, ticks=43430/55109, in_queue=384, util=42.00%</span><br></pre></td></tr></table></figure>

<p>测试完成很久后ssd还维持高水位的读写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.28    0.00    1.15    0.05    0.00   98.51</span><br><span class="line"></span><br><span class="line">Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz  aqu-sz  %util</span><br><span class="line">dm-0             5.00     56.00     0.00   0.00    0.53    11.20   39.00    292.33     0.00   0.00    0.00     7.50    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</span><br><span class="line">md6              0.00      0.00     0.00   0.00    0.00     0.00   14.00   1794.67     0.00   0.00    0.00   128.19    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.00</span><br><span class="line">nvme0n1       1164.67 144488.00 34935.33  96.77    0.74   124.06 3203.67  53877.83 10267.00  76.22    0.16    16.82    0.00      0.00     0.00   0.00    0.00     0.00    0.32  32.13</span><br><span class="line">nvme1n1       1172.33 144402.67 34925.00  96.75    0.74   123.18 3888.67  46635.17  7771.33  66.65    0.13    11.99    0.00      0.00     0.00   0.00    0.00     0.00    0.33  29.60</span><br><span class="line">nvme2n1       1166.67 144372.00 34914.00  96.77    0.74   123.75 3263.00  53699.17 10162.67  75.70    0.14    16.46    0.00      0.00     0.00   0.00    0.00     0.00    0.33  27.87</span><br><span class="line">nvme3n1       1157.67 144414.67 34934.33  96.79    0.64   124.75 3894.33  47073.83  7875.00  66.91    0.13    12.09    0.00      0.00     0.00   0.00    0.00     0.00    0.31  20.80</span><br><span class="line">sda              5.00     56.00     0.00   0.00    0.13    11.20   39.00    204.17     0.00   0.00    0.12     5.24    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</span><br></pre></td></tr></table></figure>

<h2 id="fio-结果解读"><a href="#fio-结果解读" class="headerlink" title="fio 结果解读"></a>fio 结果解读</h2><p>slat，异步场景下才有</p>
<blockquote>
<p>其中slat指的是发起IO的时间，在异步IO模式下，发起IO以后，IO会异步完成。例如调用一个异步的write，虽然write返回成功了，但是IO还未完成，slat约等于发起write的耗时；</p>
<p>slat (usec): min&#x3D;4, max&#x3D;6154, avg&#x3D;48.82, stdev&#x3D;56.38： The first latency metric you’ll see is the ‘slat’ or submission latency. It is pretty much what it sounds like, meaning “how long did it take to submit this IO to the kernel for processing?”</p>
</blockquote>
<p>clat</p>
<blockquote>
<p>clat指的是完成时间，从发起IO后到完成IO的时间，在同步IO模式下，clat是指整个写动作完成时间</p>
</blockquote>
<p>lat</p>
<blockquote>
<p>lat是总延迟时间，指的是IO单元创建到完成的总时间，通常这项数据关注较多。同步场景几乎等于clat，异步场景等于clat+slat<br>这项数据需要关注的是max，看看有没有极端的高延迟IO；另外还需要关注stdev，这项数据越大说明，IO响应时间波动越大，反之越小，波动越小</p>
</blockquote>
<p>clat percentiles (usec)：处于某个百分位的io操作时延</p>
<p>cpu          : usr&#x3D;9.11%, sys&#x3D;57.07%, ctx&#x3D;762410, majf&#x3D;0, minf&#x3D;1769  &#x2F;&#x2F;用户和系统的CPU占用时间百分比，线程切换次数，major以及minor页面错误的数量。</p>
<p>direct和buffered参数是冲突的，用一个就行，应该是direct&#x3D;0性能更好，实际不是这样，这里还需要找资料求证下</p>
<blockquote>
<ul>
<li><p><code>direct``=bool</code></p>
<p>If value is true, use non-buffered I&#x2F;O. This is usually O_DIRECT. Note that OpenBSD and ZFS on Solaris don’t support direct I&#x2F;O. On Windows the synchronous ioengines don’t support direct I&#x2F;O. Default: false.</p>
</li>
<li><p><code>buffered``=bool</code></p>
<p>If value is true, use buffered I&#x2F;O. This is the opposite of the <a href="https://fio.readthedocs.io/en/latest/fio_man.html#cmdoption-arg-direct" target="_blank" rel="noopener"><code>direct</code></a> option. Defaults to true.</p>
</li>
</ul>
</blockquote>
<h2 id="iostat-结果解读"><a href="#iostat-结果解读" class="headerlink" title="iostat 结果解读"></a><a href="linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html">iostat 结果解读</a></h2><p> iostat输出的数据来源diskstat (&#x2F;proc&#x2F;diskstats)，推荐：<a href="https://bean-li.github.io/dive-into-iostat/" target="_blank" rel="noopener">https://bean-li.github.io/dive-into-iostat/</a></p>
<p>Dm-0就是lvm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.32    0.00    3.34    0.13    0.00   96.21</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00    11.40   66.00    7.20  1227.20    74.40    35.56     0.03    0.43    0.47    0.08   0.12   0.88</span><br><span class="line">nvme0n1           0.00  8612.00    0.00 51749.60     0.00 241463.20     9.33     4.51    0.09    0.00    0.09   0.02  78.56</span><br><span class="line">dm-0              0.00     0.00    0.00 60361.80     0.00 241463.20     8.00   152.52    2.53    0.00    2.53   0.01  78.26</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.36    0.00    3.46    0.17    0.00   96.00</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     8.80    9.20    5.20  1047.20    67.20   154.78     0.01    0.36    0.46    0.19   0.33   0.48</span><br><span class="line">nvme0n1           0.00 11354.20    0.00 50876.80     0.00 248944.00     9.79     5.25    0.10    0.00    0.10   0.02  80.06</span><br><span class="line">dm-0              0.00     0.00    0.00 62231.00     0.00 248944.80     8.00   199.49    3.21    0.00    3.21   0.01  78.86</span><br></pre></td></tr></table></figure>

<p>avgqu_sz，是iostat的一项比较重要的数据。如果队列过长，则表示有大量IO在处理或等待，但是这还不足以说明后端的存储系统达到了处理极限。例如后端存储的并发能力是4096，客户端并发发送了256个IO下去，那么队列长度就是256。即使长时间队列长度是256，也不能说明什么，仅仅表明队列长度是256，有256个IO在处理或者排队。</p>
<p>avgrq-sz：请求是大IO还是小IO</p>
<p>rd_ticks和wr_ticks是把每一个IO消耗时间累加起来，但是硬盘设备一般可以并行处理多个IO，因此，rd_ticks和wr_ticks之和一般会比自然时间（wall-clock time）要大</p>
<p>那么怎么判断IO是在调度队列排队等待，还是在设备上处理呢？iostat有两项数据可以给出一个大致的判断。svctime，这项数据的指的是IO在设备处理中耗费的时间。另外一项数据await，指的是IO从排队到完成的时间，包括了svctime和排队等待的时间。那么通过对比这两项数据，如果两项数据差不多，则说明IO基本没有排队等待，耗费的时间都是设备处理。如果await远大于svctime，则说明有大量的IO在排队，并没有发送给设备处理。</p>
<h2 id="不同厂家SSD性能对比"><a href="#不同厂家SSD性能对比" class="headerlink" title="不同厂家SSD性能对比"></a>不同厂家SSD性能对比</h2><p>国产SSD指的是AliFlash</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1638359029693-73b42c13-2649-4f20-9112-a7c4c5dd5432.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1638358969626-507f34aa-201b-4fd3-91de-66c88c6ce04a.png" alt="img"></p>
<h2 id="rq-affinity"><a href="#rq-affinity" class="headerlink" title="rq_affinity"></a>rq_affinity</h2><p>参考<a href="https://help.aliyun.com/knowledge_detail/65077.html#title-x10-2c0-yll" target="_blank" rel="noopener">aliyun测试文档</a> , rq_affinity增加2的commit： git show 5757a6d76c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">function RunFio</span><br><span class="line">&#123;</span><br><span class="line"> numjobs=$1   # 实例中的测试线程数，例如示例中的10</span><br><span class="line"> iodepth=$2   # 同时发出I/O数的上限，例如示例中的64</span><br><span class="line"> bs=$3        # 单次I/O的块文件大小，例如示例中的4k</span><br><span class="line"> rw=$4        # 测试时的读写策略，例如示例中的randwrite</span><br><span class="line"> filename=$5  # 指定测试文件的名称，例如示例中的/dev/your_device</span><br><span class="line"> nr_cpus=`cat /proc/cpuinfo |grep &quot;processor&quot; |wc -l`</span><br><span class="line"> if [ $nr_cpus -lt $numjobs ];then</span><br><span class="line">     echo “Numjobs is more than cpu cores, exit!”</span><br><span class="line">     exit -1</span><br><span class="line"> fi</span><br><span class="line"> let nu=$numjobs+1</span><br><span class="line"> cpulist=&quot;&quot;</span><br><span class="line"> for ((i=1;i&lt;10;i++))</span><br><span class="line"> do</span><br><span class="line">     list=`cat /sys/block/your_device/mq/*/cpu_list | awk &apos;&#123;if(i&lt;=NF) print $i;&#125;&apos; i=&quot;$i&quot; | tr -d &apos;,&apos; | tr &apos;\n&apos; &apos;,&apos;`</span><br><span class="line">     if [ -z $list ];then</span><br><span class="line">         break</span><br><span class="line">     fi</span><br><span class="line">     cpulist=$&#123;cpulist&#125;$&#123;list&#125;</span><br><span class="line"> done</span><br><span class="line"> spincpu=`echo $cpulist | cut -d &apos;,&apos; -f 2-$&#123;nu&#125;`</span><br><span class="line"> echo $spincpu</span><br><span class="line"> fio --ioengine=libaio --runtime=30s --numjobs=$&#123;numjobs&#125; --iodepth=$&#123;iodepth&#125; --bs=$&#123;bs&#125; --rw=$&#123;rw&#125; --filename=$&#123;filename&#125; --time_based=1 --direct=1 --name=test --group_reporting --cpus_allowed=$spincpu --cpus_allowed_policy=split</span><br><span class="line">&#125;</span><br><span class="line">echo 2 &gt; /sys/block/your_device/queue/rq_affinity</span><br><span class="line">sleep 5</span><br><span class="line">RunFio 10 64 4k randwrite filename</span><br></pre></td></tr></table></figure>

<p>对NVME SSD进行测试，左边rq_affinity是2，右边rq_affinity为1，在这个测试参数下rq_affinity为1的性能要好(后许多次测试两者性能差不多)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210607113709945.png" alt="image-20210607113709945"></p>
<h2 id="scheduler-算法"><a href="#scheduler-算法" class="headerlink" title="scheduler 算法"></a>scheduler 算法</h2><p>如下，选择了bfq，ssd的话推荐用none或者mq-deadline</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#cat /sys/block/nvme&#123;0,1,2,3&#125;n1/queue/scheduler</span><br><span class="line">mq-deadline kyber [bfq] none</span><br></pre></td></tr></table></figure>

<p>bfq（Budget Fair Queueing），该调度算法令存储设备公平的对待每个线程，为各个进程服务相同数量的扇区。通常bfq适用于多媒体应用、桌面环境，对于很多IO压力很大的场景，例如IO集中在某些进程上的场景，bfq并不适用。</p>
<p>mq-deadline算法并不限制每个进程的 IO 资源，是一种以提高机械硬盘吞吐量为出发点的调度算法，该算法适用于IO压力大且IO集中在某几个进程的场景，比如大数据、数据库等场景</p>
<p>磁盘队列的主要目的是对磁盘的I&#x2F;O进行合并和排序，以提高磁盘的整理性能，对于传统的机械硬盘而言，由于其读写头需要进行物理寻址，因此请求排序和合并调度是非常必要的。但对于SSD硬盘，由于其不需要进行物理寻址，因此磁盘队列的最用相对于小一点</p>
<h3 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h3><ul>
<li>临时修改全部磁盘的I&#x2F;O调度算法，以mq-deadline为例（临时生效）：</li>
</ul>
<p>echo mq-deadline &gt; &#x2F;sys&#x2F;block&#x2F;sd*&#x2F;queue&#x2F;scheduler</p>
<ul>
<li>永久修改I&#x2F;O调度算法，以mq-deadline为例（重启后生效）：</li>
</ul>
<p>vim &#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;60-block-scheduler.rules</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkkAAABPCAIAAABwJMZXAAAAAXNSR0IArs4c6QAAHFBJREFUeF7tXU2IK0lyTvWM5+d5MfiwPpj3KJp+Jy2Y9tzmIusg0J7UF3sOzS46yAfBQIN8Wi1GCzqsfFqBDqYNFkszRoe9tU5uEKxWl7nNNgYLH95zU8ziy96MZ978djsis/6VmVVZP/opRSF4M9VZkRFfRmZURGZFVJ4/f87oIgQIAUKAECAESoTASSGytCb3t71qIaS3QlTCf7XVquYvUbV3ez9p6WTKqd9qb3J7j1d0XEL0kR3n0nOVfRRykkvJSCK5jOWNH6/syOyWQtHjslvpDHs/9HXMUNySNY+xbdWqWNFR40smuZk41WZn2H1p9kwerXPqt9VtW8vLc7guxusgX2H66/EFtrm8sfPgXWuyC8YzmVzbk7doPPOin5O+5cUO0SEEUiOgt23V5qjTBNqt7rCxg4U9qVTwehXj/SSlpGyHq+DVPPJn035N20N30n6NpameWcx+HTJqDo186BszJJcrBT6qnncllzkS+/WEkZ7nOF77hYIhN4SDIWDbaa61bdVmnS3v1gyWRvvh1XYYol4IgWNGIBr4NgiEV/EywM60vQFpakoI7BwBhW1rTW7hmrUtqz3y/p3ot9DgGbFXc9s7C8rlbfXc307iIptiP8OnFHxARkdsmAxrjNWGovP4faKqnDxT8Y9vZVHSpv3q28sZkvWL0WEX5gRwQnMOEAykC5C/3yanr9ZIFW6mOpwdT8muV+CWqVym/LMzb+8ypM+m+Mj1eTQLaDBINeu627Fqvb2f9Hq3t/cjuGY4AWLxibQXCJiMi06fZXzq5rUKf9V8V60PMjoRJLz9M36/Jx9HxTpQbbnNYeK5K6EpDsa6Rg+kR0Bh2+ZX/X5/umKrm8t+f2mz1QD+vQ5v1YQ7bU2GNXuAWzqXU1YHY+Ncrcmszab8/mBpDUfxR0xqncaiz7d9BnZt6E5tOR2xYTJYMeAQHznfDBxGsAE6Q8HP+WWQHxX/jM2vsDH24V+m/eray+WV94vRYWvpiNpfNJracyjAr+gYN9AcgPz9NplcakVS4WauetnxXL+2mXUWclFennqhBTO5zPmvtU+5fob12RQfhT7fLe1aw7Nmzbq1WohIuJZ+rX467Z9fwHV+eT1nenyAWKS9wMBkXNT6rOZTpefyEVCvG2Z01OOrGkfFOtZsMLEswbrB2s4bSBoczDWOnkiFgDImuV4zjETerdewbMAEW8Ol6aHVqNk313Nssp6PwSq6pi1y36o348Im9lLQAUKLlbuGReknoCPlNkAH1v3pyqWj4j8VqGYPSeXVkLDqZ+KAz3p+NY5uAZp1nby1CrfkFPJsCYphneIGsPsijlFzjJ5v4wrpuUR/QnqlYkilz+uAccMDQJ5p8+eRhL6nQqAUCEIcPtH2+cGm0RMjPdfMdyM6GsnixjG0jrH5GCabULD12F+XEoxvIn3IbwSIkouA3Lb1JnCN6hardyeTTo1ZjYk+IKk6rKA+xKAeAtmhhzR0ZD0gHas9cw+6YzCTX3nRT6NY8kMeCkrzK/DB6h2IPUHsNyZInIYZxTMq3HLswojUqwfu3rQals3gbQk2hi0jGI06izRW6adMr1T96A73TFe1DkY3nOXd008T+rvCR6cnJgOkm48mdHTjbLjOtDDs61zeuqEbX5PxyqKP9KwCAbltu1ssHhiDV+Ep/muvlovF4k6HoSQKIl5xNqNHqYYiTzpu9FLEMEWMLi/6qYQze2g9vsLYE4/Ytr3NGDMaxq0RHxluPiGjUwzG/UcfEOPVa1jL/tSuN5s8tJCZajICkWiop+d6fMK0dfqGThfYazRtnisaj7+M/vbxMeVThfg25qNqHGX3IUAwbNtiK2Njg0IiRF44JNNIaiVFQG7b1vP5a2atpmP+r72AfyEoqYMQJySstOJbuB64es4VvZ82cqSlA2+p0f0XFa9ApzZ0jwDg9nBPbG6o+A/S2VB6g345HdP2TueBfmF/vRd3HsdY0zfkwpnp7/q4+EhxE51BaHDGTzEYXVnw5AagbsHiP1/Y8B+yc7xJ5PIsU0RejSAhPXf1WaVXGj2U0nF1sd4Nmjaunxr8N3tJgo+Kt8TjItFnUz7T4GOgZFyTuRccWZfg/1XjKF3HoL39wPgSGFrfVPM6LxwMZKWmEQRU+23usX94e0z2RozBMmuIobJZhy39gxd4n3X4/WHdHvR151F0o6OjgxtnsL2b6Jwk0BkIfu7vR7A9fOe87qv4d3maXw3sOn/MP2lo0i/SMW3PF7pQv+vxNWuMOPMA883lxid3xgoukws7XVn84KknrAo3MbkXq5Xh595Z8YR11RJxyFcPzPmvoPBJ5eLPSORVA7m6eeBDwPXZO5qjxUdCTKfPaJhqAa9NsCjXWxWfcfgojYqBnsv02ZRPNR+5rBs4ss7SMGq8DqxLcPosOI7euqRYB+bXsBUgjmJH6cjndV44GE9oesBFoEL5JEkZ8kAATk6fXUeSnuRBl2gQAvkjgB9XnE5jD1Xn3zFR3B4CxeST3B7/1NM+IABLRYdN07rk+yAB8UAIEALlQoBsW7nGc0fS3PUvsodHd8Q7dUsIEAIlRIBikiUcVBKJECAECIEjR4D8tiNXABKfECAECIESIkC2rYSDSiIRAoQAIXDkCJBtO3IFIPEJAUKAECghAmTbSjioJBIhQAgQAkeOANm2I1cAEp8QIAQIgRIiQLathINKIhEChAAhcOQIkG07cgUg8QkBQoAQKCECZNtKOKgkEiFACBACR44A2bYjVwASnxAgBAiBEiJAtq2Eg0oiEQKEACFw5AiQbTtyBSDxCQFCgBAoIQJk20o4qCQSIUAIEAJHjgDZtiNXABKfECAECIESIkC2rYSDSiIRAoQAIXDkCJBtO3IFIPEJAUKAECghAmTbZIPamtzf9qqbf1HdL6Fi7IdIUND7ftLa4AVvO5fkrwasIyHpSBvQoKaEACGwhwiQbdvDQSGWYhBYjy/O4bq8sfcdqmqr1ZK8JO0728QfIXDwCOhtG38/3nivrfYmzmvz7UR4N+DPbF78ucAbNm8RIBYk485/Tshvk8lPgq49FrK93ctHOSf61dbk1vVCbicOEIiDz7PvvYSB9pojgzI6Ubck+P+y9spx3PiDw5y473EqRjulI5QTnrlNyVz4WbPGcCQLAeTGJhEiBAgBGQJa21Zt1i3bturNwJsnzPhZnU0v8b35vL84bWLEaH7F//f8fLBi9o342/nFeM2YeMPGF2xxn98U5nDWdshcLq3Q/Lfa3c0wVEmHD2AYsmnfga+/OOvGLoSrgdM6iJucznrcv2Ftd22t9kZtdtPnIyBvrx5HeMTrF7u/mnsDAhrSEOMF+sLsvXeltqtJ88XqmPR5u+BSb4SAGgGdbUPTtppOV0Hj1uri8ng1FxZqPb8a+4ucCc6tRs2+uRZk1uNQH6vVqtaJXeFNOgu1rbY23E7X2rreaO8s+AT4VcIpvQ3fT81B4MHqmcVWCwdNxHN85Rr/ePLru6Vtnb7kVkVFh2Mr3hVg6GA4BflM/UY4s5dLi48XdAD/Hc+3aYszd8BCfqqSiiwewGX2B9IJN4T1An1O1282ZVHTfn59YxepzzmySqQIgRIhoLFt3LQt5vji6XluuCbarx3XKwMMETqvHtxFGmkurm9YyFfkK5N/fEAS//RuxcbDWs0GWwg/6XLJ2jM3ntaaDGv2AF3Lyymr1zzZVPczCB94dP3aZrUOhHZbVeNdmWoL3eqHV0hOQ2d+NVjVhpMJyLcauO5Wln43JH99t8TxgteV1eLO/Wte48VYrX3KB+xyEPHvpUPgxwPC7dFRtZZ8gCHcwHi4wb+A21HdHoA7ml23o2xFXt3yURyiQggQAnoE1LbNMW0QcAwat63gCQ4Ji8YlneMDTjhO+Y8X8+ThUC8s6ofQ0DNyvc7xYsWsM7Fj6PuR4DxNV66cqvtoT6T0DQGaX10ObGa1h7MZeoZJ9gVrQ2HJZ0NYjUWEEaPCajrcutUCli2mvUIEt9/ItikigcZt1AHT5jvxeY0Xg2C28O/5uIQD5JucRsfLbc/v952RB0rBcMNp93bWtqcXgTgrf1/IY3zF4MDL2hHF2Q2nADUnBApBQGnb+F6bcArQq9rwowrhxiWKr7pFxXFacMTEdfOGrn+m8kfz8lM1aEFc94Kf+sNdSXCwuEMBkCsf8ffbpmzo+Z0YH96k4xBBcs5gemR17aV9B/fbAq8QwgxMbQud/CK0wiROkGYcrRpsKrOas2dYhAQ86l6UPhfCMBElBA4eAaVte3lqgTuBzsT9rA3/KfZ1MJbleDqZRI/Qgc4iS6941W34neQU44IQI7yiO6dd8OiLuFRypZfXPMYIK6DvRyZBdw0etWxNNqZj2K+MNzyFEvJ7chov6MtE39KMI/hzVxcYt42NZwcFNxxfOlKSRKOpDSGQHwIq28ZjOK4JQBvgvNdymzNyt9xhe76X7kijM9d5PLDa69Ts5V14pwMPSkAgzXczxCdNcVfEoZABZT8wcZ6iBf26DQL8JLqvHwE4Gg8xxgQBRjj3AFg6W23VXqPm7Gby/bCG+CAguK8W6rbawt1P7lur6KjYNG1vrnDmMUlVH3gUBoHg4xLSEwel4IPRcXTb8/sj2NZ0Rj6qthi3xQbJdj0Tj6/PGh0pMdcheoIQyICAwraBaQueGQk4CLBmwRmMDnfo7keNhzt9HEq8vnPPjzuB3rsxbBDdOGRmgX0jXxSM42QQTPEoLjF1sWE1arxe+j0gP9YQWZx1WIL7WtZeLVarRGfh1+PrRWM0cjbQ6uzm0nF+gvAE99WgW2/fa9apL50NNyUdBZum7ZFMcL8t7TdsaQZ0dfPQQIT4/mL43YVbJD6aEr0K7UeKDck6H2AYebapthzxhNYt8fgG5KUjJWkGn54hBNIiUHn+/HnaZ+k5DQJw4PzsOoEXSSAeJgJpxhe/DT2dhmO3hyk9cU0I7D0ClHOriCGCRazDnE/JiqBPNHeLQMrxxZjHdSHnbXYLB/VOCOwhAuS3FTEo1Wp1vc7/S6kiWCWaKRCg8U0BGj1CCGwVAbJtW4WbOiMECAFCgBDYAgIUk9wCyCKrikmtlnS1V8CdcK5ihCqOPuGTbsQINyluCXOsF6fP+tHcVb/pdOxgnyLbtsuhy7VWC2SVGo26/GoWUVel2hPEu6OR/8W4QA/WkgQfPJgjTfiYY4ZPEG4JcNPMF/xERpZzNAHV+CY7mEfxTCVtcUg1m3KybeH3R+518MVOXxvFSQ8CpWjcj+RUNW5UdBTvrUlHKtQul5omqXo2fwh4lRkTe3rFLzerGCfs5Q52KxLFvFT6KYX9cRELpiB+NU30eYO5UDk+QfikA7OsuJnIBci9PIVPa0W2Cv86pHkkkzeX9e2QajblZNtCKgBFcOBDJC9Lhao2inv/cmq3QzkhFDVBVHTSzeJjeYrnDl46OaD91NAq8aEODqQUdioYLetOCrASg0X4pBvcY8Ntj+XlIc50o2j+1AEl2MnZtvHqbkHDlgC8NX5P7eT0wuYF17hJwFHwXQ09UCxyA06PqETAYxXCM928z/0kVS0Vw1otDhf86/dAIpjbW2CleQqpqKD0C/63Vq1F7mCeUJnjHJM2UZQ1cvIvZ8iCqMbHRwdd+xDvhE9Ie4L48PhET1Hr54hwC86uqP7IalHxArwm80W1OuxoHunlRZWA5LgjuJwsSLnJq14lDyfBTp627QwMW9vQsPHZ3OXFdDw4pTVujEwSUs2pJg6Qeri+gJQVUGplisVXa17aaOl9dS0Vs1otQt5o7RWe4BhKtNRrllWH0i8XF/p6b+HcwemzY5qiz9vL8Gl1sdKMyJzWXzSCpWYIH14Dzxifo8JNiY+8FpXpfHH0fCNV+c7mkUYfgNda/RTqGl/AdS4+nEwpr9H0PpgEOznatlobqi5LcveqaqN4tVrgM2c31ZQAWVbjJpzzKT6trXk+Q1VNE8xDj1Yhmkhfel9TS8WoVgvCoKi9wtgZJOca3DCrEdkRUKpo4NhlwEGWNOdZPN3CsJjn002SbaT9orEKN6t+JlJoRirbEj4CN1N8jg03KT6aWlQp5otsujuvmm52t+3NI5U+4BRbOuWdYTIFPqeVrw9HV7MpR9u2GsD7gySfuqo2inMfXaIhLwztX9JomKbGSoqVt5hHdDVxTGq18DVOXnsFdsTqS6hENr6Ysk7C04lo6J38X76FDp7P8eisx31IuMmzLt52Ma9m1KJnxA2zNtr1DsRQeJg3GJMkfADbFPgcFW4KfDTzLs18wRpTMli3P480+qCYiankNZzVGXYrDHvK0jxH28bZMMunjk/w1XSjuNVGjRtTIXOMSRp0rYv6mdRq4X6PvPaK+/qFWPfjMjiF+QmvAFiWxr0C5WngOKSouHBxdcfyqbIeeW+BsCr0AKmLa6GCnYQPxwnxN8LnyHCT4qOZd0bzxdVUeChUsWmH80ipD4plKZW8sPthdhrlEI6U5G3b0lk3qKe8UWc7UuPGwMA4S0ReNXGMetbUUjGq1eJ2qn9XiM/rJXSQ+0ewr9mOrx9a7fmFYEYJ2huhg98jOOQ3nyN8+PcaxvgcE25KfFQ1qsJqFj9fRHs87h/+AGZH80inDwlmXlJ5y1mzKX/btmHdEtRG4TV03G0eZ8w2atyo6ITuF/MNcQI18o2RqpaKWa0Wr0uT2isSPvnjPMgItXu8Ejpqgdbj17yiDDSHCjrhfVADGJQvlddMkN9kh/BBpy0hPn3nLCvgfEy4qfFR1ahKo7NwWhjOarVDldh3M490+pBGMsUz5azZRPkkc1SR3ZKCl6/GYhsFVDY72lrXWRDeGpMF4LPL6jiHjJtOX3RyVautl2w+LzbdeQF6kn5+lLBmUxF+W3qA6clsCLgubPwx0hT9eGdPhn419BRkdvmIDp8/Y0/ZWCsBPioAyqpXSrnW6+IM2x7qSTlrNpHflm1Bo6cRga292hcC9weVx59Uvu0/vvt1IeTzwGeXfltRoCSge9h6lUDASJNdyVvOmk1k28w1kJ4oCwLP2WP/5Nsm++7HT89ePVXKIhbJQQgQAuzwYpIQCofL7MTq3g50xlzPcbU8Ah9CJPwSTo0U4p45b12svH5CWn0usawjChHIn1W+WZ68aTHw2N4hw5YVUHqeENgzBA7MtuFh1VGj0Th7WRLjVqw65FrrpNlodOGb60L28lwY8DMFkanZ+dS8EHx+WvkOrNrHlW/eZU+fPb31h8rJh5Xvf1R5LKQzIkoIEAK7QCBf28b9hMDit1Gahue76EFGT6e8TfAffC70h8gnJgAPfny8wjouoSIuu8At1GesN7JzDnNggJe4gc/s9cmGAh2lqKmhS+uyIUIK+qzOvv9t5ctfVr76IXMs2QeV739TeQO/f698+fnJ/8Hv1ckXvzl5I37/UPlG/CBuCfYPfj/MeuQkh6EgEoQAIRCLQK62DbPI27blJROGzBlO4osBJG+6EZVT8I1cdZ+zq6x9EyvMjhok+iZ6R7xl6XartTOyMJrk2ZeVp09Ovvrk5M3LOP8MnLkP2ffi16t8I37/evKVMIGfnXwhTOCnJ18K+wd/Evbv48q3wv7BLwlL1IYQIASKQyBP2yYKpECOEd+4ZWE8WvtGRStQ26I3cbzGiCcV2pcK1qBx9+1M2wd5cdK0OrfUNVyUtW/AW+XVczDDYmAjUcYndiKt5YE1UPycnHH7cJxXNf3N2hlZxnHjWVlNFrEzOGtbkFxUQOHtt8nG14Qf8LR+Wfn6t5Uv6uw7k+di2sI5FGH/wKUT9u9nla+F/YOfsH/wA3dQmEDgQZjAv2OOCaQoaI7DQaQIgQgCOdo2btoWc8xOk4tx26h9g/VwrWjuXnltC/U4Yw0aqDuADuTl0hqO4o4sxLXHZPlexTNNjRJN7ZtOY9Hn/ECGRS9rtKpfU3nVbwQaHDZqZ7hUMK9eoAScNGln3KkVaU0WsTMIeZRdt93db8si77uMgS+1PPnyp5VvdzXzwYAJEwg8CBP4qxPHBFIUdFeDQv0eAwL52TbHtEHKrYzGTVb7hid4u78fWjeBZEPcieG1N3kCgfV8PF3FjVmgPSQ4ivcx49pDPJJB/8Fu1TU4IHs/z3QAnI79R7xCFWtMPeZkvlX1ayqv0rT5uElwUNTOAGLza6z0AG4VuJiYIkqStNNNMqusGRQcr7jXII28MTU7wK8Cqwa+VOaPsuN0KvPfKQqaGUIiQAhEEcjNtvG9todXSB8KRMQtWbqBkNW+4cmw4bWetcOOltHhA+gU21ttXsIFr9gMGzHtI04brv3yGi6mtW9U/ZrKq8LZFAePDtRKhJeJwWW/H8qTbjKxTGqyZJD3D+zk46f34BikCW8FtIWv5jQ/kw5TR0Ep+GkCM7UtCQK52TYIF7pWA3dNEp+mU+IoqX2DlTPDhE0rSWP7YB24uLPm+vbSQySmNTikAKj6NZVXha4pDi4dcVAV3E+RYTxVTNKkJks2eT97Orl4ev/nT+/9L5qXHV2QyUvzS8KU3jpuSLYZBf1FpbCMK0n4pzaEwC4QyMu28diRcxDy/ByORQZ2ZdLKxWOG0do3EWKK2hZ8X8gpLFBtYf1o54L2taF7YgP+AiVF8C+m7Tm18CESfktfg2Pkl48R3aovBZ884AuQiJo1vlxK/nkPkV0yvKWibzZW2pikipS6JovkiWS1S7Rcf/L09oePzz55+hMz2TK0/iM7+ZS9pfqNn95R/T5+fO+jp/ejv8f3P3p8/8ePz158/wP57/EHL7Q/eDyDNPQoIXCQCORk22CZZ4FYE69ZEyoRkQ4cWe2bCCVe4Gzo1HCBOtHOhbeZCD6OGq/9+xg0HLCOiEqOGmxxJza+TNujGQsdIhH9amtwDOw6ZxT7dbrVGDc5nzzoaSKvJ53Fzx96xw8VOKQbJ6OnNDVZZMZNPr5GPTLw237+9O7F07PNECXcUVmaf3p6V2JpXNvzo8c/VVmUDx6fgTlR/X719I7qN2dvf/r0lvT3n085TVUz5Kg1IXCoCBxWPsm4lLFw9r3zcFlkSgtvnLfY1R7pVtwAFMxqHqBDUpLgARPwscAUFcw3kScECIFtI3BYL4PrO4hS4im9SdzR/YJxlDptBfe5Y/LwmdktfIAWPRW6Y67Mu4+EKCFBCXygZk6GniAECIG9RuCw/LY4KPN4r4/rg/6+OwRyHV8obfML9jXk3Lpjb//943u7k4p6JgQIgfwRKJdtyx8folhyBESIsv747I87PEtZcoxLK9719b9JZet2f1JamQ9HMG1MkicU3Iesgn/1l7/7/K8/579ff1QAuEr67//j74rpsQAhSkgyQ40eXpEnFpJq729//8/Dx2d/UclYdDvck5fz7CiyaMeivK8N9mZ921eADpsvjW2DrE+jUZdfzR3XS/uP//mbF79/8eK//uW/i0G7aPrFcF1+qulr9FSbjU73ZTKE3rDKzk4hYjHCBDY4mSAH0MpUXtP2BhBUe2Jx645Gs2ieOChWyEcF35AMSFLTfUJAf5bExnoyxZWUwYo2kuyD+NmZlzx4x4dGch2rP/91QX5nrlzmR0wxvvl1oKaEX9CnzpyiZ9Avn5r5RBMmDR0OE9lgTQ5ud7aETlgp2ytTdivlCvxBkco7NEk1+GzIu/nxf6g8oAQfhVwRQsFVRcUPL9qE19SODni1Oeo04SZk4WkkfEHahlJTH0YI/D+Tv1hMKWRSSAAAAABJRU5ErkJggg==" alt="img"></p>
<p>将图中的bfq改为none或者mq-deadline。</p>
<ul>
<li>验证查看磁盘使用的调度算法：</li>
</ul>
<p>使用lsblk -t查看SCHED列。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># lsblk -t</span><br><span class="line">NAME              ALIGNMENT MIN-IO OPT-IO PHY-SEC LOG-SEC ROTA SCHED       RQ-SIZE   RA WSAME</span><br><span class="line">sda                       0    512      0     512     512    0 mq-deadline      64 2048    0B</span><br><span class="line">├─sda1                    0    512      0     512     512    0 mq-deadline      64 2048    0B</span><br><span class="line">├─sda2                    0    512      0     512     512    0 mq-deadline      64 2048    0B</span><br><span class="line">└─sda3                    0    512      0     512     512    0 mq-deadline      64 2048    0B</span><br><span class="line">  ├─klas-root             0    512      0     512     512    0                 128 4096    0B</span><br><span class="line">  ├─klas-swap             0    512      0     512     512    0                 128 4096    0B</span><br><span class="line">  └─klas-backup           0    512      0     512     512    0                 128 4096    0B</span><br><span class="line">nvme3n1                   0    512      0     512     512    0 bfq             256 2048    0B</span><br><span class="line">└─vgpolarx-polarx         0 131072 524288     512     512    0                 128 4096    0B</span><br><span class="line">nvme0n1                   0    512      0     512     512    0 bfq             256 2048    0B</span><br><span class="line">└─vgpolarx-polarx         0 131072 524288     512     512    0                 128 4096    0B</span><br><span class="line">nvme2n1                   0    512      0     512     512    0 bfq             256 2048    0B</span><br><span class="line">└─vgpolarx-polarx         0 131072 524288     512     512    0                 128 4096    0B</span><br><span class="line">nvme1n1                   0    512      0     512     512    0 bfq             256 2048    0B</span><br><span class="line">└─vgpolarx-polarx         0 131072 524288     512     512    0                 128 4096    0B</span><br></pre></td></tr></table></figure>

<h4 id="修改bfq调度器的idle时间（临时生效，重启后失效。）"><a href="#修改bfq调度器的idle时间（临时生效，重启后失效。）" class="headerlink" title="修改bfq调度器的idle时间（临时生效，重启后失效。）"></a>修改bfq调度器的idle时间（临时生效，重启后失效。）</h4><p>bfq的idle时间默认是8ms，<a href="https://support.huawei.com/enterprise/zh/doc/EDOC1100063071/7aa11aeb" target="_blank" rel="noopener">将默认值修改为0</a>。</p>
<ol>
<li><p>执行如下命令修改idle值。此处以sdb举例，修改idle为0。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 &gt; /sys/block/sdb/queue/iosched/slice_idle</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="none-VS-bfq"><a href="#none-VS-bfq" class="headerlink" title="none VS bfq"></a>none VS bfq</h3><p> 从下图可以看到 iops 减少到 none 的20-40%之间，并且抖动很大</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20231011090249159.png" alt="image-20231011090249159"></p>
<p>用sysbench write only 场景下 压鲲鹏机器+麒麟(4块nvme做条带LVM )+官方MySQL 也看到了QPS 很差且长期跌0，红框是改成none，红框之前的部分是bfq</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/lQLPJwdVC35hlSDNBrrNCHawFhZ_xVTrMXIFGKolRUBPAA_2166_1722.png" alt="img"></p>
<p>下图是 sysbench write only 场景不同 scheduler 算法的 QPS，可以看到 bfq 很差，mq-deadline 和 none 几乎差不多</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20231011095227886.png" alt="image-20231011095227886"></p>
<p>对应的 iotop</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20231011090609546.png" alt="image-20231011090609546"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20231011090625857.png" alt="image-20231011090625857"></p>
<h2 id="磁盘挂载参数"><a href="#磁盘挂载参数" class="headerlink" title="磁盘挂载参数"></a>磁盘挂载参数</h2><p>内核一般配置的脏页回写超时时间是30s，理论上page cache能buffer住所有的脏页，但是ext4文件系统的默认挂载参数开始支持日志（journal），文件的inode被修改后，需要刷到journal里，这样系统crash了文件系统能恢复过来，内核配置默认5s刷一次journal。</p>
<p>ext4还有一个配置项叫挂载方式，有<code>ordered</code>和<code>writeback</code>两个选项，区别是ordered在把inode刷到journal里之前，会把inode的所有脏页先回写到磁盘里，如果不希望inode这么快写回到磁盘则可以用writeback参数。当SSD开始写盘的时候会严重影响SSD读能力</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 编辑/etc/fstab，挂载参数设置为defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback</span><br><span class="line">/dev/lvm1 /data    ext4    defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback 0 0</span><br></pre></td></tr></table></figure>

<p><code>noatime</code> 读取文件时，将禁用对元数据的更新。它还启用了 nodiratime 行为，该行为会在读取目录时禁用对元数据的更新</p>
<p><code>nodelalloc</code> 参数是关闭了ext4的delayed  allocation 特性。所谓delayed allocation 是指，把磁盘block的分配推后到真正要写数据的时候，比如写入文件的时候，先写内存，当数据需要落盘的时候，再由文件系统分配磁盘块，这有利于文件系统做出更佳的磁盘块分配决策，比如可以分配大片连续的磁盘块。显然 nodelalloc 性能要差些</p>
<blockquote>
<p>delalloc吞吐高，但是偶发性延迟抖动，平均延迟略高<br>nodelalloc延迟稳定，但是吞吐会下降，偶发性会延迟剧烈抖动.</p>
</blockquote>
<p><code>nobarrier</code> 参数是不保证先写入文件系统日志然后才写入数据，也就是不保证系统崩溃后文件系统恢复的正确性,但是对写入性能有提升</p>
<h3 id="优化case"><a href="#优化case" class="headerlink" title="优化case"></a>优化case</h3><p>10个GB的原始文件里面都是随机数，如何快速建索引支持分页查询top(k,n)场景，机器配置是24核，JVM堆内存限制2.5G，磁盘读写为490-500MB&#x2F;s左右。</p>
<p>最后成绩在22.9s，去掉评测方法引入的1.1s，5次查询含建索引总时间21.8s，因为读10GB文件就需要21.5s时间。当向SSD开始写索引文件后SSD读取性能下降厉害，实际期望的是写出索引到SSD的时候会被PageCache，没触发刷脏。但是这里的刷盘就是ext4挂载参数 ordered 导致了刷盘。</p>
<p>整个方案是：原始文件切割成小分片，喂给24个worker；每个worker读数据，处理数据，定期批量写索引出去；最后查询会去读每个worker生成的所有索引文件，通过跳表快速seek。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/586fef765e3f08f6183907f311a76259.png" alt="img"></p>
<h2 id="LVM性能对比"><a href="#LVM性能对比" class="headerlink" title="LVM性能对比"></a>LVM性能对比</h2><p>磁盘信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#lsblk</span><br><span class="line">NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda            8:0    0 223.6G  0 disk</span><br><span class="line">├─sda1         8:1    0     3M  0 part</span><br><span class="line">├─sda2         8:2    0     1G  0 part /boot</span><br><span class="line">├─sda3         8:3    0    96G  0 part /</span><br><span class="line">├─sda4         8:4    0    10G  0 part /tmp</span><br><span class="line">└─sda5         8:5    0 116.6G  0 part /home</span><br><span class="line">nvme0n1      259:4    0   2.7T  0 disk</span><br><span class="line">└─nvme0n1p1  259:5    0   2.7T  0 part</span><br><span class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</span><br><span class="line">nvme1n1      259:0    0   2.7T  0 disk</span><br><span class="line">└─nvme1n1p1  259:2    0   2.7T  0 part /u02</span><br><span class="line">nvme2n1      259:1    0   2.7T  0 disk</span><br><span class="line">└─nvme2n1p1  259:3    0   2.7T  0 part</span><br><span class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</span><br></pre></td></tr></table></figure>

<p>单块nvme SSD盘跑mysql server，运行sysbench导入测试数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#iostat -x nvme1n1 1</span><br><span class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.32    0.00    0.17    0.07    0.00   99.44</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">nvme1n1           0.00    47.19    0.19  445.15     2.03 43110.89   193.62     0.31    0.70    0.03    0.70   0.06   2.85</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.16    0.00    0.36    0.17    0.00   98.31</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">nvme1n1           0.00   122.00    0.00 3290.00     0.00 271052.00   164.77     1.65    0.50    0.00    0.50   0.05  17.00</span><br><span class="line"></span><br><span class="line">#iostat 1</span><br><span class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.14    0.00    0.13    0.05    0.00   99.67</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda              49.21       554.51      2315.83    1416900    5917488</span><br><span class="line">nvme1n1           5.65         2.34       844.73       5989    2158468</span><br><span class="line">nvme2n1           0.06         1.13         0.00       2896          0</span><br><span class="line">nvme0n1           0.06         1.13         0.00       2900          0</span><br><span class="line">dm-0              0.02         0.41         0.00       1036          0</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.39    0.00    0.23    0.08    0.00   98.30</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda               8.00         0.00        60.00          0         60</span><br><span class="line">nvme1n1         868.00         0.00    132100.00          0     132100</span><br><span class="line">nvme2n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme0n1           0.00         0.00         0.00          0          0</span><br><span class="line">dm-0              0.00         0.00         0.00          0          0</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.44    0.00    0.14    0.09    0.00   98.33</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda               0.00         0.00         0.00          0          0</span><br><span class="line">nvme1n1         766.00         0.00    132780.00          0     132780</span><br><span class="line">nvme2n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme0n1           0.00         0.00         0.00          0          0</span><br><span class="line">dm-0              0.00         0.00         0.00          0          0</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.41    0.00    0.16    0.09    0.00   98.34</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda             105.00         0.00       532.00          0        532</span><br><span class="line">nvme1n1         760.00         0.00    122236.00          0     122236</span><br><span class="line">nvme2n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme0n1           0.00         0.00         0.00          0          0</span><br><span class="line">dm-0              0.00         0.00         0.00          0          0</span><br></pre></td></tr></table></figure>

<p>如果同样写lvm，由两块nvme组成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">nvme0n1           0.00   137.00    0.00 5730.00     0.00 421112.00   146.98     2.95    0.52    0.00    0.52   0.05  27.30</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.17    0.00    0.34    0.19    0.00   98.30</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">nvme0n1           0.00   109.00    0.00 2533.00     0.00 271236.00   214.16     1.08    0.43    0.00    0.43   0.06  15.90</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.38    0.00    0.42    0.20    0.00   98.00</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">nvme0n1           0.00   118.00    0.00 3336.00     0.00 320708.00   192.27     1.50    0.45    0.00    0.45   0.06  20.00</span><br><span class="line"></span><br><span class="line">[root@k28a11352.eu95sqa /var/lib]</span><br><span class="line">#iostat  1</span><br><span class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.40    0.00    0.20    0.07    0.00   99.33</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda              38.96       334.64      1449.68    1419236    6148304</span><br><span class="line">nvme1n1         324.95         1.43     31201.30       6069  132329072</span><br><span class="line">nvme2n1           0.07         0.90         0.00       3808          0</span><br><span class="line">nvme0n1         256.24         1.60     22918.46       6801   97200388</span><br><span class="line">dm-0            266.98         1.38     22918.46       5849   97200388</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.20    0.00    0.42    0.25    0.00   98.12</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda               0.00         0.00         0.00          0          0</span><br><span class="line">nvme1n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme2n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme0n1        4460.00         0.00    332288.00          0     332288</span><br><span class="line">dm-0           4608.00         0.00    332288.00          0     332288</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           1.35    0.00    0.38    0.22    0.00   98.06</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda              48.00         0.00       200.00          0        200</span><br><span class="line">nvme1n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme2n1           0.00         0.00         0.00          0          0</span><br><span class="line">nvme0n1        4187.00         0.00    332368.00          0     332368</span><br><span class="line">dm-0           4348.00         0.00    332368.00          0     332368</span><br></pre></td></tr></table></figure>

<h2 id="数据总结"><a href="#数据总结" class="headerlink" title="数据总结"></a>数据总结</h2><ul>
<li>性能排序 NVMe SSD &gt; SATA SSD &gt; SAN &gt; ESSD &gt; HDD</li>
<li>本地ssd性能最好、sas机械盘(RAID10)性能最差</li>
<li>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</li>
<li>从rt来看 ssd:san:sas 大概是 1:3:15</li>
<li>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</li>
<li>NVMe SSD比SATA SSD快很多，latency更稳定</li>
<li>阿里云的云盘ESSD比本地SAS RAID10阵列性能还好</li>
<li>软RAID、LVM等阵列都会导致性能损耗，即使多盘一起读写也不如单盘性能</li>
<li>不同测试场景(4K&#x2F;8K&#x2F; 读写、随机与否)会导致不同品牌性能数据差异较大</li>
</ul>
<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p><a href="https://www.jianshu.com/p/d5389994fad1" target="_blank" rel="noopener">smartctl</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//raid 阵列查看</span><br><span class="line">smartctl --all /dev/sda -d megaraid,1</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="noopener">http://cizixs.com/2017/01/03/how-slow-is-disk-and-network</a></p>
<p><a href="https://tobert.github.io/post/2014-04-17-fio-output-explained.html" target="_blank" rel="noopener">https://tobert.github.io/post/2014-04-17-fio-output-explained.html</a> </p>
<p><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40497397</a></p>
<p><a href="https://linux.die.net/man/1/fio" target="_blank" rel="noopener">https://linux.die.net/man/1/fio</a></p>
<p><a href="https://www.atatech.org/articles/167736?spm=ata.home.0.0.11fd75362qwsg7&flag_data_from=home_algorithm_article" target="_blank" rel="noopener">块存储NVMe云盘原型实践</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247483999&idx=1&sn=238d3d1a8cf24443db0da4aa00c9fb7e&chksm=a6e3036491948a72704e0b114790483f227b7ce82f5eece5dd870ef88a8391a03eca27e8ff61&scene=178&cur_album_id=1371808335259090944#rd" target="_blank" rel="noopener">机械硬盘随机IO慢的超乎你的想象</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247484023&idx=1&sn=1946b4c286ed72da023b402cc30908b6&chksm=a6e3034c91948a5aa3b0e6beb31c1d3804de9a11c668400d598c2a6b12462e179cf9f1dc33e2&scene=178&cur_album_id=1371808335259090944#rd" target="_blank" rel="noopener">搭载固态硬盘的服务器究竟比搭机械硬盘快多少？</a></p>
<p><a href="http://www.360doc.com/content/15/0318/15/16824943_456186965.shtml" target="_blank" rel="noopener">SSD基本工作原理</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/347599423" target="_blank" rel="noopener">SSD原理解读</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxNDI5NzEzNg==&mid=2651171913&idx=1&sn=68f658c539edc2b5063d6d15d0bfa0cf" target="_blank" rel="noopener">Linux 后台开发必知的 I&#x2F;O 优化知识总结</a></p>
<p><a href="https://www.sohu.com/a/390625596_505795" target="_blank" rel="noopener">SSD性能怎么测？看这一篇就够了</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes calico网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes calico网络/" itemprop="url">kubernetes calico网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-calico网络"><a href="#kubernetes-calico网络" class="headerlink" title="kubernetes calico网络"></a>kubernetes calico网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">containernetworking&#x2F;cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#ls -lh /opt/cni/bin/</span><br><span class="line">总用量 90M</span><br><span class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</span><br><span class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</span><br><span class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</span><br><span class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</span><br><span class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</span><br><span class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</span><br><span class="line"></span><br><span class="line">[root@hygon3 15:55 /root]</span><br><span class="line">#ls -lh /etc/cni/net.d/</span><br><span class="line">总用量 12K</span><br><span class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</span><br><span class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</span><br><span class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</span><br></pre></td></tr></table></figure>

<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C&#x2F;S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> *<strong>Pod 1 netns*</strong> <em>through the</em> *<strong>eth1*</strong> <em>interface and reaches the</em> <em><strong>root netns*</strong> <em>through the virtual interface</em> <em><strong>veth1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>veth1*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <em><strong>cni0*</strong> <em>and is redirected to</em> <em><strong>eth0*</strong></em>;</em></li>
<li><em>Package leaves</em> *<strong>eth0*</strong> <em>from</em> <em><strong>Master 1*</strong> <em>and reaches the</em> <em><strong>gateway*</strong></em>;</em></li>
<li><em>Package leaves the</em> *<strong>gateway*</strong> <em>and reaches the</em> *<strong>root netns*</strong> <em>through the</em> <em><strong>eth0*</strong> <em>interface on</em> <em><strong>Worker 1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>eth0*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> *<strong>cni0*</strong> <em>and is redirected to the</em> *<strong>veth6*</strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> *<strong>root netns*</strong> <em>through</em> *<strong>veth6*</strong> <em>and reaches the</em> *<strong>Pod 6 netns*</strong> <em>though the</em> *<strong>eth6*</strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br><span class="line"></span><br><span class="line">#或者老版本的calico</span><br><span class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</span><br></pre></td></tr></table></figure>

<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 &#x2F;26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</span><br><span class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br><span class="line"></span><br><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了</span><br></pre></td></tr></table></figure>

<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </span><br><span class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br></pre></td></tr></table></figure>

<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64&#x2F;26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br></pre></td></tr></table></figure>

<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128&#x2F;26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</span><br><span class="line">//同时将默认路由改到3.113</span><br><span class="line">ip route del default via 192.168.0.253 dev eth0; </span><br><span class="line">ip route add default via 192.168.3.253 dev eth1</span><br></pre></td></tr></table></figure>

<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-14 ~]# ip route</span><br><span class="line">default via 192.168.3.253 dev eth1 </span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </span><br><span class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </span><br><span class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </span><br><span class="line">blackhole 10.122.157.128/26 proto bird </span><br><span class="line">10.122.157.129 dev cali19f6ea143e3 scope link </span><br><span class="line">10.122.157.130 dev cali09e016ead53 scope link </span><br><span class="line">10.122.157.131 dev cali0ad3225816d scope link </span><br><span class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </span><br><span class="line">10.122.157.133 dev cali01cf8687c65 scope link </span><br><span class="line">10.122.157.134 dev cali65232d7ada6 scope link </span><br><span class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </span><br><span class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</span><br></pre></td></tr></table></figure>

<p>正常后的抓包, 注意这里drequest的est ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//request</span><br><span class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</span><br><span class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</span><br><span class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</span><br><span class="line">    </span><br><span class="line">//reply    </span><br><span class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</span><br><span class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</span><br><span class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</span><br></pre></td></tr></table></figure>

<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="noopener">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</span><br><span class="line"> 1005  [2021-10-27 10:49:12] ip netns show</span><br><span class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</span><br><span class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</span><br><span class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</span><br><span class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</span><br><span class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </span><br><span class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</span><br><span class="line"> 1012  [2021-10-27 10:50:39] ifconfig</span><br><span class="line"> 1013  [2021-10-27 10:50:51] ip link list</span><br><span class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</span><br><span class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </span><br><span class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</span><br><span class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</span><br><span class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</span><br><span class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</span><br><span class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</span><br><span class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</span><br><span class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</span><br><span class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</span><br><span class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</span><br><span class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</span><br><span class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</span><br><span class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</span><br><span class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</span><br><span class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</span><br><span class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</span><br><span class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</span><br><span class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</span><br><span class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</span><br><span class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</span><br><span class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</span><br><span class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</span><br><span class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</span><br><span class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</span><br><span class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</span><br><span class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</span><br><span class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</span><br><span class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</span><br><span class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</span><br><span class="line"> </span><br><span class="line"> 把网卡加入到docker0的bridge下</span><br><span class="line"> 1160  [2021-10-27 12:17:37] brctl show</span><br><span class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</span><br><span class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</span><br><span class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</span><br><span class="line"> 1164  [2021-10-27 12:18:15] brctl show</span><br><span class="line"> </span><br><span class="line">brctl showmacs br0</span><br><span class="line">brctl show cni0</span><br><span class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</span><br></pre></td></tr></table></figure>

<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: net/socket.c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//file: include/net/sock.h</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="noopener">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="noopener">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="noopener">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="noopener">手工拉起flannel网络</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes_calico网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes_calico网络/" itemprop="url">kubernetes calico网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-calico网络"><a href="#kubernetes-calico网络" class="headerlink" title="kubernetes calico网络"></a>kubernetes calico网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">containernetworking&#x2F;cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#ls -lh /opt/cni/bin/</span><br><span class="line">总用量 90M</span><br><span class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</span><br><span class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</span><br><span class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</span><br><span class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</span><br><span class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</span><br><span class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</span><br><span class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</span><br><span class="line"></span><br><span class="line">[root@hygon3 15:55 /root]</span><br><span class="line">#ls -lh /etc/cni/net.d/</span><br><span class="line">总用量 12K</span><br><span class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</span><br><span class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</span><br><span class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</span><br></pre></td></tr></table></figure>

<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C&#x2F;S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> *<strong>Pod 1 netns*</strong> <em>through the</em> *<strong>eth1*</strong> <em>interface and reaches the</em> <em><strong>root netns*</strong> <em>through the virtual interface</em> <em><strong>veth1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>veth1*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <em><strong>cni0*</strong> <em>and is redirected to</em> <em><strong>eth0*</strong></em>;</em></li>
<li><em>Package leaves</em> *<strong>eth0*</strong> <em>from</em> <em><strong>Master 1*</strong> <em>and reaches the</em> <em><strong>gateway*</strong></em>;</em></li>
<li><em>Package leaves the</em> *<strong>gateway*</strong> <em>and reaches the</em> *<strong>root netns*</strong> <em>through the</em> <em><strong>eth0*</strong> <em>interface on</em> <em><strong>Worker 1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>eth0*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> *<strong>cni0*</strong> <em>and is redirected to the</em> *<strong>veth6*</strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> *<strong>root netns*</strong> <em>through</em> *<strong>veth6*</strong> <em>and reaches the</em> *<strong>Pod 6 netns*</strong> <em>though the</em> *<strong>eth6*</strong> <em>interface;</em></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br><span class="line"></span><br><span class="line">#或者老版本的calico</span><br><span class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</span><br></pre></td></tr></table></figure>

<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/yyb9c0ee93730542ebb5475a734991c7.jpg" alt="img"></p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 &#x2F;26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</span><br><span class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br><span class="line"></span><br><span class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了</span><br></pre></td></tr></table></figure>

<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </span><br><span class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</span><br></pre></td></tr></table></figure>

<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64&#x2F;26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br><span class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</span><br><span class="line">+---------------+-------------------+-------+------------+-------------+</span><br></pre></td></tr></table></figure>

<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128&#x2F;26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</span><br><span class="line">//同时将默认路由改到3.113</span><br><span class="line">ip route del default via 192.168.0.253 dev eth0; </span><br><span class="line">ip route add default via 192.168.3.253 dev eth1</span><br></pre></td></tr></table></figure>

<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@az3-k8s-14 ~]# ip route</span><br><span class="line">default via 192.168.3.253 dev eth1 </span><br><span class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </span><br><span class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </span><br><span class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </span><br><span class="line">blackhole 10.122.157.128/26 proto bird </span><br><span class="line">10.122.157.129 dev cali19f6ea143e3 scope link </span><br><span class="line">10.122.157.130 dev cali09e016ead53 scope link </span><br><span class="line">10.122.157.131 dev cali0ad3225816d scope link </span><br><span class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </span><br><span class="line">10.122.157.133 dev cali01cf8687c65 scope link </span><br><span class="line">10.122.157.134 dev cali65232d7ada6 scope link </span><br><span class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </span><br><span class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</span><br></pre></td></tr></table></figure>

<p>正常后的抓包, 注意这里reques dest ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//request</span><br><span class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</span><br><span class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</span><br><span class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</span><br><span class="line">    </span><br><span class="line">//reply    </span><br><span class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</span><br><span class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</span><br><span class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</span><br></pre></td></tr></table></figure>

<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="抓包"><a href="#抓包" class="headerlink" title="抓包"></a>抓包</h2><p>如下图，172.16.40.116是宿主机ip，192.168.196.0 是tunl0 ip</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20230531141428895.png" alt="image-20230531141428895"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="noopener">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="noopener">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="noopener">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="noopener">手工拉起flannel网络</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes_Flannel网络剖析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes_Flannel网络剖析/" itemprop="url">kubernetes Flannel网络剖析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-Flannel网络剖析"><a href="#kubernetes-Flannel网络剖析" class="headerlink" title="kubernetes Flannel网络剖析"></a>kubernetes Flannel网络剖析</h1><h2 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h2><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">containernetworking&#x2F;cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本的 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/usr/libexec/cni/</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># ls -lh /usr/libexec/cni/</span><br><span class="line">总用量 133M</span><br><span class="line">-rwxr-xr-x 1 root root 4.4M  8月 18 11:51 bandwidth</span><br><span class="line">-rwxr-xr-x 1 root root 4.3M  3月  6  2021 bridge</span><br><span class="line">-rwxr-x--- 1 root root  31M  8月 18 11:51 calico</span><br><span class="line">-rwxr-x--- 1 root root  30M  8月 18 11:51 calico-ipam</span><br><span class="line">-rwxr-xr-x 1 root root  12M  3月  6  2021 dhcp</span><br><span class="line">-rwxr-xr-x 1 root root 5.6M  3月  6  2021 firewall</span><br><span class="line">-rwxr-xr-x 1 root root 3.1M  8月 18 11:51 flannel</span><br><span class="line">-rwxr-xr-x 1 root root 3.8M  3月  6  2021 host-device</span><br><span class="line">-rwxr-xr-x 1 root root 3.9M  8月 18 11:51 host-local</span><br><span class="line">-rwxr-xr-x 1 root root 4.0M  3月  6  2021 ipvlan</span><br><span class="line">-rwxr-xr-x 1 root root 3.6M  8月 18 11:51 loopback</span><br><span class="line">-rwxr-xr-x 1 root root 4.0M  3月  6  2021 macvlan</span><br><span class="line">-rwxr-xr-x 1 root root 4.2M  8月 18 11:51 portmap</span><br><span class="line">-rwxr-xr-x 1 root root 4.2M  3月  6  2021 ptp</span><br><span class="line">-rwxr-xr-x 1 root root 2.7M  3月  6  2021 sample</span><br><span class="line">-rwxr-xr-x 1 root root 3.2M  3月  6  2021 sbr</span><br><span class="line">-rwxr-xr-x 1 root root 2.8M  3月  6  2021 static</span><br><span class="line">-rwxr-xr-x 1 root root 3.7M  8月 18 11:51 tuning</span><br><span class="line">-rwxr-xr-x 1 root root 4.0M  3月  6  2021 vlan</span><br><span class="line"></span><br><span class="line">#ls -lh /etc/cni/net.d/</span><br><span class="line">总用量 12K</span><br><span class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</span><br><span class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</span><br><span class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</span><br></pre></td></tr></table></figure>

<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C&#x2F;S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<h2 id="跨主机通信流程"><a href="#跨主机通信流程" class="headerlink" title="跨主机通信流程"></a>跨主机通信流程</h2><p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> *<strong>Pod 1 netns*</strong> <em>through the</em> *<strong>eth1*</strong> <em>interface and reaches the</em> <em><strong>root netns*</strong> <em>through the virtual interface</em> <em><strong>veth1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>veth1*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <em><strong>cni0*</strong> <em>and is redirected to</em> <em><strong>eth0*</strong></em>;</em></li>
<li><em>Package leaves</em> *<strong>eth0*</strong> <em>from</em> <em><strong>Master 1*</strong> <em>and reaches the</em> <em><strong>gateway*</strong></em>;</em></li>
<li><em>Package leaves the</em> *<strong>gateway*</strong> <em>and reaches the</em> *<strong>root netns*</strong> <em>through the</em> <em><strong>eth0*</strong> <em>interface on</em> <em><strong>Worker 1*</strong></em>;</em></li>
<li><em>Package leaves</em> <em><strong>eth0*</strong> <em>and reaches</em> <em><strong>cni0*</strong></em>, looking for</em> ***Pod 6***<em>’s</em> <em>address;</em></li>
<li><em>Package leaves</em> *<strong>cni0*</strong> <em>and is redirected to the</em> *<strong>veth6*</strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> *<strong>root netns*</strong> <em>through</em> *<strong>veth6*</strong> <em>and reaches the</em> *<strong>Pod 6 netns*</strong> <em>though the</em> *<strong>eth6*</strong> <em>interface;</em></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<blockquote>
<p><strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<p>默认cni 网络是没法跨宿主机的，跨宿主机需要走overlay（比如flannel的vxlan）或者仅限宿主机全在一个二层网络可达（比如用flannel的host-gw模式）</p>
<h2 id="flannel-vxlan网络"><a href="#flannel-vxlan网络" class="headerlink" title="flannel vxlan网络"></a><a href="https://msazure.club/flannel-networking-demystify/" target="_blank" rel="noopener">flannel vxlan网络</a></h2><p>什么是 flannel</p>
<blockquote>
<p><em>Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes.</em></p>
</blockquote>
<p>Flannel 工作原理</p>
<blockquote>
<p><em>Flannel runs a small, single binary agent called</em> <code>flanneld</code> on each host, and is responsible for allocating a subnet lease to each host out of a larger, preconfigured address space. Flannel uses either the Kubernetes API or etcd directly to store the network configuration, the allocated subnets, and any auxiliary data (such as the host’s public IP). Packets are forwarded using one of several backend mechanisms including VXLAN and various cloud integrations.</p>
</blockquote>
<p>核心原理就是将pod网络包通过vxlan协议封装成一个udp包，udp包的ip是数据ip，内层是pod原始网络通信包。</p>
<p>假如POD1访问POD4：</p>
<ol>
<li>从POD1中出来的包先到Bridge cni0上（因为POD1对应的veth挂在了cni0上），目标mac地址是cni0的Mac</li>
<li>然后进入到宿主机网络，宿主机有路由 10.244.2.0&#x2F;24 via 10.244.2.0 dev flannel.1 onlink ，也就是目标ip 10.244.2.3的包交由 flannel.1 来处理，目标mac地址是POD4所在机器的flannel.1的Mac</li>
<li>flanneld 进程将包封装成vxlan 丢到eth0从宿主机1离开（封装后的目标ip是192.168.2.91，现在都是由内核来完成flanneld这个封包过程，性能好）</li>
<li>这个封装后的vxlan udp包正确路由到宿主机2</li>
<li>然后经由 flanneld 解包成 10.244.2.3 ，命中宿主机2上的路由：10.244.2.0&#x2F;24 dev cni0 proto kernel scope link src 10.244.2.1 ，交给cni0（<strong>这里会过宿主机iptables</strong>）</li>
<li>cni0将包送给POD4</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Flannel.jpg" alt="img"></p>
<p>flannel容器启动的时候会给自己所在的node注入一些信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#kubectl describe node hygon4  |grep -i flannel</span><br><span class="line">Annotations:        flannel.alpha.coreos.com/backend-data: &#123;&quot;VNI&quot;:1,&quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;&#125;</span><br><span class="line">                    flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">                    flannel.alpha.coreos.com/kube-subnet-manager: true</span><br><span class="line">                    flannel.alpha.coreos.com/public-ip: 10.176.4.245  ---宿主机ip，vxlan封包所用</span><br><span class="line">                    </span><br><span class="line"> &quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;----宿主机网卡 flannel.1的mac</span><br></pre></td></tr></table></figure>

<p>flannel.1 知道如何通过物理网卡打包网络包到目标地址，flanneld 会在每个host 添加 arp，以及将本机的 vxlan fdb 添加到新的 host上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">//这个 flannel 集群有四个 host，这是其中一个host </span><br><span class="line">//4e:95:a9:e2:ed:28是对方 host 上 flannel.1 的 mac</span><br><span class="line">#ip neigh show dev flannel.1 </span><br><span class="line">172.19.2.0 lladdr 4e:95:a9:e2:ed:28 PERMANENT</span><br><span class="line">172.19.3.0 lladdr 2e:8b:65:d7:54:3e PERMANENT</span><br><span class="line">172.19.1.0 lladdr 6a:78:f3:db:b1:9e PERMANENT</span><br><span class="line"></span><br><span class="line">#bridge fdb show flannel.1</span><br><span class="line">01:00:5e:00:00:01 dev enp125s0f0 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev enp125s0f1 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev enp125s0f2 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev enp125s0f3 self permanent</span><br><span class="line">33:33:00:00:00:01 dev enp125s0f3 self permanent</span><br><span class="line">33:33:ff:8e:d6:ac dev enp125s0f3 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev enp2s0f0 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev enp2s0f1 self permanent</span><br><span class="line">33:33:00:00:00:01 dev cni0 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev cni0 self permanent</span><br><span class="line">f2:64:e3:49:4c:c8 dev cni0 vlan 1 master cni0 permanent</span><br><span class="line">f2:64:e3:49:4c:c8 dev cni0 master cni0 permanent</span><br><span class="line">72:d6:f3:54:7d:d6 dev vethe54b12b5 master cni0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ip neigh show dev flannel.1 //另一个host</span><br><span class="line">172.19.2.0 lladdr 4e:95:a9:e2:ed:28 PERMANENT</span><br><span class="line">172.19.3.0 lladdr 2e:8b:65:d7:54:3e PERMANENT</span><br><span class="line">172.19.0.0 lladdr 92:5c:b2:af:37:62 PERMANENT</span><br></pre></td></tr></table></figure>

<p>包流程：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220915113511706.png" alt="image-20220915113511706"></p>
<p><a href="https://blog.michaelfmcnamara.com/2008/02/what-are-the-arp-and-fdb-tables/" target="_blank" rel="noopener">ARP 和 FDB:</a></p>
<p>ARP (<a href="http://en.wikipedia.org/wiki/Address_Resolution_Protocol" target="_blank" rel="noopener">Address Resolution Protocol</a>) table is used by a <a href="http://en.wikipedia.org/wiki/Layer_3" target="_blank" rel="noopener">Layer 3</a> device (router, switch, server, desktop) to store the IP address to MAC address entries for a specific network device. </p>
<p>The FDB (<a href="http://en.wikipedia.org/wiki/Forwarding_table" target="_blank" rel="noopener">forwarding database</a>) table is used by a Layer 2 device (switch&#x2F;bridge) to store the MAC addresses that have been learned and which ports that MAC address was learned on. The MAC addresses are learned through <a href="http://en.wikipedia.org/wiki/Transparent_bridge" target="_blank" rel="noopener">transparent bridging</a> on switches and dedicated bridges.</p>
<h3 id="抓包演示packet流转以及封包解包"><a href="#抓包演示packet流转以及封包解包" class="headerlink" title="抓包演示packet流转以及封包解包"></a>抓包演示packet流转以及封包解包</h3><p>一次完整的抓包过程演示包的流转，从hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">//hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35），在cni0（a2:99:4f:dc:9d:5c）上抓包，跨机不走peer veth</span><br><span class="line">[root@hygon3 11:08 /root]</span><br><span class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</span><br><span class="line">dropped privs to tcpdump</span><br><span class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">22:d8:63:6c:e8:96 &gt; a2:99:4f:dc:9d:5c, ethertype IPv4 (0x0800), length 614: (tos 0x0, ttl 64, id 53303, offset 0, flags [DF], proto TCP (6), length 600)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x85d7 (incorrect -&gt; 0x801a), seq 150533649:150534197, ack 3441674662, win 507, options [nop,nop,TS val 1239838869 ecr 2297983667], length 548</span><br><span class="line"></span><br><span class="line">//hygon3上的pod 192.168.0.4 访问 hygon4上的pod 192.168.2.56，在本机flannel.1（a2:06:5e:83:44:78）上抓包</span><br><span class="line">[root@hygon3 10:53 /root]</span><br><span class="line">#tcpdump -i flannel.1 host 192.168.0.4 -nnetvv </span><br><span class="line">dropped privs to tcpdump</span><br><span class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 729: (tos 0x0, ttl 63, id 52997, offset 0, flags [DF], proto TCP (6), length 715)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x864a (incorrect -&gt; 0x02ae), seq 150429115:150429778, ack 3441664870, win 507, options [nop,nop,TS val 1239381169 ecr 2297525566], length 663</span><br><span class="line">       </span><br><span class="line"> [root@hygon3 11:13 /root] //通过arp 可以看到对端 flannel.1 的mac地址被缓存到了本地</span><br><span class="line">#arp -n |grep 66:c6:ba:a2:8f:a1</span><br><span class="line">192.168.2.0              ether   66:c6:ba:a2:8f:a1   CM                    flannel.1</span><br><span class="line">#ip route</span><br><span class="line">default via 10.176.3.247 dev p1p1</span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1</span><br><span class="line">192.168.0.0/24 dev cni0 proto kernel scope link src 192.168.0.1</span><br><span class="line">192.168.1.0/24 via 192.168.1.0 dev flannel.1 onlink</span><br><span class="line">192.168.2.0/24 via 192.168.2.0 dev flannel.1 onlink</span><br><span class="line">192.168.3.0/24 via 192.168.3.0 dev flannel.1 onlink</span><br><span class="line">#ip a</span><br><span class="line">18: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether a2:06:5e:83:44:78 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.0.0/32 brd 192.168.0.0 scope global flannel.1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">19: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether a2:99:4f:dc:9d:5c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.0.1/24 brd 192.168.0.255 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">//宿主机物理网卡抓包，被封成了udp的vxlan包    </span><br><span class="line">[root@hygon3 11:12 /root]</span><br><span class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</span><br><span class="line">0c:42:a1:db:b1:a8 &gt; 88:66:39:89:9b:cc, ethertype IPv4 (0x0800), length 967: (tos 0x0, ttl 64, id 33722, offset 0, flags [none], proto UDP (17), length 953)</span><br><span class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [bad udp cksum 0x88c6 -&gt; 0xe4db!] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 917: (tos 0x0, ttl 63, id 53539, offset 0, flags [DF], proto TCP (6), length 903)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8706 (incorrect -&gt; 0xe31b), seq 150613328:150614179, ack 3441682214, win 507, options [nop,nop,TS val 1240166469 ecr 2298311268], length 851</span><br><span class="line"></span><br><span class="line">---------跨机分割线--------</span><br><span class="line"></span><br><span class="line">[root@hygon4 11:15 /root] //udp ttl为61，经过了3跳(icmp ttl为63)，不过这些都和vxlan内容无关了</span><br><span class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</span><br><span class="line">88:66:39:2b:3f:ec &gt; 0c:42:a1:e9:77:2c, ethertype IPv4 (0x0800), length 736: (tos 0x0, ttl 61, id 49748, offset 0, flags [none], proto UDP (17), length 722)</span><br><span class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [udp sum ok] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 686: (tos 0x0, ttl 63, id 53631, offset 0, flags [DF], proto TCP (6), length 672)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7f0c (correct), seq 150646020:150646640, ack 3441685158, win 507, options [nop,nop,TS val 1240301769 ecr 2298444568], length 620</span><br><span class="line">0c:42:a1:e9:77:2c &gt; 88:66:39:2b:3f:ec, ethertype IPv4 (0x0800), length 180: (tos 0x0, ttl 64, id 57062, offset 0, flags [none], proto UDP (17), length 166)</span><br><span class="line">    10.176.4.245.41515 &gt; 10.176.3.245.8472: [bad udp cksum 0x9a23 -&gt; 0x8e11!] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">66:c6:ba:a2:8f:a1 &gt; a2:06:5e:83:44:78, ethertype IPv4 (0x0800), length 130: (tos 0x0, ttl 63, id 12391, offset 0, flags [DF], proto TCP (6), length 116)</span><br><span class="line">    192.168.2.56.3100 &gt; 192.168.0.4.40712: Flags [P.], cksum 0x83f3 (incorrect -&gt; 0x77e1), seq 1:65, ack 620, win 501, options [nop,nop,TS val 2298447868 ecr 1240301769], length 64</span><br><span class="line">    </span><br><span class="line">//到对端hygon4上抓包, 因为途中都是vxlan，所以ttl、mac地址都不变</span><br><span class="line">[root@hygon4 10:55 /root]</span><br><span class="line">#tcpdump -i flannel.1 host 192.168.2.56 -nnetvv</span><br><span class="line">dropped privs to tcpdump</span><br><span class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 933: (tos 0x0, ttl 63, id 52807, offset 0, flags [DF], proto TCP (6), length 919)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8d0d (correct), seq 150361706:150362573, ack 3441658790, win 507, options [nop,nop,TS val 1239073069 ecr 2297216169], length 867</span><br><span class="line">    </span><br><span class="line">#ip a //only for flannel.1 and cni0</span><br><span class="line">10: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether 66:c6:ba:a2:8f:a1 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.2.0/32 brd 192.168.2.0 scope global flannel.1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">11: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 16:97:3a:7b:53:00 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.2.1/24 brd 192.168.2.255 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever       </span><br><span class="line"></span><br><span class="line">[root@hygon4 11:24 /root]</span><br><span class="line">#arp -n | grep 44:78</span><br><span class="line">192.168.0.0              ether   a2:06:5e:83:44:78   CM                    flannel.1   </span><br><span class="line"> </span><br><span class="line"> //mac地址替换，ttl减1</span><br><span class="line"> [root@hygon4 10:55 /root]</span><br><span class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</span><br><span class="line">dropped privs to tcpdump</span><br><span class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">16:97:3a:7b:53:00 &gt; 52:e6:8e:02:80:35, ethertype IPv4 (0x0800), length 935: (tos 0x0, ttl 62, id 52829, offset 0, flags [DF], proto TCP (6), length 921)</span><br><span class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7aa8 (correct), seq 150369440:150370309, ack 3441659494, win 507, options [nop,nop,TS val 1239115869 ecr 2297259166], length 869</span><br></pre></td></tr></table></figure>

<p>这个流转流程如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/flannel-network-flow.jpg" alt="flannel-network-flow"></p>
<p>对应宿主机查询到的ip、路由信息（和上图不是对应的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#ip -d -4 addr show cni0</span><br><span class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer  161.46 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br><span class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">#ip -d -4 addr show flannel.1 //vxlan id 1 local 10.133.2.252 dev bond0 --指定了物理网卡</span><br><span class="line">474: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</span><br><span class="line">    link/ether fe:49:64:ae:36:af brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    vxlan id 1 local 10.133.2.252 dev bond0 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br><span class="line">    inet 192.168.3.0/32 brd 192.168.3.0 scope global flannel.1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p>包流转<a href="https://blog.laputa.io/kubernetes-flannel-networking-6a1cb1f8ec7c" target="_blank" rel="noopener">示意图</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220119114929034.png" alt="image-20220119114929034"></p>
<h2 id="flannel网络不通排查案例"><a href="#flannel网络不通排查案例" class="headerlink" title="flannel网络不通排查案例"></a>flannel网络不通排查案例</h2><p>当网络不通时，可以根据以上演示的包流转路径在不同的网络设备上抓包来定位哪个环节不通</p>
<h3 id="firewalld"><a href="#firewalld" class="headerlink" title="firewalld"></a>firewalld</h3><p>在麒麟系统的物理机上通过kubeadm setup集群，发现有的环境flannel网络不通，在宿主机上ping 其它物理机flannel.0网卡的ip，通过在对端宿主机抓包发现icmp收到后被防火墙扔掉了，抓包中可以看到错误信息：icmp unreachable - admin prohibited</p>
<p>下图中正常的icmp是直接ping 物理机ip</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211228203650921.png" alt="image-20211228203650921"></p>
<blockquote>
<p>The “admin prohibited filter” seen in the tcpdump output means there is a firewall blocking a connection. It does it by sending back an ICMP packet meaning precisely that: the admin of that firewall doesn’t want those packets to get through. It could be a firewall at the destination site. It could be a firewall in between. It could be iptables on the Linux system.</p>
</blockquote>
<p>发现有问题的环境中宿主机的防火墙设置报错了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATION-STAGE-1&apos; failed: iptables: No chain/target/match by that name.</span><br><span class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATION-STAGE-2&apos; failed: iptables: No chain/target/match by that name.</span><br></pre></td></tr></table></figure>

<p>应该是因为启动docker的时候 firewalld 是运行着的</p>
<blockquote>
<p>Do you have firewalld enabled, and was it (re)started after docker was started? If so, then it’s likely that firewalld wiped docker’s IPTables rules. Restarting the docker daemon should re-create those rules.</p>
</blockquote>
<p><strong>停掉 firewalld 服务可以解决这个问题</strong>，k8s集群</p>
<h3 id="flannel网络不通"><a href="#flannel网络不通" class="headerlink" title="flannel网络不通"></a><a href="https://github.com/flannel-io/flannel/issues/799" target="_blank" rel="noopener">flannel网络不通</a></h3><blockquote>
<p>Starting from Docker 1.13 default iptables policy for FORWARDING is DROP</p>
</blockquote>
<p>flannel能收到包，但是cni0收不到包，说明包进到了目标宿主机，但是从flannel解开udp转送到cni的时候出了问题，大概率是iptables 拦截了包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">It seems docker version &gt;=1.13 will add iptables rule like below,and it make this issue happen:</span><br><span class="line">iptables -P FORWARD DROP </span><br><span class="line"></span><br><span class="line">All you need to do is add a rule below:</span><br><span class="line">iptables -P FORWARD ACCEPT //将FORWARD 默认规则(没有匹配到其它规则的话）改成ACCEPT</span><br><span class="line"></span><br><span class="line">//flannel 会检查 forward chain并将之改成 accept？以下是flannel 容器日志</span><br><span class="line">I0913 07:52:30.965060       1 main.go:698] Using interface with name enp2s0f0 and address 192.168.0.1</span><br><span class="line">I0913 07:52:30.965128       1 main.go:720] Defaulting external address to interface address (192.168.0.1)</span><br><span class="line">I0913 07:52:30.965134       1 main.go:733] Defaulting external v6 address to interface address (&lt;nil&gt;)</span><br><span class="line">I0913 07:52:30.965243       1 vxlan.go:137] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false</span><br><span class="line">I0913 07:52:30.966878       1 kube.go:339] Setting NodeNetworkUnavailable</span><br><span class="line">I0913 07:52:30.977942       1 main.go:340] Setting up masking rules</span><br><span class="line">I0913 07:52:31.332105       1 main.go:361] Changing default FORWARD chain policy to ACCEPT</span><br></pre></td></tr></table></figure>

<h2 id="宿主机多-ip-下-flannel-网络不通"><a href="#宿主机多-ip-下-flannel-网络不通" class="headerlink" title="宿主机多 ip 下 flannel 网络不通"></a>宿主机多 ip 下 flannel 网络不通</h2><p>宿主机有两个ip，flannel组网ip是192.168，但是默认路由在1.1.网络下，此时能 ping 通，但是curl不通端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#tcpdump -i enp2s0f0 -nettvv host 192.168.0.3 and udp</span><br><span class="line">tcpdump: listening on enp2s0f0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line"></span><br><span class="line">//握手请求syn包，udp src ip:192.168.0.1</span><br><span class="line">1660897108.334556 0c:42:a1:4f:d1:e2 &gt; 0c:42:a1:4f:d1:ee, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 32118, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    192.168.0.1.56773 &gt; 192.168.0.3.otv: [bad udp cksum 0x81c0 -&gt; 0x459f!] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">56:fa:69:e3:dc:6b &gt; 4e:95:a9:e2:ed:28, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 41108, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.19.0.6.35118 &gt; 172.19.2.39.http: Flags [S], cksum 0x10c8 (correct), seq 582983385, win 64860, options [mss 1410,sackOK,TS val 2648241865 ecr 0,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">//对端回复syn包, 注意udp的目标ip:1.1.1.198,应该是 192.168.0.1 才对，mac是192.168.0.1 的，mac和ip不匹配，所以被内核扔掉（但是icmp不会被扔，原因未知）</span><br><span class="line">1660897108.334738 0c:42:a1:4f:d1:ee &gt; 0c:42:a1:4f:d1:e2, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 41433, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    192.168.0.3.38086 &gt; 1.1.1.198.otv: [bad udp cksum 0x5aff -&gt; 0x1769!] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">4e:95:a9:e2:ed:28 &gt; 56:fa:69:e3:dc:6b, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 0, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.19.2.39.http &gt; 172.19.0.6.35118: Flags [S.], cksum 0x8027 (correct), seq 3633913151, ack 582983386, win 64308, options [mss 1410,sackOK,TS val 3514485603 ecr 2648241865,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">//没有回复第三次握手，继续发syn，因为收到syn+ack后被扔掉了</span><br><span class="line">1660897109.363382 0c:42:a1:4f:d1:e2 &gt; 0c:42:a1:4f:d1:ee, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 32123, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    192.168.0.1.60933 &gt; 192.168.0.3.otv: [bad udp cksum 0x81c0 -&gt; 0x355f!] OTV, flags [I] (0x08), overlay 0, instance 1</span><br><span class="line">56:fa:69:e3:dc:6b &gt; 4e:95:a9:e2:ed:28, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 41109, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.19.0.6.35118 &gt; 172.19.2.39.http: Flags [S], cksum 0x0cc3 (correct), seq 582983385, win 64860, options [mss 1410,sackOK,TS val 2648242894 ecr 0,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure>

<p>多ip宿主机的网卡及路由</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">5: enp125s0f3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 64:2c:ac:e9:78:3d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 1.1.1.198/25 brd 1.1.1.255 scope global dynamic noprefixroute enp125s0f3</span><br><span class="line">       valid_lft 12463sec preferred_lft 12463sec</span><br><span class="line">    inet6 fe80::859a:7861:378e:d6ac/64 scope link noprefixroute</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: enp2s0f0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether 0c:42:a1:4f:d1:e2 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.0.1/24 brd 192.168.0.255 scope global noprefixroute enp2s0f0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line">#ip route</span><br><span class="line">default via 1.1.1.254 dev enp125s0f3 proto dhcp metric 101</span><br><span class="line">1.1.1.128/25 dev enp125s0f3 proto kernel scope link src 1.1.1.198 metric 101</span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown</span><br><span class="line">172.19.0.0/24 dev cni0 proto kernel scope link src 172.19.0.1</span><br><span class="line">172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink</span><br><span class="line">172.19.3.0/24 via 172.19.3.0 dev flannel.1 onlink</span><br><span class="line">192.168.0.0/24 dev enp2s0f0 proto kernel scope link src 192.168.0.1 metric 100</span><br></pre></td></tr></table></figure>

<p>解决办法：真正生效的是 flannel.1 中的地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//比如 flannel 选用了以下公网ip（默认路由上的ip）导致flannel网络不通，应该选内网ip</span><br><span class="line">#ip -details link show flannel.1</span><br><span class="line">29: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span><br><span class="line">    link/ether 96:ad:e2:29:29:09 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    vxlan id 1 local 30.1.1.1 dev eno1 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br></pre></td></tr></table></figure>

<p>解决办法得先删掉 flannel 网络，然后在 flannel.yaml 中指定内网网卡：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">registry:5000/quay.io/coreos/flannel:v0.14.0</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="comment">#指定网卡, enp33s0f0 为内网网卡，不是默认路由</span></span><br><span class="line">        <span class="comment">#- --iface=enp33s0f0</span></span><br><span class="line">        <span class="comment">#— --iface-regex=[enp0s8|enp0s9]</span></span><br><span class="line"></span><br><span class="line"><span class="string">//然后会看到</span> <span class="string">flannel.1</span> <span class="string">的地址用的是</span> <span class="string">enp33s0f0（192.168.0.1）</span></span><br><span class="line"><span class="comment">#ip -details link show flannel.1</span></span><br><span class="line"><span class="attr">40: flannel.1:</span> <span class="string">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> <span class="string">mtu</span> <span class="number">1450</span> <span class="string">qdisc</span> <span class="string">noqueue</span> <span class="string">state</span> <span class="string">UNKNOWN</span> <span class="string">mode</span> <span class="string">DEFAULT</span> <span class="string">group</span> <span class="string">default</span></span><br><span class="line">    <span class="string">link/ether</span> <span class="number">92</span><span class="string">:5c:b2:af:37:62</span> <span class="string">brd</span> <span class="string">ff:ff:ff:ff:ff:ff</span> <span class="string">promiscuity</span> <span class="number">0</span> <span class="string">minmtu</span> <span class="number">68</span> <span class="string">maxmtu</span> <span class="number">65535</span></span><br><span class="line">    <span class="string">vxlan</span> <span class="string">id</span> <span class="number">1</span> <span class="string">local</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span> <span class="string">dev</span> <span class="string">enp2s0f0</span> <span class="string">srcport</span> <span class="number">0</span> <span class="number">0</span> <span class="string">dstport</span> <span class="number">8472</span> <span class="string">nolearning</span> <span class="string">ttl</span> <span class="string">auto</span> <span class="string">ageing</span> <span class="number">300</span> <span class="string">udpcsum</span> <span class="string">noudp6zerocsumtx</span> <span class="string">noudp6zerocsumrx</span> <span class="string">addrgenmode</span> <span class="string">eui64</span> <span class="string">numtxqueues</span> <span class="number">1</span> <span class="string">numrxqueues</span> <span class="number">1</span> <span class="string">gso_max_size</span> <span class="number">65536</span> <span class="string">gso_max_segs</span> <span class="number">65535</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p> If you happen to have different interfaces to be matched, you can match it on a regex pattern. Let’s say the worker nodes could’ve enp0s8 or enp0s9 configured, then the flannel args would be <code>— --iface-regex=[enp0s8|enp0s9]</code></p>
</blockquote>
<p>修改node的annotation中flannel的 public-ip。如果因为 public-ip 不对导致网络不通，在annotation中修改public-ip没用，这个值是 flannel 读取underlay 网络配置后写进来的，同时也写到了 flannel.1 的 config 中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl annotate node ky1 flannel.alpha.coreos.com/public-ip-</span><br><span class="line">kubectl annotate node ky1 flannel.alpha.coreos.com/public-ip=192.168.0.1</span><br></pre></td></tr></table></figure>

<h2 id="容器调试"><a href="#容器调试" class="headerlink" title="容器调试"></a>容器调试</h2><p>可以起一个容器，里面带有各种工具，然后attach 到目标容器 ：<a href="https://github.com/zeromake/docker-debug/blob/master/README-zh-Hans.md" target="_blank" rel="noopener">https://github.com/zeromake/docker-debug/blob/master/README-zh-Hans.md</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./docker-debug-linux-amd64 --image=CentOS8 nginx top -Hp 12 //可以先把工具安装在CentOS8，然后attach 到被调试的 nginx容器</span><br></pre></td></tr></table></figure>

<h2 id="抓包和调试-–-nsenter"><a href="#抓包和调试-–-nsenter" class="headerlink" title="抓包和调试 – nsenter"></a>抓包和调试 – nsenter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">获取pid：docker inspect -f &#123;&#123;.State.Pid&#125;&#125; c8f874efea06</span><br><span class="line"></span><br><span class="line">进入namespace：nsenter --net --pid --target 17277</span><br><span class="line">nsenter --net --pid --target `docker inspect -f &#123;&#123;.State.Pid&#125;&#125; c8f874efea06`</span><br><span class="line"></span><br><span class="line">//只进入network namespace，这样看到的文件还是宿主机的，能直接用tcpdump，但是看到的网卡是容器的</span><br><span class="line">nsenter --target 17277 --net </span><br><span class="line"></span><br><span class="line">// ip netns 获取容器网络信息</span><br><span class="line"> 1022  [2021-04-14 15:53:06] docker inspect -f &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; ab4e471edf50   //获取容器进程id</span><br><span class="line"> 1023  [2021-04-14 15:53:30] ls /proc/79828/ns/net</span><br><span class="line"> 1024  [2021-04-14 15:53:57] ln -sfT /proc/79828/ns/net /var/run/netns/ab4e471edf50 //link 以便ip netns List能访问</span><br><span class="line"> </span><br><span class="line">// 宿主机上查看容器ip</span><br><span class="line"> 1026  [2021-04-14 15:54:11] ip netns list</span><br><span class="line"> 1028  [2021-04-14 15:55:19] ip netns exec ab4e471edf50 ifconfig</span><br><span class="line"> </span><br><span class="line"> //nsenter 调试网络</span><br><span class="line"> Get the pause container&apos;s sandboxkey: </span><br><span class="line">root@worker01:~# docker inspect k8s_POD_ubuntu-5846f86795-bcbqv_default_ea44489d-3dd4-11e8-bb37-02ecc586c8d5_0 | grep SandboxKey</span><br><span class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/82ec9e32d486&quot;,</span><br><span class="line">root@worker01:~#</span><br><span class="line">Now, using nsenter you can see the container&apos;s information.</span><br><span class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ip addr show</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default</span><br><span class="line">   link/ether 0a:58:0a:f4:01:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">   inet 10.244.1.2/24 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">Identify the peer_ifindex, and finally you can see the veth pair endpoint in root namespace.</span><br><span class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ethtool -S eth0</span><br><span class="line">NIC statistics:</span><br><span class="line">     peer_ifindex: 7</span><br><span class="line">root@worker01:~#</span><br><span class="line">root@worker01:~# ip -d link show | grep &apos;7: veth&apos;</span><br><span class="line">7: veth5e43ca47@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default</span><br><span class="line">root@worker01:~#</span><br></pre></td></tr></table></figure>

<p>nsenter相当于在setns的示例程序之上做了一层封装，使我们无需指定命名空间的文件描述符，而是指定进程号即可，<a href="https://medium.com/@anilkreddyr/kubernetes-with-flannel-understanding-the-networking-part-2-78b53e5364c7" target="_blank" rel="noopener">详细case</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#docker inspect cb7b05d82153 | grep -i SandboxKey   //根据 pause 容器id找network namespace</span><br><span class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/d6b2ef3cf886&quot;,</span><br><span class="line"></span><br><span class="line">[root@hygon252 19:00 /root]</span><br><span class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ip addr show</span><br><span class="line">3: eth0@if496: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default  //496对应宿主机上的veth编号</span><br><span class="line">    link/ether 1e:95:dd:d9:88:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 192.168.3.22/24 brd 192.168.3.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ethtool -S eth0</span><br><span class="line">NIC statistics:</span><br><span class="line">     peer_ifindex: 496</span><br><span class="line">     </span><br><span class="line">#ip -d -4 addr show cni0</span><br><span class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</span><br><span class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer   43.31 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</span><br><span class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<h2 id="清理"><a href="#清理" class="headerlink" title="清理"></a><a href="https://serverfault.com/questions/247767/cannot-delete-gre-tunnel" target="_blank" rel="noopener">清理</a></h2><p>cni信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/etc/cni/net.d/*</span><br><span class="line">/var/lib/cni/ 下存放有ip分配信息</span><br><span class="line"></span><br><span class="line">#cat /run/flannel/subnet.env</span><br><span class="line">FLANNEL_NETWORK=192.168.0.0/16</span><br><span class="line">FLANNEL_SUBNET=192.168.0.1/24</span><br><span class="line">FLANNEL_MTU=1450</span><br><span class="line">FLANNEL_IPMASQ=true</span><br></pre></td></tr></table></figure>

<p>calico创建的tunl0网卡是个tunnel，可以通过 ip tunnel show来查看，<a href="https://askubuntu.com/questions/1190684/how-can-i-permanently-delete-tun-interfaces#:~:text=doing%20sudo%20ip%20link%20delete,which%20removes%20all%20tun%20devices" target="_blank" rel="noopener">清理不掉</a>（重启可以清理掉tunl0）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev tunl0 name tunl0_fallback</span><br><span class="line">或者</span><br><span class="line">/sbin/ip link set eth1 down</span><br><span class="line">/sbin/ip link set eth1 name eth123</span><br><span class="line">/sbin/ip link set eth123 up</span><br></pre></td></tr></table></figure>

<h3 id="清理和创建flannel网络"><a href="#清理和创建flannel网络" class="headerlink" title="清理和创建flannel网络"></a>清理和创建flannel网络</h3><p>查看容器网卡和宿主机上的虚拟网卡veth pair:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link //宿主机上执行</span><br><span class="line">cat /sys/class/net/eth0/iflink //容器中执行</span><br></pre></td></tr></table></figure>

<p>清理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link delete cni0</span><br><span class="line">ip link delete flannel.1</span><br></pre></td></tr></table></figure>

<p>创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ip link add cni0 type bridge</span><br><span class="line">ip addr add dev cni0 172.30.0.0/24</span><br><span class="line"></span><br><span class="line">查看A simpler solution:</span><br><span class="line">ip -details link show</span><br><span class="line">ls -l /sys/class/net/ - virtual ones will show all in virtual and lan is on the PCI bus.</span><br><span class="line"></span><br><span class="line">brctl show cni0</span><br><span class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</span><br></pre></td></tr></table></figure>

<p>完全可以手工创建cni0、flannel.1等网络设备，然后将 veth添加到cni0网桥上，再在宿主机配置ip route，基本一个纯手工版本打造的flannel vxlan网络就实现了，深入理解到此任何flannel网络问题都可以解决了。</p>
<h3 id="flannel-ip在多个node之间分配错乱"><a href="#flannel-ip在多个node之间分配错乱" class="headerlink" title="flannel ip在多个node之间分配错乱"></a>flannel ip在多个node之间分配错乱</h3><p>当铲掉重新部署的时候可能cni等网络有残留，导致下一次部署会报ip已存在的错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container &quot;f7aa44bf81b27bf0ff6c02339df2d2743cf952c1519fead4c563892d2d41a979&quot; network for pod &quot;nginx-deployment-6c8c86b759-f8fb7&quot;: NetworkPlugin cni failed to set up pod &quot;nginx-deployment-6c8c86b759-f8fb7_default&quot; network: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 172.19.2.1/24</span><br></pre></td></tr></table></figure>

<p> 可以铲掉网卡重新分配，或者给cni重新分配错误信息提示的ip</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig cni0 172.19.2.1/24</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip link set cni0 down &amp;&amp; ip link set flannel.1 down </span><br><span class="line">ip link delete cni0 &amp;&amp; ip link delete flannel.1</span><br><span class="line">systemctl restart containerd &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure>

<h2 id="host-gw"><a href="#host-gw" class="headerlink" title="host-gw"></a><a href="https://msazure.club/flannel-networking-demystify/" target="_blank" rel="noopener">host-gw</a></h2><p>实现超级简单，就是在宿主机上配置路由规则，把其它宿主机ip当成其上所有pod的下一跳，不用封包解包，所以性能奇好，但是要求所有宿主机在一个2层网络，因为ip路由规则要求是直达其它宿主机。</p>
<p>手工配置实现就是vxlan的超级精简版，略！</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="noopener">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</span><br><span class="line"> 1005  [2021-10-27 10:49:12] ip netns show</span><br><span class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</span><br><span class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</span><br><span class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</span><br><span class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</span><br><span class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </span><br><span class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</span><br><span class="line"> 1012  [2021-10-27 10:50:39] ifconfig</span><br><span class="line"> 1013  [2021-10-27 10:50:51] ip link list</span><br><span class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</span><br><span class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </span><br><span class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</span><br><span class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</span><br><span class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</span><br><span class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</span><br><span class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</span><br><span class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</span><br><span class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</span><br><span class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</span><br><span class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</span><br><span class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</span><br><span class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</span><br><span class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</span><br><span class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</span><br><span class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</span><br><span class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</span><br><span class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</span><br><span class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</span><br><span class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</span><br><span class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</span><br><span class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</span><br><span class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</span><br><span class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</span><br><span class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</span><br><span class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</span><br><span class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</span><br><span class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</span><br><span class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</span><br><span class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</span><br><span class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</span><br><span class="line"> </span><br><span class="line"> 把网卡加入到docker0的bridge下</span><br><span class="line"> 1160  [2021-10-27 12:17:37] brctl show</span><br><span class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</span><br><span class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</span><br><span class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</span><br><span class="line"> 1164  [2021-10-27 12:18:15] brctl show</span><br><span class="line"> </span><br><span class="line">brctl showmacs br0</span><br><span class="line">brctl show cni0</span><br><span class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</span><br></pre></td></tr></table></figure>

<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: net/socket.c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//file: include/net/sock.h</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="etcd-中存储的-flannel-配置"><a href="#etcd-中存储的-flannel-配置" class="headerlink" title="etcd 中存储的 flannel 配置"></a>etcd 中存储的 flannel 配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec -it etcd-uos21 -n=kube-system -- /bin/sh</span><br><span class="line"></span><br><span class="line">然后：</span><br><span class="line">ETCDCTL_API=3 etcdctl --key /etc/kubernetes/pki/etcd/peer.key --cert /etc/kubernetes/pki/etcd/peer.crt --cacert /etc/kubernetes/pki/etcd/ca.crt --endpoints=https://localhost:2379 get /registry/configmaps/kube-system/kube-flannel-cfg</span><br><span class="line"></span><br><span class="line">cni-conf.json�&#123;</span><br><span class="line">  &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span><br><span class="line">  &quot;plugins&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">      &quot;delegate&quot;: &#123;</span><br><span class="line">        &quot;hairpinMode&quot;: true,</span><br><span class="line">        &quot;isDefaultGateway&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;portmap&quot;,</span><br><span class="line">      &quot;capabilities&quot;: &#123;</span><br><span class="line">        &quot;portMappings&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">Z</span><br><span class="line">net-conf.jsonI&#123;</span><br><span class="line">  &quot;Network&quot;: &quot;172.19.0.0/18&quot;,</span><br><span class="line">  &quot;Backend&quot;: &#123;</span><br><span class="line">    &quot;Type&quot;: &quot;vxlan&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&quot;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过无论是对flannel还是calico的学习，不管是使用vxlan还是host-gw发现这些所谓的overlay网络不过是披着一层udp的皮而已，只要我们对ip route&#x2F;mac地址足够了解，这些新技术剖析下来仍然逃不过 <a href="https://datatracker.ietf.org/doc/html/rfc1180" target="_blank" rel="noopener">RFC1180</a> 描述的几个最基础的知识点（基础知识的力量）的使用而已，这一切硬核的基础知识无比简单，只要你多看看我这篇旧文<a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="noopener">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="noopener">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="noopener">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="noopener">手工拉起flannel网络</a></p>
<p><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/13/不同CPU性能大PK/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/13/不同CPU性能大PK/" itemprop="url">不同CPU性能大PK</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-13T17:30:03+08:00">
                2022-01-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="不同CPU性能大PK"><a href="#不同CPU性能大PK" class="headerlink" title="不同CPU性能大PK"></a>不同CPU性能大PK</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>比较Hygon7280、Intel、AMD、鲲鹏920、飞腾2500的性能情况</p>
<table>
<thead>
<tr>
<th>CPU型号</th>
<th>Hygon 7280</th>
<th>AMD  7H12</th>
<th>AMD  7T83</th>
<th>Intel 8163</th>
<th>鲲鹏920</th>
<th>飞腾2500</th>
<th>倚天710</th>
</tr>
</thead>
<tbody><tr>
<td>物理核数</td>
<td>32</td>
<td>32</td>
<td>64</td>
<td>24</td>
<td>48</td>
<td>64</td>
<td>128core</td>
</tr>
<tr>
<td>超线程</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>路</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>NUMA Node</td>
<td>8</td>
<td>2</td>
<td>4</td>
<td>2</td>
<td>4</td>
<td>16</td>
<td>2</td>
</tr>
<tr>
<td>L1d</td>
<td>32K</td>
<td>32K</td>
<td>32K</td>
<td>32K</td>
<td>64K</td>
<td>32K</td>
<td>64K</td>
</tr>
<tr>
<td>L2</td>
<td>512K</td>
<td>512K</td>
<td>512K</td>
<td>1024K</td>
<td>512K</td>
<td>2048K</td>
<td>1024K</td>
</tr>
</tbody></table>
<p>AMD 7T83 有8个Die, 每个Die L3大小 32M，L2 大小4MiB, 每个Die上  L1I&#x2F;L1D 各256KiB，每个Die有8core，2、3代都是带有独立 IO Die<br>倚天710是一路服务器，单芯片2块对称的 Die</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220528105526139.png" alt="image-20220528105526139"></p>
<h2 id="参与比较的几款CPU参数"><a href="#参与比较的几款CPU参数" class="headerlink" title="参与比较的几款CPU参数"></a>参与比较的几款CPU参数</h2><p>IPC的说明：</p>
<blockquote>
<p>IPC: insns per cycle  insn&#x2F;cycles  也就是每个时钟周期能执行的指令数量，越大程序跑的越快</p>
<p>程序的执行时间 &#x3D; 指令数&#x2F;(主频*IPC) &#x2F;&#x2F;单核下，多核的话再除以核数</p>
</blockquote>
<h3 id="Hygon-7280"><a href="#Hygon-7280" class="headerlink" title="Hygon 7280"></a>Hygon 7280</h3><p>Hygon 7280 就是AMD Zen架构，最大IPC能到5. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">架构：                           x86_64</span><br><span class="line">CPU 运行模式：                   32-bit, 64-bit</span><br><span class="line">字节序：                         Little Endian</span><br><span class="line">Address sizes:                   43 bits physical, 48 bits virtual</span><br><span class="line">CPU:                             128</span><br><span class="line">在线 CPU 列表：                  0-127</span><br><span class="line">每个核的线程数：                 2</span><br><span class="line">每个座的核数：                   32</span><br><span class="line">座：                             2</span><br><span class="line">NUMA 节点：                      8</span><br><span class="line">厂商 ID：                        HygonGenuine</span><br><span class="line">CPU 系列：                       24</span><br><span class="line">型号：                           1</span><br><span class="line">型号名称：                       Hygon C86 7280 32-core Processor</span><br><span class="line">步进：                           1</span><br><span class="line">CPU MHz：                        2194.586</span><br><span class="line">BogoMIPS：                       3999.63</span><br><span class="line">虚拟化：                         AMD-V</span><br><span class="line">L1d 缓存：                       2 MiB</span><br><span class="line">L1i 缓存：                       4 MiB</span><br><span class="line">L2 缓存：                        32 MiB</span><br><span class="line">L3 缓存：                        128 MiB</span><br><span class="line">NUMA 节点0 CPU：                 0-7,64-71</span><br><span class="line">NUMA 节点1 CPU：                 8-15,72-79</span><br><span class="line">NUMA 节点2 CPU：                 16-23,80-87</span><br><span class="line">NUMA 节点3 CPU：                 24-31,88-95</span><br><span class="line">NUMA 节点4 CPU：                 32-39,96-103</span><br><span class="line">NUMA 节点5 CPU：                 40-47,104-111</span><br><span class="line">NUMA 节点6 CPU：                 48-55,112-119</span><br><span class="line">NUMA 节点7 CPU：                 56-63,120-127</span><br></pre></td></tr></table></figure>

<p><strong>架构说明：</strong></p>
<p> 每个CPU有4个Die，每个Die有两个CCX（2 core-Complexes），每个CCX最多有4core（例如7280&#x2F;7285）共享一个L3 cache；每个Die有两个Memory Channel，每个CPU带有8个Memory Channel，并且每个Memory Channel最多支持2根Memory；</p>
<p>海光7系列架构图：</p>
<p><img src="data:image/png;base64,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" alt="img"></p>
<p>曙光H620-G30A 机型硬件结构，CPU是hygon 7280（截图只截取了Socket0）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211231202402561.png" alt="image-20211231202402561"></p>
<h3 id="AMD-EPYC-7T83-NC"><a href="#AMD-EPYC-7T83-NC" class="headerlink" title="AMD EPYC 7T83(NC)"></a>AMD EPYC 7T83(NC)</h3><p>两路服务器，4 numa node，<a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_3" target="_blank" rel="noopener">Z3架构</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AMD-EPYC-Milan-Zen-3-Server-CPU.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220902113036283.png" alt="image-20220902113036283"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220902113336705.png" alt="image-20220902113336705"></p>
<p>详细信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                256</span><br><span class="line">On-line CPU(s) list:   0-255</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    64</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          4</span><br><span class="line">Vendor ID:             AuthenticAMD</span><br><span class="line">CPU family:            25</span><br><span class="line">Model:                 1</span><br><span class="line">Model name:            AMD EPYC 7T83 64-Core Processor</span><br><span class="line">Stepping:              1</span><br><span class="line">CPU MHz:               2154.005</span><br><span class="line">CPU max MHz:           2550.0000</span><br><span class="line">CPU min MHz:           1500.0000</span><br><span class="line">BogoMIPS:              5090.93</span><br><span class="line">Virtualization:        AMD-V</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              32768K</span><br><span class="line">NUMA node0 CPU(s):     0-31,128-159</span><br><span class="line">NUMA node1 CPU(s):     32-63,160-191</span><br><span class="line">NUMA node2 CPU(s):     64-95,192-223</span><br><span class="line">NUMA node3 CPU(s):     96-127,224-255</span><br><span class="line"></span><br><span class="line">#cat /sys/devices/system/cpu/cpu&#123;0,1,8,16,30,31,32,128&#125;/cache/index3/shared_cpu_map</span><br><span class="line">00000000,00000000,00000000,000000ff,00000000,00000000,00000000,000000ff</span><br><span class="line">00000000,00000000,00000000,000000ff,00000000,00000000,00000000,000000ff</span><br><span class="line">00000000,00000000,00000000,0000ff00,00000000,00000000,00000000,0000ff00</span><br><span class="line">00000000,00000000,00000000,00ff0000,00000000,00000000,00000000,00ff0000</span><br><span class="line">00000000,00000000,00000000,ff000000,00000000,00000000,00000000,ff000000</span><br><span class="line">00000000,00000000,00000000,ff000000,00000000,00000000,00000000,ff000000</span><br><span class="line">00000000,00000000,000000ff,00000000,00000000,00000000,000000ff,00000000</span><br><span class="line">00000000,00000000,00000000,000000ff,00000000,00000000,00000000,000000ff</span><br><span class="line"></span><br><span class="line">#cat /sys/devices/system/cpu/cpu0/cache/index2/shared_cpu_map</span><br><span class="line">00000000,00000000,00000000,00000001,00000000,00000000,00000000,00000001</span><br></pre></td></tr></table></figure>

<p>L3是8个物理核，16个超线程共享，相当于单核2MB，一块CPU有8个L3，总共是256MB</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#cat cpu0/cache/index3/shared_cpu_list</span><br><span class="line">0-7,128-135</span><br><span class="line">#cat cpu0/cache/index3/size</span><br><span class="line">32768K</span><br><span class="line">#cat cpu0/cache/index2/shared_cpu_list</span><br><span class="line">0,128</span><br><span class="line"></span><br><span class="line">#cat /sys/devices/system/cpu/cpu&#123;0,1,8,16,30,31,32,128&#125;/cache/index3/shared_cpu_list</span><br><span class="line">0-7,128-135</span><br><span class="line">0-7,128-135</span><br><span class="line">8-15,136-143</span><br><span class="line">16-23,144-151</span><br><span class="line">24-31,152-159</span><br><span class="line">24-31,152-159</span><br><span class="line">32-39,160-167</span><br><span class="line">0-7,128-135</span><br></pre></td></tr></table></figure>

<p>L1D、L1I各为 2MiB，单物理核为32KB</p>
<p>空跑nop的IPC为6（有点吓人）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#perf stat ./cpu/test</span><br><span class="line"> Performance counter stats for process id &apos;449650&apos;:</span><br><span class="line"></span><br><span class="line">          2,574.29 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">                 0      context-switches          #    0.000 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">                 0      page-faults               #    0.000 K/sec</span><br><span class="line">     8,985,622,182      cycles                    #    3.491 GHz                      (83.33%)</span><br><span class="line">         4,390,929      stalled-cycles-frontend   #    0.05% frontend cycles idle     (83.34%)</span><br><span class="line">     4,387,560,442      stalled-cycles-backend    #   48.83% backend cycles idle      (83.34%)</span><br><span class="line">    53,711,907,863      instructions              #    5.98  insn per cycle</span><br><span class="line">                                                  #    0.08  stalled cycles per insn  (83.34%)</span><br><span class="line">       418,902,363      branches                  #  162.725 M/sec                    (83.34%)</span><br><span class="line">            15,036      branch-misses             #    0.00% of all branches          (83.32%)</span><br><span class="line"></span><br><span class="line">       2.574347594 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>sysbench 测试7T83 比7H12 略好，可能是ECS、OS等带来的差异。</p>
<p>测试环境：4.19.91-011.ali4000.alios7.x86_64，5.7.34-log MySQL Community Server (GPL)</p>
<table>
<thead>
<tr>
<th>测试核数</th>
<th>AMD EPYC 7H12 2.5G（QPS、IPC）</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>单核</td>
<td>24363 0.58</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>一对HT</td>
<td>33519  0.40</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>2物理核(0-1)</td>
<td>48423 0.57</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>2物理核(0,32) 跨node</td>
<td>46232 0.55</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>2物理核(0,64) 跨socket</td>
<td>45072 0.52</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>4物理核(0-3)</td>
<td>97759 0.58</td>
<td>CPU跑满</td>
</tr>
<tr>
<td>16物理核(0-15)</td>
<td>367992 0.55</td>
<td>CPU跑满，sys占比20%，si 10%</td>
</tr>
<tr>
<td>32物理核(0-31)</td>
<td>686998 0.51</td>
<td>CPU跑满，sys占比20%, si 12%</td>
</tr>
<tr>
<td>64物理核(0-63)</td>
<td>1161079 0.50</td>
<td>CPU跑到95%以上，sys占比20%, si 12%</td>
</tr>
<tr>
<td>64物理核(0-31,64-95)</td>
<td>964441 0.49</td>
<td>socket2上的32核一直比较闲，数据无参考意义</td>
</tr>
<tr>
<td>64物理核(0-31,64-95)</td>
<td>1147846 0.48</td>
<td>重启mysqld，立即绑核，sysbench 在32-63上，导致0-31的CPU只能跑到89%</td>
</tr>
</tbody></table>
<p>说明，压测过程动态通过taskset绑核，所以会有数据残留其它核的cache问题</p>
<p>跨socket taskset绑核的时候要压很久任务才会跨socket迁移过去，也就是刚taskset后CPU是跑不满的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#numastat -p 437803</span><br><span class="line"></span><br><span class="line">Per-node process memory usage (in MBs) for PID 437803 (mysqld)</span><br><span class="line">                           Node 0          Node 1          Node 2</span><br><span class="line">                  --------------- --------------- ---------------</span><br><span class="line">Huge                         0.00            0.00            0.00</span><br><span class="line">Heap                         1.15            0.00         5403.27</span><br><span class="line">Stack                        0.00            0.00            0.09</span><br><span class="line">Private                   1921.60           16.22        10647.66</span><br><span class="line">----------------  --------------- --------------- ---------------</span><br><span class="line">Total                     1922.75           16.22        16051.02</span><br><span class="line"></span><br><span class="line">                           Node 3           Total</span><br><span class="line">                  --------------- ---------------</span><br><span class="line">Huge                         0.00            0.00</span><br><span class="line">Heap                         0.03         5404.45</span><br><span class="line">Stack                        0.00            0.09</span><br><span class="line">Private                     16.20        12601.68</span><br><span class="line">----------------  --------------- ---------------</span><br><span class="line">Total                       16.23        18006.22</span><br></pre></td></tr></table></figure>

<h3 id="AMD-EPYC-7H12-ECS"><a href="#AMD-EPYC-7H12-ECS" class="headerlink" title="AMD EPYC 7H12(ECS)"></a>AMD EPYC 7H12(ECS)</h3><p>AMD EPYC 7H12 64-Core（ECS，非物理机），最大IPC能到5. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lscpu</span></span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    16</span><br><span class="line">座：                 2</span><br><span class="line">NUMA 节点：         2</span><br><span class="line">厂商 ID：           AuthenticAMD</span><br><span class="line">CPU 系列：          23</span><br><span class="line">型号：              49</span><br><span class="line">型号名称：        AMD EPYC 7H12 64-Core Processor</span><br><span class="line">步进：              0</span><br><span class="line">CPU MHz：             2595.124</span><br><span class="line">BogoMIPS：            5190.24</span><br><span class="line">虚拟化：           AMD-V</span><br><span class="line">超管理器厂商：  KVM</span><br><span class="line">虚拟化类型：     完全</span><br><span class="line">L1d 缓存：          32K</span><br><span class="line">L1i 缓存：          32K</span><br><span class="line">L2 缓存：           512K</span><br><span class="line">L3 缓存：           16384K</span><br><span class="line">NUMA 节点0 CPU：    0-31</span><br><span class="line">NUMA 节点1 CPU：    32-63</span><br></pre></td></tr></table></figure>

<p>AMD EPYC 7T83 ECS </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@bugu88 cpu0]# cd /sys/devices/system/cpu/cpu0</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index0/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index1/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index2/size</span><br><span class="line">512K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index3/size</span><br><span class="line">32768K</span><br><span class="line">[root@bugu88 cpu0]# lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                16</span><br><span class="line">On-line CPU(s) list:   0-15</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    8</span><br><span class="line">座：                 1</span><br><span class="line">NUMA 节点：         1</span><br><span class="line">厂商 ID：           AuthenticAMD</span><br><span class="line">CPU 系列：          25</span><br><span class="line">型号：              1</span><br><span class="line">型号名称：        AMD EPYC 7T83 64-Core Processor</span><br><span class="line">步进：              1</span><br><span class="line">CPU MHz：             2545.218</span><br><span class="line">BogoMIPS：            5090.43</span><br><span class="line">超管理器厂商：  KVM</span><br><span class="line">虚拟化类型：     完全</span><br><span class="line">L1d 缓存：          32K</span><br><span class="line">L1i 缓存：          32K</span><br><span class="line">L2 缓存：           512K</span><br><span class="line">L3 缓存：           32768K</span><br><span class="line">NUMA 节点0 CPU：    0-15</span><br></pre></td></tr></table></figure>

<p>stream：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@bugu88 lmbench-master]# for i in $(seq 0 15); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">0</span><br><span class="line">STREAM copy latency: 0.68 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 23509.84 MB/sec</span><br><span class="line">STREAM scale latency: 0.69 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 23285.51 MB/sec</span><br><span class="line">STREAM add latency: 0.96 nanoseconds</span><br><span class="line">STREAM add bandwidth: 25043.73 MB/sec</span><br><span class="line">STREAM triad latency: 1.40 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 17121.79 MB/sec</span><br><span class="line">1</span><br><span class="line">STREAM copy latency: 0.68 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 23513.96 MB/sec</span><br><span class="line">STREAM scale latency: 0.68 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 23580.06 MB/sec</span><br><span class="line">STREAM add latency: 0.96 nanoseconds</span><br><span class="line">STREAM add bandwidth: 25049.96 MB/sec</span><br><span class="line">STREAM triad latency: 1.35 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 17741.93 MB/sec</span><br></pre></td></tr></table></figure>

<h3 id="Intel-8163"><a href="#Intel-8163" class="headerlink" title="Intel 8163"></a>Intel 8163</h3><p>这次对比测试的Intel 8163 CPU信息如下，最大IPC 是4：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">lscpu</span></span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    24</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          1</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2499.121</span><br><span class="line">CPU max MHz:           3100.0000</span><br><span class="line">CPU min MHz:           1000.0000</span><br><span class="line">BogoMIPS:              4998.90</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              33792K</span><br><span class="line">NUMA node0 CPU(s):     0-95</span><br><span class="line"></span><br><span class="line">-----8269CY</span><br><span class="line"><span class="meta">#</span><span class="bash">lscpu</span></span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">Stepping:              7</span><br><span class="line">CPU MHz:               3200.000</span><br><span class="line">CPU max MHz:           3800.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              4998.89</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              36608K</span><br><span class="line">NUMA node0 CPU(s):     0-25,52-77</span><br><span class="line">NUMA node1 CPU(s):     26-51,78-103</span><br></pre></td></tr></table></figure>

<h4 id="不同-intel-型号的差异"><a href="#不同-intel-型号的差异" class="headerlink" title="不同 intel 型号的差异"></a>不同 intel 型号的差异</h4><p>如下图是8269CY和E5-2682上跑的MySQL在相同业务、相同流量下的差异：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221121105650582.png" alt="image-20221121105650582"></p>
<p>CPU使用率差异(下图8051C是E5-2682，其它是 8269CY，主频也有30%的差异)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221121110004127.png" alt="image-20221121110004127"></p>
<h3 id="鲲鹏920"><a href="#鲲鹏920" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">[root@ARM 19:15 /root/lmbench3]</span><br><span class="line">#numactl -H</span><br><span class="line">available: 4 nodes (0-3)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23</span><br><span class="line">node 0 size: 192832 MB</span><br><span class="line">node 0 free: 146830 MB</span><br><span class="line">node 1 cpus: 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 193533 MB</span><br><span class="line">node 1 free: 175354 MB</span><br><span class="line">node 2 cpus: 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71</span><br><span class="line">node 2 size: 193533 MB</span><br><span class="line">node 2 free: 175718 MB</span><br><span class="line">node 3 cpus: 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</span><br><span class="line">node 3 size: 193532 MB</span><br><span class="line">node 3 free: 183643 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3</span><br><span class="line">  0:  10  12  20  22</span><br><span class="line">  1:  12  10  22  24</span><br><span class="line">  2:  20  22  10  12</span><br><span class="line">  3:  22  24  12  10</span><br><span class="line">  </span><br><span class="line">  #lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    48</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          4</span><br><span class="line">Model:                 0</span><br><span class="line">CPU max MHz:           2600.0000</span><br><span class="line">CPU min MHz:           200.0000</span><br><span class="line">BogoMIPS:              200.00</span><br><span class="line">L1d cache:             64K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              24576K</span><br><span class="line">NUMA node0 CPU(s):     0-23</span><br><span class="line">NUMA node1 CPU(s):     24-47</span><br><span class="line">NUMA node2 CPU(s):     48-71</span><br><span class="line">NUMA node3 CPU(s):     72-95</span><br><span class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma dcpop asimddp asimdfhm</span><br></pre></td></tr></table></figure>

<h3 id="飞腾2500"><a href="#飞腾2500" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><p>飞腾2500用nop去跑IPC的话，只能到1，但是跑其它代码能到2.33</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">lscpu</span></span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                128</span><br><span class="line">On-line CPU(s) list:   0-127</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    64</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          16</span><br><span class="line">Model:                 3</span><br><span class="line">BogoMIPS:              100.00</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              2048K</span><br><span class="line">L3 cache:              65536K</span><br><span class="line">NUMA node0 CPU(s):     0-7</span><br><span class="line">NUMA node1 CPU(s):     8-15</span><br><span class="line">NUMA node2 CPU(s):     16-23</span><br><span class="line">NUMA node3 CPU(s):     24-31</span><br><span class="line">NUMA node4 CPU(s):     32-39</span><br><span class="line">NUMA node5 CPU(s):     40-47</span><br><span class="line">NUMA node6 CPU(s):     48-55</span><br><span class="line">NUMA node7 CPU(s):     56-63</span><br><span class="line">NUMA node8 CPU(s):     64-71</span><br><span class="line">NUMA node9 CPU(s):     72-79</span><br><span class="line">NUMA node10 CPU(s):    80-87</span><br><span class="line">NUMA node11 CPU(s):    88-95</span><br><span class="line">NUMA node12 CPU(s):    96-103</span><br><span class="line">NUMA node13 CPU(s):    104-111</span><br><span class="line">NUMA node14 CPU(s):    112-119</span><br><span class="line">NUMA node15 CPU(s):    120-127</span><br><span class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">perf <span class="built_in">stat</span> ./nop</span></span><br><span class="line">failed to read counter stalled-cycles-frontend</span><br><span class="line">failed to read counter stalled-cycles-backend</span><br><span class="line">failed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for './nop':</span><br><span class="line"></span><br><span class="line">      78638.700540      task-clock (msec)         #    0.999 CPUs utilized</span><br><span class="line">              1479      context-switches          #    0.019 K/sec</span><br><span class="line">                55      cpu-migrations            #    0.001 K/sec</span><br><span class="line">                37      page-faults               #    0.000 K/sec</span><br><span class="line">      165127619524      cycles                    #    2.100 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">      165269372437      instructions              #    1.00  insns per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">           3057191      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">      78.692839007 seconds time elapsed</span><br><span class="line">      </span><br><span class="line"><span class="meta">#</span><span class="bash">dmidecode -t processor</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> dmidecode 3.0</span></span><br><span class="line">Getting SMBIOS data from sysfs.</span><br><span class="line">SMBIOS 3.2.0 present.</span><br><span class="line"><span class="meta">#</span><span class="bash"> SMBIOS implementations newer than version 3.0 are not</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> fully supported by this version of dmidecode.</span></span><br><span class="line"></span><br><span class="line">Handle 0x0004, DMI type 4, 48 bytes</span><br><span class="line">Processor Information</span><br><span class="line">	Socket Designation: BGA3576</span><br><span class="line">	Type: Central Processor</span><br><span class="line">	Family: &lt;OUT OF SPEC&gt;</span><br><span class="line">	Manufacturer: PHYTIUM</span><br><span class="line">	ID: 00 00 00 00 70 1F 66 22</span><br><span class="line">	Version: S2500</span><br><span class="line">	Voltage: 0.8 V</span><br><span class="line">	External Clock: 50 MHz</span><br><span class="line">	Max Speed: 2100 MHz</span><br><span class="line">	Current Speed: 2100 MHz</span><br><span class="line">	Status: Populated, Enabled</span><br><span class="line">	Upgrade: Other</span><br><span class="line">	L1 Cache Handle: 0x0005</span><br><span class="line">	L2 Cache Handle: 0x0007</span><br><span class="line">	L3 Cache Handle: 0x0008</span><br><span class="line">	Serial Number: N/A</span><br><span class="line">	Asset Tag: No Asset Tag</span><br><span class="line">	Part Number: NULL</span><br><span class="line">	Core Count: 64</span><br><span class="line">	Core Enabled: 64</span><br><span class="line">	Thread Count: 64</span><br><span class="line">	Characteristics:</span><br><span class="line">		64-bit capable</span><br><span class="line">		Multi-Core</span><br><span class="line">		Hardware Thread</span><br><span class="line">		Execute Protection</span><br><span class="line">		Enhanced Virtualization</span><br><span class="line">		Power/Performance Control</span><br></pre></td></tr></table></figure>

<h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>2Die，2node</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                128</span><br><span class="line">On-line CPU(s) list:   0-127</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    128</span><br><span class="line">Socket(s):             1</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Model:                 0</span><br><span class="line">BogoMIPS:              100.00</span><br><span class="line">L1d cache:             64K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              65536K //64core share</span><br><span class="line">NUMA node0 CPU(s):     0-63</span><br><span class="line">NUMA node1 CPU(s):     64-127</span><br><span class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma lrcpc dcpop sha3 sm3 sm4 asimddp sha512 sve asimdfhm dit uscat ilrcpc flagm ssbs sb dcpodp sve2 sveaes svepmull svebitperm svesha3 svesm4 flagm2 frint svei8mm svebf16 i8mm bf16 dgh</span><br><span class="line"></span><br><span class="line">#cat cpu&#123;0,1,8,16,30,31,32,127&#125;/cache/index3/shared_cpu_list</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">0-63</span><br><span class="line">64-127</span><br><span class="line"></span><br><span class="line">#grep -E &quot;core|64.000&quot; lat.log</span><br><span class="line">core:0</span><br><span class="line">64.00000 59.653</span><br><span class="line">core:8</span><br><span class="line">64.00000 62.265</span><br><span class="line">core:16</span><br><span class="line">64.00000 59.411</span><br><span class="line">core:24</span><br><span class="line">64.00000 55.836</span><br><span class="line">core:32</span><br><span class="line">64.00000 55.909</span><br><span class="line">core:40</span><br><span class="line">64.00000 56.176</span><br><span class="line">core:48</span><br><span class="line">64.00000 57.240</span><br><span class="line">core:56</span><br><span class="line">64.00000 59.485</span><br><span class="line">core:64</span><br><span class="line">64.00000 131.818</span><br><span class="line">core:72</span><br><span class="line">64.00000 127.182</span><br><span class="line">core:80</span><br><span class="line">64.00000 122.452</span><br><span class="line">core:88</span><br><span class="line">64.00000 121.673</span><br><span class="line">core:96</span><br><span class="line">64.00000 126.533</span><br><span class="line">core:104</span><br><span class="line">64.00000 125.673</span><br><span class="line">core:112</span><br><span class="line">64.00000 124.188</span><br><span class="line">core:120</span><br><span class="line">64.00000 130.202</span><br><span class="line"></span><br><span class="line">#numactl -H</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63</span><br><span class="line">node 0 size: 515652 MB</span><br><span class="line">node 0 free: 514913 MB</span><br><span class="line">node 1 cpus: 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127</span><br><span class="line">node 1 size: 516086 MB</span><br><span class="line">node 1 free: 514815 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  15</span><br><span class="line">  1:  15  10</span><br></pre></td></tr></table></figure>

<h2 id="单核以及HT计算Prime性能比较"><a href="#单核以及HT计算Prime性能比较" class="headerlink" title="单核以及HT计算Prime性能比较"></a>单核以及HT计算Prime性能比较</h2><p>以上两款CPU但从物理上的指标来看似乎AMD要好很多，从工艺上AMD也要领先一代(2年），从单核参数上来说是2.0 VS 2.5GHz，但是IPC 是5 VS 4，算下来理想的单核性能刚好一致（2*5&#x3D;2.5 *4）。</p>
<p>从外面的一些跑分结果显示也是AMD 要好，但是实际性能怎么样呢？</p>
<p>测试命令，这个测试命令无论在哪个CPU下，用2个物理核用时都是一个物理核的一半，所以这个计算是可以完全并行的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 1 /usr/bin/sysbench --num-threads=1 --test=cpu --cpu-max-prime=50000 run //单核用一个threads，绑核; HT用2个threads，绑一对HT</span><br></pre></td></tr></table></figure>

<p>测试结果为耗时，单位秒</p>
<table>
<thead>
<tr>
<th align="left">测试项</th>
<th>AMD EPYC 7H12 2.5G CentOS 7.9</th>
<th>Hygon 7280 2.1GHz CentOS</th>
<th align="left">Hygon 7280 2.1GHz 麒麟</th>
<th>Intel 8269 2.50G</th>
<th align="left">Intel 8163 CPU @ 2.50GHz</th>
<th align="left">Intel E5-2682 v4 @ 2.50GHz</th>
</tr>
</thead>
<tbody><tr>
<td align="left">单核  prime 50000 耗时</td>
<td>59秒  IPC 0.56</td>
<td>77秒 IPC 0.55</td>
<td align="left">89秒  IPC 0.56;</td>
<td>83 0.41</td>
<td align="left">105秒  IPC 0.41</td>
<td align="left">109秒  IPC 0.39</td>
</tr>
<tr>
<td align="left">HT  prime 50000 耗时</td>
<td>57秒  IPC 0.31</td>
<td>74秒 IPC 0.29</td>
<td align="left">87秒  IPC 0.29</td>
<td>48 0.35</td>
<td align="left">60秒   IPC 0.36</td>
<td align="left">74秒    IPC 0.29</td>
</tr>
</tbody></table>
<p>相同CPU下的 指令数 基本&#x3D; 耗时 * IPC * 核数</p>
<p>以上测试结果显示Hygon 7280单核计算能力是要强过Intel 8163的，但是超线程在这个场景下太不给力，相当于没有。</p>
<p>当然上面的计算Prime太单纯了，代表不了复杂的业务场景，所以接下来用MySQL的查询场景来看看。</p>
<p>如果是arm芯片在计算prime上明显要好过x86，猜测是除法取余指令上有优化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#taskset -c 11 sysbench cpu --threads=1 --events=50000  run</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br></pre></td></tr></table></figure>

<p>测试结果为10秒钟的event</p>
<table>
<thead>
<tr>
<th align="left">测试项</th>
<th>FT2500 2.1G</th>
<th>鲲鹏920-4826 2.6GHz</th>
<th align="left">Intel 8163 CPU @ 2.50GHz</th>
<th>Hygon C86 7280 2.1GHz</th>
<th>AMD 7T83</th>
</tr>
</thead>
<tbody><tr>
<td align="left">单核  prime 10秒 events</td>
<td>21626  IPC 0.89</td>
<td>30299 IPC 1.01</td>
<td align="left">8435  IPC 0.41</td>
<td>10349  IPC 0.63</td>
<td>40112  IPC 1.38</td>
</tr>
</tbody></table>
<h2 id="对比MySQL-sysbench和tpcc性能"><a href="#对比MySQL-sysbench和tpcc性能" class="headerlink" title="对比MySQL sysbench和tpcc性能"></a>对比MySQL sysbench和tpcc性能</h2><p>分别将MySQL 5.7.34社区版部署到intel+AliOS以及hygon 7280+CentOS上，将mysqld绑定到单核，一样的压力配置均将CPU跑到100%，然后用sysbench测试点查， HT表示将mysqld绑定到一对HT核。</p>
<h3 id="sysbench点查"><a href="#sysbench点查" class="headerlink" title="sysbench点查"></a>sysbench点查</h3><p> 测试命令类似如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysbench --test=&apos;/usr/share/doc/sysbench/tests/db/select.lua&apos; --oltp_tables_count=1 --report-interval=1 --oltp-table-size=10000000  --mysql-port=3307 --mysql-db=sysbench_single --mysql-user=root --mysql-password=&apos;Bj6f9g96!@#&apos;  --max-requests=0   --oltp_skip_trx=on --oltp_auto_inc=on  --oltp_range_size=5  --mysql-table-engine=innodb --rand-init=on   --max-time=300 --mysql-host=x86.51 --num-threads=4 run</span><br></pre></td></tr></table></figure>

<p>测试结果(测试中的差异AMD、Hygon CPU跑在CentOS7.9， intel CPU、Kunpeng 920 跑在AliOS上, xdb表示用集团的xdb替换社区的MySQL Server， 麒麟是国产OS)：</p>
<table>
<thead>
<tr>
<th align="left">测试核数</th>
<th>AMD EPYC 7H12 2.5G</th>
<th align="left">Hygon 7280 2.1G</th>
<th>Hygon 7280 2.1GHz 麒麟</th>
<th>Intel 8269 2.50G</th>
<th align="left">Intel 8163 2.50G</th>
<th align="left">Intel 8163 2.50G XDB5.7</th>
<th>鲲鹏 920-4826 2.6G</th>
<th>鲲鹏 920-4826 2.6G XDB8.0</th>
<th>FT2500 alisql 8.0 本地–socket</th>
</tr>
</thead>
<tbody><tr>
<td align="left">单核</td>
<td>24674  0.54</td>
<td align="left">13441  0.46</td>
<td>10236  0.39</td>
<td>28208 0.75</td>
<td align="left">25474   0.84</td>
<td align="left">29376    0.89</td>
<td>9694  0.49</td>
<td>8301  0.46</td>
<td>3602 0.53</td>
</tr>
<tr>
<td align="left">一对HT</td>
<td>36157 0.42</td>
<td align="left">21747  0.38</td>
<td>19417  0.37</td>
<td>36754 0.49</td>
<td align="left">35894  0.6</td>
<td align="left">40601  0.65</td>
<td>无HT</td>
<td>无HT</td>
<td>无HT</td>
</tr>
<tr>
<td align="left">4物理核</td>
<td>94132 0.52</td>
<td align="left">49822 0.46</td>
<td>38033  0.37</td>
<td>90434 0.69 350%</td>
<td align="left">87254  0.73</td>
<td align="left">106472  0.83</td>
<td>34686  0.42</td>
<td>28407  0.39</td>
<td>14232 0.53</td>
</tr>
<tr>
<td align="left">16物理核</td>
<td>325409 0.48</td>
<td align="left">171630 0.38</td>
<td>134980  0.34</td>
<td>371718 0.69 1500%</td>
<td align="left">332967  0.72</td>
<td align="left">446290  0.85 &#x2F;&#x2F;16核比4核好！</td>
<td>116122  0.35</td>
<td>94697  0.33</td>
<td>59199  0.6  8core:31210 0.59</td>
</tr>
<tr>
<td align="left">32物理核</td>
<td>542192 0.43</td>
<td align="left">298716 0.37</td>
<td>255586  0.33</td>
<td>642548 0.64 2700%</td>
<td align="left">588318  0.67</td>
<td align="left">598637  0.81 CPU 2400%</td>
<td>228601  0.36</td>
<td>177424  0.32</td>
<td>114020 0.65</td>
</tr>
</tbody></table>
<ul>
<li>麒麟OS下CPU很难跑满，大致能跑到90%-95%左右，麒麟上装的社区版MySQL-5.7.29；飞腾要特别注意mysqld所在socket，同时以上飞腾数据都是走–sock压测所得，32core走网络压测QPS为：99496（15%的网络损耗）[^说明]</li>
</ul>
<h3 id="Mysqld-二进制代码所在-page-cache带来的性能影响"><a href="#Mysqld-二进制代码所在-page-cache带来的性能影响" class="headerlink" title="Mysqld 二进制代码所在 page cache带来的性能影响"></a>Mysqld 二进制代码所在 page cache带来的性能影响</h3><p>如果是飞腾跨socket影响很大，mysqld二进制跨socket性能会下降30%以上</p>
<p>对于鲲鹏920，双路服务器上测试，mysqld绑在node0, 但是分别将mysqld二进制load进不同的node上的page cache，然后执行点查</p>
<table>
<thead>
<tr>
<th>mysqld</th>
<th>node0</th>
<th>node1</th>
<th>node2</th>
<th>node3</th>
</tr>
</thead>
<tbody><tr>
<td>QPS</td>
<td>190120 IPC 0.40</td>
<td>182518 IPC 0.39</td>
<td>189046 IPC 0.40</td>
<td>186533 IPC 0.40</td>
</tr>
</tbody></table>
<p>以上数据可以看出这里node0到node1还是很慢的，居然比跨socket还慢，反过来说鲲鹏跨socket性能很好</p>
<p>绑定mysqld到不同node的page cache操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#systemctl stop mysql-server</span><br><span class="line"></span><br><span class="line">[root@poc65 /root/vmtouch]</span><br><span class="line">#vmtouch -e /usr/local/mysql/bin/mysqld</span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">   Evicted Pages: 5916 (23M)</span><br><span class="line">         Elapsed: 0.00322 seconds</span><br><span class="line"></span><br><span class="line">#vmtouch -v /usr/local/mysql/bin/mysqld</span><br><span class="line">/usr/local/mysql/bin/mysqld</span><br><span class="line">[                                                            ] 0/5916</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">  Resident Pages: 0/5916  0/23M  0%</span><br><span class="line">         Elapsed: 0.000204 seconds</span><br><span class="line"></span><br><span class="line">#taskset -c 24 md5sum /usr/local/mysql/bin/mysqld</span><br><span class="line"></span><br><span class="line">#grep mysqld /proc/`pidof mysqld`/numa_maps  //检查mysqld具体绑定在哪个node上</span><br><span class="line">00400000 default file=/usr/local/mysql/bin/mysqld mapped=3392 active=1 N0=3392 kernelpagesize_kB=4</span><br><span class="line">0199b000 default file=/usr/local/mysql/bin/mysqld anon=10 dirty=10 mapped=134 active=10 N0=134 kernelpagesize_kB=4</span><br><span class="line">01a70000 default file=/usr/local/mysql/bin/mysqld anon=43 dirty=43 mapped=120 active=43 N0=120 kernelpagesize_kB=4</span><br></pre></td></tr></table></figure>

<h3 id="网卡以及node距离带来的性能差异"><a href="#网卡以及node距离带来的性能差异" class="headerlink" title="网卡以及node距离带来的性能差异"></a>网卡以及node距离带来的性能差异</h3><p>在鲲鹏920+mysql5.7+alios，将内存分配锁在node0上，然后分别绑核在1、24、48、72core，进行sysbench点查对比</p>
<table>
<thead>
<tr>
<th></th>
<th>Core1</th>
<th>Core24</th>
<th>Core48</th>
<th>Core72</th>
</tr>
</thead>
<tbody><tr>
<td>QPS</td>
<td>10800</td>
<td>10400</td>
<td>7700</td>
<td>7700</td>
</tr>
</tbody></table>
<p>以上测试的时候业务进程分配的内存全限制在node0上（下面的网卡中断测试也是同样内存结构）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#/root/numa-maps-summary.pl &lt;/proc/123853/numa_maps</span><br><span class="line">N0        :      5085548 ( 19.40 GB)</span><br><span class="line">N1        :         4479 (  0.02 GB)</span><br><span class="line">N2        :            1 (  0.00 GB)</span><br><span class="line">active    :            0 (  0.00 GB)</span><br><span class="line">anon      :      5085455 ( 19.40 GB)</span><br><span class="line">dirty     :      5085455 ( 19.40 GB)</span><br><span class="line">kernelpagesize_kB:         2176 (  0.01 GB)</span><br><span class="line">mapmax    :          348 (  0.00 GB)</span><br><span class="line">mapped    :         4626 (  0.02 GB)</span><br></pre></td></tr></table></figure>

<p>对比测试，将内存锁在node3上，重复进行以上测试结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Core1</th>
<th>Core24</th>
<th>Core48</th>
<th>Core72</th>
</tr>
</thead>
<tbody><tr>
<td>QPS</td>
<td>10500</td>
<td>10000</td>
<td>8100</td>
<td>8000</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#/root/numa-maps-summary.pl &lt;/proc/54478/numa_maps</span><br><span class="line">N0        :           16 (  0.00 GB)</span><br><span class="line">N1        :         4401 (  0.02 GB)</span><br><span class="line">N2        :            1 (  0.00 GB)</span><br><span class="line">N3        :      1779989 (  6.79 GB)</span><br><span class="line">active    :            0 (  0.00 GB)</span><br><span class="line">anon      :      1779912 (  6.79 GB)</span><br><span class="line">dirty     :      1779912 (  6.79 GB)</span><br><span class="line">kernelpagesize_kB:         1108 (  0.00 GB)</span><br><span class="line">mapmax    :          334 (  0.00 GB)</span><br><span class="line">mapped    :         4548 (  0.02 GB)</span><br></pre></td></tr></table></figure>

<p>机器上网卡eth1插在node0上，由以上两组对比测试发现网卡影响比内存跨node影响更大，网卡影响有20%。而内存的影响基本看不到（就近好那么一点点，但是不明显，只能解释为cache命中率很高了）</p>
<p>此时软中断都在node0上，如果将软中断绑定到node3上，第72core的QPS能提升到8500，并且非常稳定。同时core0的QPS下降到10000附近。</p>
<h4 id="网卡软中断以及网卡远近的测试结论"><a href="#网卡软中断以及网卡远近的测试结论" class="headerlink" title="网卡软中断以及网卡远近的测试结论"></a>网卡软中断以及网卡远近的测试结论</h4><p>测试机器只是用了一块网卡，网卡插在node0上。</p>
<p>一般网卡中断会占用一些CPU，如果把网卡中断挪到其它node的core上，在鲲鹏920上测试，业务跑在node3（使用全部24core），网卡中断分别在node0和node3，QPS分别是：179000 VS 175000 （此时把中断放到node0或者是和node3最近的node2上差别不大）</p>
<p>如果将业务跑在node0上（全部24core），网卡中断分别在node0和node1上得到的QPS分别是：204000 VS 212000 </p>
<h3 id="tpcc-1000仓"><a href="#tpcc-1000仓" class="headerlink" title="tpcc 1000仓"></a>tpcc 1000仓</h3><p>测试结果(测试中Hygon 7280分别跑在CentOS7.9和麒麟上， 鲲鹏&#x2F;intel CPU 跑在AliOS、麒麟是国产OS)：</p>
<p>tpcc测试数据，结果为1000仓，tpmC (NewOrders) ，未标注CPU 则为跑满了</p>
<table>
<thead>
<tr>
<th>测试核数</th>
<th>Intel 8269 2.50G</th>
<th>Intel 8163 2.50G</th>
<th>Hygon 7280 2.1GHz 麒麟</th>
<th>Hygon 7280 2.1G CentOS 7.9</th>
<th>鲲鹏 920-4826 2.6G</th>
<th>鲲鹏 920-4826 2.6G XDB8.0</th>
</tr>
</thead>
<tbody><tr>
<td>1物理核</td>
<td>12392</td>
<td>9902</td>
<td>4706</td>
<td>7011</td>
<td>6619</td>
<td>4653</td>
</tr>
<tr>
<td>一对HT</td>
<td>17892</td>
<td>15324</td>
<td>8950</td>
<td>11778</td>
<td>无HT</td>
<td>无HT</td>
</tr>
<tr>
<td>4物理核</td>
<td>51525</td>
<td>40877</td>
<td>19387 380%</td>
<td>30046</td>
<td>23959</td>
<td>20101</td>
</tr>
<tr>
<td>8物理核</td>
<td>100792</td>
<td>81799</td>
<td>39664 750%</td>
<td>60086</td>
<td>42368</td>
<td>40572</td>
</tr>
<tr>
<td>16物理核</td>
<td>160798 抖动</td>
<td>140488 CPU抖动</td>
<td>75013 1400%</td>
<td>106419 1300-1550%</td>
<td>70581  1200%</td>
<td>79844</td>
</tr>
<tr>
<td>24物理核</td>
<td>188051</td>
<td>164757 1600-2100%</td>
<td>100841 1800-2000%</td>
<td>130815 1600-2100%</td>
<td>88204  1600%</td>
<td>115355</td>
</tr>
<tr>
<td>32物理核</td>
<td>195292</td>
<td>185171 2000-2500%</td>
<td>116071 1900-2400%</td>
<td>142746 1800-2400%</td>
<td>102089  1900%</td>
<td>143567</td>
</tr>
<tr>
<td>48物理核</td>
<td>19969l</td>
<td>195730 2100-2600%</td>
<td>128188  2100-2800%</td>
<td>149782 2000-2700%</td>
<td>116374  2500%</td>
<td>206055  4500%</td>
</tr>
</tbody></table>
<p>tpcc并发到一定程度后主要是锁导致性能上不去，所以超多核意义不大。</p>
<p>如果在Hygon 7280 2.1GHz 麒麟上起两个MySQLD实例，每个实例各绑定32物理core，性能刚好翻倍：<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210823082702539.png" alt="image-20210823082702539"></p>
<p>测试过程CPU均跑满（未跑满的话会标注出来），IPC跑不起来性能就必然低，超线程虽然总性能好了但是会导致IPC降低(参考前面的公式)。可以看到对本来IPC比较低的场景，启用超线程后一般对性能会提升更大一些。</p>
<p>CPU核数增加到32核后，MySQL社区版性能追平xdb， 此时sysbench使用120线程压性能较好（AMD得240线程压）</p>
<p>32核的时候对比下MySQL 社区版在Hygon7280和Intel 8163下的表现：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210817181752243.png" alt="image-20210817181752243"></p>
<h2 id="三款CPU的性能指标"><a href="#三款CPU的性能指标" class="headerlink" title="三款CPU的性能指标"></a>三款CPU的性能指标</h2><table>
<thead>
<tr>
<th align="left">测试项</th>
<th>AMD EPYC 7H12 2.5G</th>
<th align="left">Hygon 7280 2.1GHz</th>
<th align="left">Intel 8163 CPU @ 2.50GHz</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内存带宽(MiB&#x2F;s)</td>
<td>12190.50</td>
<td align="left">6206.06</td>
<td align="left">7474.45</td>
</tr>
<tr>
<td align="left">内存延时(遍历很大一个数组)</td>
<td>0.334ms</td>
<td align="left">0.336ms</td>
<td align="left">0.429ms</td>
</tr>
</tbody></table>
<h2 id="在lmbench上的测试数据"><a href="#在lmbench上的测试数据" class="headerlink" title="在lmbench上的测试数据"></a>在lmbench上的测试数据</h2><p>stream主要用于测试带宽，对应的时延是在带宽跑满情况下的带宽。</p>
<p>lat_mem_rd用来测试操作不同数据大小的时延。总的来说带宽看stream、时延看lat_mem_rd</p>
<h3 id="飞腾2500-1"><a href="#飞腾2500-1" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><p>用stream测试带宽和latency，可以看到带宽随着numa距离不断减少、对应的latency不断增加，到最近的numa node有10%的损耗，这个损耗和numactl给出的距离完全一致。跨socket访问内存latency是node内的3倍，带宽是三分之一，但是socket1性能和socket0性能完全一致</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">time for i in $(seq 7 8 128); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 0 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 2.84 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 5638.21 MB/sec</span><br><span class="line">STREAM scale latency: 2.72 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 5885.97 MB/sec</span><br><span class="line">STREAM add latency: 2.26 nanoseconds</span><br><span class="line">STREAM add bandwidth: 10615.13 MB/sec</span><br><span class="line">STREAM triad latency: 4.53 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 5297.93 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 1 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.16 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 5058.71 MB/sec</span><br><span class="line">STREAM scale latency: 3.15 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 5074.78 MB/sec</span><br><span class="line">STREAM add latency: 2.35 nanoseconds</span><br><span class="line">STREAM add bandwidth: 10197.36 MB/sec</span><br><span class="line">STREAM triad latency: 5.12 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 4686.37 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 2 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.85 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 4150.98 MB/sec</span><br><span class="line">STREAM scale latency: 3.95 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 4054.30 MB/sec</span><br><span class="line">STREAM add latency: 2.64 nanoseconds</span><br><span class="line">STREAM add bandwidth: 9100.12 MB/sec</span><br><span class="line">STREAM triad latency: 6.39 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 3757.70 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.69 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 4340.24 MB/sec</span><br><span class="line">STREAM scale latency: 3.62 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 4422.18 MB/sec</span><br><span class="line">STREAM add latency: 2.47 nanoseconds</span><br><span class="line">STREAM add bandwidth: 9704.82 MB/sec</span><br><span class="line">STREAM triad latency: 5.74 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 4177.85 MB/sec</span><br><span class="line"></span><br><span class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</span><br><span class="line">#numactl -C 7 -m 7 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.95 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 4051.51 MB/sec</span><br><span class="line">STREAM scale latency: 3.94 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 4060.63 MB/sec</span><br><span class="line">STREAM add latency: 2.54 nanoseconds</span><br><span class="line">STREAM add bandwidth: 9434.51 MB/sec</span><br><span class="line">STREAM triad latency: 6.13 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 3913.36 MB/sec</span><br><span class="line"></span><br><span class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</span><br><span class="line">#numactl -C 7 -m 10 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 8.80 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 1817.78 MB/sec</span><br><span class="line">STREAM scale latency: 8.59 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 1861.65 MB/sec</span><br><span class="line">STREAM add latency: 5.55 nanoseconds</span><br><span class="line">STREAM add bandwidth: 4320.68 MB/sec</span><br><span class="line">STREAM triad latency: 13.94 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 1721.76 MB/sec</span><br><span class="line"></span><br><span class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</span><br><span class="line">#numactl -C 7 -m 11 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 9.27 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 1726.52 MB/sec</span><br><span class="line">STREAM scale latency: 9.31 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 1718.10 MB/sec</span><br><span class="line">STREAM add latency: 5.65 nanoseconds</span><br><span class="line">STREAM add bandwidth: 4250.89 MB/sec</span><br><span class="line">STREAM triad latency: 14.09 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 1703.66 MB/sec</span><br><span class="line"></span><br><span class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</span><br><span class="line">#numactl -C 88 -m 11 ./bin/stream  -W 5 -N 5 -M 64M //在另外一个socket上测试本numa，和node0性能完全一致</span><br><span class="line">STREAM copy latency: 2.93 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 5454.67 MB/sec</span><br><span class="line">STREAM scale latency: 2.96 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 5400.03 MB/sec</span><br><span class="line">STREAM add latency: 2.28 nanoseconds</span><br><span class="line">STREAM add bandwidth: 10543.42 MB/sec</span><br><span class="line">STREAM triad latency: 4.52 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 5308.40 MB/sec</span><br><span class="line"></span><br><span class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</span><br><span class="line">#numactl -C 7 -m 15 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 8.73 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 1831.77 MB/sec</span><br><span class="line">STREAM scale latency: 8.81 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 1815.13 MB/sec</span><br><span class="line">STREAM add latency: 5.63 nanoseconds</span><br><span class="line">STREAM add bandwidth: 4265.21 MB/sec</span><br><span class="line">STREAM triad latency: 13.09 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 1833.68 MB/sec</span><br></pre></td></tr></table></figure>

<p>Lat_mem_rd 用cpu7访问node0和node15对比结果，随着数据的加大，延时在加大，64M时能有3倍差距，和上面测试一致</p>
<p>下图 第一列 表示读写数据的大小（单位M），第二列表示访问延时（单位纳秒），一般可以看到在L1&#x2F;L2&#x2F;L3 cache大小的地方延时会有跳跃，远超过L3大小后，延时就是内存延时了</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210924185044090.png" alt="image-20210924185044090"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl -C 7 -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 64M  //-C 7 cpu 7, -m 0 node0, -W 热身 -t stride</span><br></pre></td></tr></table></figure>

<p>同样的机型，开关numa的测试结果，关numa 时延、带宽都差了几倍</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220323153507557.png" alt="image-20220323153507557"></p>
<p>关闭numa的机器上测试结果随机性很强，这应该是和内存分配在那里有关系，不过如果机器一直保持这个状态反复测试的话，快的core一直快，慢的core一直慢，这是因为物理地址分配有一定的规律，在物理内存没怎么变化的情况下，快的core恰好分到的内存比较近。</p>
<p>同时不同机器状态（内存使用率）测试结果也不一样</p>
<h3 id="鲲鹏920-1"><a href="#鲲鹏920-1" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">#for i in $(seq 0 15); do echo core:$i; numactl -N $i -m 7 ./bin/stream  -W 5 -N 5 -M 64M; done</span><br><span class="line">STREAM copy latency: 1.84 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 8700.75 MB/sec</span><br><span class="line">STREAM scale latency: 1.86 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 8623.60 MB/sec</span><br><span class="line">STREAM add latency: 2.18 nanoseconds</span><br><span class="line">STREAM add bandwidth: 10987.04 MB/sec</span><br><span class="line">STREAM triad latency: 3.03 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 7926.87 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 1 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 2.05 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 7802.45 MB/sec</span><br><span class="line">STREAM scale latency: 2.08 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 7681.87 MB/sec</span><br><span class="line">STREAM add latency: 2.19 nanoseconds</span><br><span class="line">STREAM add bandwidth: 10954.76 MB/sec</span><br><span class="line">STREAM triad latency: 3.17 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 7559.86 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 2 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.51 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 4556.86 MB/sec</span><br><span class="line">STREAM scale latency: 3.58 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 4463.66 MB/sec</span><br><span class="line">STREAM add latency: 2.71 nanoseconds</span><br><span class="line">STREAM add bandwidth: 8869.79 MB/sec</span><br><span class="line">STREAM triad latency: 5.92 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 4057.12 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 7 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 3.94 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 4064.25 MB/sec</span><br><span class="line">STREAM scale latency: 3.82 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 4188.67 MB/sec</span><br><span class="line">STREAM add latency: 2.86 nanoseconds</span><br><span class="line">STREAM add bandwidth: 8390.70 MB/sec</span><br><span class="line">STREAM triad latency: 4.78 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 5024.25 MB/sec</span><br><span class="line"></span><br><span class="line">#numactl -C 24 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</span><br><span class="line">STREAM copy latency: 4.10 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 3904.63 MB/sec</span><br><span class="line">STREAM scale latency: 4.03 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 3969.41 MB/sec</span><br><span class="line">STREAM add latency: 3.07 nanoseconds</span><br><span class="line">STREAM add bandwidth: 7816.08 MB/sec</span><br><span class="line">STREAM triad latency: 5.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 4738.66 MB/sec</span><br></pre></td></tr></table></figure>

<h3 id="海光7280"><a href="#海光7280" class="headerlink" title="海光7280"></a>海光7280</h3><p>可以看到跨numa（一个numa也就是一个socket，等同于跨socket）RT从1.5上升到2.5，这个数据比鲲鹏920要好很多</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">[root@hygon8 14:32 /root/lmbench-master]</span><br><span class="line">#lscpu</span><br><span class="line">架构：                           x86_64</span><br><span class="line">CPU 运行模式：                   32-bit, 64-bit</span><br><span class="line">字节序：                         Little Endian</span><br><span class="line">Address sizes:                   43 bits physical, 48 bits virtual</span><br><span class="line">CPU:                             128</span><br><span class="line">在线 CPU 列表：                  0-127</span><br><span class="line">每个核的线程数：                 2</span><br><span class="line">每个座的核数：                   32</span><br><span class="line">座：                             2</span><br><span class="line">NUMA 节点：                      8</span><br><span class="line">厂商 ID：                        HygonGenuine</span><br><span class="line">CPU 系列：                       24</span><br><span class="line">型号：                           1</span><br><span class="line">型号名称：                       Hygon C86 7280 32-core Processor</span><br><span class="line">步进：                           1</span><br><span class="line">CPU MHz：                        2194.586</span><br><span class="line">BogoMIPS：                       3999.63</span><br><span class="line">虚拟化：                         AMD-V</span><br><span class="line">L1d 缓存：                       2 MiB</span><br><span class="line">L1i 缓存：                       4 MiB</span><br><span class="line">L2 缓存：                        32 MiB</span><br><span class="line">L3 缓存：                        128 MiB</span><br><span class="line">NUMA 节点0 CPU：                 0-7,64-71</span><br><span class="line">NUMA 节点1 CPU：                 8-15,72-79</span><br><span class="line">NUMA 节点2 CPU：                 16-23,80-87</span><br><span class="line">NUMA 节点3 CPU：                 24-31,88-95</span><br><span class="line">NUMA 节点4 CPU：                 32-39,96-103</span><br><span class="line">NUMA 节点5 CPU：                 40-47,104-111</span><br><span class="line">NUMA 节点6 CPU：                 48-55,112-119</span><br><span class="line">NUMA 节点7 CPU：                 56-63,120-127</span><br><span class="line"></span><br><span class="line">//可以看到7号core比15、23、31号core明显要快，就近访问node 0的内存，跨numa node（跨Die）没有内存交织分配</span><br><span class="line">[root@hygon8 14:32 /root/lmbench-master]</span><br><span class="line">#time for i in $(seq 7 8 64); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">7</span><br><span class="line">STREAM copy latency: 1.38 nanoseconds    </span><br><span class="line">STREAM copy bandwidth: 11559.53 MB/sec</span><br><span class="line">STREAM scale latency: 1.16 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 13815.87 MB/sec</span><br><span class="line">STREAM add latency: 1.40 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17145.85 MB/sec</span><br><span class="line">STREAM triad latency: 1.44 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 16637.18 MB/sec</span><br><span class="line">15</span><br><span class="line">STREAM copy latency: 1.67 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 9591.77 MB/sec</span><br><span class="line">STREAM scale latency: 1.56 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10242.50 MB/sec</span><br><span class="line">STREAM add latency: 1.45 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16581.00 MB/sec</span><br><span class="line">STREAM triad latency: 2.00 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12028.83 MB/sec</span><br><span class="line">23</span><br><span class="line">STREAM copy latency: 1.65 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 9701.49 MB/sec</span><br><span class="line">STREAM scale latency: 1.53 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10427.98 MB/sec</span><br><span class="line">STREAM add latency: 1.42 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16846.10 MB/sec</span><br><span class="line">STREAM triad latency: 1.97 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12189.72 MB/sec</span><br><span class="line">31</span><br><span class="line">STREAM copy latency: 1.64 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 9742.86 MB/sec</span><br><span class="line">STREAM scale latency: 1.52 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10510.80 MB/sec</span><br><span class="line">STREAM add latency: 1.45 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16559.86 MB/sec</span><br><span class="line">STREAM triad latency: 1.92 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12490.01 MB/sec</span><br><span class="line">39</span><br><span class="line">STREAM copy latency: 2.55 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 6286.25 MB/sec</span><br><span class="line">STREAM scale latency: 2.51 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 6383.11 MB/sec</span><br><span class="line">STREAM add latency: 1.76 nanoseconds</span><br><span class="line">STREAM add bandwidth: 13660.83 MB/sec</span><br><span class="line">STREAM triad latency: 3.68 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 6523.02 MB/sec</span><br></pre></td></tr></table></figure>

<p>如果这种芯片在bios里设置Die interleaving，4块die当成一个numa node吐出来给OS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">架构：                           x86_64</span><br><span class="line">CPU 运行模式：                   32-bit, 64-bit</span><br><span class="line">字节序：                         Little Endian</span><br><span class="line">Address sizes:                   43 bits physical, 48 bits virtual</span><br><span class="line">CPU:                             128</span><br><span class="line">在线 CPU 列表：                  0-127</span><br><span class="line">每个核的线程数：                 2</span><br><span class="line">每个座的核数：                   32</span><br><span class="line">座：                             2</span><br><span class="line">NUMA 节点：                      2</span><br><span class="line">厂商 ID：                        HygonGenuine</span><br><span class="line">CPU 系列：                       24</span><br><span class="line">型号：                           1</span><br><span class="line">型号名称：                       Hygon C86 7280 32-core Processor</span><br><span class="line">步进：                           1</span><br><span class="line">CPU MHz：                        2108.234</span><br><span class="line">BogoMIPS：                       3999.45</span><br><span class="line">虚拟化：                         AMD-V</span><br><span class="line">L1d 缓存：                       2 MiB</span><br><span class="line">L1i 缓存：                       4 MiB</span><br><span class="line">L2 缓存：                        32 MiB</span><br><span class="line">L3 缓存：                        128 MiB</span><br><span class="line">//注意这里和真实物理架构不一致，bios配置了Die Interleaving Enable</span><br><span class="line">//表示每路内多个Die内存交织分配，这样整个一路就是一个大Die</span><br><span class="line">NUMA 节点0 CPU：                 0-31,64-95  </span><br><span class="line">NUMA 节点1 CPU：                 32-63,96-127</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//enable die interleaving 后继续streaming测试</span><br><span class="line">//最终测试结果表现就是7/15/23/31 core性能一致，因为默认一个numa内内存交织分配</span><br><span class="line">//可以看到同一路下的四个die内存交织访问，所以4个node内存延时一样了（被平均），都不如就近快</span><br><span class="line">[root@hygon3 16:09 /root/lmbench-master]</span><br><span class="line">#time for i in $(seq 7 8 64); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">7</span><br><span class="line">STREAM copy latency: 1.48 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10782.58 MB/sec</span><br><span class="line">STREAM scale latency: 1.20 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 13364.38 MB/sec</span><br><span class="line">STREAM add latency: 1.46 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16408.32 MB/sec</span><br><span class="line">STREAM triad latency: 1.53 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 15696.00 MB/sec</span><br><span class="line">15</span><br><span class="line">STREAM copy latency: 1.51 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10601.25 MB/sec</span><br><span class="line">STREAM scale latency: 1.24 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 12855.87 MB/sec</span><br><span class="line">STREAM add latency: 1.46 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16382.42 MB/sec</span><br><span class="line">STREAM triad latency: 1.53 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 15691.48 MB/sec</span><br><span class="line">23</span><br><span class="line">STREAM copy latency: 1.50 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10700.61 MB/sec</span><br><span class="line">STREAM scale latency: 1.27 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 12634.63 MB/sec</span><br><span class="line">STREAM add latency: 1.47 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16370.67 MB/sec</span><br><span class="line">STREAM triad latency: 1.55 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 15455.75 MB/sec</span><br><span class="line">31</span><br><span class="line">STREAM copy latency: 1.50 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10637.39 MB/sec</span><br><span class="line">STREAM scale latency: 1.25 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 12778.99 MB/sec</span><br><span class="line">STREAM add latency: 1.46 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16420.65 MB/sec</span><br><span class="line">STREAM triad latency: 1.61 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 14946.80 MB/sec</span><br><span class="line">39</span><br><span class="line">STREAM copy latency: 2.35 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 6807.09 MB/sec</span><br><span class="line">STREAM scale latency: 2.32 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 6906.93 MB/sec</span><br><span class="line">STREAM add latency: 1.63 nanoseconds</span><br><span class="line">STREAM add bandwidth: 14729.23 MB/sec</span><br><span class="line">STREAM triad latency: 3.36 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 7151.67 MB/sec</span><br><span class="line">47</span><br><span class="line">STREAM copy latency: 2.31 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 6938.47 MB/sec</span><br></pre></td></tr></table></figure>

<p><a href="https://support.huawei.com/enterprise/zh/doc/EDOC1100088653/32aa8773" target="_blank" rel="noopener">以华为泰山服务器(鲲鹏920芯片)配置为例</a>：<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211228165542167.png" alt="image-20211228165542167"></p>
<blockquote>
<p>Die Interleaving 控制是否使能DIE交织。使能DIE交织能充分利用系统的DDR带宽，并尽量保证各DDR通道的带宽均衡，提升DDR的利用率</p>
</blockquote>
<h3 id="hygon5280测试数据"><a href="#hygon5280测试数据" class="headerlink" title="hygon5280测试数据"></a>hygon5280测试数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">-----hygon5280测试数据</span><br><span class="line">[root@localhost lmbench-master]# for i in $(seq 0 8 24); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">0</span><br><span class="line">STREAM copy latency: 1.22 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 13166.34 MB/sec</span><br><span class="line">STREAM scale latency: 1.13 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 14166.95 MB/sec</span><br><span class="line">STREAM add latency: 1.15 nanoseconds</span><br><span class="line">STREAM add bandwidth: 20818.63 MB/sec</span><br><span class="line">STREAM triad latency: 1.39 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 17211.81 MB/sec</span><br><span class="line">8</span><br><span class="line">STREAM copy latency: 1.56 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10273.07 MB/sec</span><br><span class="line">STREAM scale latency: 1.50 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10701.89 MB/sec</span><br><span class="line">STREAM add latency: 1.20 nanoseconds</span><br><span class="line">STREAM add bandwidth: 19996.68 MB/sec</span><br><span class="line">STREAM triad latency: 1.93 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12443.70 MB/sec</span><br><span class="line">16</span><br><span class="line">STREAM copy latency: 2.52 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 6357.71 MB/sec</span><br><span class="line">STREAM scale latency: 2.48 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 6454.95 MB/sec</span><br><span class="line">STREAM add latency: 1.67 nanoseconds</span><br><span class="line">STREAM add bandwidth: 14362.51 MB/sec</span><br><span class="line">STREAM triad latency: 3.65 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 6572.85 MB/sec</span><br><span class="line">24</span><br><span class="line">STREAM copy latency: 2.44 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 6554.24 MB/sec</span><br><span class="line">STREAM scale latency: 2.41 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 6642.80 MB/sec</span><br><span class="line">STREAM add latency: 1.44 nanoseconds</span><br><span class="line">STREAM add bandwidth: 16695.82 MB/sec</span><br><span class="line">STREAM triad latency: 3.61 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 6639.18 MB/sec</span><br><span class="line">[root@localhost lmbench-master]# lscpu</span><br><span class="line">架构：                           x86_64</span><br><span class="line">CPU 运行模式：                   32-bit, 64-bit</span><br><span class="line">字节序：                         Little Endian</span><br><span class="line">Address sizes:                   43 bits physical, 48 bits virtual</span><br><span class="line">CPU:                             64</span><br><span class="line">在线 CPU 列表：                  0-63</span><br><span class="line">每个核的线程数：                 2</span><br><span class="line">每个座的核数：                   16</span><br><span class="line">座：                             2</span><br><span class="line">NUMA 节点：                      4</span><br><span class="line">厂商 ID：                        HygonGenuine</span><br><span class="line">CPU 系列：                       24</span><br><span class="line">型号：                           1</span><br><span class="line">型号名称：                       Hygon C86 5280 16-core Processor</span><br><span class="line">步进：                           1</span><br><span class="line">Frequency boost:                 enabled</span><br><span class="line">CPU MHz：                        2799.311</span><br><span class="line">CPU 最大 MHz：                   2500.0000</span><br><span class="line">CPU 最小 MHz：                   1600.0000</span><br><span class="line">BogoMIPS：                       4999.36</span><br><span class="line">虚拟化：                         AMD-V</span><br><span class="line">L1d 缓存：                       1 MiB</span><br><span class="line">L1i 缓存：                       2 MiB</span><br><span class="line">L2 缓存：                        16 MiB</span><br><span class="line">L3 缓存：                        64 MiB</span><br><span class="line">NUMA 节点0 CPU：                 0-7,32-39</span><br><span class="line">NUMA 节点1 CPU：                 8-15,40-47</span><br><span class="line">NUMA 节点2 CPU：                 16-23,48-55</span><br><span class="line">NUMA 节点3 CPU：                 24-31,56-63</span><br><span class="line">Vulnerability Itlb multihit:     Not affected</span><br><span class="line">Vulnerability L1tf:              Not affected</span><br><span class="line">Vulnerability Mds:               Not affected</span><br><span class="line">Vulnerability Meltdown:          Not affected</span><br><span class="line">Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp</span><br><span class="line">Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization</span><br><span class="line">Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, STIBP disabled, RSB</span><br><span class="line">                                 filling</span><br><span class="line">Vulnerability Srbds:             Not affected</span><br><span class="line">Vulnerability Tsx async abort:   Not affected</span><br><span class="line">标记：                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse3</span><br><span class="line">                                 6 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdts</span><br><span class="line">                                 cp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm</span><br><span class="line">                                  aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe p</span><br><span class="line">                                 opcnt xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy</span><br><span class="line">                                 abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfct</span><br><span class="line">                                 r_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate sme ssbd sev</span><br><span class="line">                                 ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt s</span><br><span class="line">                                 ha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt</span><br><span class="line">                                  lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassist</span><br><span class="line">                                 s pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov suc</span><br><span class="line">                                 cor smca</span><br></pre></td></tr></table></figure>

<h3 id="intel-8269CY"><a href="#intel-8269CY" class="headerlink" title="intel 8269CY"></a>intel 8269CY</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">Stepping:              7</span><br><span class="line">CPU MHz:               3200.000</span><br><span class="line">CPU max MHz:           3800.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              4998.89</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              36608K</span><br><span class="line">NUMA node0 CPU(s):     0-25,52-77</span><br><span class="line">NUMA node1 CPU(s):     26-51,78-103</span><br><span class="line"></span><br><span class="line">[root@numaopen.cloud.et93 /home/ren/lmbench3]</span><br><span class="line">#time for i in $(seq 0 8 51); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">0</span><br><span class="line">STREAM copy latency: 1.15 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 13941.80 MB/sec</span><br><span class="line">STREAM scale latency: 1.16 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 13799.89 MB/sec</span><br><span class="line">STREAM add latency: 1.31 nanoseconds</span><br><span class="line">STREAM add bandwidth: 18318.23 MB/sec</span><br><span class="line">STREAM triad latency: 1.56 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 15356.72 MB/sec</span><br><span class="line">16</span><br><span class="line">STREAM copy latency: 1.12 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 14293.68 MB/sec</span><br><span class="line">STREAM scale latency: 1.13 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 14162.47 MB/sec</span><br><span class="line">STREAM add latency: 1.31 nanoseconds</span><br><span class="line">STREAM add bandwidth: 18293.27 MB/sec</span><br><span class="line">STREAM triad latency: 1.53 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 15692.47 MB/sec</span><br><span class="line">32</span><br><span class="line">STREAM copy latency: 1.52 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10551.71 MB/sec</span><br><span class="line">STREAM scale latency: 1.52 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10508.33 MB/sec</span><br><span class="line">STREAM add latency: 1.38 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17363.22 MB/sec</span><br><span class="line">STREAM triad latency: 2.00 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12024.52 MB/sec</span><br><span class="line">40</span><br><span class="line">STREAM copy latency: 1.49 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10758.50 MB/sec</span><br><span class="line">STREAM scale latency: 1.50 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10680.17 MB/sec</span><br><span class="line">STREAM add latency: 1.34 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17948.34 MB/sec</span><br><span class="line">STREAM triad latency: 1.98 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12133.22 MB/sec</span><br><span class="line">48</span><br><span class="line">STREAM copy latency: 1.49 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10736.56 MB/sec</span><br><span class="line">STREAM scale latency: 1.50 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10692.93 MB/sec</span><br><span class="line">STREAM add latency: 1.34 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17902.85 MB/sec</span><br><span class="line">STREAM triad latency: 1.96 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 12239.44 MB/sec</span><br></pre></td></tr></table></figure>

<h3 id="Intel-R-Xeon-R-CPU-E5-2682-v4"><a href="#Intel-R-Xeon-R-CPU-E5-2682-v4" class="headerlink" title="Intel(R) Xeon(R) CPU E5-2682 v4"></a>Intel(R) Xeon(R) CPU E5-2682 v4</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">#time for i in $(seq 0 8 51); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">0</span><br><span class="line">STREAM copy latency: 1.59 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10092.31 MB/sec</span><br><span class="line">STREAM scale latency: 1.57 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10169.16 MB/sec</span><br><span class="line">STREAM add latency: 1.31 nanoseconds</span><br><span class="line">STREAM add bandwidth: 18360.83 MB/sec</span><br><span class="line">STREAM triad latency: 2.28 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 10503.81 MB/sec</span><br><span class="line">8</span><br><span class="line">STREAM copy latency: 1.55 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 10312.14 MB/sec</span><br><span class="line">STREAM scale latency: 1.56 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 10283.70 MB/sec</span><br><span class="line">STREAM add latency: 1.30 nanoseconds</span><br><span class="line">STREAM add bandwidth: 18416.26 MB/sec</span><br><span class="line">STREAM triad latency: 2.23 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 10777.08 MB/sec</span><br><span class="line">16</span><br><span class="line">STREAM copy latency: 2.02 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 7914.25 MB/sec</span><br><span class="line">STREAM scale latency: 2.02 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 7919.85 MB/sec</span><br><span class="line">STREAM add latency: 1.39 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17276.06 MB/sec</span><br><span class="line">STREAM triad latency: 2.92 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 8231.18 MB/sec</span><br><span class="line">24</span><br><span class="line">STREAM copy latency: 1.99 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 8032.18 MB/sec</span><br><span class="line">STREAM scale latency: 1.98 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 8061.12 MB/sec</span><br><span class="line">STREAM add latency: 1.39 nanoseconds</span><br><span class="line">STREAM add bandwidth: 17313.94 MB/sec</span><br><span class="line">STREAM triad latency: 2.88 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 8318.93 MB/sec</span><br><span class="line"></span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    16</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 79</span><br><span class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</span><br><span class="line">Stepping:              1</span><br><span class="line">CPU MHz:               2500.000</span><br><span class="line">CPU max MHz:           3000.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              5000.06</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              256K</span><br><span class="line">L3 cache:              40960K</span><br><span class="line">NUMA node0 CPU(s):     0-15,32-47</span><br><span class="line">NUMA node1 CPU(s):     16-31,48-63</span><br></pre></td></tr></table></figure>

<h3 id="AMD-EPYC-7T83"><a href="#AMD-EPYC-7T83" class="headerlink" title="AMD EPYC 7T83"></a>AMD EPYC 7T83</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br></pre></td><td class="code"><pre><span class="line">#time for i in $(seq 0 8 255); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</span><br><span class="line">0</span><br><span class="line">STREAM copy latency: 0.49 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 32561.30 MB/sec</span><br><span class="line">STREAM scale latency: 0.49 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 32620.66 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27575.20 MB/sec</span><br><span class="line">STREAM triad latency: 0.70 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 34397.15 MB/sec</span><br><span class="line">8</span><br><span class="line">STREAM copy latency: 0.52 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 30764.47 MB/sec</span><br><span class="line">STREAM scale latency: 0.53 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 30056.59 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27575.20 MB/sec</span><br><span class="line">STREAM triad latency: 0.69 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 34789.45 MB/sec</span><br><span class="line">16</span><br><span class="line">STREAM copy latency: 0.53 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 30173.15 MB/sec</span><br><span class="line">STREAM scale latency: 0.54 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 29895.91 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27496.11 MB/sec</span><br><span class="line">STREAM triad latency: 0.70 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 34128.93 MB/sec</span><br><span class="line">24</span><br><span class="line">STREAM copy latency: 0.78 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 20417.69 MB/sec</span><br><span class="line">STREAM scale latency: 0.51 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 31354.70 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27548.79 MB/sec</span><br><span class="line">STREAM triad latency: 0.69 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 34589.22 MB/sec</span><br><span class="line">32</span><br><span class="line">STREAM copy latency: 0.60 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 26862.34 MB/sec</span><br><span class="line">STREAM scale latency: 0.58 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27376.00 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27518.66 MB/sec</span><br><span class="line">STREAM triad latency: 0.78 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 30779.17 MB/sec</span><br><span class="line">40</span><br><span class="line">STREAM copy latency: 0.59 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 27230.21 MB/sec</span><br><span class="line">STREAM scale latency: 0.59 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27284.18 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27503.63 MB/sec</span><br><span class="line">STREAM triad latency: 0.77 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31242.48 MB/sec</span><br><span class="line">48</span><br><span class="line">STREAM copy latency: 0.59 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 27102.37 MB/sec</span><br><span class="line">STREAM scale latency: 0.59 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27164.08 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27503.63 MB/sec</span><br><span class="line">STREAM triad latency: 0.76 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31422.90 MB/sec</span><br><span class="line">56</span><br><span class="line">STREAM copy latency: 0.92 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 17453.54 MB/sec</span><br><span class="line">STREAM scale latency: 0.59 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27267.55 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27488.61 MB/sec</span><br><span class="line">STREAM triad latency: 0.77 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31169.92 MB/sec</span><br><span class="line">64</span><br><span class="line">STREAM copy latency: 0.88 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18231.15 MB/sec</span><br><span class="line">STREAM scale latency: 0.84 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18976.06 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26413.87 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22310.12 MB/sec</span><br><span class="line">72</span><br><span class="line">STREAM copy latency: 0.86 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18552.45 MB/sec</span><br><span class="line">STREAM scale latency: 0.84 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 19113.88 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26375.81 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22151.79 MB/sec</span><br><span class="line">80</span><br><span class="line">STREAM copy latency: 0.89 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18037.59 MB/sec</span><br><span class="line">STREAM scale latency: 0.87 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18398.59 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26142.91 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22133.53 MB/sec</span><br><span class="line">88</span><br><span class="line">STREAM copy latency: 0.93 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 17119.60 MB/sec</span><br><span class="line">STREAM scale latency: 0.94 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 17030.54 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26146.30 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22159.10 MB/sec</span><br><span class="line">96</span><br><span class="line">STREAM copy latency: 1.39 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 11512.93 MB/sec</span><br><span class="line">STREAM scale latency: 0.87 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18406.16 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 25991.03 MB/sec</span><br><span class="line">STREAM triad latency: 1.09 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22078.91 MB/sec</span><br><span class="line">104</span><br><span class="line">STREAM copy latency: 0.86 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18546.04 MB/sec</span><br><span class="line">STREAM scale latency: 1.39 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 11518.85 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26300.01 MB/sec</span><br><span class="line">STREAM triad latency: 1.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22599.38 MB/sec</span><br><span class="line">112</span><br><span class="line">STREAM copy latency: 0.88 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18253.46 MB/sec</span><br><span class="line">STREAM scale latency: 0.85 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18758.59 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26413.87 MB/sec</span><br><span class="line">STREAM triad latency: 1.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22648.95 MB/sec</span><br><span class="line">120</span><br><span class="line">STREAM copy latency: 0.86 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18607.75 MB/sec</span><br><span class="line">STREAM scale latency: 0.84 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18957.30 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26427.74 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22313.83 MB/sec</span><br><span class="line">128</span><br><span class="line">STREAM copy latency: 0.82 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 19432.13 MB/sec</span><br><span class="line">STREAM scale latency: 0.87 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18421.31 MB/sec</span><br><span class="line">STREAM add latency: 0.98 nanoseconds</span><br><span class="line">STREAM add bandwidth: 24546.03 MB/sec</span><br><span class="line">STREAM triad latency: 1.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22702.59 MB/sec</span><br><span class="line">136</span><br><span class="line">STREAM copy latency: 0.74 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 21568.01 MB/sec</span><br><span class="line">STREAM scale latency: 0.74 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 21668.99 MB/sec</span><br><span class="line">STREAM add latency: 0.90 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26697.59 MB/sec</span><br><span class="line">STREAM triad latency: 0.91 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 26320.64 MB/sec</span><br><span class="line">144</span><br><span class="line">STREAM copy latency: 0.79 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 20268.45 MB/sec</span><br><span class="line">STREAM scale latency: 0.66 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 24279.61 MB/sec</span><br><span class="line">STREAM add latency: 0.89 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26822.08 MB/sec</span><br><span class="line">STREAM triad latency: 0.84 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 28540.76 MB/sec</span><br><span class="line">152</span><br><span class="line">STREAM copy latency: 0.85 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18903.90 MB/sec</span><br><span class="line">STREAM scale latency: 0.56 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 28734.25 MB/sec</span><br><span class="line">STREAM add latency: 0.88 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27335.58 MB/sec</span><br><span class="line">STREAM triad latency: 0.75 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31911.01 MB/sec</span><br><span class="line">160</span><br><span class="line">STREAM copy latency: 0.64 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 25068.68 MB/sec</span><br><span class="line">STREAM scale latency: 0.63 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 25550.68 MB/sec</span><br><span class="line">STREAM add latency: 0.88 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27313.33 MB/sec</span><br><span class="line">STREAM triad latency: 0.82 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 29416.50 MB/sec</span><br><span class="line">168</span><br><span class="line">STREAM copy latency: 0.61 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 26232.33 MB/sec</span><br><span class="line">STREAM scale latency: 0.60 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 26717.96 MB/sec</span><br><span class="line">STREAM add latency: 0.88 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27398.82 MB/sec</span><br><span class="line">STREAM triad latency: 0.79 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 30411.86 MB/sec</span><br><span class="line">176</span><br><span class="line">STREAM copy latency: 0.58 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 27380.19 MB/sec</span><br><span class="line">STREAM scale latency: 0.58 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27740.96 MB/sec</span><br><span class="line">STREAM add latency: 0.94 nanoseconds</span><br><span class="line">STREAM add bandwidth: 25666.31 MB/sec</span><br><span class="line">STREAM triad latency: 0.77 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31150.63 MB/sec</span><br><span class="line">184</span><br><span class="line">STREAM copy latency: 0.90 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 17730.21 MB/sec</span><br><span class="line">STREAM scale latency: 0.57 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 27918.40 MB/sec</span><br><span class="line">STREAM add latency: 0.87 nanoseconds</span><br><span class="line">STREAM add bandwidth: 27458.61 MB/sec</span><br><span class="line">STREAM triad latency: 0.76 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 31457.27 MB/sec</span><br><span class="line">192</span><br><span class="line">STREAM copy latency: 0.91 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 17558.57 MB/sec</span><br><span class="line">STREAM scale latency: 0.88 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18115.49 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26031.36 MB/sec</span><br><span class="line">STREAM triad latency: 1.12 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 21443.95 MB/sec</span><br><span class="line">200</span><br><span class="line">STREAM copy latency: 1.34 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 11911.40 MB/sec</span><br><span class="line">STREAM scale latency: 0.85 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18893.26 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26306.88 MB/sec</span><br><span class="line">STREAM triad latency: 1.09 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22013.73 MB/sec</span><br><span class="line">208</span><br><span class="line">STREAM copy latency: 1.36 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 11724.12 MB/sec</span><br><span class="line">STREAM scale latency: 0.86 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18631.00 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26166.69 MB/sec</span><br><span class="line">STREAM triad latency: 1.10 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 21763.86 MB/sec</span><br><span class="line">216</span><br><span class="line">STREAM copy latency: 0.88 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18270.85 MB/sec</span><br><span class="line">STREAM scale latency: 0.85 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18848.15 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26176.90 MB/sec</span><br><span class="line">STREAM triad latency: 1.10 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 21799.20 MB/sec</span><br><span class="line">224</span><br><span class="line">STREAM copy latency: 0.89 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18047.29 MB/sec</span><br><span class="line">STREAM scale latency: 0.86 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 18677.66 MB/sec</span><br><span class="line">STREAM add latency: 0.92 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26112.39 MB/sec</span><br><span class="line">STREAM triad latency: 1.09 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 21966.89 MB/sec</span><br><span class="line">232</span><br><span class="line">STREAM copy latency: 1.35 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 11818.58 MB/sec</span><br><span class="line">STREAM scale latency: 0.82 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 19568.11 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26469.44 MB/sec</span><br><span class="line">STREAM triad latency: 1.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22702.59 MB/sec</span><br><span class="line">240</span><br><span class="line">STREAM copy latency: 0.87 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18325.74 MB/sec</span><br><span class="line">STREAM scale latency: 0.83 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 19331.37 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26455.52 MB/sec</span><br><span class="line">STREAM triad latency: 1.06 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22580.37 MB/sec</span><br><span class="line">248</span><br><span class="line">STREAM copy latency: 0.87 nanoseconds</span><br><span class="line">STREAM copy bandwidth: 18418.79 MB/sec</span><br><span class="line">STREAM scale latency: 0.84 nanoseconds</span><br><span class="line">STREAM scale bandwidth: 19019.09 MB/sec</span><br><span class="line">STREAM add latency: 0.91 nanoseconds</span><br><span class="line">STREAM add bandwidth: 26483.37 MB/sec</span><br><span class="line">STREAM triad latency: 1.08 nanoseconds</span><br><span class="line">STREAM triad bandwidth: 22148.13 MB/sec</span><br></pre></td></tr></table></figure>

<h3 id="stream对比数据"><a href="#stream对比数据" class="headerlink" title="stream对比数据"></a>stream对比数据</h3><p>总结下几个CPU用stream测试访问内存的RT以及抖动和带宽对比数据，重点关注带宽，这个测试中时延不重要</p>
<table>
<thead>
<tr>
<th></th>
<th>最小RT</th>
<th>最大RT</th>
<th>最大copy bandwidth</th>
<th>最小copy bandwidth</th>
</tr>
</thead>
<tbody><tr>
<td>申威3231(2numa node)</td>
<td>7.09</td>
<td>8.75</td>
<td>2256.59 MB&#x2F;sec</td>
<td>1827.88 MB&#x2F;sec</td>
</tr>
<tr>
<td>飞腾2500(16 numa node)</td>
<td>2.84</td>
<td>10.34</td>
<td>5638.21 MB&#x2F;sec</td>
<td>1546.68 MB&#x2F;sec</td>
</tr>
<tr>
<td>鲲鹏920(4 numa node)</td>
<td>1.84</td>
<td>3.87</td>
<td>8700.75 MB&#x2F;sec</td>
<td>4131.81 MB&#x2F;sec</td>
</tr>
<tr>
<td>海光7280(8 numa node)</td>
<td>1.38</td>
<td>2.58</td>
<td>11591.48 MB&#x2F;sec</td>
<td>6206.99 MB&#x2F;sec</td>
</tr>
<tr>
<td>海光5280(4 numa node)</td>
<td>1.22</td>
<td>2.52</td>
<td>13166.34 MB&#x2F;sec</td>
<td>6357.71 MB&#x2F;sec</td>
</tr>
<tr>
<td>Intel8269CY(2 numa node)</td>
<td>1.12</td>
<td>1.52</td>
<td>14293.68 MB&#x2F;sec</td>
<td>10551.71 MB&#x2F;sec</td>
</tr>
<tr>
<td>Intel E5-2682(2 numa node)</td>
<td>1.58</td>
<td>2.02</td>
<td>10092.31 MB&#x2F;sec</td>
<td>7914.25 MB&#x2F;sec</td>
</tr>
<tr>
<td>AMD EPYC 7T83(4 numa node)</td>
<td>0.49</td>
<td>1.39</td>
<td>32561.30 MB&#x2F;sec</td>
<td>11512.93 MB&#x2F;sec</td>
</tr>
<tr>
<td>Y</td>
<td>1.83</td>
<td>3.48</td>
<td>8764.72 MB&#x2F;sec</td>
<td>4593.25 MB&#x2F;sec</td>
</tr>
</tbody></table>
<p>从以上数据可以看出这5款CPU性能一款比一款好，飞腾2500慢的core上延时快到intel 8269的10倍了，平均延时5倍以上了。延时数据基本和单核上测试sysbench TPS一致。性能差不多就是：常数*主频&#x2F;RT</p>
<h3 id="lat-mem-rd对比数据"><a href="#lat-mem-rd对比数据" class="headerlink" title="lat_mem_rd对比数据"></a>lat_mem_rd对比数据</h3><p>用不同的node上的core 跑lat_mem_rd测试访问node0内存的RT，只取最大64M的时延，时延和node距离完全一致</p>
<table>
<thead>
<tr>
<th></th>
<th>RT变化</th>
</tr>
</thead>
<tbody><tr>
<td>飞腾2500(16 numa node)</td>
<td>core:0	  149.976<br>core:8	  168.805<br>core:16	 191.415<br>core:24	 178.283<br>core:32	 170.814<br>core:40	 185.699<br>core:48	 212.281<br>core:56	 202.479<br>core:64	 426.176<br>core:72	 444.367<br>core:80	 465.894<br>core:88	 452.245<br>core:96	 448.352<br>core:104   460.603<br>core:112   485.989<br>core:120	490.402</td>
</tr>
<tr>
<td>鲲鹏920(4 numa node)</td>
<td>core:0 117.323<br>core:24 135.337<br>core:48 197.782<br>core:72 219.416</td>
</tr>
<tr>
<td>海光7280(8 numa node)</td>
<td>numa0    106.839<br>numa1    168.583<br>numa2    163.925<br>numa3    163.690<br>numa4    289.628<br>numa5    288.632<br>numa6    236.615<br>numa7    291.880<br>分割行<br>enabled die interleaving <br>core:0 153.005<br>core:16 152.458<br>core:32 272.057<br>core:48 269.441</td>
</tr>
<tr>
<td>海光5280(4 numa node)</td>
<td>core:0   102.574<br>core:8   160.989<br>core:16  286.850<br>core:24  231.197</td>
</tr>
<tr>
<td>海光7260(1 numa node)</td>
<td>core:0  265</td>
</tr>
<tr>
<td>Intel 8269CY(2 numa node)</td>
<td>core:0        69.792<br>core:26      93.107</td>
</tr>
<tr>
<td>Intel 8163(2 NUMA node)</td>
<td>core:0        68.785<br>core:24      100.314</td>
</tr>
<tr>
<td>Intel 8163(1 NUMA node)</td>
<td>core:0         100.652<br>core:24       67.925 &#x2F;&#x2F;内存没有做交织</td>
</tr>
<tr>
<td>申威3231(2numa node)</td>
<td>core:0     215.146<br>core:32   282.443</td>
</tr>
<tr>
<td>AMD EPYC 7T83(4 numa node)</td>
<td>core:0 71.656<br>core:32 80.129<br>core:64 131.334<br>core:96 129.563</td>
</tr>
<tr>
<td>Y7（2Die，2node，1socket）</td>
<td>core:8   42.395<br>core:40   36.434<br>core:104  105.745<br>core:88  124.384<br><br>core:24   62.979<br>core:8      69.324<br>core:64  137.233<br>core:88  127.250<br><br>133ns 205ns （待测）</td>
</tr>
</tbody></table>
<p>测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(seq 0 8 127); do echo core:$i; numactl -C $i -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 64M; done &gt;lat.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure>

<p>测试结果和numactl -H 看到的node distance完全一致，芯片厂家应该就是这样测试然后把这个延迟当做距离写进去了</p>
<p>AMD EPYC 7T83(4 numa node)的时延相对抖动有点大，这和架构多个小Die合并成一块CPU有关</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#grep -E &quot;core|64.00000&quot; lat.log</span><br><span class="line">core:0</span><br><span class="line">64.00000 71.656</span><br><span class="line">core:32</span><br><span class="line">64.00000 80.129</span><br><span class="line">core:64</span><br><span class="line">64.00000 131.334</span><br><span class="line">core:88</span><br><span class="line">64.00000 136.774</span><br><span class="line">core:96</span><br><span class="line">64.00000 129.563</span><br><span class="line">core:120</span><br><span class="line">64.00000 140.151</span><br></pre></td></tr></table></figure>

<p>AMD EPYC 7T83(4 numa node)比Intel 8269时延要大，但是带宽也高很多</p>
<h4 id="bios-numa-on-x2F-off"><a href="#bios-numa-on-x2F-off" class="headerlink" title="bios numa on&#x2F;off"></a>bios numa on&#x2F;off</h4><p>NUMA 参数：</p>
<table>
<thead>
<tr>
<th></th>
<th>BIOS ON</th>
<th>BIOS OFF</th>
</tr>
</thead>
<tbody><tr>
<td>cmdline numa&#x3D;on（默认值）</td>
<td>NUMA 开启，内存在Node内做交织，就近有快慢之分</td>
<td>bios 关闭后numa后，OS层面完全不知道下层的结构，默认全局内存做交织，时延是个平均值</td>
</tr>
<tr>
<td>cmdline numa&#x3D;off</td>
<td>交织关闭，效果同上</td>
<td>同上</td>
</tr>
</tbody></table>
<p>测试在bios中开关numa，以及在OS 启动参数里设置 numa&#x3D;on&#x2F;off 这四种组合来对比内存时延的差异</p>
<p>测试CPU型号如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    24</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              33792K</span><br><span class="line">NUMA node0 CPU(s):     0-23,48-71 //bios on + cmdline on</span><br><span class="line">NUMA node1 CPU(s):     24-47,72-95</span><br><span class="line"></span><br><span class="line">#cat /proc/cmdline</span><br><span class="line">BOOT_IMAGE=/vmlinuz-3.10.0-327.x86_64  ro crashkernel=auto vconsole.font=latarcyrheb-sun16 vconsole.keymap=us biosdevname=0 console=tty0 console=ttyS0,115200 scsi_mod.scan=sync intel_idle.max_cstate=0 pci=pcie_bus_perf ipv6.disable=1 rd.driver.pre=ahci numa=on nosmt=force</span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/intel/lmbench" target="_blank" rel="noopener">测试命令</a>以及测试结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">for i in $(seq 0 24 95); do echo core:$i; numactl -C $i -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 64M; done &gt;lat.log 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">//从下面两种测试来看，bios层面 on后，不管OS 层面是否on，都不会跨node 做交织，抖动存在</span><br><span class="line">//bios on 即使在OS层面关闭numa也不跨node做内存交织，抖动存在</span><br><span class="line">#grep -E &quot;core|64.00000&quot; lat.log.biosON.cmdlineOff </span><br><span class="line">core:0 //第0号核</span><br><span class="line">64.00000 100.717 //64.0000为64MB， 100.717 是平均时延100.717ns, 即0号核访问node0 下的内存64MB的平均延时是100纳秒</span><br><span class="line">core:24</span><br><span class="line">64.00000 68.484</span><br><span class="line">core:48</span><br><span class="line">64.00000 101.070</span><br><span class="line">core:72</span><br><span class="line">64.00000 68.483</span><br><span class="line">#grep -E &quot;core|64.00000&quot; lat.log.biosON.cmdlineON</span><br><span class="line">core:0</span><br><span class="line">64.00000 67.094</span><br><span class="line">core:24</span><br><span class="line">64.00000 100.237</span><br><span class="line">core:48</span><br><span class="line">64.00000 67.614</span><br><span class="line">core:72</span><br><span class="line">64.00000 101.096</span><br><span class="line"></span><br><span class="line">//从下面两种测试来看只要bios off了内存就会跨node交织，大规模测试下latency是个平均值</span><br><span class="line">#grep -E &quot;core|64.00000&quot; lat.log.biosOff.cmdlineOff //bios off 做内存交织，latency就是平均值</span><br><span class="line">core:0</span><br><span class="line">64.00000 85.657</span><br><span class="line">core:24</span><br><span class="line">64.00000 85.741</span><br><span class="line">core:48</span><br><span class="line">64.00000 85.977</span><br><span class="line">core:72</span><br><span class="line">64.00000 86.671</span><br><span class="line"></span><br><span class="line">//bios 关闭后numa后，OS层面完全不知道下层的结构，默认一定是做交织</span><br><span class="line">#grep -E &quot;core|64.00000&quot; lat.log.biosOff.cmdlineON</span><br><span class="line">core:0</span><br><span class="line">64.00000 89.123</span><br><span class="line">core:24</span><br><span class="line">64.00000 87.137</span><br><span class="line">core:48</span><br><span class="line">64.00000 87.239</span><br><span class="line">core:72</span><br><span class="line">64.00000 87.323</span><br></pre></td></tr></table></figure>

<p>结论：在OS 启动引导参数里设置 numa&#x3D;off 完全没有必要、也不能起作用，反而设置了 numa&#x3D;off 只能是掩耳盗铃，让用户看不到numa结构</p>
<p>为什么是平均值，而不是短板效应的最慢值？</p>
<p>测试软件只能通过大规模数据的读写来测试获取一个平均值，所以当一大块内存读取时，虽然通过交织大块内存被切分到了快慢物理内存上，但是因为规模大慢的被平均掉了。</p>
<h4 id="bios-x3D-on-同时-cmdline-off时"><a href="#bios-x3D-on-同时-cmdline-off时" class="headerlink" title="bios&#x3D;on 同时 cmdline off时"></a>bios&#x3D;on 同时 cmdline off时</h4><p>再用<a href="https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html" target="_blank" rel="noopener">Intel 的 mlc 验证下</a>，这个结果有点意思，latency稳定在 145 而不是81 和 145两个值随机出现，应该是mlc默认选到了0核，对应这个测试数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//从下面两种测试来看，bios层面 on后，不管OS 层面是否on，都不会跨node 做交织，抖动存在</span><br><span class="line">//bios on 即使在OS层面关闭numa也不跨node做内存交织，抖动存在</span><br><span class="line">#grep -E &quot;core|64.00000&quot; lat.log.biosON.cmdlineOff  </span><br><span class="line">core:0</span><br><span class="line">64.00000 100.717</span><br><span class="line">core:24</span><br><span class="line">64.00000 68.484</span><br><span class="line">core:48</span><br><span class="line">64.00000 101.070</span><br><span class="line">core:72</span><br><span class="line">64.00000 68.483</span><br></pre></td></tr></table></figure>

<p>对应的mlc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#./mlc</span><br><span class="line">Intel(R) Memory Latency Checker - v3.9</span><br><span class="line">Measuring idle latencies (in ns)...</span><br><span class="line">		Numa node</span><br><span class="line">Numa node	     0</span><br><span class="line">       0	 145.8</span><br><span class="line"></span><br><span class="line">Measuring Peak Injection Memory Bandwidths for the system</span><br><span class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using traffic with the following read-write ratios</span><br><span class="line">ALL Reads        :	110598.7</span><br><span class="line">3:1 Reads-Writes :	93408.5</span><br><span class="line">2:1 Reads-Writes :	89249.5</span><br><span class="line">1:1 Reads-Writes :	64137.3</span><br><span class="line">Stream-triad like:	77310.4</span><br><span class="line"></span><br><span class="line">Measuring Memory Bandwidths between nodes within system</span><br><span class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">		Numa node</span><br><span class="line">Numa node	     0</span><br><span class="line">       0	110598.4</span><br><span class="line"></span><br><span class="line">Measuring Loaded Latencies for the system</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">Inject	Latency	Bandwidth</span><br><span class="line">Delay	(ns)	MB/sec</span><br><span class="line">==========================</span><br><span class="line"> 00000	506.00	 111483.5</span><br><span class="line"> 00002	505.74	 112576.9</span><br><span class="line"> 00008	505.87	 112644.3</span><br><span class="line"> 00015	508.96	 112643.6</span><br><span class="line"> 00050	574.36	 112701.5</span><br><span class="line"> 00100	501.32	 112775.9</span><br><span class="line"> 00200	475.47	 112839.3</span><br><span class="line"> 00300	224.52	  91560.4</span><br><span class="line"> 00400	194.54	  70515.6</span><br><span class="line"> 00500	185.13	  57233.2</span><br><span class="line"> 00700	178.71	  41591.6</span><br><span class="line"> 01000	170.46	  29524.1</span><br><span class="line"> 01300	165.43	  22933.2</span><br><span class="line"> 01700	164.33	  17702.9</span><br><span class="line"> 02500	164.14	  12206.9</span><br></pre></td></tr></table></figure>

<p>两个值都为on 时的mlc 测试结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#./mlc</span><br><span class="line">Intel(R) Memory Latency Checker - v3.9</span><br><span class="line">Measuring idle latencies (in ns)...</span><br><span class="line">		Numa node</span><br><span class="line">Numa node	     0	     1</span><br><span class="line">       0	  81.6	 145.9</span><br><span class="line">       1	 144.9	  81.2</span><br><span class="line"></span><br><span class="line">Measuring Peak Injection Memory Bandwidths for the system</span><br><span class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using traffic with the following read-write ratios</span><br><span class="line">ALL Reads        :	227204.2</span><br><span class="line">3:1 Reads-Writes :	212432.5</span><br><span class="line">2:1 Reads-Writes :	210423.3</span><br><span class="line">1:1 Reads-Writes :	196677.2</span><br><span class="line">Stream-triad like:	189691.4</span><br></pre></td></tr></table></figure>

<p>说明：mlc和 lmbench 测试结果不一样，mlc 时81和145，lmbench测试是68和100，这是两种测试方法的差异而已，但是快慢差距基本是一致的</p>
<h3 id="龙芯测试数据"><a href="#龙芯测试数据" class="headerlink" title="龙芯测试数据"></a>龙芯测试数据</h3><p>3A5000为龙芯，执行的命令为.&#x2F;lat_mem_rd 128M 4096，其中 4096 参数为跳步大小。其基本原理是，通过按 给定间隔去循环读一定大小的内存区域，测量每个读平均的时间。如果区域大小小于 L1 Cache 大 小，时间应该接近 L1 的访问延迟;如果大于 L1 小于 L2，则接近 L2 访问延迟;依此类推。图中横坐 标为访问的字节数，纵坐标为访存的拍数(cycles)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220221113929547.png" alt="image-20220221113929547"></p>
<p>基于跳步访问的 3A5000 和 Zen1、Skylake 各级延迟的比较(cycles)</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220221112527936.png" alt="image-20220221112527936"></p>
<p>下图给出了 LMbench 测试得到的访存操作的并发性，执行的命令为.&#x2F;par_mem。访存操作的并 发性是各级 Cache 和内存所支持并发访问的能力。在 LMbench 中，访存操作并发性的测试是设计一 个链表，不断地遍历访问下一个链表中的元素，链表所跳的距离和需要测量的 Cache 容量相关，在 一段时间能并发的发起对链表的追逐操作，也就是同时很多链表在遍历，如果发现这一段时间内 能同时完成 N 个链表的追逐操作，就认为访存的并发操作是 N。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220221112727377.png" alt="image-20220221112727377"></p>
<p>下图列出了三款处理器的功能部件操作延迟数据，使用的命令是.&#x2F;lat_ops。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220221112853404.png" alt="image-20220221112853404"></p>
<h4 id="龙芯stream数据"><a href="#龙芯stream数据" class="headerlink" title="龙芯stream数据"></a>龙芯stream数据</h4><p>LMbench 包含了 STREAM 带宽测试工具，可以用来测试可持续的内存访问带宽情况。图表12.25列 出了三款处理器的 STREAM 带宽数据，其中 STREAM 数组大小设置为 1 亿个元素，采用 OpenMP 版本 同时运行四个线程来测试满载带宽;相应测试平台均为 CPU 的两个内存控制器各接一根内存条， 3A5000 和 Zen1 用 DDR4 3200 内存条，Skylake 用 DDR4 2400 内存条(它最高只支持这个规格)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220221113037332.png" alt="image-20220221113037332"></p>
<p>从数据可以看到，虽然硬件上 3A5000 和 Zen1 都实现了 DDR4 3200，但 3A5000 的实测可持续带宽 还是有一定差距。用户程序看到的内存带宽不仅仅和内存的物理频率有关系，也和处理器内部的 各种访存队列、内存控制器的调度策略、预取器和内存时序参数设置等相关，需要进行更多分析 来定位具体的瓶颈点。像 STREAM 这样的软件测试工具，能够更好地反映某个子系统的综合能力， 因而被广泛采用。</p>
<h2 id="对比结论"><a href="#对比结论" class="headerlink" title="对比结论"></a>对比结论</h2><ul>
<li>AMD单核跑分数据比较好</li>
<li>MySQL 查询场景下Intel的性能好很多</li>
<li>xdb比社区版性能要好</li>
<li>MySQL8.0比5.7在多核锁竞争场景下性能要好</li>
<li>intel最好，AMD接近Intel，海光差的比较远但是又比鲲鹏好很多，飞腾最差，尤其是跨socket简直是灾难</li>
<li>麒麟OS性能也比CentOS略差一些</li>
<li>从perf指标来看 鲲鹏920的L1d命中率高于8163是因为鲲鹏L1 size大；L2命中率低于8163，同样是因为鲲鹏 L2 size小；同样L1i 鲲鹏也大于8163，但是实际跑起来L1i Miss Rate更高，这说明 ARM对 L1d 使用效率低</li>
</ul>
<p>整体来说AMD用领先了一代的工艺（7nm VS 14nm)，在MySQL查询场景中终于可以接近Intel了，但是海光、鲲鹏、飞腾还是不给力。</p>
<h2 id="附表"><a href="#附表" class="headerlink" title="附表"></a>附表</h2><p>鲲鹏920 和 8163 在 MySQL 场景下的 perf 指标对比</p>
<table>
<thead>
<tr>
<th>整体对比</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>指标</td>
<td>X86</td>
<td>ARM</td>
<td>增加幅度</td>
</tr>
<tr>
<td>IPC</td>
<td>0.4979</td>
<td>0.495</td>
<td>-0.6%</td>
</tr>
<tr>
<td>Branchs</td>
<td>237606414772</td>
<td>415979894985</td>
<td>75.1%</td>
</tr>
<tr>
<td>Branch-misses</td>
<td>8104247620</td>
<td>28983836845</td>
<td>257.6%</td>
</tr>
<tr>
<td>Branch-missed rate</td>
<td>0.034</td>
<td>0.070</td>
<td>104.3%</td>
</tr>
<tr>
<td>内存读带宽（GB&#x2F;S)</td>
<td>25.0</td>
<td>25.0</td>
<td>-0.2%</td>
</tr>
<tr>
<td>内存写带宽（GB&#x2F;S)</td>
<td>24.6</td>
<td>67.8</td>
<td>175.5%</td>
</tr>
<tr>
<td>内存读写带宽（GB&#x2F;S)</td>
<td>49.7</td>
<td>92.8</td>
<td>86.8%</td>
</tr>
<tr>
<td>UNALIGNED_ACCESS</td>
<td>1329146645</td>
<td>13686011901</td>
<td>929.7%</td>
</tr>
<tr>
<td>L1d_MISS_RATIO</td>
<td>0.06055</td>
<td>0.04281</td>
<td>-29.3%</td>
</tr>
<tr>
<td>L1d_MISS_RATE</td>
<td>0.01645</td>
<td>0.01711</td>
<td>4.0%</td>
</tr>
<tr>
<td>L2_MISS_RATIO</td>
<td>0.34824</td>
<td>0.47162</td>
<td>35.4%</td>
</tr>
<tr>
<td>L2_MISS_RATE</td>
<td>0.00577</td>
<td>0.03493</td>
<td>504.8%</td>
</tr>
<tr>
<td>L1_ITLB_MISS_RATE</td>
<td>0.0028</td>
<td>0.005</td>
<td>78.6%</td>
</tr>
<tr>
<td>L1_DTLB_MISS_RATE</td>
<td>0.0025</td>
<td>0.0102</td>
<td>308.0%</td>
</tr>
<tr>
<td>context-switchs</td>
<td>8407195</td>
<td>11614981</td>
<td>38.2%</td>
</tr>
<tr>
<td>Pagefault</td>
<td>228371</td>
<td>741189</td>
<td>224.6%</td>
</tr>
</tbody></table>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="https://blog.csdn.net/xuanjian_bjtu/article/details/107178226" target="_blank" rel="noopener">lmbench测试要考虑cache等</a> </p>
<p>comment：</p>
<p>Intel 8163 IPC是0.67，和在PostgreSQL下测得数据基本一致。Oracle可以达到更高的IPC。从8163的perf结果中，看不出来访存在总周期中的占比。可以添加几个cycle_activity.cycles_l1d_miss、cycle_activity.stalls_mem_any，看看访存耗用的周期占比。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/01/网络抓包常用命令/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/网络抓包常用命令/" itemprop="url">网络抓包常用命令</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-01T14:30:03+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tcpdump/" itemprop="url" rel="index">
                    <span itemprop="name">tcpdump</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="网络抓包常用命令"><a href="#网络抓包常用命令" class="headerlink" title="网络抓包常用命令"></a>网络抓包常用命令</h1><p>详细解析和Demo版本：<a href="https://plantegg.github.io/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line">//抓取一个子网范围</span><br><span class="line">tcpdump -i bond0 port 3001 and net 1.2.3.0/24 and host not 1.2.3.211 -nn -X</span><br><span class="line"></span><br><span class="line">//抓取 DNAT 包，tcp options 里面的 246 代表 DNAT</span><br><span class="line">tcpdump -nn –vvv -i eth0 tcp dst port 3306 and '(tcp[tcpflags] &amp; (tcp-syn) != 0) and (tcp[20] =246) '</span><br><span class="line"></span><br><span class="line">//在上面的基础上，抓取指定 vip：10.142.*.*</span><br><span class="line">tcpdump -nn –vvv -i eth0 tcp dst port 3306 and '(tcp[tcpflags] &amp; (tcp-syn) != 0) and tcp[20]=246 and tcp[24]=10 and tcp[25]=142'</span><br><span class="line"></span><br><span class="line">//抓取 DNAT 包，tcp options 里面的 252 代表 DNAT</span><br><span class="line">tcpdump -nn –vvv -i eth0 tcp dst port 3306 and '(tcp[tcpflags] &amp; (tcp-ack) != 0) and (tcp[20] =252) '</span><br><span class="line"></span><br><span class="line">//根据指定的VPC IP抓包，例如172.16.x.x</span><br><span class="line">tcpdump -nn –vvv -i eth0 tcp dst port 3306 and '(tcp[tcpflags] &amp; (tcp-ack) != 0) and (tcp[32] =172) and (tcp[33] =16)'</span><br><span class="line"></span><br><span class="line">//根据客户端IP抓包FNAT的包，例如172.16.x.x</span><br><span class="line">tcpdump -nn –vvv -i eth0 tcp dst port 3306 and '(tcp[tcpflags] &amp; (tcp-ack) != 0) and(tcp[20]=252) and (tcp[24]=172) and (tcp[25]=16)'</span><br><span class="line"></span><br><span class="line">用tcpdump抓取并保存包：</span><br><span class="line">sudo tcpdump -i eth0 port 3306 -w plantegg.cap</span><br><span class="line"></span><br><span class="line">抓到的包存储在plantegg.cap中，可以用作wireshark、tshark详细分析</span><br><span class="line">如果明确知道目的ip、端口等可以通过指定条件来明确只抓取某个连接的包</span><br><span class="line"></span><br><span class="line">只抓本机的8080端口：</span><br><span class="line">tcpdump -i eth0 '(src port 8001 and src host 11.59.10.106) or (dst port 8001 and dst host 11.59.10.106)' -nn -X</span><br><span class="line"></span><br><span class="line">//http 流量</span><br><span class="line">// -f 抓取过滤条件 tcp port 80 and host 11.59.10.106</span><br><span class="line">//-Y 展示过滤条件</span><br><span class="line">tshark -i eth0 -f '(tcp src port 8080 and src host 11.59.10.106) or (tcp dst port 8080 and dst host 11.59.10.106)' -t a  -Y " (http.request or http.response)" -T fields -e frame.number -e frame.time  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e http.request.full_uri -e http.response.code -e http.response.phrase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">抓取详细SQL语句：</span><br><span class="line">sudo tshark -i eth0 -Y "mysql.command==3" -T fields -e mysql.query</span><br><span class="line">sudo tshark -i eth0 -R mysql.query        -T fields -e mysql.query</span><br><span class="line"></span><br><span class="line">sudo tshark -i any -f 'port 8527' -s 0 -l -w - |strings</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">parse 8507/4444 as mysql protocol, default only parse 3306 as mysql.</span></span><br><span class="line">sudo tshark -i eth0 -d tcp.port==8507,mysql -T fields -e mysql.query 'port 8507'</span><br><span class="line">sudo tshark -i any -c 50 -d tcp.port==4444,mysql -Y " ((tcp.port eq 4444 )  )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query</span><br><span class="line"></span><br><span class="line">sudo tshark -i eth0 -R "ip.addr==11.163.182.137" -d tcp.port==3306, -T fields -e mysql.query 'port 3306'</span><br><span class="line">sudo tshark -i eth0 -R "tcp.srcport==62877" -d tcp.port==3001,mysql -T fields -e tcp.srcport -e mysql.query 'port 3001'</span><br><span class="line"></span><br><span class="line">//将3307端口解析成MySQL 协议分析</span><br><span class="line">tshark -i lo -d tcp.port==3307,mysql -T fields -e frame.number -e frame.time -e frame.time_delta -e tcp.srcport -e tcp.dstport -e tcp.len -e _ws.col.Info -e mysql.query</span><br><span class="line"></span><br><span class="line">如果MySQL开启了SSL，那么抓包后的内容tshark/wireshark分析不到MySQL的具体内容，可以强制关闭：connectionProperties里加上useSSL=false</span><br><span class="line"></span><br><span class="line">查看SQL具体内容</span><br><span class="line">sudo tshark -r gege_plantegg.cap -Y "mysql.query or (  tcp.stream==1)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e frame.time_delta_displayed  -e tcp.stream -e tcp.len -e mysql.query </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">按mysql查询分析响应时间</span><br><span class="line">对于rt分析，要注意一个query多个response情况（response结果多，分包了），分析这种rt的时候只看query之后的第一个response，其它连续response需要忽略掉。</span><br><span class="line"></span><br><span class="line">以上抓包结果文件可以用tshark进行详细分析</span><br><span class="line"></span><br><span class="line">分析MySQL rt，倒数第四列基本就是rt</span><br><span class="line">tshark -r gege_plantegg.pcap -Y " ((tcp.srcport eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e tcp.analysis.ack_rtt   </span><br><span class="line"></span><br><span class="line">或者排序一下</span><br><span class="line">tshark -r 213_php.cap -Y "mysql.query or (  tcp.srcport==3306)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query |sort -nk9 -nk1</span><br><span class="line"></span><br><span class="line">MySQL响应时间直方图【第八列的含义-- Time since previous frame in this TCP stream: seconds】：</span><br><span class="line">tshark -r gege_plantegg.pcap -Y "mysql.query or (tcp.srcport3306 and tcp.len&gt;60)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len | awk 'BEGIN &#123;sum0=0;sum3=0;sum10=0;sum30=0;sum50=0;sum100=0;sum300=0;sum500=0;sum1000=0;sumo=0;count=0;sum=0&#125; &#123;rt=$8; if(rt&gt;=0.000) sum=sum+rt; count=count+1; if(rt&lt;=0.000) sum0=sum0+1; else if(rt&lt;0.003) sum3=sum3+1 ; else if(rt&lt;0.01) sum10=sum10+1; else if(rt&lt;0.03) sum30=sum30+1; else if(rt&lt;0.05) sum50=sum50+1; else if(rt &lt; 0.1) sum100=sum100+1; else if(rt &lt; 0.3) sum300=sum300+1; else if(rt &lt; 0.5) sum500=sum500+1; else if(rt &lt; 1) sum1000=sum1000+1; else sum=sum+1 ;&#125; END&#123;printf "-------------\n3ms:\t%s \n10ms:\t%s \n30ms:\t%s \n50ms:\t%s \n100ms:\t%s \n300ms:\t%s \n500ms:\t%s \n1000ms:\t%s \n&gt;1s:\t %s\n-------------\navg: %.6f \n" , sum3,sum10,sum30,sum50,sum100,sum300,sum500,sum1000,sumo,sum/count;&#125;'</span><br><span class="line"></span><br><span class="line">按http response分析响应时间</span><br><span class="line">tshark -nr 213_php.cap -o tcp.calculate_timestamps:true  -Y "http.request or http.response" -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e ip.dst -e tcp.stream  -e http.request.full_uri -e http.response.code -e http.response.phrase | sort -nk6 -nk1</span><br><span class="line"></span><br><span class="line">分析rtt、丢包、deplicate等等，可以得到整体网络状态</span><br><span class="line"><span class="meta">$</span><span class="bash"> tshark -r retrans.cap -q -z io,<span class="built_in">stat</span>,1,<span class="string">"AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt"</span>,<span class="string">"COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission"</span>,<span class="string">"COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission"</span>,<span class="string">"COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack"</span>,<span class="string">"COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment"</span>,<span class="string">"MIN(tcp.window_size)tcp.window_size"</span></span></span><br><span class="line"></span><br><span class="line">===================================================================================</span><br><span class="line">| IO Statistics                                                                   |</span><br><span class="line">|                                                                                 |</span><br><span class="line">| Duration: 89.892365 secs                                                        |</span><br><span class="line">| Interval:  2 secs                                                               |</span><br><span class="line">|                                                                                 |</span><br><span class="line">| Col 1: AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt                            |</span><br><span class="line">|     2: COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission          |</span><br><span class="line">|     3: COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission |</span><br><span class="line">|     4: COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack             |</span><br><span class="line">|     5: COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment               |</span><br><span class="line">|     6: AVG(tcp.window_size)tcp.window_size                                      |</span><br><span class="line">|---------------------------------------------------------------------------------|</span><br><span class="line">|          |1         |2      |3      |4      |5      |6      |                   |</span><br><span class="line">| Interval |    AVG   | COUNT | COUNT | COUNT | COUNT |  AVG  |                   |</span><br><span class="line">|-------------------------------------------------------------|                   |</span><br><span class="line">|  0 &lt;&gt;  2 | 0.001152 |     0 |     0 |     0 |     0 |  4206 |                   |</span><br><span class="line">|  2 &lt;&gt;  4 | 0.002088 |     0 |     0 |     0 |     1 |  6931 |                   |</span><br><span class="line">|  4 &lt;&gt;  6 | 0.001512 |     0 |     0 |     0 |     0 |  7099 |                   |</span><br><span class="line">|  6 &lt;&gt;  8 | 0.002859 |     0 |     0 |     0 |     0 |  7171 |                   |</span><br><span class="line">|  8 &lt;&gt; 10 | 0.001716 |     0 |     0 |     0 |     0 |  6472 |                   |</span><br><span class="line">| 10 &lt;&gt; 12 | 0.000319 |     0 |     0 |     0 |     2 |  5575 |                   |</span><br><span class="line">| 12 &lt;&gt; 14 | 0.002030 |     0 |     0 |     0 |     0 |  6922 |                   |</span><br><span class="line">| 14 &lt;&gt; 16 | 0.003371 |     0 |     0 |     0 |     2 |  5884 |                   |</span><br><span class="line">| 16 &lt;&gt; 18 | 0.000138 |     0 |     0 |     0 |     1 |  3480 |                   |</span><br><span class="line">| 18 &lt;&gt; 20 | 0.000999 |     0 |     0 |     0 |     4 |  6665 |                   |</span><br><span class="line">| 20 &lt;&gt; 22 | 0.000682 |     0 |     0 |    41 |     2 |  5484 |                   |</span><br><span class="line">| 22 &lt;&gt; 24 | 0.002302 |     2 |     0 |    19 |     0 |  7127 |                   |</span><br><span class="line">| 24 &lt;&gt; 26 | 0.000156 |     1 |     0 |    22 |     0 |  3042 |                   |</span><br><span class="line">| 26 &lt;&gt; 28 | 0.000000 |     1 |     0 |    19 |     1 |   152 |                   |</span><br><span class="line">| 28 &lt;&gt; 30 | 0.001498 |     1 |     0 |    24 |     0 |  5615 |                   |</span><br><span class="line">| 30 &lt;&gt; 32 | 0.000235 |     0 |     0 |    44 |     0 |  1880 |                   |</span><br><span class="line">1</span><br><span class="line">===================================================================================</span><br><span class="line">2</span><br><span class="line">| IO Statistics                                                                   |</span><br><span class="line">3</span><br><span class="line">|                                                                                 |</span><br><span class="line">4</span><br><span class="line">| Duration: 89.892365 secs                                                        |</span><br><span class="line">5</span><br><span class="line">| Interval:  2 secs                                                               |</span><br><span class="line">6</span><br><span class="line">|                                                                                 |</span><br><span class="line">7</span><br><span class="line">| Col 1: AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt                            |</span><br><span class="line">8</span><br><span class="line">|     2: COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission          |</span><br><span class="line">9</span><br><span class="line">|     3: COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission |</span><br><span class="line">10</span><br><span class="line">|     4: COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack             |</span><br><span class="line">11</span><br><span class="line">|     5: COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment               |</span><br><span class="line">12</span><br><span class="line">|     6: AVG(tcp.window_size)tcp.window_size                                      |</span><br><span class="line">13</span><br><span class="line">|---------------------------------------------------------------------------------|</span><br><span class="line">14</span><br><span class="line">|          |1         |2      |3      |4      |5      |6      |                   |</span><br><span class="line">15</span><br><span class="line">| Interval |    AVG   | COUNT | COUNT | COUNT | COUNT |  AVG  |                   |</span><br><span class="line">16</span><br><span class="line">|-------------------------------------------------------------|                   |</span><br><span class="line">17</span><br><span class="line">|  0 &lt;&gt;  2 | 0.001152 |     0 |     0 |     0 |     0 |  4206 |                   |</span><br><span class="line">18</span><br><span class="line">|  2 &lt;&gt;  4 | 0.002088 |     0 |     0 |     0 |     1 |  6931 |                   |</span><br><span class="line">19</span><br><span class="line">|  4 &lt;&gt;  6 | 0.001512 |     0 |     0 |     0 |     0 |  7099 |                   |</span><br><span class="line">20</span><br><span class="line">|  6 &lt;&gt;  8 | 0.002859 |     0 |     0 |     0 |     0 |  7171 |                   |</span><br><span class="line">21</span><br><span class="line">|  8 &lt;&gt; 10 | 0.001716 |     0 |     0 |     0 |     0 |  6472 |                   |</span><br><span class="line">22</span><br><span class="line">| 10 &lt;&gt; 12 | 0.000319 |     0 |     0 |     0 |     2 |  5575 |                   |</span><br><span class="line">23</span><br><span class="line">| 12 &lt;&gt; 14 | 0.002030 |     0 |     0 |     0 |     0 |  6922 |                   |</span><br><span class="line">24</span><br><span class="line">| 14 &lt;&gt; 16 | 0.003371 |     0 |     0 |     0 |     2 |  5884 |                   |</span><br><span class="line">25</span><br><span class="line">| 16 &lt;&gt; 18 | 0.000138 |     0 |     0 |     0 |     1 |  3480 |                   |</span><br><span class="line">26</span><br><span class="line">| 18 &lt;&gt; 20 | 0.000999 |     0 |     0 |     0 |     4 |  6665 |                   |</span><br><span class="line">27</span><br><span class="line">| 20 &lt;&gt; 22 | 0.000682 |     0 |     0 |    41 |     2 |  5484 |                   |</span><br><span class="line">28</span><br><span class="line">| 22 &lt;&gt; 24 | 0.002302 |     2 |     0 |    19 |     0 |  7127 |                   |</span><br><span class="line">29</span><br><span class="line">| 24 &lt;&gt; 26 | 0.000156 |     1 |     0 |    22 |     0 |  3042 |                   |</span><br><span class="line">30</span><br><span class="line">| 26 &lt;&gt; 28 | 0.000000 |     1 |     0 |    19 |     1 |   152 |                   |</span><br><span class="line">31</span><br><span class="line">| 28 &lt;&gt; 30 | 0.001498 |     1 |     0 |    24 |     0 |  5615 |                   |</span><br><span class="line">32</span><br><span class="line">| 30 &lt;&gt; 32 | 0.000235 |     0 |     0 |    44 |     0 |  1880 |                   |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">tshark</span></span><br><span class="line">tshark -r ./mysql-compress.cap -o tcp.calculate_timestamps:true -T fields -e mysql.caps.cp -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e frame.time_delta_displayed  -e tcp.stream -e tcp.len -e mysql.query </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">用tcpdump抓取并保存包：</span></span><br><span class="line">sudo tcpdump -i eth0 port 3306 -w plantegg.cap</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">每隔3秒钟生成一个新文件，总共生成5个文件后（15秒后）终止抓包，然后包名也按时间规范好了</span></span><br><span class="line">sudo  tcpdump -t -s 0 tcp port 6379  -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 3 -W 5 -Z root</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">每隔30分钟生成一个包并压缩，保留48个抓包，也就是24小的内的包</span></span><br><span class="line">nohup sudo tcpdump -i eth0 -t -s 0 tcp and port 6379 -w 'dump_%Y-%m-%d_%H:%M:%S.pcap' -G 1800 -W 48 -Z root -z gzip &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">file size 512M  按文件大小不支持时间戳</span></span><br><span class="line">nohup sudo tcpdump -i eth0 -t -s 0 tcp and port 3306 -w "dump_size.pcap"  -C 1 -W 2 -Z root -z gzip &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">port range</span></span><br><span class="line">sudo  tcpdump -i eth0 -t -s 0 portrange 3000-3100  -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 60 -W 100 -Z root</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">subnet</span></span><br><span class="line">sudo  tcpdump -i enp44s0f0 -t -s 0 net 192.168.0.1/28 -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 60 -W 100 -Z root</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">抓取详细SQL语句, 快速确认client发过来的具体SQL内容：</span></span><br><span class="line">sudo tshark -i any -f 'port 8527' -s 0 -l -w - |strings</span><br><span class="line">sudo tshark -i eth0 -d tcp.port==3306,mysql -T fields -e mysql.query 'port 3306'</span><br><span class="line">sudo tshark -i eth0 -R "ip.addr==11.163.182.137" -d tcp.port==3306,mysql -T fields -e mysql.query 'port 3306'</span><br><span class="line">sudo tshark -i eth0 -R "tcp.srcport==62877" -d tcp.port==3001,mysql -T fields -e tcp.srcport -e mysql.query 'port 3001'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">query time</span></span><br><span class="line">sudo tshark -i eth0 -Y " ((tcp.port eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">如果MySQL开启了SSL，那么抓包后的内容tshark/wireshark分析不到MySQL的具体内容，可以强制关闭：connectionProperties里加上useSSL=<span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line">tshark -r ./manager.cap -o tcp.calculate_timestamps:true -Y " tcp.analysis.retransmission "  -T fields -e tcp.stream -e frame.number -e frame.time -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst | sort</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">MySQL响应时间直方图【第八列的含义-- Time since previous frame <span class="keyword">in</span> this TCP stream: seconds】：</span></span><br><span class="line">tshark -r gege_plantegg.pcap -Y "mysql.query or (tcp.srcport3306 and tcp.len&gt;60)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len | awk 'BEGIN &#123;sum0=0;sum3=0;sum10=0;sum30=0;sum50=0;sum100=0;sum300=0;sum500=0;sum1000=0;sumo=0;count=0;sum=0&#125; &#123;rt=$8; if(rt&gt;=0.000) sum=sum+rt; count=count+1; if(rt&lt;=0.000) sum0=sum0+1; else if(rt&lt;0.003) sum3=sum3+1 ; else if(rt&lt;0.01) sum10=sum10+1; else if(rt&lt;0.03) sum30=sum30+1; else if(rt&lt;0.05) sum50=sum50+1; else if(rt &lt; 0.1) sum100=sum100+1; else if(rt &lt; 0.3) sum300=sum300+1; else if(rt &lt; 0.5) sum500=sum500+1; else if(rt &lt; 1) sum1000=sum1000+1; else sum=sum+1 ;&#125; END&#123;printf "-------------\n3ms:\t%s \n10ms:\t%s \n30ms:\t%s \n50ms:\t%s \n100ms:\t%s \n300ms:\t%s \n500ms:\t%s \n1000ms:\t%s \n&gt;1s:\t %s\n-------------\navg: %.6f \n" , sum3,sum10,sum30,sum50,sum100,sum300,sum500,sum1000,sumo,sum/count;&#125;'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">分析MySQL rt，倒数第四列基本就是rt</span></span><br><span class="line">tshark -r gege_plantegg.pcap -Y " ((tcp.srcport eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e tcp.analysis.ack_rtt   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">或者排序一下</span></span><br><span class="line">tshark -r 213_php.cap -Y "mysql.query or (  tcp.srcport==3306)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query |sort -nk9 -nk1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">将 tls key和抓包文件合并</span></span><br><span class="line">editcap --inject-secrets tls,key.log in.pcap out.pcap</span><br><span class="line"><span class="meta">#</span><span class="bash">把包长截掉，只保留前面54，可以脱敏包内容</span></span><br><span class="line">editcap -s 54 old.pcap new.pcap</span><br></pre></td></tr></table></figure>

<p>DNAT:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/format,webp-4378791." alt="img"></p>
<p>FNAT:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/format,webp-20240823100700538" alt="img"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/01/Apple_M1_Pro和Intel_I9-12900K谁强/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/Apple_M1_Pro和Intel_I9-12900K谁强/" itemprop="url">Apple M1 Pro 和 Intel I9-12900K到底谁强</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-01T12:30:03+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Apple-M1-Pro-和-Intel-I9-12900K到底谁强"><a href="#Apple-M1-Pro-和-Intel-I9-12900K到底谁强" class="headerlink" title="Apple M1 Pro 和 Intel I9-12900K到底谁强"></a>Apple M1 Pro 和 Intel I9-12900K到底谁强</h1><p>主要比较 M1 Pro和 I9-12900K，从芯片的参数来分析他们的差异。不和M1Max、M1Ultra比是因为从成本看没有可比性，M1Max、M1Ultra应该比I9贵多了，比起来意义不大，M1Max、M1Ultra的场景不一样。结论在最后</p>
<p>网上很多拿I9-12900K和M1 Max比实际没有意义，CPU core方面M1 Max和M1 Pro是一样的（跑分结果一样），干嘛不挑个便宜的去比较！</p>
<h2 id="The-M1-Pro"><a href="#The-M1-Pro" class="headerlink" title="The M1 Pro"></a><strong>The M1 Pro</strong></h2><p>The M1 Pro takes this higher, with:</p>
<ul>
<li>33.7 billion transistors on a 240mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache，每个core 3MB，cache跟不要钱一样的堆</li>
<li>2 efficiency cores with 4MB L2 cache，每个core 2MB</li>
<li>16 GPU Cores.</li>
<li>32GB DDR5 memory at 200GB&#x2F;s.</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220402101632476-8873839.png" alt="image-20220402101632476"></p>
<p><strong>从性能来看不推荐买M1</strong>，内存还是DDR4，M1Pro以上就都是DDR5了（文后有惊喜告诉你怎么用M1的价格买到M1 Pro） </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220402104020407-8873873.png" alt="image-20220402104020407"></p>
<p>上图中PCPU就是高性能核，共8个，PCPU左边的是低频节能的2个ECPU，机器不忙的时候可以用ECPU，节能。一旦有复杂任务就可以用PCPU。至于M1 Max在狂堆 GPU, 然后M1 Ultra学习AMD把两块M1 Max封装在一起，有没有用就看你的应用场景了，比如搞程序编译、跑跑Idea用M1 Pro就够了，没必要多花几倍的钱用在GPU上，搞视频编辑、图片处理可以考虑Max、Ultra。</p>
<h3 id="The-M1-Max"><a href="#The-M1-Max" class="headerlink" title="The M1 Max"></a><strong>The M1 Max</strong></h3><p>The M1 Max provides:（相对M1 Pro主要是多堆了 16个GPU，CPU方面是一样的，大多数跑分是M1 Pro和Max几乎一样，多花钱买那16个GPU不一定值得）</p>
<ul>
<li>57 billion transistors on a 420mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>32 GPU Cores.</li>
<li>64GB DDR5 memory at 400GB&#x2F;s.</li>
</ul>
<h3 id="And-the-new-M1-Ultra"><a href="#And-the-new-M1-Ultra" class="headerlink" title="And the new M1 Ultra"></a><strong>And the new M1 Ultra</strong></h3><p>The M1 Ultra brings you:（下面的数据完全是M1 Max的2倍，实际就是封装两块M1 Max）</p>
<ul>
<li>114 billion transistors on a 840mm squared die.</li>
<li>16 performance cores, 48MB L2 Cache.</li>
<li>4 efficiency cores with 4MB L2 cache.</li>
<li>64 GPU Cores.</li>
<li>Up to 128GB DDR5 memory at 800GB&#x2F;s.</li>
</ul>
<h3 id="M1-Pro主板拆解"><a href="#M1-Pro主板拆解" class="headerlink" title="M1 Pro主板拆解"></a>M1 Pro主板拆解</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220506142049220.png" alt="image-20220506142049220"></p>
<p>上图中，红框是 M1 Pro 芯片，黄框是三星 8GB 内存（共两块），绿框是铠侠的 128GB 闪存（共两块）。</p>
<h2 id="Inel-I9-12900K"><a href="#Inel-I9-12900K" class="headerlink" title="Inel I9-12900K"></a>Inel I9-12900K</h2><p>对比下 i9-12900K，i9也有GPU只是没有说多少个，它的GPU频率在0.3到1.55GHz之间</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/400px-alder_lake_die_2.png" alt="alder lake die 2.png"></p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody><tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="noopener">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="noopener">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="noopener">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&action=edit&redlink=1" target="_blank" rel="noopener">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm²” 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>MCP</td>
<td>No (1 dies)</td>
</tr>
<tr>
<td>Cores</td>
<td>16</td>
</tr>
<tr>
<td>Threads</td>
<td>24</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1$_size" target="_blank" rel="noopener">l1$ size</a></td>
<td>0.75 MiB (768 KiB, 786,432 B, 7.324219e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.75-20MiB" target="_blank" rel="noopener">+</a> and 0.625 MiB (640 KiB, 655,360 B, 6.103516e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.625-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1d$_size" target="_blank" rel="noopener">l1d$ size</a></td>
<td>0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.25-20MiB" target="_blank" rel="noopener">+</a> and 0.375 MiB (384 KiB, 393,216 B, 3.662109e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.375-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1i$_size" target="_blank" rel="noopener">l1i$ size</a></td>
<td>0.5 MiB (512 KiB, 524,288 B, 4.882812e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.5-20MiB" target="_blank" rel="noopener">+</a> and 0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.25-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l2$_size" target="_blank" rel="noopener">l2$ size</a></td>
<td>4 MiB (4,096 KiB, 4,194,304 B, 0.00391 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/4-20MiB" target="_blank" rel="noopener">+</a> and 10 MiB (10,240 KiB, 10,485,760 B, 0.00977 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/10-20MiB" target="_blank" rel="noopener">+</a> 共14Mb</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l3$_size" target="_blank" rel="noopener">l3$ size</a></td>
<td>6 MiB (6,144 KiB, 6,291,456 B, 0.00586 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/6-20MiB" target="_blank" rel="noopener">+</a> and 24 MiB (24,576 KiB, 25,165,824 B, 0.0234 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/24-20MiB" target="_blank" rel="noopener">+</a> 共30Mb</td>
</tr>
<tr>
<td>TDP</td>
<td>125 W</td>
</tr>
</tbody></table>
<p>从下面的芯片分布图来看，绿色部分是8个高性能物理core，每个2 thread，绿色其右边的蓝色E Cores是8个低频节能core，没开超线程，所以24个threads就是2*8PCPU+8ECPU。真正打起仗来从蓝色部分的面积占比来看基本可以忽略，重点得靠绿色的PCPU。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/arch2_small.jpg" alt="img"></p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>从上面分析来看 I9-12900K和M1 Pro的比较最终回到了各自8个PCPU的较量。Intel&#x2F;X86的超线程在大部分场景下可以提升单核计算能力的1.5倍左右，所以这里就是Intel的12core打M1 Pro的，另外Intel主频也比M1 Pro要高，如果比较单core的计算能力Intel能睿频到5GHz以上，所以不考虑视频、图片、矩阵等简单计算场景，Intel的性能应该还是要强很多的。但是如果作为笔记本来说一定要考虑功耗，125W VS 45W，我的建议是买Apple（M1的软件兼容性也是个问题）。如果是当服务器工作站使用还是建议买I9. 价钱就不好比较了M1 Pro不单独卖没法估计价格。</p>
<p>I9弱在内存还是DDR4，而M1 Pro是DDR5了，另外就是M1 Pro的L2要大。当然I9也有DDR5的内存的。</p>
<p>笔记本领域M1整体来看应该优势明显，尤其是经过几年的生态发展能够把软件生态补上的话。</p>
<h2 id="购买建议"><a href="#购买建议" class="headerlink" title="购买建议"></a>购买建议</h2><p>如果想买苹果，推荐买这款：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220402103153047-8874337.png" alt="image-20220402103153047"></p>
<p>这种<a href="https://ata.alibaba-inc.com/articles/211563" target="_blank" rel="noopener">非标8核的M1（就是10核关闭了2核），便宜了2500，特别值</a>。苹果从来没有发布过8核的M1 Pro芯片，但是这款售卖的CPU号称是M1 Pro，比正常的M1 Pro少了两个CPU core和两个GPU。这点差异是不会重新设计一个新的芯片多搞一条生产线的，一般是正常的M1 Pro生产线下来检测发现坏了个别的core，扔了太浪费，于是关掉坏core当低配的M1 Pro在卖，价钱便宜了快一半了，实际性能其实差得不多。</p>
<p>如果是买Intel i9的话，从性价比上来看如果能买到i5-12600K也是非常不错的，实际就是i9关掉(坏掉)了2个PCPU和4个ECPU，价钱是i9的一半不到，PCPU少了但是Base主频反而高了，因为总核少了，发热就能控制，所以单核能跑到的频率更高一些。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image_19.jpg" alt="image 19"></p>
<p>其实I9、I7、I5都是同一条生产线、同样的工艺下制造出来的，差别在于帮I9分摊成本，比如你看看<a href="https://en.wikichip.org/wiki/intel/core_i5/i5-12600k" target="_blank" rel="noopener">i5-12600k的参数</a>和i9-12900K基本是一样的，重点在215.25 mm² 的 Die Size：</p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody><tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="noopener">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="noopener">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="noopener">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&action=edit&redlink=1" target="_blank" rel="noopener">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm² 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>Cores</td>
<td>10</td>
</tr>
<tr>
<td>Threads</td>
<td>16</td>
</tr>
</tbody></table>
<p>即使把 <a href="https://www.techpowerup.com/review/intel-core-i5-12600k-alder-lake-12th-gen/2.html" target="_blank" rel="noopener">i5-12600k拆开</a>用放大镜看也是和i9-12900K 一样的：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/arch1_small.jpg" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>笔记本建议买M1 Pro</li>
<li>M1和M1 Pro如果看重性能的话肯定要买M1 Pro了</li>
<li>M1 Pro 建议买8 core的，买到就是赚到</li>
<li>集团内M1 Pro想要轻便就选14寸的，综合考虑我还是推荐14寸的</li>
<li>I9的笔记本建议买I7、I5，平时使用性能差得不多</li>
<li>性能还是I9强，做服务器更合适</li>
</ul>
<p>最后我手里头既没有I9也没有M1，结论靠键盘 :)，买错了别找我。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://ata.alibaba-inc.com/articles/211563" target="_blank" rel="noopener">CPU的生产和概念</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/01/三个故事/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/三个故事/" itemprop="url">三个故事</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-01T12:30:03+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技巧/" itemprop="url" rel="index">
                    <span itemprop="name">技巧</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="三个故事"><a href="#三个故事" class="headerlink" title="三个故事"></a>三个故事</h1><h2 id="故事一-无招胜有招"><a href="#故事一-无招胜有招" class="headerlink" title="故事一 无招胜有招"></a>故事一 无招胜有招</h2><p>我有一个同事前是5Q(人人网的前身) 出来的，叫Z神，负责技术（所有解决不了的问题都找他），Z神从chinaren出道，跟着王兴一块创业做 5Q，5Q在学校靠鸡腿打下大片市场，最后被陈一舟的校内收购（据说被收购后5Q的好多技术都走了，最后王兴硬是呆在校内网把合约上的所有钱都拿到了）。</p>
<p>Z神让我最佩服的解决问题的能力，好多问题其实他也不一定就擅长，但是他就是有本事通过Help、Google不停地验证尝试就把一个不熟悉的问题给解决了，这是我最羡慕的能力，在后面的职业生涯中一直不停地往这个方面尝试。</p>
<h3 id="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"><a href="#应用刚启动连接到数据库的时候比较慢，但又不是慢查询" class="headerlink" title="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"></a>应用刚启动连接到数据库的时候比较慢，但又不是慢查询</h3><ol>
<li>Z神的解决办法是通过tcpdump来分析网络包，看网络包的时间戳和网络包的内容，然后找到了具体卡在了哪里。</li>
<li>如果是专业的DBA可能会通过show processlist 看具体连接在做什么，比如看到这些连接状态是 <strong>authentication</strong> 状态，然后再通过Google或者对这个状态的理解知道创建连接的时候MySQL需要反查IP、域名这里比较耗时，通过配置参数 <strong>skip-name-resolve</strong> 跳过去就好了。</li>
<li>如果是MySQL的老司机，一上来就知道连接慢的话跟 <strong>skip-name-resolve</strong> 关系最大。</li>
</ol>
<p>在我眼里这三种方式都解决了问题，最后一种最快但是纯靠积累和经验，换个问题也许就不灵了；第一种方式是最牛逼和通用的，只需要最少的知识就把问题解决了。</p>
<p>我当时跟着Z神从sudo、ls等linux命令开始学起。当然我不会轻易去打搅他问他，每次碰到问题我尽量让他在我的电脑上来操作，解决后我再自己复盘，通过history调出他的所有操作记录，看他在我的电脑上用Google搜啥了，然后一个个去学习分析他每个动作，去想他为什么搜这个关键字，复盘完还有不懂的再到他面前跟他面对面的讨论他为什么要这么做，指导他这么做的知识和逻辑又是什么。</p>
<p><strong>如果你学不会无招胜有招，那么history你总能学会吧！</strong></p>
<p>这是当时的Z神用我的工作台（方方正正的显示器可见年代很久远了）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/63683421ly1h249wsg025j218g0xcnpd-20220610210134388.jpg" alt="img"></p>
<h2 id="故事二-网络专家的机会"><a href="#故事二-网络专家的机会" class="headerlink" title="故事二 网络专家的机会"></a>故事二 网络专家的机会</h2><p>N年前我刚加入一家公司几个月，有一个客户购买了我们的产品上线后金额对不上（1类生产事故），于是经理带着我们几个技术去现场看看是什么原因，路上经理说你们不要有什么心理压力，我不懂技术但是我过去就是替你们挨骂的，我好好跪在客户那挨骂，你们好好安心解决问题。</p>
<p>问题大概就是客户有一段涉及交易的代码在事务中，但是提交到后端我们的服务上后钱对不上了，客户认为我们产品事务实现有问题。</p>
<p>到了现场客户不让下载他们代码，只能人肉趴在他们指定的机器上用眼睛看问题在哪里，看了三天自然是没找到为啥，大家非常沮丧地回来了，然后我们的产品被下线，客户直接把数据库换成了Oracle，换完后第一天没问题，我们是越发沮丧，大家都不敢提这个事情了，但是三天后一个振奋人心的消息传过来了：金额还是对不上 …… :))))))</p>
<p>于是我们再度派出技术人员帮他们看为什么（这次客户配合度高了很多），最后有个同事提了一嘴要不用 tcpdump 抓个包看看，到底应用代码有没有set autocommit&#x3D;0, 半个小时后传来喜讯用户代码发出的就是autocommit&#x3D;1,说明用户代码的事务配置没生效。</p>
<p>最后查出来配置文件中有中文注释，测试环境没有问题，但是生产环境机器不支持中文出现了乱码，中文注释后的配置文件没有被解析到，导致事务没有生效！</p>
<p>打个岔，类似问题你也可以看看这个<a href="https://zhuanlan.zhihu.com/p/532243682" target="_blank" rel="noopener">MySQL JDBC驱动8.0的bug导致事务没生效</a></p>
<p>事情还没完，当我听到这个结果后恨不得实际抽自己，tcpdump咱也会用，怎么当时就没想到呢！于是后来我天天看tcpdump、分析网络包，有段时间最开心的是在酒店看书了。一个月后写了几篇文章放在公司内网，再然后公司内部各个团队开始拿着各种问题找过来，我的case也越来越多。</p>
<p>有一次产品调用是这样的 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6  产品5是我们的，1说性能上不去，rt 是100太大，扯了两天皮，然后说5有问题，于是我到5上抓了个包，抓完包一分析，我心里有底了，明确告诉他们5的rt才2，压力还没有到5这里来，另外按照我抓包结果的rt分析，5的能力是20万，现在还不到1万，瓶颈在1-5之间，然后我上1&#x2F;2&#x2F;3&#x2F;4用 netstat 分别看下网络状态发现1-2之间网络到了瓶颈（2回包给1的时候大量的包no ack）,不要怀疑netstat真有这么强大，只是你不会看而已。如下图 2上的9108服务端口给1发回结果的时候1那边迟迟不给ack。其实这个case用好工具只是很小的一点，关键的是我能抓包分析出rt，然后从rt推断出系统的能力（别说全链路监控之类的，有时候还得拼刺刀），进而快速定位到瓶颈</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220611101850071.png" alt="image-20220611101850071"></p>
<p>现在我们的产品文档必备一份tcpdump、tshark（wireshark命令行版本）<a href="https://plantegg.github.io/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">救急命令箱</a>，有时候让客户复制粘贴执行后给我们某个结果，好多问题不再是问题了</p>
<p>这个故事的结果是我成了公司的网络“专家”</p>
<h2 id="故事三-Die是什么"><a href="#故事三-Die是什么" class="headerlink" title="故事三 Die是什么"></a>故事三 Die是什么</h2><p>2021年4月的时候，我们有个项目要在不同的硬件平台验收，那天傍晚7点正要回家的我被项目经理拽到了现场</p>
<blockquote>
<p>系统性能不达标，现场都不知道为啥</p>
</blockquote>
<p>我到现场看了下perf </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/16b271c8-5132-4273-a26a-4b35e8f92882.png" alt="img"></p>
<p>然后处理了下，IPC从0.08提升到了0.22(IPC代表性能，越大越好)，再细调下最终能到0.27，对应的业务测试QPS也是原来的4倍。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/4d4fdebb-6146-407e-881d-19170fbfd82b.png" alt="img"></p>
<p>到这里谈不上任何故事性，我也很好奇为什么有这么好的效果，不信可以看这篇《<a href="https://plantegg.github.io/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a>》。</p>
<p>接下来的几天那个项目经理特批我拿他们的环境随便测试，于是我停下手头的工作，花了一周在这个环境做了很多验证和学习，并请教了公司CPU方面特别厉害的大佬，如下图（2021年我的水平就是这样，和所有程序员对CPU的了解一样，只是知道主频、核数，会看top）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/63683421gy1h30yi296dij207e038t9b.jpg" alt="img"></p>
<p>大佬跟我说：两个Die的L3不互通。我就问了一句Die是啥意思，他回答一个晶圆。其实这时我还没有听懂，但是不好意思再问了– 这感觉你们平时都有吧，就是不在一个段位，差太远了，不好意思再问，到了该自己先去弄脏双手后再请教的时候了！</p>
<p>于是就Google各种概念、并收集各种资料和图，最后整理了一下（所以文章的连贯性其实不好），以个人笔记的形式存档下来了。</p>
<p>最后把这些笔记从多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）总结成了一系列文章。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"></p>
<p>这个故事你觉得我想说啥，辛苦帮我在评论里总结下</p>
<h2 id="其他想说的"><a href="#其他想说的" class="headerlink" title="其他想说的"></a>其他想说的</h2><p>看完故事升华一下方法论：<a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a></p>
<h2 id="如果你觉得看完对你很有帮助可以通过如下方式找到我"><a href="#如果你觉得看完对你很有帮助可以通过如下方式找到我" class="headerlink" title="如果你觉得看完对你很有帮助可以通过如下方式找到我"></a>如果你觉得看完对你很有帮助可以通过如下方式找到我</h2><p>find me on twitter: <a href="https://twitter.com/plantegg" target="_blank" rel="noopener">@plantegg</a></p>
<p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="noopener">https://t.zsxq.com/0cSFEUh2J</a></p>
<p>开了一个星球，在里面讲解一些案例、知识、学习方法，肯定没法让大家称为顶尖程序员(我自己都不是)，只是希望用我的方法、知识、经验、案例作为你的垫脚石，帮助你快速、早日成为一个基本合格的程序员。</p>
<p>争取在星球内：</p>
<ul>
<li>养成基本动手能力</li>
<li>拥有起码的分析推理能力–按我接触的程序员，大多都是没有逻辑的</li>
<li>知识上教会你几个关键的知识点</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/11/26/数据库计算向量化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/11/26/数据库计算向量化/" itemprop="url">数据库计算向量化</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-26T17:30:03+08:00">
                2021-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库计算向量化"><a href="#数据库计算向量化" class="headerlink" title="数据库计算向量化"></a>数据库计算向量化</h1><p>前面我们通过一系列的CPU原理来学习了CPU的结构，以及怎么样让CPU跑得更快，那么我们有没有很好的案例来实战让CPU跑得更快呢。接下来我们通过数据库领域的向量化计算是如何利用CPU这些特性来让CPU更快地帮我们处理数据(SQL)</p>
<p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">CPU性能和CACHE</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/08/13/AMD_Zen_CPU%E6%9E%B6%E6%9E%84/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>在做向量化之前数据库一直用的是volcano模型来处理SQL</p>
<h2 id="volcano火山模型"><a href="#volcano火山模型" class="headerlink" title="volcano火山模型"></a>volcano火山模型</h2><p>对于如下一条SQL, 数据库会将它解析成一颗树，这棵树每个节点就是一个operator(简单理解就是一个函数，进行一次计算处理)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> pv.siteId, user.nickame</span><br><span class="line"><span class="keyword">FROM</span> pv <span class="keyword">JOIN</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">ON</span> pv.siteId = user.siteId <span class="keyword">AND</span> pv.userId = user.id</span><br><span class="line"><span class="keyword">WHERE</span> pv.siteId = <span class="number">123</span>;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/relation-algebra.png" alt="Relation Algebra"></p>
<p>可以看到火山模型实现简单，只需要根据不同的计算提供一堆算子(operator)就可以了，然后根据不同的SQL只需要将operator进行组装（类似搭积木一样），就能得到一个递归调用结构（火山模型），每行数据按照这个调用逻辑经过每个operator进行嵌套处理就得到最终结果。</p>
<p>火山模型不但实现简单，框架结构性也非常好容易扩展。</p>
<p>但是火山模型效率不高: </p>
<ol>
<li>每个operator拆分必须到最小粒度，导致嵌套调用过多过深；</li>
<li>嵌套都是虚函数无法内联；</li>
<li>这个处理逻辑整体对CPU流水线不友好，CPU希望你不停地给我数据我按一个固定的逻辑(流程)来处理，而不是在不同的算子中间跳来跳去。</li>
</ol>
<h2 id="向量化加速的CPU原理"><a href="#向量化加速的CPU原理" class="headerlink" title="向量化加速的CPU原理"></a>向量化加速的CPU原理</h2><p>向量化加速的CPU原理:</p>
<ul>
<li><a href="https://topic.atatech.org/articles/210128" target="_blank" rel="noopener">内存访问比CPU计算慢两个数量级</a></li>
<li><a href="https://ata.alibaba-inc.com/articles/214221" target="_blank" rel="noopener">cpu按cache_line从内存取数据，取一个数据和取多个数据代价一样</a></li>
<li>以及数据局部性原理</li>
</ul>
<p>如下图，表示的是for循环每次跳K个int，在K小于16的时候虽然循环次数逐渐减少到原来的1&#x2F;16, 但是总时间没变，因为一直是访问的同一个cache里面的数据。 到16个之后就会产生突变（跨了cache_line），再后面32、64、128的时间减少来源于循环次数的减少，因为如论如何每次循环都需要访问内存加载数据到cache_line中. </p>
<p>Cache_line大小是64，正好16个int，也就是存取1个或者16个int的代价基本是一样的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; arr.Length; i += K) arr[i] *= 3;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image6.png" alt="running times of this loop for different step values (https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image6.png)"></p>
<p>另外 一个大家耳熟能详的案例是对一个二维数组<strong>逐行遍历</strong>和<strong>逐列遍历</strong>的时间差异，循环次数一样，但是因为二维数组按行保存，所以逐行遍历对cache line 更友好，最终按行访问效率更高:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> row = <span class="number">1024</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> col = <span class="number">512</span></span><br><span class="line"><span class="keyword">int</span> matrix[row][col];</span><br><span class="line"><span class="comment">//逐行遍历耗时0.081ms</span></span><br><span class="line"><span class="keyword">int</span> sum_row=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> _r=<span class="number">0</span>; _r&lt;row; _r++) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> _c=<span class="number">0</span>; _c&lt;col; _c++)&#123;</span><br><span class="line">        sum_row += matrix[_r][_c];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//逐列遍历耗时1.069ms</span></span><br><span class="line"><span class="keyword">int</span> sum_col=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> _c=<span class="number">0</span>; _c&lt;col; _c++) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> _r=<span class="number">0</span>; _r&lt;row; _r++)&#123;</span><br><span class="line">        sum_col += matrix[_r][_c];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>了解了以上CPU运算的原理我们再来看向量化就很简单了</p>
<h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>向量化执行的思想就是不再像火山模型一样调用一个算子一次处理一行数据，而是一次处理一批数据来均摊开销：这个开销很明显会因为一次处理一个数据没用利用好cache_line以及局部性原理，导致CPU在切换算子的时候要stall在取数据上，表现出来的结果就是IPC很低，cache miss、branch prediction失败都会增加。</p>
<p>举例来说，对于一个实现两个 int 相加的 expression，在向量化之前，其实现可能是这样的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExpressionIntAdd</span> <span class="title">extends</span> <span class="title">Expression</span> &#123;</span></span><br><span class="line">        <span class="function">Datum <span class="title">eval</span><span class="params">(Row input)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> left = input.getInt(leftIndex);</span><br><span class="line">                <span class="keyword">int</span> right = input.getInt(rightIndex);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Datum(left+right);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在向量化之后，其实现可能会变为这样：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VectorExpressionIntAdd</span> <span class="title">extends</span> <span class="title">VectorExpression</span> &#123;</span></span><br><span class="line">        <span class="keyword">int</span>[] eval(<span class="keyword">int</span>[] left, <span class="keyword">int</span>[] right) &#123;</span><br><span class="line">                <span class="keyword">int</span>[] ret = <span class="keyword">new</span> <span class="keyword">int</span>[input.length];</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; input.length; i++) &#123;</span><br><span class="line">                  <span class="comment">//利用cache局部性原理一次取多个数据和取一个代价一样</span></span><br><span class="line">                  ret[i] = <span class="keyword">new</span> Datum(left[i] + right[i]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>很明显对比向量化之前的版本，向量化之后的版本不再是每次只处理一条数据，而是每次能处理一批数据，而且这种向量化的计算模式在计算过程中也具有更好的数据局部性。</p>
<p>向量化–Vector、批量化（一次处理一批数据）。向量化核心是利用数据局部性原理，一次取一个和取一批的时延基本是同样的。volcanno模型每次都是取一个处理一个，跳转到别的算子；而向量化是取一批处理一批后再跳转。整个过程中最耗时是取数据（访问内存比CPU计算慢两个数量级）</p>
<p><strong>如果把向量化计算改成批量化处理应该就好理解多了，但是low，向量化多玄乎啊</strong></p>
<p>为了支持这种批量处理数据的需求，CPU设计厂家又搞出了SIMD这种大杀器</p>
<h3 id="SIMD-Single-Instruction-Multiple-Data，单指令多数据"><a href="#SIMD-Single-Instruction-Multiple-Data，单指令多数据" class="headerlink" title="SIMD (Single Instruction Multiple Data，单指令多数据)"></a><a href="https://plantegg.github.io/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">SIMD (Single Instruction Multiple Data，单指令多数据)</a></h3><p>SIMD指令的作用是向量化执行(Vectorized Execution)，中文通常翻译成向量化，但是这个词并不是很好，更好的翻译是数组化执行，表示一次指令操作数组中的多个数据，而不是一次处理一个数据；向量则代表有数值和方向，显然在这里的意义用数组更能准确的表达。</p>
<p>在操作SIMD指令时，一次性把多条数据从内存加载到宽寄存器中，通过一条并行指令同时完成多条数据的计算。例如一个操作32字节(256位)的指令，可以同时操作8个int类型，获得8倍的加速。同时利用SIMD减少循环次数，大大减少了循环跳转指令，也能获得加速。SIMD指令可以有0个参数、1个数组参数、2个数组参数。如果有一个数组参数，指令计算完数组中的每个元素后，分别把结果写入对应位置；如果是有两个参数，则两个参数对应的位置分别完成指定操作，写入到对应位置。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220627165706516.png" alt="image-20220627165706516"></p>
<p>如上图所示：SIMD指令同时操作A和B中4对数字，产生4个结果存放到C中</p>
<p>以如下代码为例，对4个float计算平方：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">squre</span><span class="params">( <span class="keyword">float</span>* ptr )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">float</span> f = ptr[ i ];</span><br><span class="line">      ptr[ i ] = f * f;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码转写成SIMD指令，则可以删除循环，用三条指令即可完成计算，分别是加载到寄存器，计算平方，结果写回内存:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">squre</span><span class="params">(<span class="keyword">float</span> * ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __m128 f = _mm_loadu_ps( ptr ); </span><br><span class="line">    f = _mm_mul_ps( f, f ); </span><br><span class="line">    _mm_storeu_ps( ptr, f );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>简单理解SIMD就是相对于之前一个指令(一般是一个时钟周期)操作一个数据，但现在有了SIMD就可以在一个时钟周期操作一批数据，这个批如果是64，那么性能就提升了64倍。</p>
<p>英特尔在1996年率先引入了MMX（Multi Media eXtensions）多媒体扩展指令集，也开创了<strong>SIMD</strong>（Single Instruction Multiple Data，单指令多数据）指令集之先河，即在一个周期内一个指令可以完成多个数据操作，MMX指令集的出现让当时的MMX Pentium处理器大出风头。</p>
<p><strong>SSE</strong>（Streaming SIMD Extensions，流式单指令多数据扩展）指令集是1999年英特尔在Pentium III处理器中率先推出的，并将矢量处理能力从64位扩展到了128位。</p>
<p>AVX 所代表的单指令多数据（Single Instruction Multi Data，SIMD）指令集，是近年来 CPU 提升 IPC（每时钟周期指令数）上为数不多的重要革新。随着每次数据宽度的提升，CPU 的性能都会大幅提升，但同时晶体管数量和能耗也会有相应的提升。因此在对功耗有较高要求的场景，如笔记本电脑或服务器中，CPU 运行 AVX 应用时需要降低频率从而降低功耗。</p>
<p>向量化当然也非常希望利用SIMD(跟GPU为什么挖矿比CPU快是一样的道理)</p>
<p>这里可以参考为什么这20年CPU主频基本都在2G-3G附近不再提升但是性能仍然遵循摩尔定律在提升。</p>
<h3 id="如何生成SIMD指令呢？"><a href="#如何生成SIMD指令呢？" class="headerlink" title="如何生成SIMD指令呢？"></a>如何生成SIMD指令呢？</h3><p>有几种方式：</p>
<ol>
<li>编译器自动向量化： <ul>
<li>静态编译（代码满足一定的范；编译选项 -O3 or  -mavx2 -march&#x3D;native -ftree-vectorize）</li>
<li>即时编译（JIT）</li>
</ul>
</li>
<li>可以手写SIMD指令，比如JDK17 开始提供Vector API，也就是应用Java 代码中可以通过这个API 直接调用 SIMD 指令</li>
</ol>
<h3 id="向量化的代码要求"><a href="#向量化的代码要求" class="headerlink" title="向量化的代码要求"></a>向量化的代码要求</h3><ul>
<li>循环次数可计算 </li>
<li>简单计算，不包含函数调用、switch&#x2F;if&#x2F;return 等</li>
<li>在循环在内层</li>
<li>访问连续的内存空间（才可以通过simd指令从内存加载数据到寄存器）</li>
<li>数据无依赖</li>
<li>使用数组而不是指针</li>
</ul>
<h2 id="向量化的问题"><a href="#向量化的问题" class="headerlink" title="向量化的问题"></a>向量化的问题</h2><p>向量化的前提是L3 cache够用，在L3不够用的时候，向量化的收益是负的，国内大部分文章都是为了PR而讲向量化。并发稍微高点，向量化立马就没足够的加速效果了。L2的一次miss就足够让向量化收益清零了，都轮不到 L3 Miss。</p>
<p>比如 avx512，向量化基本是用8倍的带宽，换取2-3倍的延迟，还要降频（指令复杂了）。所以 skylake 开始，intel砍了L3，加了L2。</p>
<p>大部分向量化引擎的收益是来自向量化后被迫做了列存（或者说列存做向量化更加简单，所以大家工程上会选择向量化），这天然带来了数据密度更高，不是向量化导致了性能好。</p>
<p>SIMD 的代码对流水线要求很高的，如何写出流水线层面不stall的代码很难，主要问题是大部分SIMD都不是编译器生成的，需要开发者自己去做指令的调度，但是大部分开发者并没有微架构的知识，所以这玩意很难写好。</p>
<p>SIMD 适合解决计算瓶颈的问题，而不是数据库的内存瓶颈。计算瓶颈和内存瓶颈是完全的2个概念，只是大部分时候，我们会把内存瓶颈和计算瓶颈合起来叫做 CPU 瓶颈，但是db 90%以上场景，确实是内存而不是计算瓶颈…尤其是AP领域对同一份数据多次重复运算的， 那才叫做计算瓶颈。</p>
<p>向量化的本质不是 SIMD，是内存密度，SIMD 从头到尾就是一个骗局，用来PR的。</p>
<p>向量化最成功的Case 是字符大小写转换(可惜这个场景不多)，有几十倍的性能提升，因为原来一个个字符处理，现在如果128 的SIMD 指令一次可以出来 16个 Char，性能简单理解就是能提升16倍</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">CPU性能和CACHE</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/08/13/AMD_Zen_CPU%E6%9E%B6%E6%9E%84/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/08/13/AMD_Zen_CPU架构/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/08/13/AMD_Zen_CPU架构/" itemprop="url">AMD Zen CPU 架构以及不同CPU性能大PK</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-08-13T17:30:03+08:00">
                2021-08-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="AMD-Zen-CPU-架构"><a href="#AMD-Zen-CPU-架构" class="headerlink" title="AMD Zen CPU 架构"></a>AMD Zen CPU 架构</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文先介绍AMD Zen 架构，结合前一篇文章《<a href="https://www.atatech.org/articles/211563" target="_blank" rel="noopener">CPU的生产和概念</a>》一起来看效果会更好，在<a href="https://www.atatech.org/articles/211563" target="_blank" rel="noopener">CPU的生产和概念</a>中主要是以Intel方案来介绍，CPU的生产和概念中的 多核和多个CPU方案2 就是指的AMD Zen2架构。</p>
<p>Zen1 和 Intel 还比较像，只是一个CPU会封装多个小的Die来得到多核能力，导致NUMA node比较多。</p>
<p>AMD 从Zen2开始架构有了比较大的变化，Zen2架构改动比较大，将IO从Core Die中抽离出来，形成一个专门的IO Die，这个IO Die可以用上一代的工艺实现来提升成品率降低成本。剩下的core Die 专注在core和cache的实现上，同时可以通过最新一代的工艺来提升性能。并且在一个CPU上封装一个 IO Die + 8个 core Die这样一块CPU做到像Intel一样就是一个大NUMA，但是成本低了很多，也许在云计算时代这么搞比较合适。当然会被大家笑话为胶水核（用胶水把多个Die拼在一起），性能肯定是不如一个大Die好，但是挡不住便宜啊。这估计就是大家所说的 <strong>AMD YES！</strong>吧</p>
<p>比如Core Die用7nm工艺，IO Die用14nm工艺，一块CPU封装8个Core Die+1个IO Die的话既能得到一个多核的CPU成本有非常低，参考 《CPU的生产和概念》中的良品率和成品部分。</p>
<p>介绍完AMD架构后，会拿海光7280这块CPU（实际是OEM的AMD Zen1 架构，一块芯片封装4个die）和 Intel的CPU用MySQL 来对比一下实际性能。</p>
<p>网上Intel CPU架构、技术参数等各种资料还是很丰富的，但是AMD EPYC就比较少了，所以先来学习一下EPYC的架构特点。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220331120118117.png" alt="image-20220331120118117"></p>
<h2 id="AMD-EPYC-CPU演进路线"><a href="#AMD-EPYC-CPU演进路线" class="headerlink" title="AMD EPYC CPU演进路线"></a>AMD EPYC CPU演进路线</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/amd-rome-naples-chiplets.jpg" alt="img"></p>
<p>后面会针对 第二代的 EPYC来做一个对比测试。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AMD-Packaging-to-X3D-FAD-2020.jpg" alt="AMD Accelerated Computing FAD 2020"></p>
<p> AMD EPYC CPU Families:</p>
<table>
<thead>
<tr>
<th align="left">Family Name</th>
<th align="left">AMD EPYC Naples</th>
<th align="left">AMD EPYC Rome</th>
<th align="left">AMD EPYC Milan</th>
<th align="left">AMD EPYC Genoa</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Family Branding</td>
<td align="left">EPYC 7001</td>
<td align="left">EPYC 7002</td>
<td align="left">EPYC 7003</td>
<td align="left">EPYC 7004?</td>
</tr>
<tr>
<td align="left">Family Launch</td>
<td align="left">2017</td>
<td align="left">2019</td>
<td align="left">2021</td>
<td align="left">2022</td>
</tr>
<tr>
<td align="left">CPU Architecture</td>
<td align="left">Zen 1</td>
<td align="left">Zen 2</td>
<td align="left">Zen 3</td>
<td align="left">Zen 4</td>
</tr>
<tr>
<td align="left">Process Node</td>
<td align="left">14nm GloFo</td>
<td align="left">7nm TSMC</td>
<td align="left">7nm TSMC</td>
<td align="left">5nm TSMC</td>
</tr>
<tr>
<td align="left">Platform Name</td>
<td align="left">SP3</td>
<td align="left">SP3</td>
<td align="left">SP3</td>
<td align="left">SP5</td>
</tr>
<tr>
<td align="left">Socket</td>
<td align="left">LGA 4094</td>
<td align="left">LGA 4094</td>
<td align="left">LGA 4094</td>
<td align="left">LGA 6096</td>
</tr>
<tr>
<td align="left">Max Core Count</td>
<td align="left">32</td>
<td align="left">64</td>
<td align="left">64</td>
<td align="left">96</td>
</tr>
<tr>
<td align="left">Max Thread Count</td>
<td align="left">64</td>
<td align="left">128</td>
<td align="left">128</td>
<td align="left">192</td>
</tr>
<tr>
<td align="left">Max L3 Cache</td>
<td align="left">64 MB</td>
<td align="left">256 MB</td>
<td align="left">256 MB</td>
<td align="left">384 MB?</td>
</tr>
<tr>
<td align="left">Chiplet Design</td>
<td align="left">4 CCD’s (2 CCX’s per CCD)，4 Die</td>
<td align="left">8 CCD’s (2 CCX’s per CCD) + 1 IOD ，9 Die</td>
<td align="left">8 CCD’s (1 CCX per CCD) + 1 IOD</td>
<td align="left">12 CCD’s (1 CCX per CCD) + 1 IOD</td>
</tr>
<tr>
<td align="left">Memory Support</td>
<td align="left">DDR4-2666</td>
<td align="left">DDR4-3200</td>
<td align="left">DDR4-3200</td>
<td align="left">DDR5-5200</td>
</tr>
<tr>
<td align="left">Memory Channels</td>
<td align="left">8 Channel</td>
<td align="left">8 Channel</td>
<td align="left">8 Channel</td>
<td align="left">12 Channel</td>
</tr>
<tr>
<td align="left">PCIe Gen Support</td>
<td align="left">64 Gen 3</td>
<td align="left">128 Gen 4</td>
<td align="left">128 Gen 4</td>
<td align="left">128 Gen 5</td>
</tr>
<tr>
<td align="left">TDP Range</td>
<td align="left">200W</td>
<td align="left">280W</td>
<td align="left">280W</td>
<td align="left">320W (cTDP 400W)</td>
</tr>
</tbody></table>
<p>命名规范：</p>
<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220721174306194.png" alt="image-20220721174306194" style="zoom:70%;">

<h2 id="Zen1"><a href="#Zen1" class="headerlink" title="Zen1"></a>Zen1</h2><p>hygon 5280封装后类似下图(一块CPU封装了2个Die，还有封装4个Die的，core更多更贵而已)</p>
<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210812204437220.png" alt="image-20210812204437220" style="zoom:50%;">

<p>或者4个Die封装在一起</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210813085044786.png" alt="image-20210813085044786"></p>
<h3 id="Zen1-Die"><a href="#Zen1-Die" class="headerlink" title="Zen1 Die"></a>Zen1 Die</h3><p>下面这块Die集成了两个CCX（每个CCX四个物理core), 同时还有IO接口</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/zeppelin_face_down2.png" alt="Блоки CCX"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/515px-zen-1zep.svg.png" alt="img"></p>
<p>Quad-Zeppelin Configuration, as found in <a href="https://en.wikichip.org/wiki/amd/epyc" target="_blank" rel="noopener">EPYC</a>. </p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/512px-zen-4zep.svg.png" alt="img"></p>
<h3 id="Zen-CPU-Complex-CCX"><a href="#Zen-CPU-Complex-CCX" class="headerlink" title="Zen CPU Complex(CCX)"></a>Zen CPU Complex(CCX)</h3><p>hygon 5280使用这个结构， There are 4 cores per CCX and 2 CCXs per die for 8 cores.</p>
<ul>
<li>44 mm² area</li>
<li>L3 8 MiB; 16 mm²</li>
<li>1,400,000,000 transistors</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/450px-amd_zen_ccx.png" alt="amd zen ccx.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/700px-amd_zen_ccx_2_annotated.png" alt="amd zen ccx 2"></p>
<h3 id="封装后的Zen1（4Die）"><a href="#封装后的Zen1（4Die）" class="headerlink" title="封装后的Zen1（4Die）"></a>封装后的Zen1（4Die）</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210813085044786.png" alt="image-20210813085044786"></p>
<p>4个Die的内部关系</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/800px-AMD_Naples_SoC.svg.png" alt="AMD Naples SoC.svg"></p>
<p>详实数据和结构</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AMD-EPYC-Infinity-Fabric-Topology-Mapping.webp" alt="Топология процессора"></p>
<h2 id="Zen2-Rome"><a href="#Zen2-Rome" class="headerlink" title="Zen2 Rome"></a><a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2" target="_blank" rel="noopener">Zen2 Rome</a></h2><p>Zen2开始最大的变化就是将IO从Core Die中抽离出来，形成一个专门的IO Die。封装后如下图：</p>
<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602165525641.png" alt="AMD Rome package with card" style="zoom:50%;">

<p>以上结构的CPU在2路服务器下的内部结构：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1624282522149-35de1452-3e8d-4632-a53a-b99f1ed39a21.png" alt="img"></p>
<p>跨socket的内存访问的数据流跟互联有关，如上图标示，比如从左边的CCD0到右边的CCD0的内存，大概需要经过10跳。</p>
<table>
<thead>
<tr>
<th></th>
<th>node0</th>
<th>node1</th>
<th>node2</th>
<th>node3</th>
<th>node4</th>
<th>node5</th>
<th>node6</th>
<th>node7</th>
</tr>
</thead>
<tbody><tr>
<td>node0</td>
<td>89.67</td>
<td>99.357</td>
<td>108.11</td>
<td>110.54</td>
<td>181.85</td>
<td>187.71</td>
<td>179.507</td>
<td>179.463</td>
</tr>
<tr>
<td>node1</td>
<td></td>
<td>90.983</td>
<td>111.65</td>
<td>106.11</td>
<td>188.77</td>
<td>194.7</td>
<td>188.179</td>
<td>189.512</td>
</tr>
<tr>
<td>node2</td>
<td></td>
<td></td>
<td>91.2</td>
<td>98.272</td>
<td>180.95</td>
<td>190.53</td>
<td>184.865</td>
<td>186.088</td>
</tr>
<tr>
<td>node3</td>
<td></td>
<td></td>
<td></td>
<td>89.971</td>
<td>186.81</td>
<td>193.43</td>
<td>192.459</td>
<td>192.615</td>
</tr>
<tr>
<td>node4</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>89.566</td>
<td>97.943</td>
<td>108.19</td>
<td>109.942</td>
</tr>
<tr>
<td>node5</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>90.927</td>
<td>111.123</td>
<td>108.046</td>
</tr>
<tr>
<td>node6</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>91.212</td>
<td>103.719</td>
</tr>
<tr>
<td>node7</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>89.692</td>
</tr>
</tbody></table>
<p>上面表格是3 xGMI互联的情况下，测试出来的访存时延，可以看到在某些node间访存时延会有一些的突增，不够均匀，比如node1到node 5、node2到node5；上述latency跨socket如果用默认BIOS值在280左右</p>
<p>以下表格是厂商默认值和优化值对比（用优化值能将latency从280下降到180左右）：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>可选项</th>
<th>默认值 （milan:V260 rome:V26.02）</th>
<th>优化值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>xGMI Link Width Control</td>
<td>Manual&#x2F;Auto</td>
<td>Auto</td>
<td>Manual</td>
<td></td>
</tr>
<tr>
<td>xGMI Force Link Width Control</td>
<td>Unforce&#x2F;Force</td>
<td>Unforce</td>
<td>Force</td>
<td></td>
</tr>
<tr>
<td>xGMI Force Link Width</td>
<td>0&#x2F;1&#x2F;2</td>
<td>2</td>
<td>2</td>
<td>2 &#x3D; Force xGMI link width to x16</td>
</tr>
<tr>
<td>3-link xGMI max speed</td>
<td>[00]6.4Gbps     ……   [0A]16Gbps   ……[13]25Gbps     *[FF]Auto</td>
<td>Auto</td>
<td>16Gbps</td>
<td>IEC的rome和milan都是16Gbs，其他产品要与硬件确认</td>
</tr>
</tbody></table>
<p>另外发现启用透明大页后测试内存时延能降低20%（通过perf发现没开THP的tlb miss很高）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AMD_Rome_layout-617x486.jpg" alt="AMD Rome layout"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/amd-rome-feature-chart.jpg" alt="img"></p>
<h3 id="Zen2-Core-Complex-Die"><a href="#Zen2-Core-Complex-Die" class="headerlink" title="Zen2 Core Complex Die"></a>Zen2 Core Complex Die</h3><ul>
<li>TSMC <a href="https://en.wikichip.org/wiki/N7" target="_blank" rel="noopener">7-nanometer process</a></li>
<li>13 metal layers[<a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2#cite_note-isscc2020j-zen2-1" target="_blank" rel="noopener">1</a>]</li>
<li>3,800,000,000 transistors[<a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2#cite_note-isscc2020p-chiplet-2" target="_blank" rel="noopener">2</a>]</li>
<li>Die size: 74 mm²</li>
<li>CCX size: 31.3 mm²， 4core per CCX &#x2F;&#x2F; 16M L3 perf CCX</li>
<li>2 × 16 MiB L3 cache: 2 × 16.8 mm² (estimated) &#x2F;&#x2F; 中间蓝色部分是L3 16M，一个Die封装两个CCX的情况下</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/500px-AMD_Zen_2_CCD.jpg" alt="AMD Zen 2 CCD.jpg"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/4f71c923-4601-4d98-a311-91da8996c526.png" alt="img"></p>
<p>在Zen2&#x2F;Rome架构中，一个CCD由两个CCX构成，一个CCX包含4个物理核，共享16MB的L3 cache。</p>
<h2 id="Zen3"><a href="#Zen3" class="headerlink" title="Zen3"></a>Zen3</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AMD-3D-V-Cache-Stack-Chiplet-Design-For-Next-Gen-Ryzen-Desktop-CPUs-1030x518.png" alt="img"></p>
<p>在Zen3&#x2F;Milan架构中，抛弃了两个CCX组成一个CCD的概念，一个CCD直接由8个物理核构成，共享整个Die上的32MB L3 cache。</p>
<p>再就是<strong>可以选择</strong>增加 v-cache，3D封装更大的L3 cache，如下图，一个CCD 默认是32M L3，但是 v-cache 可以增加一块 64 MB的L3进去（TSMC的SOIC封装在一起），这块 L3 Die 可以单独生产</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220923162521398.png" alt="image-20220923162521398"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/2005042726.png" alt="AMD 3D V-Cache"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1628095021605-740x594.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Milan-X4.png" alt="img"></p>
<h3 id="Milan-X芯片面积及定价策略"><a href="#Milan-X芯片面积及定价策略" class="headerlink" title="Milan-X芯片面积及定价策略"></a><strong>Milan-X芯片面积及定价策略</strong></h3><table>
<thead>
<tr>
<th></th>
<th>TDP (W)</th>
<th>Cores</th>
<th>Base Freq (GHz)</th>
<th>Max. Freq (GHz)</th>
<th>L3(MB)</th>
<th>Channels DDR</th>
<th>Max DDR Freq</th>
<th>PCIeLane</th>
</tr>
</thead>
<tbody><tr>
<td>7763</td>
<td>280</td>
<td>64</td>
<td>2.45</td>
<td>3.5</td>
<td>256</td>
<td>8</td>
<td>3200</td>
<td>x128</td>
</tr>
<tr>
<td>7773X</td>
<td>280</td>
<td>64</td>
<td>2.2</td>
<td>3.5</td>
<td>768</td>
<td>8</td>
<td>3200</td>
<td>x128</td>
</tr>
</tbody></table>
<p>比如上表中 7773X 相对 7763 封装了更大的L3，同时降低了主频来控制发热</p>
<p>下表为标品的芯片面积和售价数据，对比可以看出，扩容2倍L3的芯片整体硅面积增加了31%，售价提升了12%</p>
<table>
<thead>
<tr>
<th></th>
<th>area mm^2</th>
<th>price 1KU($)</th>
</tr>
</thead>
<tbody><tr>
<td>7763</td>
<td>IOD 416+CCD 81*8&#x3D;1064</td>
<td>7890</td>
</tr>
<tr>
<td>7773x</td>
<td>+add L3D 41*8&#x3D;1392</td>
<td>8800</td>
</tr>
</tbody></table>
<p>AMD PPOG文档中摘录的关于CPU的micro-bench相关的数据：</p>
<p>1，访存时延上， Vcache普遍有2~6ns的延迟优化；访存带宽上二者基本一致；</p>
<p>2，spec CPU上，整形跑分基本持平，vcache的容量增加部分被主频的降低抵消；浮点跑分提升10%，mem-intensive类型的HPC&#x2F;AI类应用，将得到比较明显的提升；</p>
<p>3，spec JBB上，vcache的改善明显，critical和max jOPS均得到了10%以上的提升；</p>
<table>
<thead>
<tr>
<th>Workloads</th>
<th>7763</th>
<th>7773X vcache</th>
</tr>
</thead>
<tbody><tr>
<td>NPS4 Core0 Node0 (ns)</td>
<td>85</td>
<td>83</td>
</tr>
<tr>
<td>NPS4 Core0 Node1 (ns)</td>
<td>97</td>
<td>92</td>
</tr>
<tr>
<td>NPS4 Core0 Node2 (ns)</td>
<td>106</td>
<td>100</td>
</tr>
<tr>
<td>NPS4 Core0 Node3 (ns)</td>
<td>109</td>
<td>104</td>
</tr>
<tr>
<td>STREAM Add (GBps)</td>
<td>100%</td>
<td>99.9%</td>
</tr>
<tr>
<td>STREAM Copy(GBps)</td>
<td>100%</td>
<td>99.9%</td>
</tr>
<tr>
<td>STREAM Scale(GBps)</td>
<td>100%</td>
<td>100.1%</td>
</tr>
<tr>
<td>STREAM Triad(GBps)</td>
<td>100%</td>
<td>99.8%</td>
</tr>
<tr>
<td>SPEC CPU2017 FP Rate Base</td>
<td>100%</td>
<td>109.8%</td>
</tr>
<tr>
<td>SPEC CPU2017 Int Rate Base</td>
<td>100%</td>
<td>100.9%</td>
</tr>
<tr>
<td>SPECjbb2015-MultiJVM Critical-Jops</td>
<td>100%</td>
<td>111.6%</td>
</tr>
<tr>
<td>SPECjbb2015-MultiJVM Max-jOPS</td>
<td>100%</td>
<td>116.7%</td>
</tr>
</tbody></table>
<h2 id="Zen1-VS-Zen2"><a href="#Zen1-VS-Zen2" class="headerlink" title="Zen1 VS Zen2"></a>Zen1 VS Zen2</h2><p>Here is what the Naples and Rome packages look like from the outside:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/amd-rome-epyc-zen1-zen2.jpg" alt="img"></p>
<p>numa</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210813091455662.png" alt="image-20210813091455662"></p>
<p>zen1 numa distance:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/OctalNUMA_575px.png" alt="img"></p>
<p>hygon numa distance:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># numactl -H  //Zen1 hygon 7280  2 socket enable die interleaving</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</span><br><span class="line">node 0 size: 257578 MB</span><br><span class="line">node 0 free: 115387 MB</span><br><span class="line">node 1 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127</span><br><span class="line">node 1 size: 257005 MB</span><br><span class="line">node 1 free: 221031 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  22</span><br><span class="line">  1:  22  10</span><br><span class="line">  </span><br><span class="line">  #numactl -H //Zen1 hygon 5280  2 socket disable die interleaving</span><br><span class="line">available: 4 nodes (0-3)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 32 33 34 35 36 37 38 39</span><br><span class="line">node 0 size: 128854 MB</span><br><span class="line">node 0 free: 89350 MB</span><br><span class="line">node 1 cpus: 8 9 10 11 12 13 14 15 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 129019 MB</span><br><span class="line">node 1 free: 89326 MB</span><br><span class="line">node 2 cpus: 16 17 18 19 20 21 22 23 48 49 50 51 52 53 54 55</span><br><span class="line">node 2 size: 128965 MB</span><br><span class="line">node 2 free: 86542 MB</span><br><span class="line">node 3 cpus: 24 25 26 27 28 29 30 31 56 57 58 59 60 61 62 63</span><br><span class="line">node 3 size: 129020 MB</span><br><span class="line">node 3 free: 98227 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3</span><br><span class="line">  0:  10  16  28  22</span><br><span class="line">  1:  16  10  22  28</span><br><span class="line">  2:  28  22  10  16</span><br><span class="line">  3:  22  28  16  10</span><br></pre></td></tr></table></figure>

<p>看完这些结构上的原理，让我们实际来看看AMD的性能怎么样。</p>
<h2 id="hygon-7280-PCM数据"><a href="#hygon-7280-PCM数据" class="headerlink" title="hygon 7280 PCM数据"></a>hygon 7280 PCM数据</h2><p>hygon pcm(performance counter monitor) 工具由芯片公司提供</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[root@hygon3 16:58 /root/PCM]</span><br><span class="line"><span class="meta">#</span>./pcm.x -r -topdown -i=1 -nc -ns -l2</span><br><span class="line"></span><br><span class="line"> Processor Counter Monitor  (2019-08-21 17:07:31 +0800 ID=378f2fc)</span><br><span class="line"></span><br><span class="line">Number of physical cores: 64</span><br><span class="line">Number of logical cores: 128</span><br><span class="line">Number of online logical cores: 128</span><br><span class="line">Threads (logical cores) per physical core: 2</span><br><span class="line">Num sockets: 2</span><br><span class="line">Physical cores per socket: 32</span><br><span class="line">Core PMU (perfmon) version: 3</span><br><span class="line">Number of core PMU generic (programmable) counters: 6</span><br><span class="line">Width of generic (programmable) counters: 64 bits</span><br><span class="line">Ccxs per Node: 8</span><br><span class="line">Logical cores per Ccx: 8</span><br><span class="line">Physical Cores per Ccx: 4</span><br><span class="line">Nodes per socket: 4</span><br><span class="line">Number of core PMU fixed counters: 0</span><br><span class="line">Width of fixed counters: 0 bits</span><br><span class="line">Nominal core frequency: 2000000000 Hz</span><br><span class="line">Package thermal spec power: -1 Watt; Package minimum power: -1 Watt; Package maximum power: -1 Watt;</span><br><span class="line"></span><br><span class="line"> Resetting PMU configuration</span><br><span class="line"> Zeroed PMU registers</span><br><span class="line"></span><br><span class="line">Detected Hygon C86 7280 32-core Processor  "Hygon(r) microarchitecture codename DHYANA" stepping 1</span><br><span class="line"></span><br><span class="line"> EXEC  : instructions per nominal CPU cycle</span><br><span class="line"> IPC   : instructions per CPU cycle</span><br><span class="line"> FREQ  : relation to nominal CPU frequency='unhalted clock ticks'/'invariant timer ticks' (includes Intel Turbo Boost)</span><br><span class="line"> AFREQ : relation to nominal CPU frequency while in active state (not in power-saving C state)='unhalted clock ticks'/'invariant timer ticks while in C0-state'  (includes Intel Turbo Boost)</span><br><span class="line"> L3MISS: L3 (read) cache misses</span><br><span class="line"> L3MPKI: L3 misses per kilo instructions</span><br><span class="line"> L3HIT : L3 (read) cache hit ratio (0.00-1.00)</span><br><span class="line"> L2DMISS:L2 data cache misses</span><br><span class="line"> L2DHIT :L2 data cache hit ratio (0.00-1.00)</span><br><span class="line"> L2DMPKI:number of L2 data cache misses per kilo instruction</span><br><span class="line"> L2IMISS:L2 instruction cache misses</span><br><span class="line"> L2IHIT :L2 instructoon cache hit ratio (0.00-1.00)</span><br><span class="line"> L2IMPKI:number of L2  instruction cache misses per kilo instruction</span><br><span class="line"> L2MPKI :number of both L2 instruction and data cache misses per kilo instruction</span><br><span class="line"></span><br><span class="line"> Core (SKT) |  EXEC  |   IPC  |  FREQ  |  AFREQ | L2DMISS| L2DHIT | L2DMPKI| L2IMISS| L2IHIT | L2IMPKI| L2MPKI | L3MISS | L3MPKI |  L3HIT | TEMP</span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------------------------------------------</span><br><span class="line"> TOTAL  *     1.29     1.20     1.08     1.00     12 M     0.73     0.04     10 M     0.87     0.03     0.07     19 M     0.00     0.55     N/A</span><br><span class="line"></span><br><span class="line"> Instructions retired:  336 G ; Active cycles:  281 G ; Time (TSC): 2082 Mticks ; C0 (active,non-halted) core residency: 107.90 %</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> PHYSICAL CORE IPC                 : 2.39 =&gt; corresponds to 34.14 % utilization for cores in active state</span><br><span class="line"> Instructions per nominal CPU cycle: 2.58 =&gt; corresponds to 36.84 % core utilization over time interval</span><br><span class="line">---------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Cleaning up</span><br><span class="line"> Zeroed PMU registers</span><br></pre></td></tr></table></figure>

<p>在本地启动benchmarksql压力，并将进程绑定到0-8core，然后采集到数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>./pcm.x -r -topdown -i=1 -l2</span><br><span class="line"></span><br><span class="line"> Processor Counter Monitor  (2019-08-21 17:07:31 +0800 ID=378f2fc)</span><br><span class="line"></span><br><span class="line">Number of physical cores: 64</span><br><span class="line">Number of logical cores: 128</span><br><span class="line">Number of online logical cores: 128</span><br><span class="line">Threads (logical cores) per physical core: 2</span><br><span class="line">Num sockets: 2</span><br><span class="line">Physical cores per socket: 32</span><br><span class="line">Core PMU (perfmon) version: 3</span><br><span class="line">Number of core PMU generic (programmable) counters: 6</span><br><span class="line">Width of generic (programmable) counters: 64 bits</span><br><span class="line">Ccxs per Node: 8</span><br><span class="line">Logical cores per Ccx: 8</span><br><span class="line">Physical Cores per Ccx: 4</span><br><span class="line">Nodes per socket: 4</span><br><span class="line">Number of core PMU fixed counters: 0</span><br><span class="line">Width of fixed counters: 0 bits</span><br><span class="line">Nominal core frequency: 2000000000 Hz</span><br><span class="line">Package thermal spec power: -1 Watt; Package minimum power: -1 Watt; Package maximum power: -1 Watt;</span><br><span class="line"></span><br><span class="line"> Resetting PMU configuration</span><br><span class="line"> Zeroed PMU registers</span><br><span class="line"></span><br><span class="line">Detected Hygon C86 7280 32-core Processor  "Hygon(r) microarchitecture codename DHYANA" stepping 1</span><br><span class="line"></span><br><span class="line"> EXEC  : instructions per nominal CPU cycle</span><br><span class="line"> IPC   : instructions per CPU cycle</span><br><span class="line"> FREQ  : relation to nominal CPU frequency='unhalted clock ticks'/'invariant timer ticks' (includes Intel Turbo Boost)</span><br><span class="line"> AFREQ : relation to nominal CPU frequency while in active state (not in power-saving C state)='unhalted clock ticks'/'invariant timer ticks while in C0-state'  (includes Intel Turbo Boost)</span><br><span class="line"> L3MISS: L3 (read) cache misses</span><br><span class="line"> L3MPKI: L3 misses per kilo instructions</span><br><span class="line"> L3HIT : L3 (read) cache hit ratio (0.00-1.00)</span><br><span class="line"> L2DMISS:L2 data cache misses</span><br><span class="line"> L2DHIT :L2 data cache hit ratio (0.00-1.00)</span><br><span class="line"> L2DMPKI:number of L2 data cache misses per kilo instruction</span><br><span class="line"> L2IMISS:L2 instruction cache misses</span><br><span class="line"> L2IHIT :L2 instructoon cache hit ratio (0.00-1.00)</span><br><span class="line"> L2IMPKI:number of L2  instruction cache misses per kilo instruction</span><br><span class="line"> L2MPKI :number of both L2 instruction and data cache misses per kilo instruction</span><br><span class="line"></span><br><span class="line"> Core (SKT) |  EXEC  |   IPC  |  FREQ  |  AFREQ | L2DMISS| L2DHIT | L2DMPKI| L2IMISS| L2IHIT | L2IMPKI| L2MPKI | L3MISS | L3MPKI |  L3HIT | TEMP</span><br><span class="line"></span><br><span class="line">   0    0     1.34     1.26     1.06     1.00   8901 K     0.72     3.15     15 M     0.68     5.43     8.58     71 M     4.00     0.60      N/A</span><br><span class="line">   1    0     1.42     1.33     1.06     1.00   8491 K     0.73     2.83     14 M     0.68     4.67     7.50     71 M     4.00     0.60      N/A</span><br><span class="line">   2    0     1.41     1.33     1.06     1.00   8206 K     0.74     2.75     12 M     0.72     4.25     7.00     71 M     4.00     0.60      N/A</span><br><span class="line">   3    0     1.46     1.38     1.06     1.00   7464 K     0.75     2.40     11 M     0.68     3.81     6.21     71 M     4.00     0.60      N/A</span><br><span class="line">   4    0     1.31     1.24     1.06     1.00   9118 K     0.71     3.28     15 M     0.69     5.61     8.88     70 M     4.00     0.61      N/A</span><br><span class="line">   5    0     1.41     1.33     1.06     1.00   8700 K     0.74     2.92     13 M     0.69     4.66     7.57     70 M     4.00     0.61      N/A</span><br><span class="line">   6    0     1.41     1.33     1.06     1.00   8094 K     0.74     2.79     12 M     0.70     4.40     7.18     70 M     4.00     0.61      N/A</span><br><span class="line">   7    0     1.43     1.35     1.06     1.00   7873 K     0.74     2.68     12 M     0.71     4.13     6.81     70 M     4.00     0.61      N/A</span><br><span class="line">   8    0     1.44     1.36     1.06     1.00   8544 K     0.73     2.79     14 M     0.67     4.87     7.66     20 M     1.00     0.61      N/A</span><br><span class="line">   9    0     1.24     1.16     1.06     1.00    524 K     0.51     0.21     86 K     0.94     0.03     0.24     20 M     1.00     0.61      N/A</span><br><span class="line">  10    0     1.26     1.18     1.07     1.00    379 K     0.50     0.15     60 K     0.95     0.02     0.17     20 M     1.00     0.61      N/A</span><br><span class="line">  11    0     1.24     1.16     1.07     1.00    533 K     0.50     0.20     96 K     0.94     0.04     0.24     20 M     1.00     0.61      N/A</span><br><span class="line">  12    0     1.22     1.14     1.07     1.00   1180 K     0.34     0.47     98 K     0.94     0.04     0.51   3872 K     0.12     0.46      N/A</span><br><span class="line">  13    0     1.24     1.16     1.07     1.00    409 K     0.49     0.16     64 K     0.94     0.03     0.19   3872 K     0.12     0.46      N/A</span><br><span class="line">  </span><br><span class="line">  ---------------------------------------------------------------------------------------------------------------</span><br><span class="line"> SKT    0     1.18     1.11     1.06     1.00    113 M     0.67     0.73    139 M     0.71     0.89     1.62    186 M     1.12     0.59      N/A</span><br><span class="line"> SKT    1     1.23     1.14     1.08     1.00     33 M     0.53     0.21     11 M     0.89     0.07     0.28     38 M     0.12     0.45      N/A</span><br><span class="line">---------------------------------------------------------------------------------------------------------------</span><br><span class="line"> TOTAL  *     1.21     1.13     1.07     1.00    147 M     0.65     0.46    150 M     0.74     0.47     0.93    224 M     0.62     0.57     N/A</span><br><span class="line"></span><br><span class="line"> Instructions retired:  319 G ; Active cycles:  283 G ; Time (TSC): 2108 Mticks ; C0 (active,non-halted) core residency: 107.12 %</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> PHYSICAL CORE IPC                 : 2.25 =&gt; corresponds to 32.18 % utilization for cores in active state</span><br><span class="line"> Instructions per nominal CPU cycle: 2.41 =&gt; corresponds to 34.48 % core utilization over time interval</span><br><span class="line">---------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Cleaning up</span><br><span class="line"> Zeroed PMU registers</span><br></pre></td></tr></table></figure>

<h2 id="Apple-M1"><a href="#Apple-M1" class="headerlink" title="Apple M1"></a>Apple M1</h2><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220402101632476.png" alt="M1, M1 Pro, and M1 Max chips are shown next to each other." style="zoom:50%;">

<h3 id="The-M1"><a href="#The-M1" class="headerlink" title="The M1"></a><strong>The M1</strong></h3><p>The critically-acclaimed M1 processor delivers:</p>
<ul>
<li>16 billion transistors and a 119mm squared-die size.</li>
<li>4 performance cores, 12MB L2 Cache.</li>
<li>4 efficiency cores ith 4MB L2 cache.</li>
<li>8 GPU Cores.</li>
<li>16GB DDR4x memory at 68GB&#x2F;s.</li>
</ul>
<h3 id="The-M1-Pro"><a href="#The-M1-Pro" class="headerlink" title="The M1 Pro"></a><strong>The M1 Pro</strong></h3><p>The M1 Pro takes this higher, with:</p>
<ul>
<li>33.7 billion transistors on a 240mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>16 GPU Cores.</li>
<li>32GB DDR5 memory at 200GB&#x2F;s.</li>
</ul>
<p>对比下 i9-12000，i9也有GPU只是没有说多少个，它的GPU频率在0.3到1.55GHz之间</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/400px-alder_lake_die_2.png" alt="alder lake die 2.png"></p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody><tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="noopener">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="noopener">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="noopener">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&action=edit&redlink=1" target="_blank" rel="noopener">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm²” 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>MCP</td>
<td>No (1 dies)</td>
</tr>
<tr>
<td>Cores</td>
<td>16</td>
</tr>
<tr>
<td>Threads</td>
<td>24</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1$_size" target="_blank" rel="noopener">l1$ size</a></td>
<td>0.75 MiB (768 KiB, 786,432 B, 7.324219e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.75-20MiB" target="_blank" rel="noopener">+</a> and 0.625 MiB (640 KiB, 655,360 B, 6.103516e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.625-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1d$_size" target="_blank" rel="noopener">l1d$ size</a></td>
<td>0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.25-20MiB" target="_blank" rel="noopener">+</a> and 0.375 MiB (384 KiB, 393,216 B, 3.662109e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.375-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1i$_size" target="_blank" rel="noopener">l1i$ size</a></td>
<td>0.5 MiB (512 KiB, 524,288 B, 4.882812e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.5-20MiB" target="_blank" rel="noopener">+</a> and 0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.25-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l2$_size" target="_blank" rel="noopener">l2$ size</a></td>
<td>4 MiB (4,096 KiB, 4,194,304 B, 0.00391 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/4-20MiB" target="_blank" rel="noopener">+</a> and 10 MiB (10,240 KiB, 10,485,760 B, 0.00977 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/10-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l3$_size" target="_blank" rel="noopener">l3$ size</a></td>
<td>6 MiB (6,144 KiB, 6,291,456 B, 0.00586 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/6-20MiB" target="_blank" rel="noopener">+</a> and 24 MiB (24,576 KiB, 25,165,824 B, 0.0234 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/24-20MiB" target="_blank" rel="noopener">+</a></td>
</tr>
</tbody></table>
<h3 id="The-M1-Max"><a href="#The-M1-Max" class="headerlink" title="The M1 Max"></a><strong>The M1 Max</strong></h3><p>The M1 Max provides:</p>
<ul>
<li>57 billion transistors on a 420mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>32 GPU Cores.</li>
<li>64GB DDR5 memory at 400GB&#x2F;s.</li>
</ul>
<h3 id="And-the-new-M1-Ultra"><a href="#And-the-new-M1-Ultra" class="headerlink" title="And the new M1 Ultra"></a><strong>And the new M1 Ultra</strong></h3><p>The M1 Ultra brings you:</p>
<ul>
<li>114 billion transistors on a 840mm squared die.</li>
<li>16 performance cores, 48MB L2 Cache.</li>
<li>4 efficiency cores with 4MB L2 cache.</li>
<li>64 GPU Cores.</li>
<li>Up to 128GB DDR5 memory at 800GB&#x2F;s.</li>
</ul>
<h2 id="倚天710"><a href="#倚天710" class="headerlink" title="倚天710"></a>倚天710</h2><p>一个die有64core，每两个core是一个cluster，一块cpu封装两个die</p>
<p>一个die大小是314平方毫米，600亿晶体管</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211205130348832.png" alt="image-20211205130348832"></p>
<p>平头哥的几款芯片：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/v2-4a587237e30986b36c5657761c31ae21_r.jpg" alt="preview"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>AMD和Intel在服务器领域CPU设计上走了两个不同的方向，Intel通过RingBus、Mesh等方案在一块Die上集成多个core，成本高，在多核场景下性能好。</p>
<p>AMD则是通过设计小的Die来降低成本，然后将多个Die封装到一块CPU上来售卖，Zen1架构的多个Die之间延迟高，于是Zen2将IO抽离出来用一块单独的IO Die来负责IO，这样多核之间的时延比Zen1好了很多。</p>
<p>而在云计算场景下AMD的设计非常有竞争优势，因为云计算大部分时候是要把一块大的CPU分拆售卖，从架构上AMD对分拆售卖非常友好。</p>
<p>整体来说AMD用领先了一代的工艺（7nm VS 14nm)，在MySQL查询场景中终于可以接近Intel了，但是海光、鲲鹏、飞腾还是不给力。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="https://blog.csdn.net/xuanjian_bjtu/article/details/107178226" target="_blank" rel="noopener">lmbench测试要考虑cache等</a> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/19/CPU性能和CACHE/" itemprop="url">CPU性能和CACHE</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-19T12:30:03+08:00">
                2021-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a>CPU性能和CACHE</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210802161558248.png" alt="image-20210802161558248"></p>
<h2 id="CPU中为什么要L1-x2F-L2等各级cache"><a href="#CPU中为什么要L1-x2F-L2等各级cache" class="headerlink" title="CPU中为什么要L1&#x2F;L2等各级cache"></a>CPU中为什么要L1&#x2F;L2等各级cache</h2><p>因为CPU的速度和访问内存速度差异太大，导致CPU在计算的时候90%以上的时间花在等待从内存中取数据、写数据而此时CPU处于闲置状态，也就导致了所谓的 <strong>内存墙</strong></p>
<p>cpu的速度大概50-60%每年的增长率，内存只有7%每年增长率：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/476909_1_En_15_Fig3_HTML.png" alt="A 1000× Improvement of the Processor-Memory Gap | SpringerLink"></p>
<p>CPU访问内存慢的案例参考：<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></p>
<p>在数据使用前加载到CPU内更快的缓存中，最快的一级缓存等待时间是1~3个时钟周期。限制在于对于不在缓存中的数据，还是要等待数十上百个周期——按50周期算的话，不考虑并发和指令执行时间，缓存命中率达到98%，才能发挥一半的理论性能。然而实际情况中，大部分应用都无法达到这个命中率。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211110174606037.png" alt="image-20211110174606037"></p>
<h2 id="CPU中的cache变迁历史"><a href="#CPU中的cache变迁历史" class="headerlink" title="CPU中的cache变迁历史"></a>CPU中的cache变迁历史</h2><p>80486(1989), 8K的L1 cache第一次被集成在CPU中:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/42gg2.png" alt="486 motherboard with CPU location and 2nd level cache marked"></p>
<p><strong>80686</strong>(1995) ，<a href="https://superuser.com/questions/196143/where-exactly-l1-l2-and-l3-caches-located-in-computer" target="_blank" rel="noopener">L2被放入到CPU的Package</a>上，但是是一个独立的Die，可以看到L2大小和一个Die差不多:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/eAvLK.png" alt="Picture of a pentium Pro CPU, 256KB cache model"></p>
<p>以酷睿为例，现在的CPU集成了L1&#x2F;L2&#x2F;L3等各级CACHE，<strong>CACHE面积能占到CPU的一半</strong>:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/4Z1nU.png" alt="modernCPUwithL3.png"></p>
<p>从上图可以看到L3的大小快到die的一半，L1&#x2F;L2由每个core独享，L3是所有core共享，3级CACHE总面积跟所有core差不多大了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20211110174810752.png" alt="image-20211110174810752"></p>
<p>下图是目前一个主流的Die中CACHE的构成：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/cache.architecture.png" alt="img"></p>
<p>cache对速度的影响：</p>
<ul>
<li>一个方面是物理速度，如果要更大的容量就需要更多的晶体管，除了芯片的体积会变大，更重要的是大量的晶体管会导致速度下降，因为访问速度和要访问的晶体管所在的位置成反比，也就是当信号路径变长时，通信速度会变慢。这部分是物理问题。</li>
<li>另外一个问题是，多核技术中，数据的状态需要在多个CPU中进行同步，并且，我们可以看到，cache和RAM的速度差距太大，所以，多级不同尺寸的缓存有利于提高整体的性能。</li>
</ul>
<p>cache 大小查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bugu88 cpu0]# cd /sys/devices/system/</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index0/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index1/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index2/size</span><br><span class="line">512K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index3/size</span><br><span class="line">32768K</span><br></pre></td></tr></table></figure>

<h2 id="不同型号CPU的cache、内存时延"><a href="#不同型号CPU的cache、内存时延" class="headerlink" title="不同型号CPU的cache、内存时延"></a>不同型号CPU的cache、内存时延</h2><p>测试命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl --membind=0 --cpunodebind=0 ./bin/lat_mem_rd 2000 64 //从结果看L3/memory latency不符合常识</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220304104859770.png" alt="image-20220304104859770"></p>
<p>调整测试参数，增加 -t 参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl -C 0 -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 2000M</span><br></pre></td></tr></table></figure>

<blockquote>
<p>内存基准测试命令 lat_mem_rd 的 -t 参数指定测试集以制造 TLB miss, Cache miss的压力场景，以测试 TLB miss,Cache miss对内存访问延迟的影响</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220304152056740.png" alt="image-20220304152056740"></p>
<p>从上图可以看到的一些测试结论</p>
<ul>
<li>添加 -t 后(第二组测试)，L2和L3的延时比较正常了</li>
<li>倒数第三图hygon 7280 2node VS 8node(橙色) , 可以看到8node 内存延时降低了25%</li>
<li>飞腾没开numa内存延时抖动非常大（倒数图二，灰色线），基本不可用，整体延时也比其它CPU高很多</li>
<li>hygon L3大小比较特殊，一个socket下多个Die之间没有共享</li>
<li>intel E5时延表现很优秀，intel E5 CPU开启numa后内存延时有30%以上的减少（图三）</li>
<li>鲲鹏数据比较中规中矩，接近intel</li>
<li>stride参数、-t参数对整体数据影响比较大，x86、arm不同参数下也不一样</li>
</ul>
<p>E5机器内存速度为2133 MT&#x2F;S, 8163和8269则是2666 MT&#x2F;S, 所以说E5的时延表现很优秀</p>
<h2 id="矩阵乘法案例"><a href="#矩阵乘法案例" class="headerlink" title="矩阵乘法案例"></a><a href="https://quick-bench.com/q/mmCA_YqPBiGsE8vY8POpSvYzwCo" target="_blank" rel="noopener">矩阵乘法案例</a></h2><p>不做任何处理，最直白的矩阵乘法运算，在Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz 运行情况 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#cat simple.c</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;emmintrin.h&gt;</span><br><span class="line">#define N 2000</span><br><span class="line">double res[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul1[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul2[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">#define SM (CLS / sizeof (double))</span><br><span class="line"></span><br><span class="line">//compile:gcc -o simd -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ./simd.c</span><br><span class="line">//</span><br><span class="line">int main (void)</span><br><span class="line">&#123;</span><br><span class="line">  // ... Initialize mul1 and mul2</span><br><span class="line">  int i, i2, j, j2, k, k2;</span><br><span class="line"></span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	  for (j = 0; j &lt; N; ++j)</span><br><span class="line">		  for (k = 0; k &lt; N; ++k)</span><br><span class="line">			  res[i][j] += mul1[i][k] * mul2[k][j]; //mul2[k][j]是先列后行，对cache不友好；</span><br><span class="line"></span><br><span class="line">  // ... use res matrix</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果现将矩阵转置一下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;emmintrin.h&gt;</span><br><span class="line">#define N 2000</span><br><span class="line">double res[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul1[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul2[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double tmp[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">#define SM (CLS / sizeof (double))</span><br><span class="line"></span><br><span class="line">//compile:gcc -o simd -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ./simd.c</span><br><span class="line">//</span><br><span class="line">int main (void)</span><br><span class="line">&#123;</span><br><span class="line">  // ... Initialize mul1 and mul2</span><br><span class="line">  int i, i2, j, j2, k, k2;</span><br><span class="line"></span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	    for (j = 0; j &lt; N; ++j)</span><br><span class="line">			    tmp[i][j] = mul2[j][i]; //先转置</span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	    for (j = 0; j &lt; N; ++j)</span><br><span class="line">			    for (k = 0; k &lt; N; ++k)</span><br><span class="line">					      res[i][j] += mul1[i][k] * tmp[j][k]; //转置后按行访问，对内存友好</span><br><span class="line"></span><br><span class="line">  // ... use res matrix</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">//未做任何优化，直接矩阵乘法</span><br><span class="line">#taskset -c 1 perf stat ./simple</span><br><span class="line">      47192.640339      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">                88      context-switches          #    0.002 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,392      page-faults               #    0.665 K/sec</span><br><span class="line">   117,866,224,774      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   264,254,238,724      instructions              #    2.24  insns per cycle</span><br><span class="line">     8,052,145,218      branches                  #  170.623 M/sec</span><br><span class="line">         4,573,572      branch-misses             #    0.06% of all branches</span><br><span class="line"></span><br><span class="line">      47.151498977 seconds time elapsed</span><br><span class="line">      </span><br><span class="line">//转置后都是按行取数据，但是需要额外的空间</span><br><span class="line">#taskset -c 0 perf stat ./simp2</span><br><span class="line">      30457.259168      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               137      context-switches          #    0.004 K/sec</span><br><span class="line">                 7      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            86,081      page-faults               #    0.003 M/sec</span><br><span class="line">    76,068,232,551      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   264,385,818,470      instructions              #    3.48  insns per cycle</span><br><span class="line">     8,072,001,639      branches                  #  265.027 M/sec</span><br><span class="line">         4,414,867      branch-misses             #    0.05% of all branches</span><br><span class="line"></span><br><span class="line">      30.437018792 seconds time elapsed</span><br><span class="line"></span><br><span class="line">//按cache line 运算</span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">      29767.847109      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">                41      context-switches          #    0.001 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,454      page-faults               #    0.001 M/sec</span><br><span class="line">    74,346,857,277      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   253,099,702,393      instructions              #    3.40  insns per cycle</span><br><span class="line">    11,450,804,877      branches                  #  384.670 M/sec</span><br><span class="line">        16,043,642      branch-misses             #    0.14% of all branches</span><br><span class="line"></span><br><span class="line">      29.742025067 seconds time elapsed   </span><br><span class="line"></span><br><span class="line">//使用simd指令，按理应该最快，实际效果很差 :( </span><br><span class="line">#taskset -c 1 perf stat ./simd</span><br><span class="line">     140224.550539      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               243      context-switches          #    0.002 K/sec</span><br><span class="line">                 2      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            70,569      page-faults               #    0.503 K/sec</span><br><span class="line">   350,218,614,852      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   717,191,577,191      instructions              #    2.05  insns per cycle</span><br><span class="line">    25,161,922,136      branches                  #  179.440 M/sec</span><br><span class="line">        54,411,349      branch-misses             #    0.22% of all branches</span><br><span class="line"></span><br><span class="line">     140.101635085 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>On ARM Kunpeng 920-4826:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#taskset -c 1 perf stat ./simple</span><br><span class="line">        150,242.52 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               943      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.208 K/sec</span><br><span class="line">   390,626,613,178      cycles                    #    2.600 GHz</span><br><span class="line">   432,396,482,134      instructions              #    1.11  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">        11,348,599      branch-misses</span><br><span class="line"></span><br><span class="line">     150.249408485 seconds time elapsed</span><br><span class="line">     </span><br><span class="line">#taskset -c 1 perf stat ./simp2</span><br><span class="line">         69,008.66 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               426      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            39,104      page-faults               #    0.567 K/sec</span><br><span class="line">   179,417,225,187      cycles                    #    2.600 GHz</span><br><span class="line">   432,409,078,894      instructions              #    2.41  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">        11,122,131      branch-misses</span><br><span class="line"></span><br><span class="line">      69.014491453 seconds time elapsed     </span><br><span class="line">      </span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">			   50,251.34 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               315      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.623 K/sec</span><br><span class="line">   130,652,187,736      cycles                    #    2.600 GHz</span><br><span class="line">   291,261,746,765      instructions              #    2.23  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">       160,585,583      branch-misses</span><br><span class="line"></span><br><span class="line">      50.254025852 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>如果在aarch编译开启gcc -O3 优化选项：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">//aarch gcc -O3 on</span><br><span class="line">#taskset -c 1 perf stat ./simple //开O3后 优化器走了simd指令</span><br><span class="line">         67,897.93 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               414      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.461 K/sec</span><br><span class="line">   176,532,812,062      cycles                    #    2.600 GHz</span><br><span class="line">    28,214,139,367      instructions              #    0.16  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         3,250,598      branch-misses</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">#perf stat ./s2 //s2代码直接按行访问mul2,不考虑结果对错，运算量一样，相当于整体转置</span><br><span class="line">         15,963.30 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">                20      context-switches          #    0.001 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,288      page-faults               #    0.002 M/sec</span><br><span class="line">    41,504,239,031      cycles                    #    2.600 GHz</span><br><span class="line">    56,108,176,644      instructions              #    1.35  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         4,586,197      branch-misses</span><br><span class="line">     </span><br><span class="line">      </span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">          5,695.85 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">                35      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.005 M/sec</span><br><span class="line">    14,808,977,314      cycles                    #    2.600 GHz</span><br><span class="line">    24,281,358,553      instructions              #    1.64  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         2,006,221      branch-misses</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line">s3.c反编译后的汇编：</span><br><span class="line">  bc:	913a0060 	add	x0, x3, #0xe80</span><br><span class="line">  c0:	eb04001f 	cmp	x0, x4</span><br><span class="line">  c4:	1f584010 	fmadd	d16, d0, d24, d16</span><br><span class="line">  c8:	1f571c07 	fmadd	d7, d0, d23, d7 //参数 d7-精度，d0 </span><br><span class="line">  cc:	1f561806 	fmadd	d6, d0, d22, d6</span><br><span class="line">  d0:	1f551405 	fmadd	d5, d0, d21, d5</span><br><span class="line">  d4:	1f541004 	fmadd	d4, d0, d20, d4</span><br><span class="line">  d8:	1f530c03 	fmadd	d3, d0, d19, d3</span><br><span class="line">  dc:	1f520802 	fmadd	d2, d0, d18, d2</span><br><span class="line">  e0:	1f510401 	fmadd	d1, d0, d17, d1</span><br><span class="line">  e4:	54fffd81 	b.ne	94 &lt;main+0x94&gt;</span><br><span class="line">  e8:	91400c22 	add	x2, x1, #0x3, lsl #12</span><br><span class="line">  ec:	fd000030 	str	d16, [x1]</span><br></pre></td></tr></table></figure>

<p><a href="https://developer.arm.com/documentation/ddi0596/2021-12/SIMD-FP-Instructions/FMADD--Floating-point-fused-Multiply-Add--scalar--" target="_blank" rel="noopener">FMADD指令</a></p>
<blockquote>
<p>Floating-point fused Multiply-Add (scalar). This instruction multiplies the values of the first two SIMD&amp;FP source registers, adds the product to the value of the third SIMD&amp;FP source register, and writes the result to the SIMD&amp;FP destination register.</p>
</blockquote>
<p>一些对比解释：</p>
<blockquote>
<p>编译优化选项设置-O2 级别及以上时，Kunpeng 处理器将对连续的浮点数乘法、加法融 合为乘加运算，以提升性能和精度。在-O2 级以上编译选项，x86 处理器不会将乘法和 加法做融合乘加运算，因此两种处理器在连续的浮点数乘法、加法运算后，小数点后 16 位存在差异。</p>
</blockquote>
<h2 id="cache对CPU性能的影响"><a href="#cache对CPU性能的影响" class="headerlink" title="cache对CPU性能的影响"></a>cache对CPU性能的影响</h2><p>CPU访问内存是非常慢的，所以我们在CPU中增加了多级缓存来<strong>匹配</strong>CPU和内存的速度。主频这20年基本都没怎么做高了，但是工艺提升了两个数量级，也就是集成的晶体管数量提升了2个数量级，工艺提升的能力主要给了cache，从而整体CPU性能提升了很多。</p>
<h3 id="缓存对Oceanbase-，MySQL-ODPS的性能影响"><a href="#缓存对Oceanbase-，MySQL-ODPS的性能影响" class="headerlink" title="缓存对Oceanbase ，MySQL, ODPS的性能影响"></a>缓存对Oceanbase ，MySQL, ODPS的性能影响</h3><p>以下测试数据主要来源于真实的业务场景：OB&#x2F;MySQL&#x2F;ODPS</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/bb29ac99-3645-4482-8473-c55b190af777.png" alt="img"></p>
<p>x86 Skylake之前，L1 I&#x2F;D 32KB, L2 256KB, L3 2.5MB&#x2F;core， 2.5MB&#x2F;core的L3（LLC）芯片面积相当于1&#x2F;2 CPU core 的尺寸</p>
<ol>
<li>关闭L3（2.5MB），关闭L2（256KB），此时性能CPI（越小越好）是4.25</li>
<li>关闭L3，打开L2（256KB），此时性能CPI为2.23</li>
<li>关闭L3，打开L2同时增加256KB，L2尺寸到512KB，性能CPI为1.38</li>
<li>打开L3（2.5MB），打开L2（256KB），性能为1.28 ，该状态就是intel CPU出厂的状态</li>
<li>打开L3，增加到16MB，打开L2（256KB），性能为1.25</li>
</ol>
<p>上面的数据显示当L3关闭之后，从case 3 开始，L2仅仅增加256KB，L2芯片面积相对于CPU core 增加 5%(0.5 &#x2F;2.5M * 025M)，性能相对于case 2 提升1.61倍（2.23&#x2F;1.38），而使用case 4 ,L3 2.5MB打开，相对于case 3，增加2.3MB（2.5MB - 256KB）,芯片面积相对于CPU core 增加 46%（0.5&#x2F;2.5M * 2.3M）， 而性能仅仅提升 1.07倍（1.38&#x2F;1.28），所以14年给Intel提议需要增加L2尺寸降低L3尺寸，这些数据促使Intel开始重新考虑对于数据中心缓存新的设计。</p>
<p>2014年的 Broadwell 的第五代智能酷睿处理器，是 Haswell 的 14nm 升级版（$1745.00 - $1749.00）：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210719102039296.png" alt="image-20210719102039296"></p>
<p>E5一个Die有16个物理core（上面截图是两个Socket, 每个Socket一个Die，每个物理core两个超线程），所以每core的L3大小：40M&#x2F;16&#x3D;2.5M&#x2F;core</p>
<p>2015年则推出 SkyLake 架构的Platinum 8269CY（$4702.00）, 每core的L3大小：36M&#x2F;26&#x3D;1.38M&#x2F;core：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210719102112331.png" alt="image-20210719102112331"></p>
<p>Intel 2015年 发表论文<a href="https://people.csail.mit.edu/emer/papers/2015.02.hpca.cache_hierarchy.pdf" target="_blank" rel="noopener">《High Performing Cache Hierarchies for Server Workloads》</a>证明了阿里提出的建议的正确性，从Skylake架构开始将L2 cache 由 256KB 升级到 1MB， L3由2.5MB &#x2F;core 压缩到 1.375MB &#x2F; core， Intel之所以没有完全去掉L3的原因是希望这样设计的CPU对于 使用 CPU2006的workload性能仍然能够做到不受影响。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210716102624566.png" alt="image-20210716102624566"></p>
<p>上图是不同业务场景下，CPI 随cache大小的变化，可以看到随着cache增加性能基本不增加了。</p>
<h3 id="CPU-L2-Last-Level-Cache-LLC-缓存的演变"><a href="#CPU-L2-Last-Level-Cache-LLC-缓存的演变" class="headerlink" title="CPU L2, Last Level Cache (LLC) 缓存的演变"></a>CPU L2, Last Level Cache (LLC) 缓存的演变</h3><p>Last Level Cache(L3) 在2016年之前都是2MB&#x2F;core 或者 2.5MB&#x2F;core, 这个原因取决于在此之前行业都是使用CPU2006作为设计CPU的benchmark，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/141f4ccd-37ce-41e5-b404-101e6b9acf5d.png" alt="img"></p>
<p>根据上图中CPU2006的MPKI数据显示如果LLC在4MB的时候非常好，LLC在2.5MB之后MKPI提升10%性能只有1～3%的提升，2.5MB LLC cache是 CPU core 1&#x2F;2 的芯片面积，因此若将LLC 由2.5MB升级到4MB，换算成CPU core的芯片面积是增长30%（1&#x2F;2 * 1.5M&#x2F;2.5M），但性能仅仅提升最多3%，这就是为什么基于CPU2006的benchmark条件下，intel将LLC设定为2~2.5MB的原因。</p>
<h2 id="Cache的缺点"><a href="#Cache的缺点" class="headerlink" title="Cache的缺点"></a>Cache的缺点</h2><p>缓存有两大缺点：</p>
<ul>
<li>当数据集非常大的时候，时间空间局部性较低时缓存的工作效率很低；</li>
<li>当缓存工作效率高的时候，局部性非常高，这意味着，根据定义，大多数缓存在大多数时间都处于空闲状态。</li>
</ul>
<h2 id="Hardware-Memory-Models-顺序一致性"><a href="#Hardware-Memory-Models-顺序一致性" class="headerlink" title="Hardware Memory Models 顺序一致性"></a><a href="https://colobu.com/2021/06/30/hwmm/" target="_blank" rel="noopener">Hardware Memory Models 顺序一致性</a></h2><blockquote>
<p>对存储在内存中数据更改的可见性和一致性，所以这个契约被称为内存一致性模型（<code>memory consistency model</code>）或仅仅是内存模型(<code>memory model</code>)</p>
</blockquote>
<p>r1&#x2F;r2是线程本地变量，如下代码的可能结果是哪些？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Litmus Test: Message Passing</span><br><span class="line">Can this program see r1 = 1, r2 = 0?</span><br><span class="line"></span><br><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 r1 = y</span><br><span class="line">y = 1                 r2 = x</span><br></pre></td></tr></table></figure>

<p>如果该<code>litmus test</code>的执行顺序一致，则只有六种可能的交替:</p>
<p><a href="https://colobu.com/2021/06/30/hwmm/mem-litmus.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/mem-litmus.png" alt="img"></a></p>
<p>因为没有交替执行的结果会产生<code>r1 = 1, r2 = 0</code>,所以这个结果是不允许的。也就是说，在顺序执行的硬件上，litmus test执行结果出现<code>r1 = 1, r2 = 0</code>是不可能的。</p>
<p>顺序一致性的一个很好的思维模型是想象所有处理器直接连接到同一个共享内存，它可以一次处理一个线程的读或写请求。 不涉及缓存，因此每次处理器需要读取或写入内存时，该请求都会转到共享内存。 一次使用一次的共享内存对所有内存访问的执行施加了顺序顺序：顺序一致性。</p>
<p><a href="https://colobu.com/2021/06/30/hwmm/mem-sc.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/mem-sc.png" alt="img"></a></p>
<h3 id="x86-Total-Store-Order-x86-TSO-总存储有序"><a href="#x86-Total-Store-Order-x86-TSO-总存储有序" class="headerlink" title="x86 Total Store Order (x86-TSO) 总存储有序"></a><a href="https://research.swtch.com/hwmm#x86" target="_blank" rel="noopener">x86 Total Store Order (x86-TSO) 总存储有序</a></h3><p>所有处理器仍然连接到一个共享内存，但是每个处理器都将对该内存的写入(<code>write</code>)放入到本地写入队列中。处理器继续执行新指令，同时写操作(<code>write</code>)会更新到这个共享内存。一个处理器上的内存读取在查询主内存之前会查询本地写队列，但它看不到其他处理器上的写队列。其效果就是当前处理器比其他处理器会先看到自己的写操作。但是——这一点非常重要——&#x3D;&#x3D;所有处理器都保证写入(存储<code>store</code>)到共享内存的(总)顺序，所以给这个模型起了个名字:总存储有序，或<code>TSO</code>&#x3D;&#x3D;。当一个写操作到达共享内存时，任何处理器上的任何未来读操作都将看到它并使用该值(直到它被以后的写操作覆盖，或者可能被另一个处理器的缓冲写操作覆盖)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/mem-tso.png" alt="img"></p>
<p>针对前文的litmus test案例，写队列保证线程1在y之前将x写入内存，关于内存写入顺序(总存储有序)的系统级协议保证线程2在读y的新值之前读x的新值。因此，<code>r1 = y</code>在<code>r2 = x</code>看不到新的x之前不可能看到新的y。存储顺序至关重要:线程1在写入y之前先写入x，因此线程2在看到x的写入之前不可能看到y的写入。</p>
<p>但是对于TSO系统下，以下case能看到r1 &#x3D; 0, r2 &#x3D; 0, 如果在顺序一致性的协议下这是不可能发生的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Litmus Test: Write Queue (also called Store Buffer)</span><br><span class="line">Can this program see r1 = 0, r2 = 0?</span><br><span class="line"></span><br><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 y = 1</span><br><span class="line">r1 = y                r2 = x</span><br><span class="line">On sequentially consistent hardware: no.</span><br><span class="line">On x86 (or other TSO): yes!</span><br></pre></td></tr></table></figure>

<p>为了让TSO和顺序一致性协议保持一致，我们需要依赖于更强的内存排序，非顺序一致的硬件提供了称为内存屏障(或栅栏)的显式指令，可用于控制排序。我们可以添加一个内存屏障，以确保每个线程在开始读取之前都会刷新其先前对内存的写入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 y = 1</span><br><span class="line">barrier               barrier</span><br><span class="line">r1 = y                r2 = x</span><br></pre></td></tr></table></figure>

<p>加上正确的障碍，<code>r1 = 0，r2 = 0</code>也是不可能的了。内存屏障有很多种，它的存在给了程序员或语言实现者一种在程序的关键时刻强制顺序一致行为的方法。</p>
<h3 id="ARM-x2F-POWER-Relaxed-Memory-Model"><a href="#ARM-x2F-POWER-Relaxed-Memory-Model" class="headerlink" title="ARM&#x2F;POWER Relaxed Memory Model"></a><a href="https://research.swtch.com/hwmm#relaxed" target="_blank" rel="noopener">ARM&#x2F;POWER Relaxed Memory Model</a></h3><p>ARM和POWER系统的概念模型是，每个处理器从其自己的完整内存副本中读取和向其写入，每个写入独立地传播到其他处理器，随着写入的传播，允许重新排序。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/mem-weak.png" alt="img"></p>
<p>这里没有总存储顺序。虽然没有描述，但是每个处理器都被允许推迟读取(<code>read</code>)，直到它等到它需要结果:读取(<code>read</code>)可以被延迟到稍后的写入(<code>write</code>)之后。在这个宽松的(<code>relaxed</code>)模型中，我们迄今为止所看到的每一个litmus test的答案都是“yes，这真的可能发生。”</p>
<p>在这个内存模型下，对于前文中的 Litmus Test: Message Passing case是可以看到r1&#x3D;1,r2&#x3D;0的（TSO保证不会），但是可以保证 Litmus Test: Store Buffering case 和TSO一致。</p>
<p>最后再附加几个Latency数据，让大家比较起来更有体感一些</p>
<h2 id="各级IO延迟数字"><a href="#各级IO延迟数字" class="headerlink" title="各级IO延迟数字"></a>各级IO延迟数字</h2><h3 id="Cache、内存、磁盘、网络的延迟比较"><a href="#Cache、内存、磁盘、网络的延迟比较" class="headerlink" title="Cache、内存、磁盘、网络的延迟比较"></a>Cache、内存、磁盘、网络的延迟比较</h3><p><a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="noopener">假设主频2.6G的CPU，每个指令只需要 0.38ns</a> </p>
<p>每次内存寻址需要 100ns </p>
<p>一次 CPU 上下文切换（系统调用）需要大约 1500ns，也就是 1.5us（这个数字参考了<a href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="noopener">这篇文章</a>，采用的是单核 CPU 线程平均时间）</p>
<p>SSD 随机读取耗时为 150us</p>
<p>从内存中读取 1MB 的连续数据，耗时大约为 250us</p>
<p>同一个数据中心网络上跑一个来回需要 0.5ms</p>
<p>从 SSD 读取 1MB 的顺序数据，大约需要 1ms （是内存速度的四分之一）</p>
<p>磁盘寻址时间为 10ms</p>
<p>从磁盘读取 1MB 连续数据需要 20ms</p>
<p>如果 CPU 访问 L1 缓存需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<h2 id="内存和cache的latency对比"><a href="#内存和cache的latency对比" class="headerlink" title="内存和cache的latency对比"></a>内存和cache的latency对比</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/latency.png" alt="latency"></p>
<p><a href="http://www.webstersystems.co.uk/threads.htm" target="_blank" rel="noopener">各级cache的Latency</a>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/cycle_times.jpg" alt="Cycle times"></p>
<p><strong>2012 年延迟数字对比表：</strong></p>
<table>
<thead>
<tr>
<th>Work</th>
<th>Latency</th>
</tr>
</thead>
<tbody><tr>
<td>L1 cache reference</td>
<td>0.5 ns</td>
</tr>
<tr>
<td>Branch mispredict</td>
<td>5 ns</td>
</tr>
<tr>
<td>L2 cache reference</td>
<td>7 ns</td>
</tr>
<tr>
<td>Mutex lock&#x2F;unlock</td>
<td>25 ns</td>
</tr>
<tr>
<td>Main memory reference</td>
<td>100 ns</td>
</tr>
<tr>
<td>持久内存</td>
<td>300 ns</td>
</tr>
<tr>
<td>Compress 1K bytes with Zippy</td>
<td>3,000 ns</td>
</tr>
<tr>
<td>Send 1K bytes over 1 Gbps network</td>
<td>10,000 ns</td>
</tr>
<tr>
<td>Read 4K randomly from SSD*</td>
<td>150,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from memory</td>
<td>250,000 ns</td>
</tr>
<tr>
<td>Round trip within same datacenter</td>
<td>500,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from SSD*</td>
<td>1,000,000 ns</td>
</tr>
<tr>
<td>Disk seek</td>
<td>10,000,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from disk</td>
<td>20,000,000 ns</td>
</tr>
<tr>
<td>Send packet CA-&gt;Netherlands-&gt;CA</td>
<td>150,000,000 ns</td>
</tr>
</tbody></table>
<p>一个比较有体感的比较：如果 CPU 访问 寄存器需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1460000039103606.png" alt="img"></p>
<p>当然更古老一点的年代给出来的数据可能又不一样一点，但是基本比例差异还是差不多的：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/cache-hierarchy-1.jpg" alt="Memory Hierarchy"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/0d31418e-78e9-46ac-ac8e-0fcc295f1050.png" alt="img"></p>
<p>测试Inte E5 L1 、L2、L3的cache延时图来加深印象，可以看到在每级cache大小附近时延有个跳跃(纵坐标是纳秒，横坐标是大小 M)：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220321172431647.png" alt="image-20220321172431647"></p>
<p><a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html" target="_blank" rel="noopener">推荐从这里看延时，拖动时间轴可以看到随着技术、工艺的改变Latency每一年的变化</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210613123006681.png" alt="image-20210613123006681"></p>
<p>查看cpu cache数据</p>
<pre><code>cat /proc/cpuinfo |grep -i cache
</code></pre>
<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/ad19b92ccc97763aa7f78d8d1d514c84.jpg" alt="image.png" style="zoom:50%;">

<h3 id="L1C、L2C、L3C、DDR-的Latency测试数据"><a href="#L1C、L2C、L3C、DDR-的Latency测试数据" class="headerlink" title="L1C、L2C、L3C、DDR 的Latency测试数据"></a>L1C、L2C、L3C、DDR 的Latency测试数据</h3><p><a href="https://topic.atatech.org/articles/100065" target="_blank" rel="noopener">下图从左至右响应时间分别是L1C、L2C、L3C、DDR</a>，可以看出这四个Latency变化还是非常明显的，泾渭分明。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/58286da947132f269cb26ff3eda25c68.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210511160107225.png" alt="image-20210511160107225"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f5728a2afb29c653a3e1bf21f4d56056.png" alt="image.png"></p>
<h2 id="测试memory-latency"><a href="#测试memory-latency" class="headerlink" title="测试memory latency"></a>测试memory latency</h2><p><a href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw" target="_blank" rel="noopener">memory latency逻辑</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;sys/mman.h&gt;</span><br><span class="line">#include &lt;sys/time.h&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line"></span><br><span class="line">#define ONE p = (char **)*p;</span><br><span class="line">#define FIVE    ONE ONE ONE ONE ONE</span><br><span class="line">#define TEN FIVE FIVE</span><br><span class="line">#define FIFTY   TEN TEN TEN TEN TEN</span><br><span class="line">#define HUNDRED FIFTY FIFTY</span><br><span class="line"></span><br><span class="line">static void usage()</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;Usage: ./mem-lat -b xxx -n xxx -s xxx\n&quot;);</span><br><span class="line">    printf(&quot;   -b buffer size in KB\n&quot;);</span><br><span class="line">    printf(&quot;   -n number of read\n\n&quot;);</span><br><span class="line">    printf(&quot;   -s stride skipped before the next access\n\n&quot;);</span><br><span class="line">    printf(&quot;Please don&apos;t use non-decimal based number\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[])</span><br><span class="line">&#123;</span><br><span class="line">  unsigned long i, j, size, tmp;</span><br><span class="line">    unsigned long memsize = 0x800000; /* 1/4 LLC size of skylake, 1/5 of broadwell */</span><br><span class="line">    unsigned long count = 1048576; /* memsize / 64 * 8 */</span><br><span class="line">    unsigned int stride = 64; /* skipped amount of memory before the next access */</span><br><span class="line">    unsigned long sec, usec;</span><br><span class="line">    struct timeval tv1, tv2;</span><br><span class="line">    struct timezone tz;</span><br><span class="line">    unsigned int *indices;</span><br><span class="line"></span><br><span class="line">    while (argc-- &gt; 0) &#123;</span><br><span class="line">        if ((*argv)[0] == &apos;-&apos;) &#123;  /* look at first char of next */</span><br><span class="line">            switch ((*argv)[1]) &#123;   /* look at second */</span><br><span class="line">                case &apos;b&apos;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    memsize = atoi(*argv) * 1024;</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                case &apos;n&apos;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    count = atoi(*argv);</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                case &apos;s&apos;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    stride = atoi(*argv);</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                default:</span><br><span class="line">                    usage();</span><br><span class="line">                    exit(1);</span><br><span class="line">                    break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        argv++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  char* mem = mmap(NULL, memsize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);</span><br><span class="line">    // trick3: init pointer chasing, per stride=8 byte</span><br><span class="line">    size = memsize / stride;</span><br><span class="line">    indices = malloc(size * sizeof(int));</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; size; i++)</span><br><span class="line">        indices[i] = i;</span><br><span class="line"></span><br><span class="line">    // trick 2: fill mem with pointer references</span><br><span class="line">    for (i = 0; i &lt; size - 1; i++)</span><br><span class="line">        *(char **)&amp;mem[indices[i]*stride]= (char*)&amp;mem[indices[i+1]*stride];</span><br><span class="line">    *(char **)&amp;mem[indices[size-1]*stride]= (char*)&amp;mem[indices[0]*stride];</span><br><span class="line"></span><br><span class="line">    register char **p = (char **) mem;</span><br><span class="line">    //char **p = (char **) mem;</span><br><span class="line">    tmp = count / 100;</span><br><span class="line"></span><br><span class="line">    gettimeofday (&amp;tv1, &amp;tz);</span><br><span class="line">    for (i = 0; i &lt; tmp; ++i) &#123;</span><br><span class="line">        HUNDRED;  //trick 1</span><br><span class="line">    &#125;</span><br><span class="line">    gettimeofday (&amp;tv2, &amp;tz);</span><br><span class="line">    char **touch = p;</span><br><span class="line">    if (tv2.tv_usec &lt; tv1.tv_usec) &#123;</span><br><span class="line">        usec = 1000000 + tv2.tv_usec - tv1.tv_usec;</span><br><span class="line">        sec = tv2.tv_sec - tv1.tv_sec - 1;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        usec = tv2.tv_usec - tv1.tv_usec;</span><br><span class="line">        sec = tv2.tv_sec - tv1.tv_sec;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printf(&quot;Buffer size: %ld KB, stride %d, time %d.%06d s, latency %.2f ns\n&quot;,</span><br><span class="line">            memsize/1024, stride, sec, usec, (sec * 1000000  + usec) * 1000.0 / (tmp *100));</span><br><span class="line">    munmap(mem, memsize);</span><br><span class="line">    free(indices);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分别在intel 8163和arm 鲲鹏920上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">$cat run_mem_lat.sh</span><br><span class="line">#!/bin/sh</span><br><span class="line">#set -x</span><br><span class="line"></span><br><span class="line">work=./mem-lat</span><br><span class="line">buffer_size=1</span><br><span class="line">node=$1</span><br><span class="line">mem=$2</span><br><span class="line"></span><br><span class="line">for i in `seq 1 15`; do</span><br><span class="line">    #echo $i</span><br><span class="line">        #echo $buffer_size</span><br><span class="line">    taskset -ac 1 $work -b $buffer_size -s 64</span><br><span class="line">    buffer_size=$(($buffer_size*2))</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#sh run_mem_lat.sh</span><br><span class="line">Buffer size: 1 KB, stride 64, time 0.001682 s, latency 1.60 ns</span><br><span class="line">Buffer size: 2 KB, stride 64, time 0.001685 s, latency 1.61 ns</span><br><span class="line">Buffer size: 4 KB, stride 64, time 0.001687 s, latency 1.61 ns</span><br><span class="line">Buffer size: 8 KB, stride 64, time 0.001682 s, latency 1.60 ns</span><br><span class="line">Buffer size: 16 KB, stride 64, time 0.001688 s, latency 1.61 ns</span><br><span class="line">Buffer size: 32 KB, stride 64, time 0.001817 s, latency 1.73 ns</span><br><span class="line">Buffer size: 64 KB, stride 64, time 0.005842 s, latency 5.57 ns</span><br><span class="line">Buffer size: 128 KB, stride 64, time 0.005838 s, latency 5.57 ns</span><br><span class="line">Buffer size: 256 KB, stride 64, time 0.005838 s, latency 5.57 ns</span><br><span class="line">Buffer size: 512 KB, stride 64, time 0.005841 s, latency 5.57 ns</span><br><span class="line">Buffer size: 1024 KB, stride 64, time 0.006056 s, latency 5.78 ns</span><br><span class="line">Buffer size: 2048 KB, stride 64, time 0.006175 s, latency 5.89 ns</span><br><span class="line">Buffer size: 4096 KB, stride 64, time 0.006203 s, latency 5.92 ns</span><br><span class="line">Buffer size: 8192 KB, stride 64, time 0.006383 s, latency 6.09 ns</span><br><span class="line">Buffer size: 16384 KB, stride 64, time 0.007345 s, latency 7.01 ns</span><br><span class="line"></span><br><span class="line">[root@x86.170 /root]</span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    24</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          1</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2500.390</span><br><span class="line">CPU max MHz:           3100.0000</span><br><span class="line">CPU min MHz:           1000.0000</span><br><span class="line">BogoMIPS:              4998.87</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              33792K</span><br><span class="line">NUMA node0 CPU(s):     0-95</span><br><span class="line"></span><br><span class="line">//鲲鹏920</span><br><span class="line">#sh run_mem_lat.sh</span><br><span class="line">Buffer size: 1 KB, stride 64, time 0.001628 s, latency 1.55 ns</span><br><span class="line">Buffer size: 2 KB, stride 64, time 0.001623 s, latency 1.55 ns</span><br><span class="line">Buffer size: 4 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 8 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 16 KB, stride 64, time 0.001622 s, latency 1.55 ns</span><br><span class="line">Buffer size: 32 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 64 KB, stride 64, time 0.001637 s, latency 1.56 ns</span><br><span class="line">Buffer size: 128 KB, stride 64, time 0.003749 s, latency 3.58 ns</span><br><span class="line">Buffer size: 256 KB, stride 64, time 0.003320 s, latency 3.17 ns</span><br><span class="line">Buffer size: 512 KB, stride 64, time 0.003779 s, latency 3.60 ns</span><br><span class="line">Buffer size: 1024 KB, stride 64, time 0.004310 s, latency 4.11 ns</span><br><span class="line">Buffer size: 2048 KB, stride 64, time 0.004655 s, latency 4.44 ns</span><br><span class="line">Buffer size: 4096 KB, stride 64, time 0.005032 s, latency 4.80 ns</span><br><span class="line">Buffer size: 8192 KB, stride 64, time 0.005721 s, latency 5.46 ns</span><br><span class="line">Buffer size: 16384 KB, stride 64, time 0.006470 s, latency 6.17 ns</span><br><span class="line"></span><br><span class="line">[root@ARM 15:58 /root]</span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    48</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          4</span><br><span class="line">Model:                 0</span><br><span class="line">CPU max MHz:           2600.0000</span><br><span class="line">CPU min MHz:           200.0000</span><br><span class="line">BogoMIPS:              200.00</span><br><span class="line">L1d cache:             64K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              24576K</span><br><span class="line">NUMA node0 CPU(s):     0-23</span><br><span class="line">NUMA node1 CPU(s):     24-47</span><br><span class="line">NUMA node2 CPU(s):     48-71</span><br><span class="line">NUMA node3 CPU(s):     72-95</span><br></pre></td></tr></table></figure>

<h2 id="为什么CACHE比内存快？"><a href="#为什么CACHE比内存快？" class="headerlink" title="为什么CACHE比内存快？"></a>为什么CACHE比内存快？</h2><p>首先肯定是距离的原因，另外这两种存储结构的制造工艺不同导致的速度差异也很大，从上面可以看到一块4000刀的CPU有一半的面积是cache，也就是40M CACHE花了2000刀，如果用来买内存条能卖一大堆吧。</p>
<p>接下来说下CACHE（SRAM) 和内存（DRAM）制造的工艺差异</p>
<h3 id="SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片"><a href="#SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片" class="headerlink" title="SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片"></a>SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片</h3><p>CPU Cache 用的是一种叫作 SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片。</p>
<p>SRAM 之所以被称为”静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。在 SRAM 里面，一个比特的数据，需要 6～8 个晶体管。所以 SRAM 的存储密度不高。同样的物理空间下，能够存储的数据有限。不过，因为 SRAM 的电路简单，所以访问速度非常快。</p>
<p>L1和L2一般是SRAM， L1的容量通常比L2小，容量大的SRAM访问时间就越长，同样制程和设计的情况下，<strong>访问延时与容量的开方大致是成正比</strong>的。</p>
<p>另外工作原理不同速度差异也不一样，L1就是讲究快，比如L1是N路组相联，N路阻相联的意思就是N个Cache单元同时读取数据（有点类似RAID0）。</p>
<p>L3用的还是SRAM，但是在考虑换成STT-MRAM，这样容量更大。</p>
<h3 id="DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片"><a href="#DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片" class="headerlink" title="DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片"></a>DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片</h3><p>为磁芯存储器画上句号的是集成电路随机存储器件。1966年，IBM Thomas J. Watson研究中心的Dr. Robert H. Dennard开发出了单个单元的动态随机存储器DRAM，DRAM每个单元包含一个开关晶体管和一个电容，利用电容中的电荷存储数据。因为电容中的电荷会泄露，需要每个周期都进行刷新重新补充电量，所以称其为动态随机存储器。</p>
<p>内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。</p>
<p>动态随机存取存储器（DRAM）是一种半导体存储器，主要的作用原理是利用电容内存储电荷的多寡来代表一个二进制比特（bit）是1还是0。由于<strong>在现实中晶体管会有漏电电流的现象</strong>，导致电容上所存储的电荷数量并不足以正确的判别数据，而导致数据毁损。因此对于DRAM来说，周期性地充电是一个无可避免的要件。由于这种需要定时刷新的特性，因此被称为“动态”存储器。相对来说，静态存储器（SRAM）只要存入数据后，纵使不刷新也不会丢失记忆。</p>
<p>DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多，也就是存储的”密度”更大。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/d39b0f2b3962d646133d450541fb75a6.png" alt="img"></p>
<p>SRAM是比<strong>DRAM</strong>更为昂贵，但更为快速、非常低功耗（特别是在空闲状态）。 因此<strong>SRAM</strong>首选用于带宽要求高，或者功耗要求低，或者二者兼而有之。 <strong>SRAM</strong>比起<strong>DRAM</strong>更为容易控制，也更是随机访问。 由于复杂的内部结构，<strong>SRAM</strong>比<strong>DRAM</strong>的占用面积更大，因而不适合用于更高储存密度低成本的应用，如PC内存。</p>
<h3 id="SRAM和DRAM原理比较"><a href="#SRAM和DRAM原理比较" class="headerlink" title="SRAM和DRAM原理比较"></a>SRAM和DRAM原理比较</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI2NDYwMDAxOQ==&mid=2247483772&idx=1&sn=d7c188247b9851f7985676e2f9dd9a0e&chksm=eaab61c0dddce8d62bdb521de1ada13142264882feae1ff06d6dcd81430a0063377e4b34cedb&scene=178&cur_album_id=1368835510680272898#rd" target="_blank" rel="noopener">简单说DRAM只有一个晶体管和一个电容，SRAM就复杂多了，需要6个晶体管</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210603114550646.png" alt="What is the difference between SRAM and DRAM"></p>
<p>图左边的 DRAM 的状态是保持在电容器C中。晶体管M用来控制访问。如果要读取状态，拉升访问线AL，这时，可能会有电流流到数据线DL上，也可能没有，取决于电容器是否有电。如果要写入状态，先设置DL，然后升起AL一段时间，直到电容器充电或放电完毕。</p>
<p>由于读取状态时需要对电容器放电，所以这一过程不能无限重复，不得不在某个点上对它重新充电。更糟糕的是，为了容纳大量单元(现在一般在单个芯片上容纳109以上的RAM单元)，电容器的容量必须很小(0.000000000000001法拉以下)。这样，完整充电后大约持有几万个电子。即使电容器的电阻很大(若干兆欧姆)，仍然只需很短的时间就会耗光电荷，称为「泄漏」。</p>
<p>这种泄露就是现在的大部分DRAM芯片每隔64ms就必须进行一次刷新的原因。在刷新期间，对于该芯片的访问是不可能的，这甚至会造成半数任务的延宕。（相关内容请察看【highperfdram】一章）</p>
<p>这个问题的另一个后果就是无法直接读取芯片单元中的信息，而必须通过信号放大器将0和1两种信号间的电势差增大，才能分辨出来。</p>
<p>DRAM 主要靠电容充放电来识别0和1，<strong>但是充放电是一个持续过程，需要耗时，这也是导致内存延时大的主要原因</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220730161825538.png" alt="image-20220730161825538"></p>
<p>不像SRAM可以即刻读取数据，当要读取DRAM的时候，必须花一点时间来等待电容的冲放电完全。这一点点的时间最终限制了DRAM的速度。</p>
<p>SRAM 需要注意以下问题:</p>
<ul>
<li>一个单元需要6个晶体管。也有采用4个晶体管的SRAM，体积大、贵、结构复杂。</li>
<li>维持状态需要恒定的电源。</li>
<li>升起WL后<strong>立即可以读取状态</strong>。信号与其它晶体管控制的信号一样，是直角的(快速在两个状态间变化)。</li>
<li>状态稳定，不需要刷新循环。</li>
</ul>
<p>SRAM也有其它形式，不那么费电，但比较慢。由于我们需要的是快速RAM，因此不在关注范围内。这些较慢的SRAM的主要优点在于接口简单，比动态RAM更容易使用。</p>
<p>详细比较：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/maxresdefault.jpg" alt="Difference Between SRAM and DRAM - YouTube"></p>
<p>SRAM 也有其它形式，不那么费电，但比较慢。由于我们需要的是快速RAM，因此其它形式的 SRAM 不在关注范围内。这些较慢的SRAM的主要优点在于接口简单，比动态RAM更容易使用。CPU cache用的是快速 SRAM，本文提到的 SRAM 都是指快速 SRAM</p>
<h3 id="DRAM-刷新"><a href="#DRAM-刷新" class="headerlink" title="DRAM 刷新"></a>DRAM 刷新</h3><p>DRAM内存内部使用电容来存储数据，由于电容有漏电现象，经过一段时间电荷会泄放，导致数据不能长时间存储。因此需要不断充电，这个充电的动作叫做刷新。自动刷新是以“行”为单位进行刷新，刷新操作与读写访问无法同时进行，即刷新时会对内存的性能造成影响。同时温度越高电容泄放越快，器件手册通常要求芯片表面温度在0℃-85℃时，内存需要按照64ms的周期刷新数据，在85℃~95℃时，按照32ms的周期刷新数据。</p>
<p>BIOS中内存刷新速率选项提供了auto选项，可以根据工作温度自动调节内存刷新速率。相比默认32ms配置可以提升内存性能，同时确保工作温度在85℃~95℃时内存数据的可靠性。</p>
<h3 id="DRAM-频率"><a href="#DRAM-频率" class="headerlink" title="DRAM 频率"></a>DRAM 频率</h3><p>内存实际有3种频率：</p>
<ul>
<li>核心频率</li>
<li>时钟频率(IO控制器频率）</li>
<li>等效频率（有效数据传输频率）</li>
</ul>
<p>核心频率就是内存的Cell阵列（内存电容）的刷新频率，只与内存本身物理特性有关，目前频率基本都在133MHz~200MH之间</p>
<p>我们俗称DDR4-2666实际指的是等效频率，是通过上升下降沿进行数据预取放大后的实际数据传输频率，DDR4 prefetch是8，通过bank group提升到核心频率的16倍，所以DDR4的最低起频是133.333MHz*16&#x3D;2133MHz。DDR(Double Data Rate)因为是在一个时钟周期的上升沿和下降沿个执行预取，所以时钟频率&#x3D;等效频率&#x2F;2</p>
<h2 id="Persistence-memory"><a href="#Persistence-memory" class="headerlink" title="Persistence memory"></a>Persistence memory</h2><p>左边是在32G物理内存的基础上挂了128G pmem, 然后系统通过free能看到 154G内存，用 <code>lat_mem_rd</code> 实际测试速度可以看到左边的机器抖动比较大</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220607154156826.png" alt="image-20220607154156826"></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></p>
<p><a href="https://coolshell.cn/articles/10249.html" target="_blank" rel="noopener">7个示例科普CPU CACHE</a></p>
<p><a href="https://coolshell.cn/articles/20793.html" target="_blank" rel="noopener">与程序员相关的CPU缓存知识</a></p>
<p><a href="https://arxiv.org/ftp/arxiv/papers/1803/1803.00254.pdf" target="_blank" rel="noopener">45-year CPU evolution: one law and two equations</a></p>
<p><a href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw" target="_blank" rel="noopener">揭秘 cache 访问延迟背后的计算机原理</a></p>
<p><a href="https://mp.weixin.qq.com/s/FC-bPwHUT7EpTydxDk5btQ" target="_blank" rel="noopener">业务与芯片垂直整合的一点思考</a></p>
<p> <a href="http://www.akkadia.org/drepper/cpumemory.pdf" target="_blank" rel="noopener">What Every Programmer Should Know About Main Memory</a> by Ulrich Drepper  中文版：<a href="https://zhuanlan.zhihu.com/p/611133924" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/611133924</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/23/做了一道数学几何题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/23/做了一道数学几何题/" itemprop="url">做了一道数学几何题</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-23T12:30:03+08:00">
                2021-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技巧/" itemprop="url" rel="index">
                    <span itemprop="name">技巧</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="做了一道数学几何题"><a href="#做了一道数学几何题" class="headerlink" title="做了一道数学几何题"></a>做了一道数学几何题</h1><p>John Hattie的visible learning，这本书集成了两亿多学生的数据，然后得到了哪些品质能够决定一个人学习好坏，想通过一道几何题目来验证下。先看下John Hattie的结论</p>
<h2 id="哪些品质能够决定一个人学习好坏"><a href="#哪些品质能够决定一个人学习好坏" class="headerlink" title="哪些品质能够决定一个人学习好坏"></a>哪些品质能够决定一个人学习好坏</h2><h3 id="排在第一名的品质是复盘、总结能力"><a href="#排在第一名的品质是复盘、总结能力" class="headerlink" title="排在第一名的品质是复盘、总结能力"></a>排在第一名的品质是复盘、总结能力</h3><p>简单的说，这个能力就是这个孩子心里是否有个“小教练”，能够每次跳脱出当前任务，帮助自己分析，失败在哪里，成功在哪里，如何进阶，如何训练等等。</p>
<p>举几个例子：</p>
<ol>
<li><p>如果写不出作文，这个“小教练”能告诉孩子，是没有素材，还是文字能力不强。</p>
<p>如果是文字能力不强，应该如何训练（是造句，还是拆段落）</p>
</li>
<li><p>如果数学题做不出来，这个“小教练”能告诉孩子，我的弱点在哪里，哪个类型题我有重大问题，是因为哪里没有理解和打通。</p>
</li>
</ol>
<p>有内化的“自我教练”，这个能力系数是1.67。也就是其他能力相当，学习效果可以翻1.67倍。</p>
<h3 id="排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等"><a href="#排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等" class="headerlink" title="排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等"></a>排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等</h3><p>在内心“小教练”能把问题进行拆解之后，建构能力能把这些问题进行排序，应该怎么做更合理。</p>
<p>最终怎么把训练步骤整合。遇见一个问题，先干什么，再干什么等等。</p>
<p>有很强的顺序能力，系数为1.44。也就是其他能力相当，学习效果可以翻1.44倍。</p>
<h3 id="排在第三名的能力是智商和过去成绩"><a href="#排在第三名的能力是智商和过去成绩" class="headerlink" title="排在第三名的能力是智商和过去成绩"></a>排在第三名的能力是智商和过去成绩</h3><p>这个毋庸置疑，聪明做事就会简单一些。平均效应系数为0.67。</p>
<p>也就是说，其他能力相当，智商高和过去成绩好，学习效果提升67%</p>
<p>智商重要程度应该比这里更高，但是实际高智商的太少，<strong>大多都是因为基础知识好给人产生了智商高的误解！</strong></p>
<h3 id="排在第四名的能力是自我驱动力"><a href="#排在第四名的能力是自我驱动力" class="headerlink" title="排在第四名的能力是自我驱动力"></a>排在第四名的能力是自我驱动力</h3><p>简单的说，知道自己为什么学习，能够自我鼓励，遇见失败能抗挫，有很强的心理驱动力。</p>
<p>平均效应系数为0.48。也就是说，其他能力相当，有自我驱动力的人，学习效果提升48%。</p>
<h3 id="排在第五名的才是集中注意力"><a href="#排在第五名的才是集中注意力" class="headerlink" title="排在第五名的才是集中注意力"></a>排在第五名的才是集中注意力</h3><p>也就是说，注意力强。注意力对学习影响，并没有很多家长想象的那么大。</p>
<p>注意力的平均效应系数为0.44</p>
<p>也就是说，其他能力相当，注意力好的孩子，效果能提升44%</p>
<p>———总结一下——-</p>
<p>学习提升的个人因素：</p>
<p>自我分析，自我教练的元认知能力 》 逻辑排序与制定计划的建构能力》 智商和过去成绩 》自我驱动力》 集中注意力。</p>
<p>很多家长痴迷于“专注力”。当然专注力是一个效应量很强的学习力，但是从整体数据看，对学习的提升效果，仅仅排到第五名。</p>
<p>帮助孩子建立元认知能力和建构能力的培训，才能给他们对终身学习有帮助的技能包</p>
<p>以上缺少了对方法的落地执行能力的评估，实际这是影响最大的</p>
<h2 id="案例数学几何题"><a href="#案例数学几何题" class="headerlink" title="案例数学几何题"></a>案例数学几何题</h2><p>题目如下（图中红色、绿色线是我绘上去的辅助线）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210623121704887.png" alt="image-20210623121704887"></p>
<h3 id="目标分解"><a href="#目标分解" class="headerlink" title="目标分解"></a><strong>目标分解</strong></h3><p>求得四个阴影部分的面积相加；</p>
<p>求得白色部分面积即可以得到三角形内部两块阴影部分面积；</p>
<p>求得红色三角形面积记得通过圆面积减得三角形面积得到三角形外部阴影面积。红色辅助线、绿色辅助线</p>
<h3 id="题目给出的条件"><a href="#题目给出的条件" class="headerlink" title="题目给出的条件"></a><strong>题目给出的条件</strong></h3><p>大三角形是等腰直角三角形（两个角都是45度，直角90度）；</p>
<p>两圆相切：圆心连线经过切点，连线长度为两圆半径相加。大圆半径为2</p>
<p>这里关于两圆相切我完全不记得有啥特性了，所以去Google了一把得到如下两圆相切的特性：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210623130815151.png" alt="image-20210623130815151"></p>
<blockquote>
<p>想了一下在我丢开课本几十年后我看到等要直接三角形我能得到：45度、两条边相等这两个结论；但是看到两圆相切我完全想不起来这是什么东西了。相信这两个知识点在我中学的时候肯定无比熟练。</p>
<p>但是两圆相切完全不会出现在我的生活和应用中，但是等要直接三角形太常见了，它反复出现在我的生活中，所以我只要没得老年痴呆应该会一直记得。</p>
</blockquote>
<h3 id="解题关键"><a href="#解题关键" class="headerlink" title="解题关键"></a><strong>解题关键</strong></h3><ol>
<li>如何求得小圆半径；</li>
<li>如何求红色辅助线构成的右下角三角形的面积（是否是个等腰直角三角形？），求得这个三角形的面积就能算出右下角阴影面积</li>
<li>从1的小圆半径和2的方法同理可得左上角的外部阴影面积</li>
<li>从2、3的阴影面积可以求得大三角形内部两块白色区域面积</li>
<li>这样的到了全部阴影的面积</li>
</ol>
<h3 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a><strong>详细步骤</strong></h3><ol>
<li>求解小圆半径：相切是切入点，两圆圆心连线经过想切点（连线长&#x3D;大圆半径+小圆半径）（绿线）</li>
<li>利用等腰直接三角形得到左下角绿色新直角三角形由勾股定理算出小圆半径（绿线）</li>
<li>大圆交点到圆心作辅助线得到右下角等腰三角形，由一个角是45度，和等腰三角形的特点退出另外一个角也为45度，从而得到右下角红色三角形是等腰直角三角形（红线）</li>
<li>通过大圆四分之一面积减掉右下角红线等腰三角形面积得到右下阴影部分面积，同理可得右上阴影面积。</li>
<li>通过半圆面积减掉阴影面积可分别得到两个半圆内部的白色部分面积</li>
<li>大三角形面积减掉6中的两个白色面积得到两个小阴影面积</li>
<li>到此分别得到了四个阴影部分面积</li>
</ol>
<p>大圆半径很容易求得为2，设小圆半径为r，根据左下角绿色直角三角形的勾股定理有：(4-r)(4-4)+2X2&#x3D;(2+r)(2+r)，可得r&#x3D;4&#x2F;3</p>
<p>右下角的红色三角形是个等腰三角形，且一个底角为45度，可得这个三角形是等腰直角三角形，求得大圆半径为2</p>
<h3 id="复盘求解过程"><a href="#复盘求解过程" class="headerlink" title="复盘求解过程"></a><strong>复盘求解过程</strong></h3><h4 id="教练在哪里"><a href="#教练在哪里" class="headerlink" title="教练在哪里?"></a>教练在哪里?</h4><p>教练就是日益自我训练的过程，教练在事后复盘上述过程，解题过程中没有教练参与</p>
<p>如果做不出来，那么教练就来问：</p>
<p>是题目没读懂得到的信息不够（仔细多读题，提高阅读能力）；</p>
<p>还是由题目中的已知条件得不到相关的直接推理（比如两圆相切因为不了解特性，所以得不到连线就是两个圆半径之和—-这种只能多看书）；</p>
<p>或者推不出来右下角的直角等腰三角形（对等腰三角形理解不够）……</p>
<p>如果做得过于绕，那么教练就来问：</p>
<p>还能简化（这个简化不是要奇技淫巧的快解），而是要既解决问题又不啰嗦，同时又是自己掌握知识的恰切运用！</p>
<p>教练就是复盘上述过程，得到方法进步或者知识缺陷或者理解缺陷，而不是得到答案。</p>
<h4 id="逻辑推理，做事顺序"><a href="#逻辑推理，做事顺序" class="headerlink" title="逻辑推理，做事顺序"></a>逻辑推理，做事顺序</h4><p>先求什么再求什么，怎么样从已知条件得到简单结论，然后再分步得到阶段性小结论（各个小块面积）到最终目标，这就是John Hattie提到的逻辑推理做事顺序能力</p>
<h4 id="基础知识的运用"><a href="#基础知识的运用" class="headerlink" title="基础知识的运用"></a><strong>基础知识的运用</strong></h4><p>勾股定理、等腰三角形、三角形三角之和、相切特性、圆面积、等腰三角形面积计算</p>
<p>没有任何一个复杂的基础知识，也没有任何需要几次的推导，全是定理带来的直接特性，对智力要求极低</p>
<p>自我驱动和集中注意力是个长期过程，自我驱动决定了之前的学习欲望和基本知识点的掌握</p>
<h2 id="其他总结"><a href="#其他总结" class="headerlink" title="其他总结"></a>其他总结</h2><p>你有更巧妙的解法？对不起，我不需要，我要的就是这种学渣也完全能掌握，只需要简单地1+1+1+1就得到4的方法，我不需要2*2得到4，因为1+1+1+1对不会乘法的学渣也能掌握，我要的就是这种普适的方法。</p>
<p>学渣也能掌握这个方法，然后用这个方法训练自己解决其他类似题目。对学渣来说考80分就很开心了，等他们有了考80分的能力就有野心向90进发。</p>
<p>学渣更重要的是追求容易的全部解决，复杂的直接战略性放弃，只有在容易的全部掌握后才能慢慢挑战复杂题目。容易的基础题都解决不好只是追求奇技淫巧的解法或者复杂题目容易迷失自己和快速遗忘。</p>
<h2 id="受过训练的中学生如何解这题"><a href="#受过训练的中学生如何解这题" class="headerlink" title="受过训练的中学生如何解这题"></a>受过训练的中学生如何解这题</h2><p>做如下BD和HE两条辅助线，梯形BDEH的面积就是要求的面积。</p>
<p>也就是ABC三角形的面积减掉AEH和BCD两个三角形的面积。</p>
<p>那么需要证明 BD&#x3D;CD，因为DF&#x3D;CF，角FCD为45度，所以CDF为等腰三角形，接下来证明过程和上面一样。同时同理可证AEH也是等腰直角三角形。</p>
<p>可以看到受过训练的中学生的解题方法更为犀利一些，但是前面文章的方法最为朴素和直接。训练过的方法效率更高，当然两个方法基本知识的运用没有差别。</p>
<p>比如受过训练的方法还是需要下图红色、绿色两条辅助线。这就是职业和业余的差距。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210625175006683.png" alt="image-20210625175006683"></p>
<p>最后如果你发现我题目做错了，也别较真了，我就是借案例说明下学习方法，不代表我现在还有初中数学能力</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/18/几款CPU性能对比/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/18/几款CPU性能对比/" itemprop="url">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-18T17:30:03+08:00">
                2021-06-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Intel-海光-鲲鹏920-飞腾2500-CPU性能对比"><a href="#Intel-海光-鲲鹏920-飞腾2500-CPU性能对比" class="headerlink" title="Intel 海光 鲲鹏920 飞腾2500 CPU性能对比"></a>Intel 海光 鲲鹏920 飞腾2500 CPU性能对比</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">CPU性能和CACHE</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>本篇是收尾篇，横向对比一下x86和ARM芯片，以及不同方案权衡下的性能比较</p>
<h2 id="CPU基本信息"><a href="#CPU基本信息" class="headerlink" title="CPU基本信息"></a>CPU基本信息</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210723161314138.png" alt="image-20210723161314138"></p>
<h3 id="海光"><a href="#海光" class="headerlink" title="海光"></a>海光</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    2      //每个物理core有两个超线程</span><br><span class="line">Core(s) per socket:    16     //每路16个物理core</span><br><span class="line">Socket(s):             2      //2路</span><br><span class="line">NUMA node(s):          4</span><br><span class="line">Vendor ID:             HygonGenuine</span><br><span class="line">CPU family:            24</span><br><span class="line">Model:                 1</span><br><span class="line">Model name:            Hygon C86 5280 16-core Processor</span><br><span class="line">Stepping:              1</span><br><span class="line">CPU MHz:               2455.552</span><br><span class="line">CPU max MHz:           2500.0000</span><br><span class="line">CPU min MHz:           1600.0000</span><br><span class="line">BogoMIPS:              4999.26</span><br><span class="line">Virtualization:        AMD-V</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              8192K</span><br><span class="line">NUMA node0 CPU(s):     0-7,32-39</span><br><span class="line">NUMA node1 CPU(s):     8-15,40-47</span><br><span class="line">NUMA node2 CPU(s):     16-23,48-55</span><br><span class="line">NUMA node3 CPU(s):     24-31,56-63</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate sme ssbd sev ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 MySQLeed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca</span><br><span class="line"></span><br><span class="line">#numactl -H</span><br><span class="line">available: 4 nodes (0-3)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 32 33 34 35 36 37 38 39</span><br><span class="line">node 0 size: 128854 MB</span><br><span class="line">node 0 free: 89350 MB</span><br><span class="line">node 1 cpus: 8 9 10 11 12 13 14 15 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 129019 MB</span><br><span class="line">node 1 free: 89326 MB</span><br><span class="line">node 2 cpus: 16 17 18 19 20 21 22 23 48 49 50 51 52 53 54 55</span><br><span class="line">node 2 size: 128965 MB</span><br><span class="line">node 2 free: 86542 MB</span><br><span class="line">node 3 cpus: 24 25 26 27 28 29 30 31 56 57 58 59 60 61 62 63</span><br><span class="line">node 3 size: 129020 MB</span><br><span class="line">node 3 free: 98227 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3</span><br><span class="line">  0:  10  16  28  22</span><br><span class="line">  1:  16  10  22  28</span><br><span class="line">  2:  28  22  10  16</span><br><span class="line">  3:  22  28  16  10</span><br></pre></td></tr></table></figure>

<p>这CPU据说是胶水核，也就是把两个die拼一块封装成一块CPU，所以一块CPU内跨die之间延迟还是很高的。</p>
<h4 id="64-个-core-的分配策略"><a href="#64-个-core-的分配策略" class="headerlink" title="64 个 core 的分配策略"></a>64 个 core 的分配策略</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">physical         core      processor</span><br><span class="line">0                0~15         0~15</span><br><span class="line">1                0~15         16~31</span><br><span class="line">0                0~15         32~47</span><br><span class="line">1                0~15         48~63</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210805085715353.png" alt="image-20210805085715353"></p>
<h3 id="Intel-CPU"><a href="#Intel-CPU" class="headerlink" title="Intel CPU"></a>Intel CPU</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/750px-cascade_lake_naming_scheme.svg.png" alt="cascade lake naming scheme.svg"></p>
<p>Cascade Lake架构相对Broadwell L1没变，L2从256K增加到1M增加了4倍，L3从2.5下降到1.38M每core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">座：                 2</span><br><span class="line">NUMA 节点：         1</span><br><span class="line">厂商 ID：           GenuineIntel</span><br><span class="line">CPU 系列：          6</span><br><span class="line">型号：              85</span><br><span class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">步进：              7</span><br><span class="line">CPU MHz：             1200.000</span><br><span class="line">CPU max MHz:           2501.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS：            5000.00</span><br><span class="line">虚拟化：           VT-x</span><br><span class="line">L1d 缓存：          32K</span><br><span class="line">L1i 缓存：          32K</span><br><span class="line">L2 缓存：           1024K</span><br><span class="line">L3 缓存：           36608K</span><br><span class="line">NUMA 节点0 CPU：    0-103</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_ppin intel_pt ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke avx512_vnni spec_ctrl intel_stibp flush_l1d arch_capabilities</span><br><span class="line"></span><br><span class="line"># numactl -H</span><br><span class="line">available: 1 nodes (0)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103</span><br><span class="line">node 0 size: 785826 MB</span><br><span class="line">node 0 free: 108373 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0</span><br><span class="line">  0:  10  </span><br><span class="line"></span><br><span class="line">//志强E5</span><br><span class="line">  #lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    16</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 79</span><br><span class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</span><br><span class="line">Stepping:              1</span><br><span class="line">CPU MHz:               2500.000</span><br><span class="line">CPU max MHz:           3000.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              5000.06</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              256K</span><br><span class="line">L3 cache:              40960K</span><br><span class="line">NUMA node0 CPU(s):     0-15,32-47</span><br><span class="line">NUMA node1 CPU(s):     16-31,48-63</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3</span><br><span class="line"></span><br><span class="line">#numactl -H</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</span><br><span class="line">node 0 size: 262008 MB</span><br><span class="line">node 0 free: 240846 MB</span><br><span class="line">node 1 cpus: 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63</span><br><span class="line">node 1 size: 262144 MB</span><br><span class="line">node 1 free: 242774 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  21</span><br><span class="line">  1:  21  10</span><br></pre></td></tr></table></figure>

<h3 id="鲲鹏920"><a href="#鲲鹏920" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>鲲鹏920-4826的L1比8269C 大一倍，但是L2小一倍。L3鲲鹏为1M&#x2F;core  8269为1.38M&#x2F;core(物理core）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    48</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          1</span><br><span class="line">Model:                 0</span><br><span class="line">CPU max MHz:           2600.0000</span><br><span class="line">CPU min MHz:           200.0000</span><br><span class="line">BogoMIPS:              200.00</span><br><span class="line">L1d cache:             64K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              49152K</span><br><span class="line">NUMA node0 CPU(s):     0-95</span><br><span class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma dcpop asimddp asimdfhm</span><br><span class="line"></span><br><span class="line">#numactl -H</span><br><span class="line">available: 4 nodes (0-3)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23</span><br><span class="line">node 0 size: 192832 MB</span><br><span class="line">node 0 free: 187693 MB</span><br><span class="line">node 1 cpus: 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 193533 MB</span><br><span class="line">node 1 free: 191827 MB</span><br><span class="line">node 2 cpus: 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71</span><br><span class="line">node 2 size: 193533 MB</span><br><span class="line">node 2 free: 192422 MB</span><br><span class="line">node 3 cpus: 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</span><br><span class="line">node 3 size: 193532 MB</span><br><span class="line">node 3 free: 193139 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3</span><br><span class="line">  0:  10  12  20  22</span><br><span class="line">  1:  12  10  22  24</span><br><span class="line">  2:  20  22  10  12</span><br><span class="line">  3:  22  24  12  10</span><br><span class="line"></span><br><span class="line">#dmidecode -t processor | grep Version</span><br><span class="line">    Version: Kunpeng 920-4826</span><br><span class="line">    Version: Kunpeng 920-4826  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">以上四个鲲鹏920的四个NUMA node之间的距离描述如下：</span><br><span class="line">node 0 &lt;------------ socket distance ------------&gt; node 2</span><br><span class="line">    | (die distance)                                  | (die distance)</span><br><span class="line">node 1                                             node 3    </span><br><span class="line">要注意node1到node3比node0到node3要大，猜测Socket之间的UPI只接上了node1和node2</span><br></pre></td></tr></table></figure>

<p><a href="https://fuse.wikichip.org/news/2274/huawei-expands-kunpeng-server-cpus-plans-smt-sve-for-next-gen/" target="_blank" rel="noopener">鲲鹏920架构参考这里</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/taishan-v110-soc-block-diagram.png" alt="img"></p>
<p>Though Huawei has been keeping a tight lip on the chip design itself, the Hi1620 is actually a multi-chip design. Actually, we believe are three dies. The chip itself comprise two compute dies called the <strong>Super CPU cluster</strong> (SCCL), each one packing 32 cores. It’s also possible the SCCL only have 24 cores, in which case there are three such dies with a theoretical maximum core count of 72 cores possible but are not offered for yield reasons. Regardless of this, there are at least two SCCL dies for sure. Additionally, there is also an I&#x2F;O die called the <strong>Super IO Cluster</strong> (SICL) which contains all the high-speed SerDes and low-speed I&#x2F;Os.</p>
<p>下图是6426型号，我测试用的是4826型号，也就是一个CPU内是48core，一个CPU封装3个Die，两个Die是 core，还有一个是Super IO Cluster</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/700px-taishan_v110_soc_details.svg.png" alt="taishan v110 soc details.svg"></p>
<p>鲲鹏命令规范：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/kunpeng-naming-scheme.png" alt="img"></p>
<p>鲲鹏 RoadMap</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/kunpeng-future-roadmap-1024x512.png" alt="img"></p>
<h4 id="鲲鹏-Kunpeng-920-4826-跨numa性能比较"><a href="#鲲鹏-Kunpeng-920-4826-跨numa性能比较" class="headerlink" title="鲲鹏 Kunpeng 920-4826 跨numa性能比较"></a>鲲鹏 Kunpeng 920-4826 跨numa性能比较</h4><p>绑24core，跨numa0、numa3，是numactl -H看到的比较远距离。两分钟的 Current tpmC: 69660</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#taskset -a -cp  12-23,72-83 20799</span><br><span class="line"></span><br><span class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 20799</span><br><span class="line">^C</span><br><span class="line"> Performance counter stats for process id &apos;20799&apos;:</span><br><span class="line"></span><br><span class="line">     2,866,418,154      branch-misses                                                 (59.84%)</span><br><span class="line">   549,673,215,827      bus-cycles                                                    (59.89%)</span><br><span class="line">     2,179,816,578      cache-misses              #    2.360 % of all cache refs      (59.93%)</span><br><span class="line">    92,377,674,343      cache-references                                              (60.04%)</span><br><span class="line">   549,605,057,475      cpu-cycles                                                    (65.05%)</span><br><span class="line">   229,958,980,614      instructions              #    0.42  insn per cycle</span><br><span class="line">                                                  #    1.31  stalled cycles per insn  (65.05%)</span><br><span class="line">   146,201,062,116      stalled-cycles-backend    #   26.60% backend cycles idle      (65.08%)</span><br><span class="line">   301,814,831,043      stalled-cycles-frontend   #   54.91% frontend cycles idle     (65.08%)</span><br><span class="line">     2,177,062,319      L1-dcache-load-misses     #    2.35% of all L1-dcache hits    (65.04%)</span><br><span class="line">    92,481,797,426      L1-dcache-loads                                               (65.11%)</span><br><span class="line">     2,175,030,428      L1-dcache-store-misses                                        (65.15%)</span><br><span class="line">    92,507,474,710      L1-dcache-stores                                              (65.14%)</span><br><span class="line">     9,299,812,249      L1-icache-load-misses     #   12.47% of all L1-icache hits    (65.20%)</span><br><span class="line">    74,579,909,037      L1-icache-loads                                               (65.16%)</span><br><span class="line">     2,862,664,443      branch-load-misses                                            (65.08%)</span><br><span class="line">    52,826,930,842      branch-loads                                                  (65.04%)</span><br><span class="line">     3,729,265,130      dTLB-load-misses          #    3.11% of all dTLB cache hits   (64.95%)</span><br><span class="line">   119,896,014,498      dTLB-loads                                                    (59.90%)</span><br><span class="line">     1,350,782,047      iTLB-load-misses          #    1.83% of all iTLB cache hits   (59.84%)</span><br><span class="line">    74,005,620,378      iTLB-loads                                                    (59.82%)</span><br><span class="line">               510      cpu-migrations</span><br><span class="line"></span><br><span class="line">       9.483137760 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>绑72-95core，在同一个numa下，但是没有重启进程，导致有一半内存仍然在numa0上，2分钟的Current tpmC: 75900</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#taskset -a -cp  72-95 20799</span><br><span class="line"></span><br><span class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 20799</span><br><span class="line">^C</span><br><span class="line"> Performance counter stats for process id &apos;20799&apos;:</span><br><span class="line"></span><br><span class="line">     2,665,583,722      branch-misses                                                 (59.90%)</span><br><span class="line">   500,184,789,050      bus-cycles                                                    (59.95%)</span><br><span class="line">     1,997,726,097      cache-misses              #    2.254 % of all cache refs      (59.94%)</span><br><span class="line">    88,628,013,529      cache-references                                              (59.93%)</span><br><span class="line">   500,111,712,450      cpu-cycles                                                    (64.98%)</span><br><span class="line">   221,098,464,920      instructions              #    0.44  insn per cycle</span><br><span class="line">                                                  #    1.35  stalled cycles per insn  (65.02%)</span><br><span class="line">   105,957,124,479      stalled-cycles-backend    #   21.19% backend cycles idle      (65.02%)</span><br><span class="line">   298,186,439,955      stalled-cycles-frontend   #   59.62% frontend cycles idle     (65.02%)</span><br><span class="line">     1,996,313,908      L1-dcache-load-misses     #    2.25% of all L1-dcache hits    (65.04%)</span><br><span class="line">    88,701,699,646      L1-dcache-loads                                               (65.09%)</span><br><span class="line">     1,997,851,364      L1-dcache-store-misses                                        (65.10%)</span><br><span class="line">    88,614,658,960      L1-dcache-stores                                              (65.10%)</span><br><span class="line">     8,635,807,737      L1-icache-load-misses     #   12.30% of all L1-icache hits    (65.13%)</span><br><span class="line">    70,233,323,630      L1-icache-loads                                               (65.16%)</span><br><span class="line">     2,665,567,783      branch-load-misses                                            (65.10%)</span><br><span class="line">    50,482,936,168      branch-loads                                                  (65.09%)</span><br><span class="line">     3,614,564,473      dTLB-load-misses          #    3.15% of all dTLB cache hits   (65.04%)</span><br><span class="line">   114,619,822,486      dTLB-loads                                                    (59.96%)</span><br><span class="line">     1,270,926,362      iTLB-load-misses          #    1.81% of all iTLB cache hits   (59.97%)</span><br><span class="line">    70,248,645,721      iTLB-loads                                                    (59.94%)</span><br><span class="line">               128      cpu-migrations</span><br><span class="line"></span><br><span class="line">       8.610934700 seconds time elapsed</span><br><span class="line"></span><br><span class="line">#/root/numa-maps-summary.pl &lt;/proc/20799/numa_maps</span><br><span class="line">N0        :      8220658 ( 31.36 GB)</span><br><span class="line">N1        :        38620 (  0.15 GB)</span><br><span class="line">N2        :       480619 (  1.83 GB)</span><br><span class="line">N3        :      8281759 ( 31.59 GB)</span><br><span class="line">active    :        28797 (  0.11 GB)</span><br><span class="line">anon      :     17015902 ( 64.91 GB)</span><br><span class="line">dirty     :     16990615 ( 64.81 GB)</span><br><span class="line">kernelpagesize_kB:         9076 (  0.03 GB)</span><br><span class="line">mapmax    :          760 (  0.00 GB)</span><br><span class="line">mapped    :         5754 (  0.02 GB)</span><br></pre></td></tr></table></figure>

<p>重启进程后继续绑72-95core，在同一个numa下，先进成充分热身，然后2分钟的 Current tpmC: 77880</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 49512</span><br><span class="line">^C</span><br><span class="line"> Performance counter stats for process id &apos;49512&apos;:</span><br><span class="line"></span><br><span class="line">     1,849,313,199      branch-misses                                                 (59.99%)</span><br><span class="line">   319,122,053,367      bus-cycles                                                    (60.02%)</span><br><span class="line">     1,319,212,546      cache-misses              #    2.238 % of all cache refs      (59.95%)</span><br><span class="line">    58,950,581,370      cache-references                                              (60.02%)</span><br><span class="line">   319,088,767,311      cpu-cycles                                                    (65.01%)</span><br><span class="line">   146,580,891,374      instructions              #    0.46  insn per cycle</span><br><span class="line">                                                  #    1.32  stalled cycles per insn  (65.01%)</span><br><span class="line">    61,109,919,226      stalled-cycles-backend    #   19.15% backend cycles idle      (65.04%)</span><br><span class="line">   193,963,590,196      stalled-cycles-frontend   #   60.79% frontend cycles idle     (65.06%)</span><br><span class="line">     1,319,593,051      L1-dcache-load-misses     #    2.24% of all L1-dcache hits    (65.03%)</span><br><span class="line">    58,967,303,454      L1-dcache-loads                                               (65.04%)</span><br><span class="line">     1,318,842,690      L1-dcache-store-misses                                        (65.13%)</span><br><span class="line">    58,988,059,583      L1-dcache-stores                                              (65.07%)</span><br><span class="line">     5,769,871,870      L1-icache-load-misses     #   12.25% of all L1-icache hits    (65.12%)</span><br><span class="line">    47,085,299,316      L1-icache-loads                                               (65.10%)</span><br><span class="line">     1,850,419,802      branch-load-misses                                            (65.03%)</span><br><span class="line">    33,687,548,636      branch-loads                                                  (65.08%)</span><br><span class="line">     2,375,028,039      dTLB-load-misses          #    3.12% of all dTLB cache hits   (65.08%)</span><br><span class="line">    76,113,084,244      dTLB-loads                                                    (60.01%)</span><br><span class="line">       825,388,210      iTLB-load-misses          #    1.75% of all iTLB cache hits   (59.99%)</span><br><span class="line">    47,092,738,092      iTLB-loads                                                    (59.95%)</span><br><span class="line">                49      cpu-migrations</span><br><span class="line"></span><br><span class="line">#/root/numa-maps-summary.pl &lt;/proc/49512/numa_maps</span><br><span class="line">N0        :         5765 (  0.02 GB)</span><br><span class="line">N1        :        41599 (  0.16 GB)</span><br><span class="line">N2        :          566 (  0.00 GB)</span><br><span class="line">N3        :     16955491 ( 64.68 GB)</span><br><span class="line">active    :        30430 (  0.12 GB)</span><br><span class="line">anon      :     16997663 ( 64.84 GB)</span><br><span class="line">dirty     :     16989252 ( 64.81 GB)</span><br><span class="line">kernelpagesize_kB:         9020 (  0.03 GB)</span><br><span class="line">mapmax    :          745 (  0.00 GB)</span><br><span class="line">mapped    :         5758 (  0.02 GB)</span><br></pre></td></tr></table></figure>

<p>IPC从0.42到0.44再到0.46，tpmC也不断增加，整体压力都不大只压了25%的CPU，所以跨NUMA大概有10%的性能差异. IPC也是0.42 VS 0.46 。测试场景是DRDS Server服务。</p>
<p>如果跨4core绑定core的话最好和最差绑法性能会下降25-30%，四个core绑不同numa的性能比较</p>
<table>
<thead>
<tr>
<th>被压进程绑定的core id</th>
<th>tpmC</th>
</tr>
</thead>
<tbody><tr>
<td>72,73,74,75</td>
<td>14460</td>
</tr>
<tr>
<td>48,49,72,73</td>
<td>13800</td>
</tr>
<tr>
<td>24,25,72,73</td>
<td>11760</td>
</tr>
<tr>
<td>0,1,72,73</td>
<td>11940</td>
</tr>
<tr>
<td>0,24,48,72</td>
<td>10800</td>
</tr>
</tbody></table>
<h3 id="飞腾2500"><a href="#飞腾2500" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">#lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                128</span><br><span class="line">On-line CPU(s) list:   0-127</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    64</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          16</span><br><span class="line">Model:                 3</span><br><span class="line">BogoMIPS:              100.00</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              2048K</span><br><span class="line">L3 cache:              65536K</span><br><span class="line">NUMA node0 CPU(s):     0-7</span><br><span class="line">NUMA node1 CPU(s):     8-15</span><br><span class="line">NUMA node2 CPU(s):     16-23</span><br><span class="line">NUMA node3 CPU(s):     24-31</span><br><span class="line">NUMA node4 CPU(s):     32-39</span><br><span class="line">NUMA node5 CPU(s):     40-47</span><br><span class="line">NUMA node6 CPU(s):     48-55</span><br><span class="line">NUMA node7 CPU(s):     56-63</span><br><span class="line">NUMA node8 CPU(s):     64-71</span><br><span class="line">NUMA node9 CPU(s):     72-79</span><br><span class="line">NUMA node10 CPU(s):    80-87</span><br><span class="line">NUMA node11 CPU(s):    88-95</span><br><span class="line">NUMA node12 CPU(s):    96-103</span><br><span class="line">NUMA node13 CPU(s):    104-111</span><br><span class="line">NUMA node14 CPU(s):    112-119</span><br><span class="line">NUMA node15 CPU(s):    120-127</span><br><span class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</span><br><span class="line"></span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15</span><br><span class="line">  0:  10  20  40  30  20  30  50  40  100  100  100  100  100  100  100  100</span><br><span class="line">  1:  20  10  30  40  50  20  40  50  100  100  100  100  100  100  100  100</span><br><span class="line">  2:  40  30  10  20  40  50  20  30  100  100  100  100  100  100  100  100</span><br><span class="line">  3:  30  40  20  10  30  20  40  50  100  100  100  100  100  100  100  100</span><br><span class="line">  4:  20  50  40  30  10  50  30  20  100  100  100  100  100  100  100  100</span><br><span class="line">  5:  30  20  50  20  50  10  50  40  100  100  100  100  100  100  100  100</span><br><span class="line">  6:  50  40  20  40  30  50  10  30  100  100  100  100  100  100  100  100</span><br><span class="line">  7:  40  50  30  50  20  40  30  10  100  100  100  100  100  100  100  100</span><br><span class="line">  8:  100  100  100  100  100  100  100  100  10  20  40  30  20  30  50  40</span><br><span class="line">  9:  100  100  100  100  100  100  100  100  20  10  30  40  50  20  40  50</span><br><span class="line"> 10:  100  100  100  100  100  100  100  100  40  30  10  20  40  50  20  30</span><br><span class="line"> 11:  100  100  100  100  100  100  100  100  30  40  20  10  30  20  40  50</span><br><span class="line"> 12:  100  100  100  100  100  100  100  100  20  50  40  30  10  50  30  20</span><br><span class="line"> 13:  100  100  100  100  100  100  100  100  30  20  50  20  50  10  50  40</span><br><span class="line"> 14:  100  100  100  100  100  100  100  100  50  40  20  40  30  50  10  30</span><br><span class="line"> 15:  100  100  100  100  100  100  100  100  40  50  30  50  20  40  30  10</span><br><span class="line"></span><br><span class="line">#dmidecode -t processor</span><br><span class="line"># dmidecode 3.0</span><br><span class="line">Getting SMBIOS data from sysfs.</span><br><span class="line">SMBIOS 3.2.0 present.</span><br><span class="line"># SMBIOS implementations newer than version 3.0 are not</span><br><span class="line"># fully supported by this version of dmidecode.</span><br><span class="line"></span><br><span class="line">Handle 0x0004, DMI type 4, 48 bytes</span><br><span class="line">Processor Information</span><br><span class="line">    Socket Designation: BGA3576</span><br><span class="line">    Type: Central Processor</span><br><span class="line">    Family: &lt;OUT OF SPEC&gt;</span><br><span class="line">    Manufacturer: PHYTIUM</span><br><span class="line">    ID: 00 00 00 00 70 1F 66 22</span><br><span class="line">    Version: FT2500</span><br><span class="line">    Voltage: 0.8 V</span><br><span class="line">    External Clock: 50 MHz</span><br><span class="line">    Max Speed: 2100 MHz</span><br><span class="line">    Current Speed: 2100 MHz</span><br><span class="line">    Status: Populated, Enabled</span><br><span class="line">    Upgrade: Other</span><br><span class="line">    L1 Cache Handle: 0x0005</span><br><span class="line">    L2 Cache Handle: 0x0007</span><br><span class="line">    L3 Cache Handle: 0x0008</span><br><span class="line">    Serial Number: 1234567</span><br><span class="line">    Asset Tag: No Asset Tag</span><br><span class="line">    Part Number: NULL</span><br><span class="line">    Core Count: 64</span><br><span class="line">    Core Enabled: 64</span><br><span class="line">    Thread Count: 64</span><br><span class="line">    Characteristics:</span><br><span class="line">        64-bit capable</span><br><span class="line">        Multi-Core</span><br><span class="line">        Hardware Thread</span><br><span class="line">        Execute Protection</span><br><span class="line">        Enhanced Virtualization</span><br><span class="line">        Power/Performance Control</span><br></pre></td></tr></table></figure>

<h3 id="申威3231"><a href="#申威3231" class="headerlink" title="申威3231"></a>申威3231</h3><p>申威系列微处理器的开发主要是被<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD" target="_blank" rel="noopener">中华人民共和国</a>用于军事方面[<a href="https://zh.wikipedia.org/wiki/Wikipedia:%E5%88%97%E6%98%8E%E6%9D%A5%E6%BA%90" target="_blank" rel="noopener">来源请求]</a>。根据部分公开信息表明，此系列的微体系架构基于<a href="https://zh.wikipedia.org/wiki/DEC_Alpha" target="_blank" rel="noopener">DEC Alpha</a>派生而来。[<a href="https://zh.wikipedia.org/wiki/%E7%94%B3%E5%A8%81%E5%A4%84%E7%90%86%E5%99%A8#cite_note-gen123-1" target="_blank" rel="noopener">1]</a>[<a href="https://zh.wikipedia.org/wiki/%E7%94%B3%E5%A8%81%E5%A4%84%E7%90%86%E5%99%A8#cite_note-linkedin-chengang-2" target="_blank" rel="noopener">2]</a>而SW-3&#x2F;SW1600处理器则是基于Alpha 21164。[<a href="https://zh.wikipedia.org/wiki/%E7%94%B3%E5%A8%81%E5%A4%84%E7%90%86%E5%99%A8#cite_note-3" target="_blank" rel="noopener">3]</a></p>
<p>不过申威系列最新的SW26010处理器，目前没有详细的信息表明它是基于DEC Alpha微架构的派生品。[<a href="https://zh.wikipedia.org/wiki/%E7%94%B3%E5%A8%81%E5%A4%84%E7%90%86%E5%99%A8#cite_note-dongarra2016-4" target="_blank" rel="noopener">4]</a>[<a href="https://zh.wikipedia.org/wiki/%E7%94%B3%E5%A8%81%E5%A4%84%E7%90%86%E5%99%A8#cite_note-next-platform-5" target="_blank" rel="noopener">5]</a>不过处理器的处理器核心结构布局，则是类似于基于POWER指令集架构的<a href="https://zh.wikipedia.org/wiki/Cell_(%E5%BE%AE%E8%99%95%E7%90%86%E5%99%A8)" target="_blank" rel="noopener">Cell微架构</a>。</p>
<p>申威 3231处理器是基于第三代“申威 64” 二次优化版核心（C3B）的国产高性能多核处理器。3231的内核与1621属于同一代，采用新一代工艺，最高主频2.5Ghz，32核心，3231基本上可以视为1621换工艺后的32核版本，主要面向高性能计算和高端服务器应用。</p>
<p>申威 3231采用“申威64”自主指令系统；</p>
<p>基于第三代“申威 64”二次优化版核心（C3B）的32核64位通用处理器;</p>
<p>采用CC-NUMA多核结构和SoC技术，片内包含8路DDR4存储控制器接口以及40lane的PCI-E 4.0标准I&#x2F;O接口；</p>
<p>集成3路直连接口，可构建2路或4路服务器系统；</p>
<p>计算性能：双精度浮点性能可达1280GFlops，整数性能可达880Gops；</p>
<p>访存性能：最大传输率为3200Mbps，最大总存储器容量2TB；</p>
<p>I&#x2F;O性能：双向聚合有效带宽可达到160GB&#x2F;s，支持I&#x2F;O虚拟化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/641.png" alt="img"></p>
<p>3232推出的时间会比3231迟一些，采用新一代CPU核，IPC会非常惊人，保底10&#x2F;G，争取12&#x2F;G，考虑倒申威团队一向严谨，以及过去基本没有让大家失望过，因而对3232的IPC，可以采用就高原则。</p>
<p>申威 3231架构</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1604285554727-f6a30266-c4be-42b4-ad77-2fabbf066070.png" alt="image.png"></p>
<p>申威 6B 芯片结构的主要特点如下：</p>
<ul>
<li><p>全芯片集成 32 个物理核心，每个物理核心支持 1 个线程，软件可见 32 个逻辑核心；</p>
</li>
<li><p>每个物理核心集成 32KB L1 指令 Cache（ICache）、32KB L1 数据 Cache（DCache）和 512KB 的 L2 Cache（SCache），核心内的所有 Cache 为核心私有 Cache；</p>
</li>
<li><p>全芯片集成 64MB 的 L3 Cache（TCache），本芯片内所有核心分布共享，TCache 由16 个体组成，每个体跟2 个物理核心及其对应的管理部件（LCPM）一起组成一个核组，连接在环网节点上，核心访问不同 TCache 体中的副本延迟略有不同；</p>
</li>
<li><p>存储器接口：全芯片集成 8 个 DDR4 存储器通道，每个通道数据宽度为 72bit（含 8 位 ECC），支持 UDIMM、RDIMM 和 LRDIMM，单通道内存容量最大支持 256GB 容量，单通道带宽可达 25.6GB&#x2F;s（DDR4-3200）；每4 个存储器通道对应一个主存代理部件（GCPM），所有核心和 IO 设备都可访问；</p>
</li>
<li><p>PCIe 接口：全芯片集成 40 Lane 的 PCIe 4.0 链路，支持 x4、x8 和 x16 灵活配置，最大支持 6 个 RC；</p>
</li>
<li><p>直连接口：全芯片集成 3 路直连接口，可构建 2 路或 4 路服务器系统，每路直连接口为9 个lane的serdes 接口，接口速率为28Gbps；</p>
</li>
<li><p>维护调试测试接口：维护控制部件实现芯片配置、初始引导以及提供各种维护和调试支持。维护控制部件支持芯片的上电初始化、配置加载、存储器读写或 IO 读写、维护中断以及内部状态的扫描观测等。支持外部维护通过 Jtag 接口进行初始引导；支持通过 SPI Master 接口从 SPI Flash中进行自举引导；</p>
</li>
<li><p>集成三套 I2C 接口、一套 Uart、GPIO 和 LPC 低速接口。</p>
</li>
</ul>
<p> 申威1621处理器是基于第三代“申威64”核心（增强版）的国产高性能多核处理器，主要面向高性能计算和中高端服务器应用。目前，该处理器已经实现量产。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/20170829092439580.png" alt="img">    申威1621采用对称多核结构和SoC技术，单芯片集成了16个64位RISC结构的申威处理器核心，目标设计主频为2GHz。芯片还集成八路DDR3存储控制器和双路PCI-E3.0标准I&#x2F;O接口。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">#dmidecode -t processor</span><br><span class="line"># dmidecode 3.0</span><br><span class="line">Getting SMBIOS data from sysfs.</span><br><span class="line">SMBIOS 3.2.0 present.</span><br><span class="line"># SMBIOS implementations newer than version 3.0 are not</span><br><span class="line"># fully supported by this version of dmidecode.</span><br><span class="line"></span><br><span class="line">Handle 0x0022, DMI type 4, 48 bytes</span><br><span class="line">Processor Information</span><br><span class="line">        Socket Designation: CPU 0</span><br><span class="line">        Type: Central Processor</span><br><span class="line">        Family: Other</span><br><span class="line">        Manufacturer: SW3231</span><br><span class="line">        ID: 28 00 C8 80 01 00 00 00</span><br><span class="line">        Version: Product</span><br><span class="line">        Voltage: 3.3 V</span><br><span class="line">        External Clock: 200 MHz</span><br><span class="line">        Max Speed: 2400 MHz</span><br><span class="line">        Current Speed: 2400 MHz</span><br><span class="line">        Status: Unpopulated</span><br><span class="line">        Upgrade: Other</span><br><span class="line">        L1 Cache Handle: 0x2000</span><br><span class="line">        L2 Cache Handle: 0x2002</span><br><span class="line">        L3 Cache Handle: 0x2003</span><br><span class="line">        Serial Number: .......</span><br><span class="line">        Asset Tag: Asset Tag#To Be Filled By O.E.M.</span><br><span class="line">        Part Number: Part Number#To Be Filled By O.E.M.</span><br><span class="line">        Core Count: 32</span><br><span class="line">        Core Enabled: 32</span><br><span class="line">        Thread Count: 0</span><br><span class="line">        Characteristics:</span><br><span class="line">                64-bit capable</span><br><span class="line"></span><br><span class="line">Handle 0x0023, DMI type 4, 48 bytes</span><br><span class="line">Processor Information</span><br><span class="line">        Socket Designation: CPU 1</span><br><span class="line">        Type: Central Processor</span><br><span class="line">        Family: Other</span><br><span class="line">        Manufacturer: SW3231</span><br><span class="line">        ID: 28 00 C8 80 01 00 00 00</span><br><span class="line">        Version: Product</span><br><span class="line">        Voltage: 3.3 V</span><br><span class="line">        External Clock: 200 MHz</span><br><span class="line">        Max Speed: 2400 MHz</span><br><span class="line">        Current Speed: 2400 MHz</span><br><span class="line">        Status: Unpopulated</span><br><span class="line">        Upgrade: Other</span><br><span class="line">        L1 Cache Handle: 0x2000</span><br><span class="line">        L2 Cache Handle: 0x2002</span><br><span class="line">        L3 Cache Handle: 0x2003</span><br><span class="line">        Serial Number: .......</span><br><span class="line">        Asset Tag: Asset Tag#To Be Filled By O.E.M.</span><br><span class="line">        Part Number: Part Number#To Be Filled By O.E.M.</span><br><span class="line">        Core Count: 32</span><br><span class="line">        Core Enabled: 32</span><br><span class="line">        Thread Count: 0</span><br><span class="line">        Characteristics:</span><br><span class="line">                64-bit capable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@d22b04001.cloud.b04.amtest11 /root] 193E_OPS1</span><br><span class="line">#numactl -H</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31</span><br><span class="line">node 0 size: 259482 MB</span><br><span class="line">node 0 free: 121171 MB</span><br><span class="line">node 1 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63</span><br><span class="line">node 1 size: 260091 MB</span><br><span class="line">node 1 free: 88564 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  20</span><br><span class="line">  1:  20  10</span><br><span class="line"></span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          sw_64</span><br><span class="line">CPU op-mode(s):        64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    32</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             sw</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 6</span><br><span class="line">Model name:            sw</span><br><span class="line">CPU MHz:               2400.00</span><br><span class="line">BogoMIPS:              4800.00</span><br><span class="line">NUMA node0 CPU(s):     0-31</span><br><span class="line">NUMA node1 CPU(s):     32-63</span><br></pre></td></tr></table></figure>

<h2 id="openssl-speed-aes-256-ige性能比较"><a href="#openssl-speed-aes-256-ige性能比较" class="headerlink" title="openssl speed aes-256-ige性能比较"></a>openssl speed aes-256-ige性能比较</h2><p>测试脚本</p>
<blockquote>
<p>openssl speed aes-256-ige -multi 1</p>
</blockquote>
<p>单核能力</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige      89602.86k    97498.37k    98271.49k    98399.91k    89101.65k</th>
</tr>
</thead>
<tbody><tr>
<td>海光（32物理core）</td>
<td>aes-256 ige      76919.66k    77935.81k    79201.88k    79529.30k    79555.24k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige     133174.89k   140578.99k   142156.46k   142663.34k   143196.16k</td>
</tr>
</tbody></table>
<p>测试32个线程并行</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige    2642742.25k  2690638.98k  2703860.74k  2734114.82k  2680422.40</th>
</tr>
</thead>
<tbody><tr>
<td>海光（32物理core）</td>
<td>aes-256 ige    2464568.75k  2499381.80k  2528665.34k  2544845.14k  2550723.93k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige    4261589.92k  4501245.55k  4552731.56k  4570456.75k  4584330.58k</td>
</tr>
</tbody></table>
<p>将所有核跑满包括HT</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige    4869950.82k  5179884.71k  5135412.14k  5211367.08k  5247858.60k</th>
</tr>
</thead>
<tbody><tr>
<td>海光（32物理core）</td>
<td>aes-256 ige    2730195.74k  2836759.53k  2865252.35k  2857900.71k  2884302.17k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige   12788358.79k 13502288.53k 13657385.98k 13710908.76k 13751432.53k</td>
</tr>
</tbody></table>
<h2 id="单核计算-7-999999”-的性能对比"><a href="#单核计算-7-999999”-的性能对比" class="headerlink" title="单核计算 7^999999” 的性能对比"></a>单核计算 7^999999” 的性能对比</h2><p>测试命令：bash -c ‘echo “7^999999” | bc &gt; &#x2F;dev&#x2F;null’</p>
<table>
<thead>
<tr>
<th></th>
<th>执行时间(秒)</th>
<th>IPC</th>
<th>主频</th>
</tr>
</thead>
<tbody><tr>
<td>海光</td>
<td>26.729972414</td>
<td>0.92</td>
<td>2.5G</td>
</tr>
<tr>
<td>鲲鹏920</td>
<td>24.604603640</td>
<td>1.84</td>
<td>2.6G</td>
</tr>
<tr>
<td>飞腾2500</td>
<td>39.654819568</td>
<td>0.43</td>
<td>2.1G</td>
</tr>
<tr>
<td>Intel</td>
<td>18.603323495</td>
<td>2.19</td>
<td>2.5G</td>
</tr>
<tr>
<td>710</td>
<td>15.832394912</td>
<td>2.64</td>
<td>2.75G</td>
</tr>
</tbody></table>
<p>当然也可以通过计算pi值来测试</p>
<blockquote>
<p>bash -c ‘ echo “scale&#x3D;5000; 4*a(1)” | bc -l -q &gt;&#x2F;dev&#x2F;null ‘</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>执行时间(秒)</th>
<th>主频</th>
</tr>
</thead>
<tbody><tr>
<td>海光</td>
<td>31.061s</td>
<td>2.5G</td>
</tr>
<tr>
<td>鲲鹏920</td>
<td>23.521s</td>
<td>2.6G</td>
</tr>
<tr>
<td>飞腾2500</td>
<td></td>
<td>2.1G</td>
</tr>
<tr>
<td>Intel</td>
<td>22.979s(8163)</td>
<td>2.5G</td>
</tr>
<tr>
<td>710</td>
<td>15.570s</td>
<td>2.75G</td>
</tr>
</tbody></table>
<p>多核一起跑的话可以这样:</p>
<blockquote>
<p>for i in {0..95}; do time echo “scale&#x3D;5000; 4*a(1)” | bc -l -q &gt;&#x2F;dev&#x2F;null &amp; done</p>
<p>perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads – </p>
</blockquote>
<h3 id="710"><a href="#710" class="headerlink" title="710"></a>710</h3><p>耗时15.83秒，ipc 2.64</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-icache-load-misses,L1-icache-loads,LLC-load-misses,LLC-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;bash -c echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;:</span><br><span class="line"></span><br><span class="line">       985,496,277      branch-misses                                                 (29.97%)</span><br><span class="line">    43,509,183,948      bus-cycles                # 2748.210 M/sec                    (29.97%)</span><br><span class="line">         7,068,868      cache-misses              #    0.020 % of all cache refs      (29.96%)</span><br><span class="line">    35,165,185,942      cache-references          # 2221.170 M/sec                    (29.97%)</span><br><span class="line">    43,508,579,063      cpu-cycles                #    2.748 GHz                      (34.97%)</span><br><span class="line">   114,779,081,188      instructions              #    2.64  insn per cycle</span><br><span class="line">                                                  #    0.04  stalled cycles per insn  (34.99%)</span><br><span class="line">     4,913,750,141      stalled-cycles-backend    #   11.29% backend cycles idle      (35.02%)</span><br><span class="line">     4,255,139,235      stalled-cycles-frontend   #    9.78% frontend cycles idle     (35.02%)</span><br><span class="line">                 0      alignment-faults          #    0.000 K/sec</span><br><span class="line">                 0      bpf-output                #    0.000 K/sec</span><br><span class="line">                24      context-switches          #    0.002 K/sec</span><br><span class="line">         15,831.82 msec cpu-clock                 #    1.000 CPUs utilized</span><br></pre></td></tr></table></figure>

<h3 id="intel"><a href="#intel" class="headerlink" title="intel"></a>intel</h3><p>耗时18.60秒，ipc 2.19</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># sudo perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;bash -c echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;:</span><br><span class="line"></span><br><span class="line">    25,130,886,211      branch-instructions                                           (10.72%)</span><br><span class="line">     1,200,086,175      branch-misses             #    4.78% of all branches          (14.29%)</span><br><span class="line">       460,824,074      bus-cycles                                                    (14.29%)</span><br><span class="line">         1,983,459      cache-misses              #   46.066 % of all cache refs      (14.30%)</span><br><span class="line">         4,305,730      cache-references                                              (14.30%)</span><br><span class="line">    58,626,314,801      cpu-cycles                                                    (17.87%)</span><br><span class="line">   128,284,870,917      instructions              #    2.19  insn per cycle           (21.45%)</span><br><span class="line">    46,040,656,499      ref-cycles                                                    (25.02%)</span><br><span class="line">        22,821,794      L1-dcache-load-misses     #    0.10% of all L1-dcache hits    (25.02%)</span><br><span class="line">    23,041,732,649      L1-dcache-loads                                               (25.01%)</span><br><span class="line">     5,386,243,625      L1-dcache-stores                                              (25.00%)</span><br><span class="line">        12,443,154      L1-icache-load-misses                                         (25.00%)</span><br><span class="line">           178,790      LLC-load-misses           #   30.52% of all LL-cache hits     (14.28%)</span><br><span class="line">           585,724      LLC-loads                                                     (14.28%)</span><br><span class="line">           469,381      LLC-store-misses                                              (7.14%)</span><br><span class="line">           664,865      LLC-stores                                                    (7.14%)</span><br><span class="line">     1,201,547,113      branch-load-misses                                            (10.71%)</span><br><span class="line">    25,139,625,428      branch-loads                                                  (14.28%)</span><br><span class="line">            63,334      dTLB-load-misses          #    0.00% of all dTLB cache hits   (14.28%)</span><br><span class="line">    23,023,969,089      dTLB-loads                                                    (14.28%)</span><br><span class="line">            17,355      dTLB-store-misses                                             (14.28%)</span><br><span class="line">     5,378,496,562      dTLB-stores                                                   (14.28%)</span><br><span class="line">           341,119      iTLB-load-misses          #  119.92% of all iTLB cache hits   (14.28%)</span><br><span class="line">           284,445      iTLB-loads                                                    (14.28%)</span><br><span class="line">           151,608      node-load-misses                                              (14.28%)</span><br><span class="line">            37,553      node-loads                                                    (14.29%)</span><br><span class="line">           434,537      node-store-misses                                             (7.14%)</span><br><span class="line">            65,709      node-stores                                                   (7.14%)</span><br><span class="line"></span><br><span class="line">      18.603323495 seconds time elapsed</span><br><span class="line"></span><br><span class="line">      18.525904000 seconds user</span><br><span class="line">       0.015197000 seconds sys</span><br></pre></td></tr></table></figure>

<h3 id="鲲鹏920-1"><a href="#鲲鹏920-1" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>耗时24.6秒, IPC 1.84</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;bash -c echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;:</span><br><span class="line"></span><br><span class="line">     1,467,769,425      branch-misses                                                 (59.94%)</span><br><span class="line">    63,866,536,853      bus-cycles                                                    (59.94%)</span><br><span class="line">         6,571,273      cache-misses              #    0.021 % of all cache refs      (59.94%)</span><br><span class="line">    30,768,754,927      cache-references                                              (59.96%)</span><br><span class="line">    63,865,354,560      cpu-cycles                                                    (64.97%)</span><br><span class="line">   117,790,453,518      instructions              #    1.84  insns per cycle</span><br><span class="line">                                                  #    0.07  stalled cycles per insn  (64.98%)</span><br><span class="line">       833,090,930      stalled-cycles-backend    #    1.30% backend  cycles idle     (65.00%)</span><br><span class="line">     7,918,227,782      stalled-cycles-frontend   #   12.40% frontend cycles idle     (65.01%)</span><br><span class="line">         6,962,902      L1-dcache-load-misses     #    0.02% of all L1-dcache hits    (65.03%)</span><br><span class="line">    30,804,266,645      L1-dcache-loads                                               (65.05%)</span><br><span class="line">         6,960,157      L1-dcache-store-misses                                        (65.06%)</span><br><span class="line">    30,807,954,068      L1-dcache-stores                                              (65.06%)</span><br><span class="line">         1,012,171      L1-icache-load-misses                                         (65.06%)</span><br><span class="line">    45,256,066,296      L1-icache-loads                                               (65.04%)</span><br><span class="line">     1,470,467,198      branch-load-misses                                            (65.03%)</span><br><span class="line">    27,108,794,972      branch-loads                                                  (65.01%)</span><br><span class="line">           475,707      dTLB-load-misses          #    0.00% of all dTLB cache hits   (65.00%)</span><br><span class="line">    35,159,826,836      dTLB-loads                                                    (59.97%)</span><br><span class="line">               912      iTLB-load-misses          #    0.00% of all iTLB cache hits   (59.96%)</span><br><span class="line">    45,325,885,822      iTLB-loads                                                    (59.94%)</span><br><span class="line"></span><br><span class="line">      24.604603640 seconds time elapsed</span><br></pre></td></tr></table></figure>

<h3 id="海光-1"><a href="#海光-1" class="headerlink" title="海光"></a>海光</h3><p>耗时 26.73秒, IPC 0.92</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">sudo perf stat -e branch-instructions,branch-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-prefetches,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -a -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;system wide&apos;:</span><br><span class="line"></span><br><span class="line">    57,795,675,025      branch-instructions                                           (27.78%)</span><br><span class="line">     2,459,509,459      branch-misses             #    4.26% of all branches          (27.78%)</span><br><span class="line">    12,171,133,272      cache-references                                              (27.79%)</span><br><span class="line">   317,353,262,523      cpu-cycles                                                    (27.79%)</span><br><span class="line">   293,162,940,548      instructions              #    0.92  insn per cycle</span><br><span class="line">                                                  #    0.19  stalled cycles per insn  (27.79%)</span><br><span class="line">    55,152,807,029      stalled-cycles-backend    #   17.38% backend cycles idle      (27.79%)</span><br><span class="line">    44,410,732,991      stalled-cycles-frontend   #   13.99% frontend cycles idle     (27.79%)</span><br><span class="line">     4,065,273,083      L1-dcache-load-misses     #    3.58% of all L1-dcache hits    (27.79%)</span><br><span class="line">   113,699,208,151      L1-dcache-loads                                               (27.79%)</span><br><span class="line">     1,351,513,191      L1-dcache-prefetches                                          (27.79%)</span><br><span class="line">     2,091,035,340      L1-icache-load-misses     #    4.43% of all L1-icache hits    (27.79%)</span><br><span class="line">    47,240,289,316      L1-icache-loads                                               (27.79%)</span><br><span class="line">     2,459,838,728      branch-load-misses                                            (27.79%)</span><br><span class="line">    57,855,156,991      branch-loads                                                  (27.78%)</span><br><span class="line">        69,731,473      dTLB-load-misses          #   20.40% of all dTLB cache hits   (27.78%)</span><br><span class="line">       341,773,319      dTLB-loads                                                    (27.78%)</span><br><span class="line">        26,351,132      iTLB-load-misses          #   15.91% of all iTLB cache hits   (27.78%)</span><br><span class="line">       165,656,863      iTLB-loads                                                    (27.78%)</span><br><span class="line"></span><br><span class="line">      26.729972414 seconds time elapsed</span><br></pre></td></tr></table></figure>

<h3 id="飞腾"><a href="#飞腾" class="headerlink" title="飞腾"></a>飞腾</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">time perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses -a -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;system wide&apos;:</span><br><span class="line"></span><br><span class="line">        2552812813      branch-misses                                                 (38.08%)</span><br><span class="line">      602038279874      bus-cycles                                                    (37.54%)</span><br><span class="line">        1742826523      cache-misses              #    2.017 % of all cache refs      (37.54%)</span><br><span class="line">       86400294181      cache-references                                              (37.55%)</span><br><span class="line">      612467194375      cpu-cycles                                                    (43.79%)</span><br><span class="line">      263691445872      instructions              #    0.43  insns per cycle          (43.79%)</span><br><span class="line">        1706247569      L1-dcache-load-misses     #    2.00% of all L1-dcache hits    (43.78%)</span><br><span class="line">       85122454139      L1-dcache-loads                                               (43.77%)</span><br><span class="line">        1711243358      L1-dcache-store-misses                                        (39.38%)</span><br><span class="line">       86288158984      L1-dcache-stores                                              (37.52%)</span><br><span class="line">        2006641212      L1-icache-load-misses                                         (37.51%)</span><br><span class="line">      146380907111      L1-icache-loads                                               (37.51%)</span><br><span class="line">        2560208048      branch-load-misses                                            (37.52%)</span><br><span class="line">       63127187342      branch-loads                                                  (41.38%)</span><br><span class="line">         768494735      dTLB-load-misses                                              (43.77%)</span><br><span class="line">         124424415      iTLB-load-misses                                              (43.77%)</span><br><span class="line"></span><br><span class="line">      39.654819568 seconds time elapsed</span><br><span class="line"></span><br><span class="line">real    0m39.763s</span><br><span class="line">user    0m39.635s</span><br><span class="line">sys    0m0.127s</span><br></pre></td></tr></table></figure>

<h2 id="perf-数据对比"><a href="#perf-数据对比" class="headerlink" title="perf 数据对比"></a>perf 数据对比</h2><h3 id="Intel"><a href="#Intel" class="headerlink" title="Intel"></a>Intel</h3><p>intel的cpu随着线程的增加，ipc稳定减少，但不是线性的</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/dcb68dff74ace2cf6f9c30378acdb377.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/d0151c855011b24590efd672398bd9eb.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/175a1df9274a830d4a7157dfda96c180.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/e63a992fcd1df547568eb93f515a5c99.png" alt="image.png"></p>
<h3 id="海光-2"><a href="#海光-2" class="headerlink" title="海光"></a>海光</h3><p>如下数据可以看到在用满32个物理core之前，ipc保持稳定，超过32core后随着并发增加ipc相应减少，性能再也上不去了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/ded1ee0ed8d5d2fa3822e6fdfa4335f1.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/0f2410165932835a36d8c0611877ae77.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/67df9ff04209a00bd864ba21b7593477.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/1bc01f6e880c7e49672170f940ff40a0.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/307d30c2b3507d5561d774f96b13e67a.png" alt="image.png"></p>
<h3 id="鲲鹏920-2"><a href="#鲲鹏920-2" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>可以看到<strong>鲲鹏920多核跑openssl是没有什么争抢的，所以还能保证完全线性</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/39720b5eb41937b462e1772854e2d832.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/a98a482a10f09bccd4a6ac49fd2850b9.png" alt="image.png"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>intel的流水线适合跑高带宽应用，不适合跑密集计算应用，也就是intel的pipeline数量少，但是内存读写上面优化好，乱序优化好。跑纯计算，不是intel的强项。</p>
<p>数据库场景下鲲鹏920大概相当于X86的70%的能力</p>
<p>prime计算一般走的fpu，不走cpu</p>
<h2 id="intel-x86-cpu-bound和memory-bond数据"><a href="#intel-x86-cpu-bound和memory-bond数据" class="headerlink" title="intel x86 cpu bound和memory bond数据"></a>intel x86 cpu bound和memory bond数据</h2><p>测试代码</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;emmintrin.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> a = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">memory_bound</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">register</span> <span class="keyword">unsigned</span> i=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">register</span> <span class="keyword">char</span> b;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;(<span class="number">1u</span>&lt;&lt;<span class="number">24</span>);i++) &#123;</span><br><span class="line">                <span class="comment">// evict cacheline containing a</span></span><br><span class="line">                 _mm_clflush(&amp;a);</span><br><span class="line">                 b = a;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cpu_bound</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">register</span> <span class="keyword">unsigned</span> i=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;(<span class="number">1u</span>&lt;&lt;<span class="number">31</span>);i++) &#123;</span><br><span class="line">                __asm__ (<span class="string">"nop\nnop\nnop"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;<span class="number">10</span>; ++i)&#123;</span><br><span class="line">                 <span class="comment">//cpu_bound();</span></span><br><span class="line">                 memory_bound();</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a><strong>测试结果</strong></h3><p><strong>cpu_bound部分飞腾只有intel性能的30%</strong></p>
<p>如下测试perf数据可以看到IPC的明显差异</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> sudo perf <span class="built_in">stat</span> -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -a ./memory_bound</span></span><br><span class="line"></span><br><span class="line"> Performance counter stats for 'system wide':</span><br><span class="line"></span><br><span class="line">    36,162,872,212      branch-instructions                                           (14.21%)</span><br><span class="line">       586,644,153      branch-misses             #    1.62% of all branches          (12.95%)</span><br><span class="line">     4,632,787,085      bus-cycles                                                    (14.40%)</span><br><span class="line">       476,189,785      cache-misses              #   17.714 % of all cache refs      (14.38%)</span><br><span class="line">     2,688,284,129      cache-references                                              (14.35%)</span><br><span class="line">   258,946,713,506      cpu-cycles                                                    (17.93%)</span><br><span class="line">   181,069,328,200      instructions              #    0.70  insn per cycle           (21.51%)</span><br><span class="line">   456,889,428,341      ref-cycles                                                    (22.31%)</span><br><span class="line">     3,928,434,098      L1-dcache-load-misses     #    7.46% of all L1-dcache hits    (14.21%)</span><br><span class="line">    52,656,559,902      L1-dcache-loads                                               (14.31%)</span><br><span class="line">    26,711,751,387      L1-dcache-stores                                              (14.30%)</span><br><span class="line">     2,618,739,340      L1-icache-load-misses                                         (18.05%)</span><br><span class="line">       154,326,888      LLC-load-misses           #    8.60% of all LL-cache hits     (19.84%)</span><br><span class="line">     1,795,112,198      LLC-loads                                                     (9.81%)</span><br><span class="line">        66,802,375      LLC-store-misses                                              (10.19%)</span><br><span class="line">       206,810,811      LLC-stores                                                    (11.16%)</span><br><span class="line">       586,120,789      branch-load-misses                                            (14.28%)</span><br><span class="line">    36,121,237,395      branch-loads                                                  (14.29%)</span><br><span class="line">       114,927,298      dTLB-load-misses          #    0.22% of all dTLB cache hits   (14.29%)</span><br><span class="line">    52,902,163,128      dTLB-loads                                                    (14.29%)</span><br><span class="line">         7,010,297      dTLB-store-misses                                             (14.29%)</span><br><span class="line">    26,587,353,417      dTLB-stores                                                   (18.00%)</span><br><span class="line">       106,209,281      iTLB-load-misses          #  174.17% of all iTLB cache hits   (19.33%)</span><br><span class="line">        60,978,626      iTLB-loads                                                    (21.53%)</span><br><span class="line">       117,197,042      node-load-misses                                              (19.71%)</span><br><span class="line">        35,764,508      node-loads                                                    (11.65%)</span><br><span class="line">        57,655,994      node-store-misses                                             (7.80%)</span><br><span class="line">        11,563,328      node-stores                                                   (9.45%)</span><br><span class="line"></span><br><span class="line">      16.700731355 seconds time elapsed</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo perf <span class="built_in">stat</span> -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -a ./cpu_bound</span></span><br><span class="line"></span><br><span class="line"> Performance counter stats for 'system wide':</span><br><span class="line"></span><br><span class="line">    43,013,055,562      branch-instructions                                           (14.33%)</span><br><span class="line">       436,722,063      branch-misses             #    1.02% of all branches          (11.58%)</span><br><span class="line">     3,154,327,457      bus-cycles                                                    (14.31%)</span><br><span class="line">       306,977,772      cache-misses              #   17.837 % of all cache refs      (14.42%)</span><br><span class="line">     1,721,062,233      cache-references                                              (14.39%)</span><br><span class="line">   176,119,834,487      cpu-cycles                                                    (17.98%)</span><br><span class="line">   276,038,539,571      instructions              #    1.57  insn per cycle           (21.55%)</span><br><span class="line">   309,334,354,268      ref-cycles                                                    (22.31%)</span><br><span class="line">     2,551,915,790      L1-dcache-load-misses     #    6.78% of all L1-dcache hits    (13.12%)</span><br><span class="line">    37,638,319,334      L1-dcache-loads                                               (14.32%)</span><br><span class="line">    19,132,537,445      L1-dcache-stores                                              (15.73%)</span><br><span class="line">     1,834,976,400      L1-icache-load-misses                                         (18.90%)</span><br><span class="line">       131,307,343      LLC-load-misses           #   11.46% of all LL-cache hits     (19.94%)</span><br><span class="line">     1,145,964,874      LLC-loads                                                     (16.60%)</span><br><span class="line">        45,561,247      LLC-store-misses                                              (8.11%)</span><br><span class="line">       140,236,535      LLC-stores                                                    (9.60%)</span><br><span class="line">       423,294,349      branch-load-misses                                            (14.27%)</span><br><span class="line">    46,645,623,485      branch-loads                                                  (14.28%)</span><br><span class="line">        73,377,533      dTLB-load-misses          #    0.19% of all dTLB cache hits   (14.28%)</span><br><span class="line">    37,905,428,246      dTLB-loads                                                    (15.69%)</span><br><span class="line">         4,969,973      dTLB-store-misses                                             (17.21%)</span><br><span class="line">    18,729,947,580      dTLB-stores                                                   (19.71%)</span><br><span class="line">        72,073,313      iTLB-load-misses          #  167.86% of all iTLB cache hits   (20.60%)</span><br><span class="line">        42,935,532      iTLB-loads                                                    (19.16%)</span><br><span class="line">       112,306,453      node-load-misses                                              (15.35%)</span><br><span class="line">        37,239,267      node-loads                                                    (7.44%)</span><br><span class="line">        37,455,335      node-store-misses                                             (10.00%)</span><br><span class="line">         8,134,155      node-stores                                                   (8.87%)</span><br><span class="line"></span><br><span class="line">      10.838808208 seconds time elapsed</span><br></pre></td></tr></table></figure>

<h3 id="飞腾-1"><a href="#飞腾-1" class="headerlink" title="飞腾"></a>飞腾</h3><p>ipc 大概是intel的30%，加上主频也要差一些，</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">time perf <span class="built_in">stat</span> -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses -a ./cpu_bound</span></span><br><span class="line"></span><br><span class="line"> Performance counter stats for 'system wide':</span><br><span class="line"></span><br><span class="line">       10496356859      branch-misses                                                 (37.60%)</span><br><span class="line">     2813170983911      bus-cycles                                                    (37.58%)</span><br><span class="line">       17604745519      cache-misses              #    3.638 % of all cache refs      (37.55%)</span><br><span class="line">      483878256161      cache-references                                              (37.54%)</span><br><span class="line">     2818545529083      cpu-cycles                                                    (43.78%)</span><br><span class="line">     1280497827941      instructions              #    0.45  insns per cycle          (43.78%)</span><br><span class="line">       17623592806      L1-dcache-load-misses     #    3.65% of all L1-dcache hits    (43.78%)</span><br><span class="line">      482429613337      L1-dcache-loads                                               (41.83%)</span><br><span class="line">       17604561232      L1-dcache-store-misses                                        (37.53%)</span><br><span class="line">      484126081882      L1-dcache-stores                                              (37.52%)</span><br><span class="line">       17774514325      L1-icache-load-misses                                         (37.50%)</span><br><span class="line">      641046300400      L1-icache-loads                                               (37.50%)</span><br><span class="line">       10574973722      branch-load-misses                                            (39.45%)</span><br><span class="line">      273851009656      branch-loads                                                  (43.76%)</span><br><span class="line">        9457594390      dTLB-load-misses                                              (43.77%)</span><br><span class="line">        1813954093      iTLB-load-misses                                              (43.77%)</span><br><span class="line"></span><br><span class="line">      31.172754504 seconds time elapsed</span><br><span class="line"></span><br><span class="line">real    0m31.284s</span><br><span class="line">user    0m31.096s</span><br><span class="line">sys    0m0.165s</span><br></pre></td></tr></table></figure>

<h2 id="unixBench-5-1-3-性能对比"><a href="#unixBench-5-1-3-性能对比" class="headerlink" title="unixBench 5.1.3 性能对比"></a>unixBench 5.1.3 性能对比</h2><p>测试命令： .&#x2F;Run -c 1 -c 4</p>
<table>
<thead>
<tr>
<th>芯片</th>
<th>架构</th>
<th>逻辑核数</th>
<th>单核能力</th>
<th>4核能力</th>
<th>单核比值</th>
<th>4核比值</th>
<th>整机对比</th>
</tr>
</thead>
<tbody><tr>
<td>Intel 4114</td>
<td>x86</td>
<td>40</td>
<td>1150</td>
<td>3095</td>
<td>100%</td>
<td>100%</td>
<td>100%</td>
</tr>
<tr>
<td>海光 7165</td>
<td>x86</td>
<td>48</td>
<td>1586</td>
<td>2533</td>
<td>138%</td>
<td>82%</td>
<td>98%</td>
</tr>
<tr>
<td>华为鲲鹏920</td>
<td>arm</td>
<td>96</td>
<td>1168</td>
<td>2066</td>
<td>102%</td>
<td>67%</td>
<td>160%</td>
</tr>
<tr>
<td>飞腾2000</td>
<td>arm</td>
<td>64</td>
<td>731</td>
<td>1902</td>
<td>64%</td>
<td>61%</td>
<td>98%</td>
</tr>
<tr>
<td>申威1621</td>
<td>alpha</td>
<td>16</td>
<td>445</td>
<td>1065</td>
<td>39%</td>
<td>34%</td>
<td>14%</td>
</tr>
</tbody></table>
<p>以上CPU除了Intel，其它都没有HT，也就是Intel 4114实际是20个物理核。以上数据来自ata，仅供参考</p>
<h2 id="ARM-和-X86的总结"><a href="#ARM-和-X86的总结" class="headerlink" title="ARM 和 X86的总结"></a>ARM 和 X86的总结</h2><p>对比硬件：</p>
<p>ARM：泰山ARM 双路 128核心64核心&#x2F;路），2.5G，4指令&#x2F;周期，8个内存通道&#x2F;路，mips体系架构。<br>X86: intel 8163服务器 双路 48核心（24核心&#x2F;路），2.5GHZ， 6指令&#x2F;周期，96smt， 6个内存通道</p>
<p>用 Geabase(C++)  测试所得 ARM是X86 性能的1.36倍，接近理论值的1.4倍</p>
<p>理论值的计算公式：</p>
<blockquote>
<p>CPU性能验证公式：频率 x 核数 x 发射数&#x2F;周期 x 1.3&#x2F;1.5(smt2&#x2F;smt4) (smt是指超线程数量)</p>
</blockquote>
<p>ARM 优势的来源主要是工艺领先一代(7nm VS 14nm)</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>对纯CPU 运算场景，并发不超过物理core时，比如Prime运算，比如DRDS(CPU bound，IO在网络，可以加并发弥补)<ul>
<li>海光的IPC能保持稳定；</li>
<li>intel的IPC有所下降，但是QPS在IPC下降后还能完美线性</li>
</ul>
</li>
<li>在openssl和MySQL oltp_read_only场景下<ul>
<li>如果并发没超过物理core数时，海光和Intel都能随着并发的翻倍性能能增加80%</li>
<li>如果并发超过物理core数后，Intel还能随着并发的翻倍性能增加50%，海光增加就只有20%了</li>
<li>简单理解在这两个场景下Intel的HT能发挥半个物理core的作用，海光的HT就只能发挥0.2个物理core的作用了</li>
</ul>
</li>
<li>海光zen1的AMD 架构，每个core只有一个fpu，综上在多个场景下HT基本上都可以忽略</li>
<li>飞腾2500性能比较差</li>
<li>国产CPU：飞腾、鲲鹏、龙芯、申威、海光(AMD授权)、兆芯(威盛via 授权x86)</li>
<li>CPU性能验证公式：频率 x 核数 x 发射数&#x2F;周期 x 1.3&#x2F;1.5(smt2&#x2F;smt4) (smt是指超线程数量)</li>
<li>大吞吐量计算由多核CPU数量决定，多核CPU数量由制程工艺决定，制程工艺由资本决定，制程工艺资本由主流消费电子决定, 摩尔定律仍在持续</li>
</ul>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="https://bbs.huaweicloud.com/blogs/146367" target="_blank" rel="noopener">华为TaiShan服务器ARMNginx应用调优案例 大量绑核、中断、Numa等相关调优信息</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/01/CPU的制造和概念/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/01/CPU的制造和概念/" itemprop="url">CPU的制造和概念</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-01T17:30:03+08:00">
                2021-06-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU的制造和概念"><a href="#CPU的制造和概念" class="headerlink" title="CPU的制造和概念"></a>CPU的制造和概念</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">CPU性能和CACHE</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/08/13/AMD_Zen_CPU%E6%9E%B6%E6%9E%84/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"></p>
<h2 id="几个重要概念"><a href="#几个重要概念" class="headerlink" title="几个重要概念"></a>几个重要概念</h2><p>为了增加对文章的理解先解释下几个高频概念</p>
<p>Wafer：晶圆，一片大的纯硅圆盘，新闻里常说的12寸、30寸晶圆厂说的就是它，光刻机在晶圆上蚀刻出电路</p>
<p>Die：从晶圆上切割下来的CPU(通常一个Die中包含多个core、L3cache、内存接口、GPU等，core里面又包含了L1、L2cache），Die的大小可以自由决定，得考虑成本和性能, Die做成方形便于切割和测试，服务器所用的Intel CPU的Die大小一般是大拇指指甲大小。</p>
<p>封装：将一个或多个Die封装成一个物理上可以售卖的CPU</p>
<p>路：就是socket、也就是封装后的物理CPU</p>
<p>node：同一个Die下的多个core以及他们对应的内存，对应着NUMA</p>
<h2 id="售卖的CPU实物"><a href="#售卖的CPU实物" class="headerlink" title="售卖的CPU实物"></a>售卖的CPU实物</h2><p>购买到的CPU实体外观和大小，一般是40mm X 50mm大小，可以看出一个CPU比一个Die大多了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/AFCCC93B-D8A7-400A-9E80-978F8B05CD7E.jpeg" alt="How to Perform a CPU Stress Test and Push It to the Limit | AVG"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/images.jpeg" alt="Coffee Lake-Refresh Desktop CPU List Surfaces: 35W Core i9-9900T &amp; 8-Core  Xeon E-2200 Confirmed"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/yp6cf.jpg" alt="enter image description here"></p>
<h2 id="裸片Die-制作"><a href="#裸片Die-制作" class="headerlink" title="裸片Die 制作"></a>裸片Die 制作</h2><p>晶圆为什么总是圆的呢？生产过程就是从沙子中提纯硅，硅晶柱生长得到晶圆，生长是以圆柱形式的，所以切割下来的晶圆就是圆的了：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/gif/weixin15664418828781.gif" alt="img"></p>
<p>硅晶柱切片：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/e510d61ed3e648a3ae64be7ac1da26e7.png" alt="img"></p>
<p>直径为 300 毫米的纯硅晶圆（从硅柱上切割下来的圆片），俗称 12 寸晶圆，大约是 400 美金。但尺寸并不是衡量硅晶圆的最重要指标，纯度才是。日本的信越公司可以生产 13 个 9 纯度的晶圆。</p>
<p>高纯硅的传统霸主依然是德国Wacker和美国Hemlock(美日合资)，中国任重而道远。太阳能级高纯硅要求是99.9999%，低纯度的硅全世界超过一半是中国产的，但是不值钱。而芯片用的电子级高纯硅要求99.999999999%，几乎全赖进口，直到2018年江苏鑫华公司才实现量产，目前年产0.5万吨，而中国一年进口15万吨。核心材料技术这块毫无疑问“外国仍然把中国摁在地上摩擦”。</p>
<h3 id="芯片设计"><a href="#芯片设计" class="headerlink" title="芯片设计"></a>芯片设计</h3><p>主要依赖EDA， EDA工具是电子设计自动化（Electronic Design Automation）的简称，从计算机辅助设计（CAD）、计算机辅助制造（CAM）、计算机辅助测试（CAT）和计算机辅助工程（CAE）的概念发展而来的，是IC基础设计能力。利用EDA工具，工程师将芯片的电路设计、性能分析、设计出IC版图的整个过程交由计算机自动处理完成。</p>
<p> EDA软件方面早已形成了三巨头——Synopsys、Cadence、Mentor。Synopsys是EDA三巨头之首，国内从事EDA软件开发的华大九天和这三家比起来不是一个数量级。国内IC设计公司几乎100%采用国外EDA工具，在未来的相当长的一段时间里，我们应该看不到缩小和Synopsys、Cadence、Mentor技术差距的可能性。</p>
<h3 id="光刻"><a href="#光刻" class="headerlink" title="光刻"></a>光刻</h3><p>使用特定波长的光，透过光罩（类似印炒里面的母版），照射在涂有光刻胶的晶圆上，光罩上芯片的设计图像，就复制到晶圆上了，这就是光刻，这一步是由光刻机完成的，光刻机是芯片制造中光刻环节的核心设备。你可以把光刻理解为，就是用光罩这个母版，一次次在晶圆上印电路的过程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/b62d2a87a74c1ba90a069624bdc91eee.jpeg" alt="img"></p>
<p>光刻是最贵的一个环节，一方面是光罩越来越多，越来越贵，另一方面光刻机也很贵。光刻机是半导体制造设备中价格占比最大，也是最核心的设备。2020 年荷兰公司 ASML 的极紫外光源（EUV）光刻机每台的平均售价是 1.45 亿欧元，而且全世界独家供货，年产量 31 台，有钱也未必能买得到。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210601160424815.png" alt="image-20210601160424815"></p>
<p>短波长光源是提高光刻机分辨力的有效方，光刻机的发展历史，就从紫外光源（UV）、深紫外光源（DUV），发展到了现在的极紫外光源（EUV）。</p>
<p>回顾光刻机的发展历史，从 1960 年代的接触式光刻机、接近式光刻机，到 1970 年代的投影式光刻机，1980 年代的步进式光刻机，到步进式扫描光刻机、浸入式光刻机和现在的深紫外光源（DUV）和极紫外光源（EUV）光刻机，一边是设备性能的不断提高，另一边是价格逐年上升，且供应商逐渐减少。到了 EUV 光刻机，ASML(阿斯麦) 就是独家供货了。英特尔有阿斯麦15%的股份，台积电有5%，三星有3%，另外美国弄了一个《瓦森纳协定》，敏感技术不能卖，中国、朝鲜、伊朗、利比亚均是被限制国家。</p>
<p>品质合格的die切割下去后，原来的晶圆成了下图的样子，是挑剩下的Downgrade Flash Wafer。残余的die是品质不合格的晶圆。黑色的部分是合格的die，会被原厂封装制作为成品NAND颗粒，而不合格的部分，也就是图中留下的部分则当做废品处理掉。</p>
<p>从晶圆上切割检测合格的Die（螺片），所以Die跟Wafer不一样不是圆的，而是是方形的，因为方形的在切割封测工艺上最简单</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/gif/weixin15664418828785.gif" alt="img"></p>
<p>一个大晶圆，拿走了合格的Die后剩下的次品：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/bba1cd11728b47103777e2dbcccec3fdfc032348.png" alt="img"></p>
<p>可见次品率不低，后面会谈到怎么降低次品率，次品率决定了CPU的价格。</p>
<p>台积电一片 5nm 晶圆的加工费高达 12500 美金。根据台积电的财报推算，台积电平均每片晶圆可以产生近 4000 美金（300mm 晶圆）的利润。无论是哪个数字，对比 400 美金的纯硅晶圆原料来说，这都是一个至少增值 10 倍的高价值的加工过程。</p>
<p>随着Die的缩小，浪费的比例也从36%缩小成为12.6%。根据极限知识，我们知道如果Die的大小足够小，我们理论上可以100%用上所有的Wafer大小。从中我们可以看出越小的Die，浪费越小，从而降低CPU价格，对CPU生产者和消费者都是好事。</p>
<p>光刻机有一个加工的最大尺寸，一般是 858mm²，而 Cerebras 和台积电紧密合作，做了一个 46255mm²，1.2T 个晶体管的世界第一大芯片。这也是超摩尔定律的一个突破。</p>
<p>AMD在工艺落后Intel的前提下，又想要堆核，只能采取一个Package封装4个独立Die的做法，推出了Zen1 EPYC服务器芯片，即不影响良率，又可以核心数目好看，可谓一举两得。</p>
<p>可惜连接四个Die的片外总线终归没有片内通信效率高，在好些benchmark中败下阵来，可见没有免费的午餐。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/v2-7d77aa1100b77261f2626791954e79ad_720w.jpg" alt="img"></p>
<p>Intel的Pakcage内部是一个Die, Core之间原来是Ring Bus，在Skylake后改为Mesh。<strong>AMD多Die封装的目的是省钱和增加灵活性！AMD每个Zeppelin Die都比Intel的小，这对良品率提高很大，节约了生产费用。</strong></p>
<p>这种胶水核强行将多个die拼一起是没考虑跨die之间的延迟，基本上跨die跟intel跨socket（numa）时延一样了。</p>
<p>一颗芯片的 1&#x2F;3 的成本，是花在封测阶段的</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/738303bb-e157-47d2-a085-6daac98f04ec.jpeg" alt="img"></p>
<p>一个晶体管（纳米尺度），注意三个黄色的导电铜点</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20230621183939476.png" alt="image-20230621183939476"></p>
<p>对应的一个逻辑意义上的NPMOS 晶体管：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20230621184113927.png" alt="image-20230621184113927"></p>
<blockquote>
<p>MOS :<strong>金属-氧化物-半导体</strong>，而拥有这种结构的晶体管我们称之为MOS晶体管。 MOS晶体管有P型MOS管和N型MOS管之分。 由MOS管构成的集成电路称为MOS集成电路，由NMOS组成的电路就是NMOS集成电路，由PMOS管组成的电路就是PMOS集成电路，由NMOS和PMOS两种管子组成的互补MOS电路，即CMOS电路</p>
</blockquote>
<h3 id="Die和core"><a href="#Die和core" class="headerlink" title="Die和core"></a>Die和core</h3><p>One die with multiple cores，下图是一个Die内部图:</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/xCqqv.jpg" alt="enter image description here"></p>
<p>或者Skylake：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1000px-skylake_sp_mesh_core_tile_zoom_with_client_shown.png" alt="skylake sp mesh core tile zoom with client shown.png"></p>
<p>将两个Die封装成一块CPU(core多，成本低):</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/dataf1-1372099277050.jpg" alt="data f1"></p>
<p>第4代酷睿（Haswell）的die：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210601162558479.png" alt="image-20210601162558479"></p>
<p>第4代酷睿（Haswell）的die主要分为几个部分：GPU、4个core、System Agent(uncore,类似北桥)、cache和内存控制器和其他小部件。<strong>比如我们发现core 3和4有问题，我们可以直接关闭3和4。坏的关掉就是i5, 都是好的就当i7来卖。</strong></p>
<h2 id="北桥和南桥"><a href="#北桥和南桥" class="headerlink" title="北桥和南桥"></a>北桥和南桥</h2><p>早期CPU core和内存硬盘的连接方式(FSB 是瓶颈)：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602113401202.png" alt="image-20210602113401202"></p>
<p>个人PC主板实物图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/northsouth2.jpg" alt="img"></p>
<p>由于FSB变成了系统性能的瓶颈和对多CPU的制约，在台式机和笔记本电脑中，MCH(Memory Control Hub)被请进CPU中，服务器市场虽然短暂的出现了IOH。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/640.jpeg" alt="Image"></p>
<p>集成北桥后的内存实物图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602114931825.png" alt="image-20210602114931825"></p>
<p>北桥已经集成到CPU中，南桥还没有，主要是因为：集成后Die增大不少，生产良品率下降成本上升；不集成两者采用不同的工艺；另外就是CPU引脚不够了！</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/640-20210601095028465" alt="Image"></p>
<p>SoC（System on Chip）：南桥北桥都集成在CPU中，单芯片解决方案。ATOM就是SoC</p>
<h2 id="现代CPU的基本架构"><a href="#现代CPU的基本架构" class="headerlink" title="现代CPU的基本架构"></a><a href="https://frankdenneman.nl/2016/07/08/numa-deep-dive-part-2-system-architecture/" target="_blank" rel="noopener">现代CPU的基本架构</a></h2><p>下图是一个两路的服务器结构，每路4个内存channel</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220711110145506.png" alt="image-20220711110145506"></p>
<h2 id="一个Core的典型结构"><a href="#一个Core的典型结构" class="headerlink" title="一个Core的典型结构"></a>一个Core的典型结构</h2><p>Intel skylake 架构图</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/950px-skylake_server_block_diagram.svg.png" alt="skylake server block diagram.svg"></p>
<p>iTLB:instruct TLB </p>
<p>dTLB:data TLB</p>
<p>多个core加上L3等组成一个Die：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/cache-ht-hierarchy-2.jpg" alt="img"></p>
<h2 id="多核和多个CPU"><a href="#多核和多个CPU" class="headerlink" title="多核和多个CPU"></a>多核和多个CPU</h2><p>如果要实现一台48core的计算能力的服务器，可以有如下三个方案</p>
<h3 id="方案1：一个大Die集成48core："><a href="#方案1：一个大Die集成48core：" class="headerlink" title="方案1：一个大Die集成48core："></a>方案1：一个大Die集成48core：<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Intel-Skylake-SP-Mesh-Architecture-Conceptual-Diagram.png" alt="Intel Skylake SP Mesh Architecture Conceptual Diagram"></h3><h3 id="方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die-6个core"><a href="#方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die-6个core" class="headerlink" title="方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die 6个core"></a><a href="https://wccftech.com/amd-epyc-rome-zen-2-7nm-server-cpu-162-pcie-gen-4-lanes-report/" target="_blank" rel="noopener">方案2</a>：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die 6个core</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602165525641.png" alt="image-20210602165525641"></p>
<p>四个Die之间的连接方法：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602172555232.png" alt="image-20210602172555232"></p>
<p>上图最下面的方案为<a href="https://venturebeat.com/2017/03/28/intel-moves-tech-forward-by-putting-two-chips-in-a-single-package/" target="_blank" rel="noopener">Intel采用的EMIB</a>（Embedded Multi-die Interconnect Bridge）方案，cost 最低。中间的方案是使用“硅中介层”(Interposer，AMD采用的方案)。这意味着你能在两枚主要芯片的下面放置和使用第三枚芯片。这枚芯片的目的是使得多个设备的连接更加容易，但是也带来了更高的成本。</p>
<h3 id="方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core："><a href="#方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core：" class="headerlink" title="方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core："></a>方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core：</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602171352551.png" alt="image-20210602171352551"></p>
<p>三者的比较：</p>
<p>性能肯定是大Die最好，但是良品率低、成本高；</p>
<p>方案2的多个Die节省了主板上的大量布线和VR成本，总成本略低，但是方案3更容易堆出更多的core和<strong>内存</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602170727459.png" alt="image-20210602170727459"></p>
<h3 id="面积和性能"><a href="#面积和性能" class="headerlink" title="面积和性能"></a>面积和性能</h3><p>我们使用了当时Intel 用在数据中心计算的大核CPU IvyBridge与当时用于 存储系列的小核CPU Avoton（ATOM）, 分别测试阿里巴巴的workload，得到性能吞吐如下：</p>
<table>
<thead>
<tr>
<th>Intel 大小CPU 核心</th>
<th>阿里 Workload Output(QPS)</th>
</tr>
</thead>
<tbody><tr>
<td>Avoton(8 cores) 2.4GHZ</td>
<td>10K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 disable HT) 2.6GHZ</td>
<td>20K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 enable HT) 2.4GHZ</td>
<td>25K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 enable HT) 2.6GHZ</td>
<td>27K on single core</td>
</tr>
</tbody></table>
<ol>
<li>大小核心直观比较：超线程等于将一个大核CPU 分拆成两个小核，Ivy Bridge的数据显示超线程给 Ivy Bridge <strong>1.35倍</strong>(27K&#x2F;20K) 的提升</li>
<li>性能与芯片面积方面比较：现在我们分别评判 两种CPU对应的性能密度 (performance&#x2F;core die size) ，该数据越大越好，根据我们的计算和测量发现 Avoton(包含L1D, L1I, and L2 per core)大约是 3<del>4平方毫米，Ivy Bridge (包含L1D, L1I, L2 )大约是12</del>13平方毫米, L3&#x2F;core是 6~7平方毫米, 所以 Ivy Bridge 单核心的芯片面积需要18 ~ 20平方毫米。基于上面的数据我们得到的 Avoton core的性能密度为 2.5 (10K&#x2F;4sqmm)，而Ivy Bridge的性能密度是1.35 (27K&#x2F;20sqmm)，因此相同的芯片面积下 Avoton 的性能是 Ivy Bridge的 <strong>1.85倍</strong>(2.5&#x2F;1.35).</li>
<li>性能与功耗方面比较：  从功耗的角度看性能的提升的对比数据，E5-2650v2(Ivy Bridge) 8core TDP 90w， Avoton 8 core TDP 20瓦， 性能&#x2F;功耗 Avoton 是 10K QPS&#x2F;20瓦， Ivy Bridge是 27KQPS&#x2F;90瓦， 因此 相同的功耗下 Avoton是 Ivy Bridge的 <strong>1.75倍</strong>（10K QPS&#x2F;20）&#x2F; （27KQPS&#x2F;95）</li>
<li>性能与价格方面比较：  从价格方面再进行比较，E5-2650v2(Ivy Bridge) 8core 官方价格是1107美元， Avoton 8 core官方价格是171美元性能&#x2F;价格 Avoton是 10KQPS&#x2F;171美元，Ivy Bridge 是 27KQPS&#x2F;1107美元， 因此相同的美元 Avoton的性能是 Ivy Bridge 的<strong>2.3倍（</strong>1 10KQPS&#x2F;171美元）&#x2F; （27KQPS&#x2F;1107美元）</li>
</ol>
<p>总结：在数据中心的场景下，由于指令数据相关性较高，同时由于内存访问的延迟更多，复杂的CPU体系结构并不能获得相应性能提升，该原因导致我们需要的是更多的小核CPU，以达到高吞吐量的能力，因此2014 年我们向Intel提出数据中心的CPU倾向“小核”CPU，需要将现有的大核CPU的超线程由 2个升级到4个&#x2F;8个， 或者直接将用更多的小核CPU增加服务器的吞吐能力，经过了近8年，最新数据表明Intel 会在每个大核CPU中引入4个超线程，和在相同的芯片面积下单socket CPU 引入200多个小核CPU，该方案与我们的建议再次吻合</p>
<h2 id="为什么这20年主频基本没有提升了"><a href="#为什么这20年主频基本没有提升了" class="headerlink" title="为什么这20年主频基本没有提升了"></a>为什么这20年主频基本没有提升了</h2><p>今天的2.5G CPU性能和20年前的2.5G比起来性能差别大吗？</p>
<p>因为能耗导致CPU的主频近些年基本不怎么提升了，不是技术上不能提升，是性价比不高. </p>
<p>在提升主频之外可以提升性能的有：提升跳转预测率，增加Decoded Cache，增加每周期的并发读个数，增加执行通道，增加ROB， RS，Read &amp; Write buffer等等，这些主要是为了增加IPC，当然增加core数量也是提升整体性能的王道。另外就是优化指令所需要的时钟周期、增加并行度更好的指令等等指令集相关的优化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/main-qimg-7a34de25ee9d09ba88a1671d22d4b0f1.jpeg" alt="img"></p>
<p>the industry came up with many different solution to create better computers w&#x2F;o (or almost without) increasing the clock speed. </p>
<h3 id="比较两代CPU性能变化"><a href="#比较两代CPU性能变化" class="headerlink" title="比较两代CPU性能变化"></a>比较两代CPU性能变化</h3><p>Intel 最新的CPU Ice Lake(8380)和其上一代(8280)的性能对比数据：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/intel-ice-lake-sunny-cove-core-table.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Intel-Ice-Lake-3rd-Gen-Xeon-overview-slide.png" alt="img"></p>
<p>上图最终结果导致了IPC提升了20%</p>
<blockquote>
<p>But tock Intel did with the <a href="https://www.nextplatform.com/2021/04/19/deep-dive-into-intels-ice-lake-xeon-sp-architecture/" target="_blank" rel="noopener">Ice Lake</a> processors and their Sunny Cove cores, and the tock, at 20 percent instructions per clock (IPC) improvement on integer work</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/intel-ice-lake-ipc-over-time.jpg" alt="img"></p>
<p>ICE Lake在网络转发上的延时更小、更稳定了：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/intel-ice-lake-sunny-cove-dpdk-latency.jpg" alt="img"></p>
<p><a href="https://wccftech.com/intel-unveils-ice-lake-sp-xeon-cpu-family-10nm-sunny-cove-cores-28-core-die/" target="_blank" rel="noopener">两代CPU整体性能差异</a>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Intel-Ice-Lake-improved-perf-per-core-April-2021.png" alt="img"></p>
<h3 id="指令集优化"><a href="#指令集优化" class="headerlink" title="指令集优化"></a>指令集优化</h3><p>新增等效于某种常见指令组合的指令。原来多个指令执行需要多个时钟周期，合并后的单条指令可以在一个时钟周期执行完成。例如FMA指令，就是一条指令计算A×B+C，而无需分两个时钟周期计算。这种指令一般来说现有程序直接就能用上，无需优化。限制在于只对特定代码有效，还是以FMA为例，更普遍的普通加法、乘法运算都不能从中获益。</p>
<p>案例， ssse3(<strong>Supplemental Streaming SIMD Extensions 3</strong> ) 是simd的一种，在libc-2.17.so中就有使用到，如下是mysqld进程中采集到的</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.79</span>%  mysqld                [.] MYSQLparse                                   </span><br><span class="line"><span class="number">2.27</span>%  libc<span class="number">-2.17</span>.so          [.] __memcpy_ssse3_back  <span class="comment">//ssse3                </span></span><br><span class="line"><span class="number">2.19</span>%  mysqld                [.] ha_insert_for_fold_func                         </span><br><span class="line"><span class="number">1.95</span>%  mysqld                [.] rec_get_offsets_func                           </span><br><span class="line"><span class="number">1.35</span>%  mysqld                [.] <span class="built_in">malloc</span></span><br></pre></td></tr></table></figure>

<h4 id="AVX-Advanced-Vector-Extension，高级矢量扩展指令集"><a href="#AVX-Advanced-Vector-Extension，高级矢量扩展指令集" class="headerlink" title="AVX(Advanced Vector Extension，高级矢量扩展指令集)"></a>AVX(Advanced Vector Extension，高级矢量扩展指令集)</h4><p>英特尔在1996年率先引入了MMX（Multi Media eXtensions）多媒体扩展指令集，也开创了<strong>SIMD</strong>（Single Instruction Multiple Data，单指令多数据）指令集之先河，即在一个周期内一个指令可以完成多个数据操作，MMX指令集的出现让当时的MMX Pentium处理器大出风头。</p>
<p><strong>SSE</strong>（Streaming SIMD Extensions，流式单指令多数据扩展）指令集是1999年英特尔在Pentium III处理器中率先推出的，并将矢量处理能力从64位扩展到了128位。</p>
<p>AVX 所代表的单指令多数据（Single Instruction Multi Data，SIMD）指令集，是近年来 CPU 提升 IPC（每时钟周期指令数）上为数不多的重要革新。随着每次数据宽度的提升，CPU 的性能都会大幅提升，但同时晶体管数量和能耗也会有相应的提升。因此在对功耗有较高要求的场景，如笔记本电脑或服务器中，CPU 运行 AVX 应用时需要降低频率从而降低功耗。</p>
<blockquote>
<p>2013 年， 英特尔 发布了<strong>AVX</strong>-<strong>512 指令</strong>集，其<strong>指令</strong>宽度扩展为512bit，每个时钟周期内可打包32 次双精度或64 次单精度浮点运算，因此在图像&#x2F; 音视频处理、数据分析、科学计算、数据加密和压缩和 深度学习 等应用场景中，会带来更强大的性能表现，理论上浮点性能翻倍，整数计算则增加约33% 的性能。</p>
</blockquote>
<p>Linus Torvalds ：</p>
<blockquote>
<p>AVX512 有很明显的缺点。我宁愿看到那些晶体管被用于其他更相关的事情。即使同样是用于进行浮点数学运算（通过 GPU 来做，而不是通过 AVX512 在 CPU 上），或者直接给我更多的核心（有着更多单线程性能，而且没有 AVX512 这样的垃圾），就像 AMD 所做的一样。</p>
<p>我希望通过常规的整数代码来达到自己能力的极限，而不是通过 AVX512 这样的功率病毒来达到最高频率（因为人们最终还是会拿它来做 memory-to-memory copy），还占据了核心的很大面积。</p>
</blockquote>
<h3 id="关于性能提升的小结"><a href="#关于性能提升的小结" class="headerlink" title="关于性能提升的小结"></a>关于性能提升的小结</h3><p>所以今天的2.6G单核skylake，能秒掉20年前2.6G的酷睿, 尤其是复杂场景。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210715094527563.png" alt="image-20210715094527563"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210715094637227.png" alt="image-20210715094637227"></p>
<p>CPU能耗公式：</p>
<blockquote>
<p>P &#x3D; C V*V * f</p>
</blockquote>
<p>C是常数，f就是频率，V 电压。 f频率加大后因为充放电带来的Gate Delay，也就是频率增加，充放电时间短，为了保证信号的完整性就一定要增加电压来加快充放电。</p>
<p>所以最终能耗和f频率是 f^3 的指数关系。</p>
<blockquote>
<p>The successive nodes of CMOS technologies lead to x1.4 decrease of the gate delays. It led to a 25% increase per year of clock frequencies from 740 kHz (Intel 4004) to 3 GHz (Intel Xeons with 45-nm nodes).</p>
<p>每一代光刻工艺的改进可以降低1.4倍的门延迟</p>
</blockquote>
<p>即使不考虑散热问题，Core也没法做到无限大，目前光刻机都有最大加工尺寸限制。光刻机加工的最大尺寸，一般是 858mm²，而 Cerebras 和台积电紧密合作，做了一个 46255mm²，1.2T 个晶体管的世界第一大芯片。这也是超摩尔定律的一个突破。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210715100609552.png" alt="image-20210715100609552"></p>
<h2 id="主频和外频"><a href="#主频和外频" class="headerlink" title="主频和外频"></a>主频和外频</h2><p><strong>主频&#x3D;外频×倍频系数</strong></p>
<p>不只是CPU需要一个切换频率，像GPU、cache、内存都需要一个外频来指导他们的电压脉冲的切换频率。CPU的发展比其它设备快，所以没法统一一个，于是就各自在外频的基础上X倍频系数。</p>
<p>超频：认为加大CPU的倍频系数，切换变快以后最大的问题是电容在短时间内充电不完整，这样导致信号失真，所以一般配套需要增加电压（充电更快），带来的后果是温度更高。</p>
<p>睿频：大多时候多核用不上，如果能智能地关掉无用的核同时把这些关掉的核的电源累加到在用的核上（通过增加倍频来实现），这样单核拥有更高的主频。也就是把其它核的电源指标和发热指标给了这一个核来使用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1000.jpeg" alt="img"></p>
<h2 id="多core通讯和NUMA"><a href="#多core通讯和NUMA" class="headerlink" title="多core通讯和NUMA"></a>多core通讯和NUMA</h2><h3 id="uma下cpu访问内存"><a href="#uma下cpu访问内存" class="headerlink" title="uma下cpu访问内存"></a>uma下cpu访问内存</h3><p>早期core不多统一走北桥总线访问内存，对所有core时延统一</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/numa-fsb-3.png" alt="x86 UMA"></p>
<h3 id="NUMA"><a href="#NUMA" class="headerlink" title="NUMA"></a>NUMA</h3><p>如下图，左右两边的是内存条，每个NUMA的cpu访问直接插在自己CPU上的内存必然很快，如果访问插在其它NUMA上的内存条还要走QPI，所以要慢很多。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1620954546311-096702b9-9929-4f47-8811-dc4d08829f31.png" alt="undefined"> </p>
<p>如上架构是4路CPU，每路之间通过QPI相连，每个CPU内部8core用的是双Ring Bus相连，Memory Control Hub集成到了Die里面。一路CPU能连4个SMB，每个SMB有两个channel，每个channel最多接三个内存条（图中只画了2个）。</p>
<p><strong>快速通道互联</strong>[<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E9%80%9A%E9%81%93%E4%BA%92%E8%81%94#cite_note-1" target="_blank" rel="noopener">1]</a>[<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E9%80%9A%E9%81%93%E4%BA%92%E8%81%94#cite_note-2" target="_blank" rel="noopener">2]</a>（英语：Intel <strong>Q</strong>uick<strong>P</strong>ath <strong>I</strong>nterconnect，<a href="https://zh.wikipedia.org/wiki/%E7%B8%AE%E5%AF%AB" target="_blank" rel="noopener">缩写</a>：<strong>QPI</strong>）[<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E9%80%9A%E9%81%93%E4%BA%92%E8%81%94#cite_note-Intel_QPI-3" target="_blank" rel="noopener">3]</a>[<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E9%80%9A%E9%81%93%E4%BA%92%E8%81%94#cite_note-4" target="_blank" rel="noopener">4]</a>，是一种由英特尔开发并使用的点对点处理器互联架构，用来实现CPU之间的互联。英特尔在2008年开始用QPI取代以往用于<a href="https://zh.wikipedia.org/wiki/Intel_Xeon" target="_blank" rel="noopener">至强</a>、<a href="https://zh.wikipedia.org/wiki/Intel_Itanium" target="_blank" rel="noopener">安腾</a>处理器的<a href="https://zh.wikipedia.org/wiki/%E5%89%8D%E7%AB%AF%E5%8C%AF%E6%B5%81%E6%8E%92" target="_blank" rel="noopener">前端总线</a>（<a href="https://zh.wikipedia.org/wiki/FSB" target="_blank" rel="noopener">FSB</a>），<strong>用来实现芯片之间的直接互联，而不是再通过FSB连接到北桥</strong>。Intel于2017年发布的SkyLake-SP Xeon中，用UPI（<strong>U</strong>ltra<strong>P</strong>ath <strong>I</strong>nterconnect）取代QPI。</p>
<h4 id="Ring-Bus"><a href="#Ring-Bus" class="headerlink" title="Ring Bus"></a>Ring Bus</h4><p>2012年英特尔发布了业界期待已久的Intel Sandy Bridge架构至强E5-2600系列处理器。该系列处理器采用 Intel Sandy Bridge微架构和32nm工艺，与前一代的至强5600系列相比，具有更多的内核、更大的缓存、更多的内存通道，Die内采用的是Ring Bus。</p>
<p>Ring Bus设计简单，双环设计可以保证任何两个ring stop之间距离不超过Ring Stop总数的一半，延迟控制在60ns，带宽100G以上，但是core越多，ring bus越长性能下降迅速，在12core之后性能下降明显。</p>
<p>于是采用如下两个Ring Bus并列，然后再通过双向总线把两个Ring Bus连起来。</p>
<p>在至强HCC(High Core Count, 核很多版)版本中，又加入了一个ring bus。两个ring bus各接12个Core，将延迟控制在可控的范围内。俩个Ring Bus直接用两个双向Pipe Line连接，保证通讯顺畅。与此同时由于Ring 0中的模块访问Ring 1中的模块延迟明显高于本Ring，亲缘度不同，所以两个Ring分属于不同的NUMA（Non-Uniform Memory Access Architecture）node。这点在BIOS设计中要特别注意。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Intel-Xeon-E5-2600-V4-High-Core-Count-Die.png" alt="Intel Xeon E5-2600 V4 High Core Count Die"></p>
<p>或者这个更清晰点的图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/03-05-Broadwell_HCC_Architecture.svg" alt="03-05-Broadwell_HCC_Architecture"></p>
<h4 id="Mesh网络"><a href="#Mesh网络" class="headerlink" title="Mesh网络"></a><a href="https://www.servethehome.com/the-new-intel-mesh-interconnect-architecture-and-platform-implications/" target="_blank" rel="noopener">Mesh网络</a></h4><p>Intel在Skylake和Knight Landing中引入了新的片内总线：Mesh。它是一种2D的Mesh网络：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Intel-Skylake-SP-Mesh-Architecture-Conceptual-Diagram.png" alt="Intel Skylake SP Mesh Architecture Conceptual Diagram"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1620956208262-c20677c5-8bf5-4cd4-81c6-1bf492159394.png" alt="undefined"></p>
<p>一个skylake 28core die的实现：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Skylake-SP-28-Core-Die-Mesh-800x666.jpg" alt="Skylake SP 28 Core Die Mesh"></p>
<p>Mesh网络引入片内总线是一个巨大的进步，它有很多优点：</p>
<ol>
<li>首先当然是灵活性。新的模块或者节点在Mesh中增加十分方便，它带来的延迟不是像ring bus一样线性增加，而是非线性的。从而可以容纳更多的内核。</li>
<li>设计弹性很好，不需要1.5 ring和2ring的委曲求全。</li>
<li>双向mesh网络减小了两个node之间的延迟。过去两个node之间通讯，最坏要绕过半个ring。而mesh整体node之间距离大大缩减。</li>
<li>外部延迟大大缩短</li>
</ol>
<p>RAM延迟大大缩短：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/Broadwell-Ring-v-Skylake-Mesh-DRAM-Example-696x272.jpg" alt="Broadwell Ring V Skylake Mesh DRAM Example"></p>
<p>上图左边的是ring bus，从一个ring里面访问另一个ring里面的内存控制器。最坏情况下是那条绿线，拐了一个大圈才到达内存控制器，需要310个cycle。而在Mesh网络中则路径缩短很多。</p>
<p>Mesh网络带来了这么多好处，那么缺点有没有呢？网格化设计带来复杂性的增加，从而对Die的大小带来了负面影响</p>
<p>CPU的总线为铜薄膜，虽然摩尔定律使单位面积晶体管的密度不断增加，但是对于连接导线的电阻却没有明显的下降，导线的RC延迟几乎决定现有CPU性能，因此数据传输在CPU的角度来看是个极为沉重的负担。 虽然2D-mesh为数据提供了更多的迁移路径减少了数据堵塞，但也同样为数据一致性带来更多问题，例如过去ring-bus 结构下对于存在于某个CPU私用缓存的数据争抢请求只有两个方向（左和右）， 但是在2D-mesh环境下会来自于4个方向（上，下，左，右）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602104851803.png" alt="image-20210602104851803"></p>
<h3 id="SUB-NUMA-Cluster-SNC"><a href="#SUB-NUMA-Cluster-SNC" class="headerlink" title="SUB_NUMA Cluster(SNC)"></a>SUB_NUMA Cluster(SNC)</h3><p>在intel 8269的CPU中，core比较多，core之间通信采取的是mesh架构，实际在BIOS中的NUMA NODE设置上，还有个sub_numa的设置，开启后，一个Die拆成了两个node</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220418101937564.png" alt="image-20220418101937564"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@registry Linux]# lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">座：                 2</span><br><span class="line">NUMA 节点：         4</span><br><span class="line">厂商 ID：           GenuineIntel</span><br><span class="line">CPU 系列：          6</span><br><span class="line">型号：              85</span><br><span class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">步进：              7</span><br><span class="line">CPU MHz：             1200.000</span><br><span class="line">CPU max MHz:           2501.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS：            5000.00</span><br><span class="line">虚拟化：           VT-x</span><br><span class="line">L1d 缓存：          32K</span><br><span class="line">L1i 缓存：          32K</span><br><span class="line">L2 缓存：           1024K</span><br><span class="line">L3 缓存：           36608K</span><br><span class="line">NUMA 节点0 CPU：    0-3,7-9,13-15,20-22,52-55,59-61,65-67,72-74</span><br><span class="line">NUMA 节点1 CPU：    4-6,10-12,16-19,23-25,56-58,62-64,68-71,75-77</span><br><span class="line">NUMA 节点2 CPU：    26-29,33-35,39-41,46-48,78-81,85-87,91-93,98-100</span><br><span class="line">NUMA 节点3 CPU：    30-32,36-38,42-45,49-51,82-84,88-90,94-97,101-103</span><br></pre></td></tr></table></figure>

<p>不过在8269上开启sub_numa对性能的影响不是特别大，mlc测试如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line">[root@registry Linux]# ./mlc</span><br><span class="line">Intel(R) Memory Latency Checker - v3.9</span><br><span class="line">Measuring idle latencies (in ns)...</span><br><span class="line">		Numa node</span><br><span class="line">Numa node	     0	     1	     2	     3</span><br><span class="line">       0	  77.3	  81.6	 129.8	 136.1</span><br><span class="line">       1	  82.1	  78.1	 134.1	 137.6</span><br><span class="line">       2	 129.8	 135.8	  73.5	  81.7</span><br><span class="line">       3	 134.4	 137.7	  81.7	  78.5</span><br><span class="line"></span><br><span class="line">Measuring Peak Injection Memory Bandwidths for the system</span><br><span class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using traffic with the following read-write ratios</span><br><span class="line">ALL Reads        :	232777.7</span><br><span class="line">3:1 Reads-Writes :	216680.7</span><br><span class="line">2:1 Reads-Writes :	213856.4</span><br><span class="line">1:1 Reads-Writes :	197430.7</span><br><span class="line">Stream-triad like:	194310.3</span><br><span class="line"></span><br><span class="line">Measuring Memory Bandwidths between nodes within system</span><br><span class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">		Numa node</span><br><span class="line">Numa node	     0	     1	     2	     3</span><br><span class="line">       0	58908.9	59066.0	50548.0	50479.6</span><br><span class="line">       1	59111.3	58882.6	50539.0	50479.3</span><br><span class="line">       2	50541.7	50495.8	58950.2	58934.0</span><br><span class="line">       3	50526.3	50492.4	59171.9	58701.5</span><br><span class="line"></span><br><span class="line">Measuring Loaded Latencies for the system</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">Inject	Latency	Bandwidth</span><br><span class="line">Delay	(ns)	MB/sec</span><br><span class="line">==========================</span><br><span class="line"> 00000	242.78	 232249.0</span><br><span class="line"> 00002	242.90	 232248.8</span><br><span class="line"> 00008	242.63	 232226.0</span><br><span class="line"> 00015	247.47	 233159.0</span><br><span class="line"> 00050	250.26	 233489.7</span><br><span class="line"> 00100	245.88	 233253.4</span><br><span class="line"> 00200	109.72	 183071.9</span><br><span class="line"> 00300	 93.95	 128676.2</span><br><span class="line"> 00400	 88.51	  98678.4</span><br><span class="line"> 00500	 85.15	  80026.2</span><br><span class="line"> 00700	 83.74	  58136.1</span><br><span class="line"> 01000	 82.16	  41372.4</span><br><span class="line"> 01300	 81.59	  32184.0</span><br><span class="line"> 01700	 81.14	  24896.1</span><br><span class="line"> 02500	 80.80	  17248.5</span><br><span class="line"> 03500	 80.32	  12571.3</span><br><span class="line"> 05000	 79.58	   9060.5</span><br><span class="line"> 09000	 78.27	   5411.6</span><br><span class="line"> 20000	 76.09	   2911.5</span><br><span class="line"></span><br><span class="line">Measuring cache-to-cache transfer latency (in ns)...</span><br><span class="line">Local Socket L2-&gt;L2 HIT  latency	45.0</span><br><span class="line">Local Socket L2-&gt;L2 HITM latency	45.1</span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in writer socket)</span><br><span class="line">			Reader Numa Node</span><br><span class="line">Writer Numa Node     0	     1	     2	     3</span><br><span class="line">            0	     -	  48.2	 107.2	 109.2</span><br><span class="line">            1	  50.6	     -	 111.2	 113.1</span><br><span class="line">            2	 107.6	 109.6	     -	  48.0</span><br><span class="line">            3	 111.6	 113.5	  49.7	     -</span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in reader socket)</span><br><span class="line">			Reader Numa Node</span><br><span class="line">Writer Numa Node     0	     1	     2	     3</span><br><span class="line">            0	     -	  48.6	 169.1	 175.0</span><br><span class="line">            1	  46.3	     -	 167.9	 172.1</span><br><span class="line">            2	 171.4	 175.3	     -	  48.6</span><br><span class="line">            3	 169.7	 173.6	  45.1	     -</span><br><span class="line">            </span><br><span class="line">[root@registry Linux]# numactl -H</span><br><span class="line">available: 4 nodes (0-3)</span><br><span class="line">node 0 cpus: 0 1 2 3 7 8 9 13 14 15 20 21 22 52 53 54 55 59 60 61 65 66 67 72 73 74</span><br><span class="line">node 0 size: 64162 MB</span><br><span class="line">node 0 free: 60072 MB</span><br><span class="line">node 1 cpus: 4 5 6 10 11 12 16 17 18 19 23 24 25 56 57 58 62 63 64 68 69 70 71 75 76 77</span><br><span class="line">node 1 size: 65536 MB</span><br><span class="line">node 1 free: 63575 MB</span><br><span class="line">node 2 cpus: 26 27 28 29 33 34 35 39 40 41 46 47 48 78 79 80 81 85 86 87 91 92 93 98 99 100</span><br><span class="line">node 2 size: 65536 MB</span><br><span class="line">node 2 free: 63834 MB</span><br><span class="line">node 3 cpus: 30 31 32 36 37 38 42 43 44 45 49 50 51 82 83 84 88 89 90 94 95 96 97 101 102 103</span><br><span class="line">node 3 size: 65536 MB</span><br><span class="line">node 3 free: 63867 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1   2   3</span><br><span class="line">  0:  10  11  21  21</span><br><span class="line">  1:  11  10  21  21</span><br><span class="line">  2:  21  21  10  11</span><br><span class="line">  3:  21  21  11  10</span><br><span class="line">[root@registry Linux]# lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">座：                 2</span><br><span class="line">NUMA 节点：         4</span><br><span class="line">厂商 ID：           GenuineIntel</span><br><span class="line">CPU 系列：          6</span><br><span class="line">型号：              85</span><br><span class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">步进：              7</span><br><span class="line">CPU MHz：             1200.000</span><br><span class="line">CPU max MHz:           2501.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS：            5000.00</span><br><span class="line">虚拟化：           VT-x</span><br><span class="line">L1d 缓存：          32K</span><br><span class="line">L1i 缓存：          32K</span><br><span class="line">L2 缓存：           1024K</span><br><span class="line">L3 缓存：           36608K</span><br><span class="line">NUMA 节点0 CPU：    0-3,7-9,13-15,20-22,52-55,59-61,65-67,72-74</span><br><span class="line">NUMA 节点1 CPU：    4-6,10-12,16-19,23-25,56-58,62-64,68-71,75-77</span><br><span class="line">NUMA 节点2 CPU：    26-29,33-35,39-41,46-48,78-81,85-87,91-93,98-100</span><br><span class="line">NUMA 节点3 CPU：    30-32,36-38,42-45,49-51,82-84,88-90,94-97,101-103</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
</tr>
</thead>
<tbody><tr>
<td>DDR4 speed MT&#x2F;s (32GB RDIMMs)</td>
<td>2666</td>
<td>2666</td>
<td>2400</td>
<td>2400</td>
</tr>
<tr>
<td>Page Policy</td>
<td>Adaptive</td>
<td>Adaptive</td>
<td>Adaptive</td>
<td>Adaptive</td>
</tr>
<tr>
<td>SNC (sub-NUMA cluster)</td>
<td>disabled</td>
<td>enabled</td>
<td>disabled</td>
<td>enabled</td>
</tr>
<tr>
<td>Uncore frequency (Mhz)</td>
<td>2400</td>
<td>2400</td>
<td>2400</td>
<td>2400</td>
</tr>
<tr>
<td>L1 cache latency (nsec)</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
</tr>
<tr>
<td>L2 cache latency (nsec)</td>
<td>4.7</td>
<td>4.6</td>
<td>4.7</td>
<td>4.6</td>
</tr>
<tr>
<td>L3 cache latency (nsec)</td>
<td>19.5</td>
<td>17.8</td>
<td>19.5</td>
<td>17.8</td>
</tr>
<tr>
<td>Local mem latency (nsec)</td>
<td>83</td>
<td>81</td>
<td>85</td>
<td>83</td>
</tr>
<tr>
<td>Remote mem latency (nsec)</td>
<td>143</td>
<td>139</td>
<td>145</td>
<td>141</td>
</tr>
</tbody></table>
<h3 id="uncore"><a href="#uncore" class="headerlink" title="uncore"></a>uncore</h3><p>“<strong>Uncore</strong>“ is a term used by <a href="https://en.wikipedia.org/wiki/Intel" target="_blank" rel="noopener">Intel</a> to describe the functions of a <a href="https://en.wikipedia.org/wiki/Microprocessor" target="_blank" rel="noopener">microprocessor</a> that are not in the core, but which must be closely connected to the core to achieve high performance.[<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-modular_uncore-1" target="_blank" rel="noopener">1]</a> It has been called “<strong>system agent</strong>“ since the release of the <a href="https://en.wikipedia.org/wiki/Sandy_Bridge" target="_blank" rel="noopener">Sandy Bridge</a> <a href="https://en.wikipedia.org/wiki/Microarchitecture" target="_blank" rel="noopener">microarchitecture</a>.[<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-sandybridge-2" target="_blank" rel="noopener">2]</a></p>
<p>The core contains the components of the processor involved in executing instructions, including the <a href="https://en.wikipedia.org/wiki/Arithmetic_logic_unit" target="_blank" rel="noopener">ALU</a>, <a href="https://en.wikipedia.org/wiki/Floating_point_unit" target="_blank" rel="noopener">FPU</a>, <a href="https://en.wikipedia.org/wiki/L1_cache" target="_blank" rel="noopener">L1</a> and <a href="https://en.wikipedia.org/wiki/L2_cache" target="_blank" rel="noopener">L2 cache</a>. Uncore functions include <a href="https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect" target="_blank" rel="noopener">QPI</a> controllers, <a href="https://en.wikipedia.org/wiki/L3_cache" target="_blank" rel="noopener">L3 cache</a>, <a href="https://en.wikipedia.org/wiki/Memory_coherence" target="_blank" rel="noopener">snoop agent</a> <a href="https://en.wikipedia.org/wiki/Instruction_pipeline" target="_blank" rel="noopener">pipeline</a>, on-die <a href="https://en.wikipedia.org/wiki/Memory_controller" target="_blank" rel="noopener">memory controller</a>, on-die <a href="https://en.wikipedia.org/wiki/PCI_Express_Root_Complex" target="_blank" rel="noopener">PCI Express Root Complex</a>, and <a href="https://en.wikipedia.org/wiki/Thunderbolt_(interface)" target="_blank" rel="noopener">Thunderbolt controller</a>.[<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-thunderbolt-3" target="_blank" rel="noopener">3]</a> Other bus controllers such as <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface_Bus" target="_blank" rel="noopener">SPI</a> and <a href="https://en.wikipedia.org/wiki/Low_Pin_Count" target="_blank" rel="noopener">LPC</a> are part of the <a href="https://en.wikipedia.org/wiki/Chipset" target="_blank" rel="noopener">chipset</a>.[<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-Anandtech:_Nehalem:_The_Unwritten_Chapters-4" target="_blank" rel="noopener">4]</a></p>
<h2 id="一些Intel-CPU-NUMA结构参考"><a href="#一些Intel-CPU-NUMA结构参考" class="headerlink" title="一些Intel CPU NUMA结构参考"></a>一些Intel CPU NUMA结构参考</h2><p>Intel Xeon Platinum 8163（Skylake）阿里云第四代服务器采用的CPU，Skylake架构，主频2.5GHz，计算性能问题。8163这款型号在intel官网上并没有相关信息，应该是阿里云向阿里云定制的，与之相近的Intel Xeon Platinum 8168，价格是$5890，约合￥38900元。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">lscpu:</span><br><span class="line">      Architecture:        x86_64</span><br><span class="line">      CPU op-mode(s):      32-bit, 64-bit</span><br><span class="line">      Byte Order:          Little Endian</span><br><span class="line">      CPU(s):              96</span><br><span class="line">      On-line CPU(s) list: 0-95</span><br><span class="line">      Thread(s) per core:  2</span><br><span class="line">      Core(s) per socket:  24</span><br><span class="line">      Socket(s):           2</span><br><span class="line">      NUMA node(s):        4</span><br><span class="line">      Vendor ID:           GenuineIntel</span><br><span class="line">      CPU family:          6</span><br><span class="line">      Model:               85</span><br><span class="line">      Model name:          Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz</span><br><span class="line">      Stepping:            6</span><br><span class="line">      CPU MHz:             2400.000</span><br><span class="line">      CPU max MHz:         3900.0000</span><br><span class="line">      CPU min MHz:         1000.0000</span><br><span class="line">      BogoMIPS:            4800.00</span><br><span class="line">      Virtualization:      VT-x</span><br><span class="line">      L1d cache:           32K</span><br><span class="line">      L1i cache:           32K</span><br><span class="line">      L2 cache:            1024K</span><br><span class="line">      L3 cache:            36608K</span><br><span class="line">      NUMA node0 CPU(s):   0-3,7-9,13-15,19,20,48-51,55-57,61-63,67,68</span><br><span class="line">      NUMA node1 CPU(s):   4-6,10-12,16-18,21-23,52-54,58-60,64-66,69-71</span><br><span class="line">      NUMA node2 CPU(s):   24-27,31-33,37-39,43,44,72-75,79-81,85-87,91,92</span><br><span class="line">      NUMA node3 CPU(s):   28-30,34-36,40-42,45-47,76-78,82-84,88-90,93-95</span><br><span class="line">      </span><br><span class="line"> Model: 85</span><br><span class="line"> Model name: Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz</span><br><span class="line"> Stepping: 6</span><br><span class="line"> CPU MHz: 3252.490</span><br><span class="line"> BogoMIPS: 5800.00</span><br><span class="line"> Virtualization: VT-x</span><br><span class="line"> L1d cache: 32K</span><br><span class="line"> L1i cache: 32K</span><br><span class="line"> L2 cache: 1024K</span><br><span class="line"> L3 cache: 36608K</span><br><span class="line"> NUMA node0 CPU(s):</span><br><span class="line"> 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92</span><br><span class="line"> NUMA node1 CPU(s):</span><br><span class="line"> 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77,81,85,89,93</span><br><span class="line"> NUMA node2 CPU(s):</span><br><span class="line"> 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78,82,86,90,94</span><br><span class="line"> NUMA node3 CPU(s):</span><br><span class="line"> 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79,83,87,91,95   </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">  lscpu:</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPU op-mode(s): 32-bit, 64-bit</span><br><span class="line"> Byte Order: Little Endian</span><br><span class="line"> CPU(s): 192</span><br><span class="line"> On-line CPU(s) list: 0-191</span><br><span class="line"> Thread(s) per core: 1</span><br><span class="line"> Core(s) per socket: 24</span><br><span class="line"> Socket(s): 8 //每个物理CPU 24个物理core，这24个core应该是分布在2个Die中</span><br><span class="line"> NUMA node(s): 16</span><br><span class="line"> Vendor ID: GenuineIntel</span><br><span class="line"> CPU family: 6</span><br><span class="line"> Model: 85</span><br><span class="line"> Model name: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz</span><br><span class="line"> Stepping: 7</span><br><span class="line"> CPU MHz: 2400.000</span><br><span class="line"> CPU max MHz: 3900.0000</span><br><span class="line"> CPU min MHz: 1000.0000</span><br><span class="line"> BogoMIPS: 4800.00</span><br><span class="line"> Virtualization: VT-x</span><br><span class="line"> L1d cache: 32K</span><br><span class="line"> L1i cache: 32K</span><br><span class="line"> L2 cache: 1024K</span><br><span class="line"> L3 cache: 36608K</span><br><span class="line"> NUMA node0 CPU(s): 0-3,7-9,13-15,19,20</span><br><span class="line"> NUMA node1 CPU(s): 4-6,10-12,16-18,21-23</span><br><span class="line"> NUMA node2 CPU(s): 24-27,31-33,37-39,43,44</span><br><span class="line"> NUMA node3 CPU(s): 28-30,34-36,40-42,45-47</span><br><span class="line"> NUMA node4 CPU(s): 48-51,55,56,60-62,66-68</span><br><span class="line"> NUMA node5 CPU(s): 52-54,57-59,63-65,69-71</span><br><span class="line"> NUMA node6 CPU(s): 72-75,79-81,85-87,91,92</span><br><span class="line"> NUMA node7 CPU(s): 76-78,82-84,88-90,93-95</span><br><span class="line"> NUMA node8 CPU(s): 96-99,103,104,108-110,114-116</span><br><span class="line"> NUMA node9 CPU(s): 100-102,105-107,111-113,117-119</span><br><span class="line"> NUMA node10 CPU(s): 120-123,127,128,132-134,138-140</span><br><span class="line"> NUMA node11 CPU(s): 124-126,129-131,135-137,141-143</span><br><span class="line"> NUMA node12 CPU(s): 144-147,151-153,157-159,163,164</span><br><span class="line"> NUMA node13 CPU(s): 148-150,154-156,160-162,165-167</span><br><span class="line"> NUMA node14 CPU(s): 168-171,175-177,181-183,187,188</span><br><span class="line"> NUMA node15 CPU(s): 172-174,178-180,184-186,189-191</span><br><span class="line"> </span><br><span class="line"> //v62</span><br><span class="line"> #lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                104</span><br><span class="line">On-line CPU(s) list:   0-103</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    26</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</span><br><span class="line">Stepping:              7</span><br><span class="line">CPU MHz:               3200.097</span><br><span class="line">CPU max MHz:           3800.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              4998.89</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              36608K</span><br><span class="line">NUMA node0 CPU(s):     0-25,52-77</span><br><span class="line">NUMA node1 CPU(s):     26-51,78-103</span><br><span class="line"></span><br><span class="line">//2016Intel开始出售Intel Xeon E5-2682 v4。 这是一种基于Broadwell架构的桌面处理器，主要为办公系统而设计。 它具有16 核心和32 数据流并使用, 售价约为7000人民币</span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                64</span><br><span class="line">On-line CPU(s) list:   0-63</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    16</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 79</span><br><span class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</span><br><span class="line">Stepping:              1</span><br><span class="line">CPU MHz:               2499.902</span><br><span class="line">CPU max MHz:           3000.0000</span><br><span class="line">CPU min MHz:           1200.0000</span><br><span class="line">BogoMIPS:              5000.06</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              256K</span><br><span class="line">L3 cache:              40960K</span><br><span class="line">NUMA node0 CPU(s):     0-15,32-47</span><br><span class="line">NUMA node1 CPU(s):     16-31,48-63</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3</span><br></pre></td></tr></table></figure>

<h3 id="intel-架构迭代"><a href="#intel-架构迭代" class="headerlink" title="intel 架构迭代"></a><a href="https://jcf94.com/2018/02/13/2018-02-13-intel/" target="_blank" rel="noopener">intel 架构迭代</a></h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/94d79c38-b577-4d31-b40c-fbec4cdc5f2e.png" alt="Intel processor roadmap"></p>
<p>2006年90、65纳米工艺酷睿core Yonah上市，32位架构，仍然算是奔腾Pro系列；2006推出酷睿处理器是介于NetBurst和Core之间，其实是NetBurst的改版，Core 2是第一个基于Core架构的原生双核处理器，65nm工艺，使得AMD K8架构优势全无，直接投入开发原生四核架构K10去了。</p>
<p>2006年7月<a href="https://zh.wikipedia.org/wiki/%E9%85%B7%E7%9D%BF2" target="_blank" rel="noopener">酷睿2</a>处理器代号为“<a href="https://zh.wikipedia.org/w/index.php?title=Conroe&action=edit&redlink=1" target="_blank" rel="noopener">Conroe</a>”，采用<a href="https://zh.wikipedia.org/wiki/X86-64" target="_blank" rel="noopener">x86-64</a>指令集与65纳米双核心架构。该处理器基于全新的酷睿微架构，虽然时脉大大降低，但在效率方面和性能方面有了重大改进。从这一时期开始，在深度流水线和资源混乱的运行引擎上维持每个周期的高指令（IPC）</p>
<p>2008年的 Nehalem （酷睿i7）是采用 45nm 工艺的新架构，主要优势来自重新设计的I&#x2F;O和存储系统，这些系统具有新的Intel QuickPath Interconnect和集成的内存控制器，可支持三通道的DDR3内存。引入片内4-12MB的L3 Cache；重新加入超线程；分支预测分级；取消北桥，IMC(集成内存控制器）从北桥挪到片内</p>
<p>2009年的 Westmere 升级到 32nm；退出第一代I5&#x2F;I3，Xeon 系列也开始推出第一代E命名的E7-x8xx系列。</p>
<p>2010年的 Lynnfield&#x2F;Clarkdale 基于 45nm&#x2F;32nm 工艺的新架构，第一代智能酷睿处理器；</p>
<p>2011年的 <strong>Sandy Bridge</strong> ，基于 32nm 工艺的新架构，第二代智能酷睿处理器，增加AVX指令集扩展， 对虚拟化提供更好支持；实现了GPU和CPU的融合</p>
<p>2012年的 IVY Bridge，是 Sandy Bridge 的 22nm 升级版，第三代智能酷睿处理器，Tick级改进；</p>
<p>2013年的 Haswell ，基于 22nm 工艺的新架构，第四代智能酷睿处理器，Tock级改进；</p>
<p>2014年的 <strong>Broadwell</strong>，是 Haswell 的 14nm 升级版，第五代智能酷睿处理器；</p>
<p>2015年则推出 <strong>SkyLake</strong>，基于 14nm 工艺的新架构， Tock级改进，Ring-Bus改成了Mesh架构，第6代Core i系列，8163就是这款；socket之间UPI互联，内存频率通道增强。不再使用Xeon命名，而是改用Bronze&#x2F;Silver&#x2F;Gold&#x2F;Platinum 4个系列。青铜和白银系列支持双路（原本的 E5-24xx、E7-28xx 系列），黄金系列支持四路（原本的 E5-46xx、E7-48xx 系列），白金系列支持八路（原本的 E7-88xx 系列）；</p>
<p>2019年的Cascade Lake(X2XX命名)也是Skylake的优化，是Intel首个支持基于3D XPoint的内存模块的微体系结构。同年也正式宣布了十代酷睿处理器，即i9-10900k，还是Skylake微内核不变。</p>
<p>2020年的10nm Ice Lake自家工厂无能，改由台积电加工。</p>
<p>2023年 Intel 发布代号Sapphire Rapids（SPR）的第四代英特尔至强（Intel Xeon）可扩展处理器，其核心数最多可达60个，比代号Ice Lake(-SP)的第三代至强可扩展处理器高出50%。相应的，公开款的TDP指标上限，也从270瓦（W）一跃而至350瓦。这一波核数增长的关键是，大英（终于）从单片式（monolithic）的die，转为四等分的die拼接(跟随了 AMD 的策略)</p>
<p>Core 架构代号是 Yonah，把 NetBurst 做深了的流水线级数又砍下来了，主频虽然降下来了（而且即使后来工艺提升到 45nm 之后也没有超过 NetBurst 的水平），但是却提高了整个流水线中的资源利用率，所以性能还是提升了；把奔腾 4 上曾经用过的超线程也砍掉了；对各个部分进行了强化，双核共享 L2 cache 等等。</p>
<p>从 Core 架构开始是真的走向多核了，就不再是以前 “胶水粘的” 伪双核了，这时候已经有最高 4 核的处理器设计了。</p>
<p>Core 从 65nm 改到 45nm 之后，基于 45nm 又推出了新一代架构叫 Nehalem，新架构Nehalem<strong>采用 Intel QPI 来代替原来的前端总线</strong>，<strong>PCIE 和 DMI 控制器直接做到片内了</strong>，不再需要北桥。</p>
<p>2006年Intel也提出了Tick-Tock架构战略。Tick年改进制程工艺，微架构基本不做大改，重点在把晶体管的工艺水平往上提升;Tock年改进微架构设计，保持工艺水平不变，重点在用更复杂、更高级的架构设计。然后就是一代 Tick 再一代 Tock交替演进。</p>
<p>从2006年酷睿架构开始，基本是摁着AMD在地上摩擦，直到2017年的AMD Zen杀回来，性能暴增。<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f5e72f61ed8b6c2ba163e00491c7db40.png" alt="img"></p>
<p><strong>Sandy Bridge 引入核间的ring bus</strong></p>
<p>感觉Broadwell前面这几代都是在优化cache、通信；接下来的Broadwell和SkyLake就开始改进不大了，疯狂挤牙膏（唯一比较大的改进就是<strong>Ring bus到Mesh</strong>）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210602154509596.png" alt="image-20210602154509596"></p>
<h3 id="命名规律"><a href="#命名规律" class="headerlink" title="命名规律"></a>命名规律</h3><p>Intel E3、E5、E7代表了3个不同档次的至强CPU。EX是按性能和应用场景分的，以前是E3 E5 E7，E3核最少，轻负载应用，E5 核多均衡型，E7是超高性能，核最多。Xeon E5是针对高端工作站及服务器的处理器系列，此系列每年更新，不过架构落后Xeon E3一代。从skylake开始，不再使用EX(E3&#x2F;E5&#x2F;E7)了，而是铜、银、金、铂金四种组合。</p>
<p>V2 是ivy bridge，V3 是 haswell， V4 是broadwell，不带VX的是sandy bridge。所以2682是boradwell系列CPU。<br>然后到了4114，就是Silver，8186就是Platinum，81是skylake，82是cscadelake，再下一代是83。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/750px-cascade_lake_naming_scheme.svg.png" alt="cascade lake naming scheme.svg"></p>
<h3 id="不同的架构下的参数"><a href="#不同的架构下的参数" class="headerlink" title="不同的架构下的参数"></a>不同的架构下的参数</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/e4a2fb522be7aa65158778b7ea825207.png" alt="image.png"></p>
<h2 id="UEFI和Bios"><a href="#UEFI和Bios" class="headerlink" title="UEFI和Bios"></a>UEFI和Bios</h2><p><strong>UEFI</strong>，全称Unified Extensible Firmware Interface，即“统一的可扩展固件接口”，是一种详细描述全新类型接口的标准，是适用于电脑的标准固件接口，旨在代替BIOS（基本输入&#x2F;输出系统）</p>
<p>电脑中有一个BIOS设置，它主要负责开机时检测硬件功能和引导操作系统启动的功能。而UEFI则是用于操作系统自动从预启动的操作环境，加载到一种操作系统上从而节省开机时间。</p>
<p>UEFI启动是一种新的主板引导项，它被看做是bios的继任者。UEFI最主要的特点是图形界面，更利于用户对象图形化的操作选择。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/webp" alt="img"></p>
<p>UEFI 图形界面：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/webp-20210601102242967" alt="img"></p>
<p>简单的来说UEFI启动是新一代的BIOS，功能更加强大，而且它是以图形图像模式显示，让用户更便捷的直观操作。</p>
<p>如今很多新产品的电脑都支持UEFI启动模式，甚至有的电脑都已抛弃BIOS而仅支持UEFI启动。这不难看出UEFI正在取代传统的BIOS启动。</p>
<p>UEFI固件通过ACPI报告给OS NUMA的组成结构，其中最重要的是SRAT（System Resource Affinity Table）和SLIT（System Locality Information Table）表。</p>
<h2 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h2><p>socket对应主板上的一个插槽，也可以简单理解为一块物理CPU。同一个socket对应着 &#x2F;proc&#x2F;cpuinfo 里面的physical id一样。</p>
<p>一个socket至少对应着一个或多个node&#x2F;NUMA</p>
<h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>GPU只处理有限的计算指令（主要是浮点运算–矩阵操作），不需要分支预测、乱序执行等，所以将Core里面的电路简化（如下图左边），同时通过SIMT（Single Instruction，Multiple Threads， 类似 SIMD）在取指令和指令译码的阶段，取出的指令可以给到后面多个不同的 ALU 并行进行运算。这样，我们的一个 GPU 的核里，就可以放下更多的 ALU，同时进行更多的并行运算了（如下图右边） 。 在 SIMD 里面，CPU 一次性取出了固定长度的多个数据，放到寄存器里面，用一个指令去执行。<strong>而 SIMT，可以把多条数据，交给不同的线程去处理。</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/3d7ce9c053815f6a32a6fbf6f7fb9628.jpeg" alt="img"></p>
<p>GPU的core在流水线stall的时候和超线程一样，可以调度别的任务给ALU，既然要调度一个不同的任务过来，我们就需要针对这个任务，提供更多的执行上下文。所以，一个 Core 里面的执行上下文的数量，需要比 ALU 多。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/c971c34e0456dea9e4a87857880bb5b8.jpeg" alt="img"></p>
<p>在通过芯片瘦身、SIMT 以及更多的执行上下文，我们就有了一个更擅长并行进行暴力运算的 GPU。这样的芯片，也正适合我们今天的深度学习和挖矿的场景。</p>
<p>NVidia 2080 显卡的技术规格，就可以算出，它到底有多大的计算能力。2080 一共有 46 个 SM（Streaming Multiprocessor，流式处理器），这个 SM 相当于 GPU 里面的 GPU Core，所以你可以认为这是一个 46 核的 GPU，有 46 个取指令指令译码的渲染管线。每个 SM 里面有 64 个 Cuda Core。你可以认为，这里的 Cuda Core 就是我们上面说的 ALU 的数量或者 Pixel Shader 的数量，46x64 呢一共就有 2944 个 Shader。然后，还有 184 个 TMU，TMU 就是 Texture Mapping Unit，也就是用来做纹理映射的计算单元，它也可以认为是另一种类型的 Shader。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/14d05a43f559cecff2b0813e8d5bdde2.png" alt="img"></p>
<p>2080 的主频是 1515MHz，如果自动超频（Boost）的话，可以到 1700MHz。而 NVidia 的显卡，根据硬件架构的设计，每个时钟周期可以执行两条指令。所以，能做的浮点数运算的能力，就是：</p>
<blockquote>
<p> （2944 + 184）× 1700 MHz × 2  &#x3D; 10.06  TFLOPS</p>
</blockquote>
<p>最新的 Intel i9 9900K 的性能是多少呢？不到 1TFLOPS。而 2080 显卡和 9900K 的价格却是差不多的。所以，在实际进行深度学习的过程中，用 GPU 所花费的时间，往往能减少一到两个数量级。而大型的深度学习模型计算，往往又是多卡并行，要花上几天乃至几个月。这个时候，用 CPU 显然就不合适了。</p>
<h3 id="为什么GPU比CPU快"><a href="#为什么GPU比CPU快" class="headerlink" title="为什么GPU比CPU快"></a><a href="https://medium.com/@shachishah.ce/do-we-really-need-gpu-for-deep-learning-47042c02efe2#:~:text=Bandwidth%20is%20one%20of%20the,be%20used%20for%20other%20tasks." target="_blank" rel="noopener">为什么GPU比CPU快</a></h3><p>GPU拥有更多的计算单元</p>
<p>GPU像是大卡车，每次去内存取数据取得多，但是Latency高（AP）；CPU像是法拉利，更在意处理速度而不是一次处理很多数据，所以CPU有多级cache，都是围绕速度在优化（TP）。在GPU中取数据和处理是流水线所以能消除高Latency。</p>
<p>GPU的每个core拥有更小更快的cache和registry，但是整个GPU的registry累加起来能比CPU大30倍，同时带宽也是后者的16倍</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210615105019238.png" alt="image-20210615105019238"></p>
<p>总之GPU相对于CPU像是一群小学生和一个大学教授一起比赛计算10以内的加减法。</p>
<h3 id="英伟达的GPU出圈"><a href="#英伟达的GPU出圈" class="headerlink" title="英伟达的GPU出圈"></a>英伟达的GPU出圈</h3><p>2016年之前英伟达的营收和市值基本跟intel一致，但是2021 年 4 月中旬的数字，Intel 是英伟达的近 5 倍，但是如果论市值，英伟达是 Intel 的 1.5 倍。</p>
<p><strong>GPGPU：点亮并行计算的科技树</strong></p>
<p>2007 年，英伟达首席科学家 David Kirk 非常前瞻性地提出 GPGPU 的概念，把英伟达和 GPU 从单纯图形计算拓展为通用计算，强调并行计算，鼓励开发者用 GPU 做计算，而不是局限在图形加速这个传统的领域。GPGPU，前面这个 GP，就是 General Purpose 通用的意思。</p>
<p>CUDA（Compute Unified Device Architecture，统一计算架构），CUDA 不仅仅是一个 GPU 计算的框架，它对下抽象了所有的英伟达出品的 GPU，对上构建了一个通用的编程框架，它实质上制定了一个 GPU 和上层软件之间的接口标准。</p>
<p>在 GPU 市场的早期竞争中，英伟达认识到软硬件之间的标准的重要性，花了 10 年苦功，投入 CUDA 软件生态建设，把软硬件之间的标准，变成自己的核心竞争力。</p>
<p>英伟达可以说是硬件公司中软件做得最好的。同样是生态强大，Wintel 的生态是微软帮忙建的，ARM-Android 的生态是 Google 建的，而 GPU-CUDA 的生态是英伟达自建的。</p>
<p>这个标准有多重要？这么说吧，一流企业定标准，二流企业做品牌，三流企业做产品。在所有的半导体公司中，制定出软件与硬件之间的标准，而且现在还算成功的，只有 3 个，一个是 x86 指令集，一个是 ARM 指令集，还有一个就是 CUDA 了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/313d469d57e6b92eyy03dee63614a72c.png" alt="img"></p>
<p>GPU 相对 CPU 的 TOPS per Watt（花费每瓦特电能可以获得的算力）的差异竞争优势，它的本质就是将晶体管花在计算上，而不是逻辑判断上</p>
<p>2020 年超级计算机 TOP500 更新榜单，可以看到 TOP10 的超级计算机中有 8 台采用了英伟达 GPU、InfiniBand 网络技术，或同时采用了两种技术。TOP500 榜单中，有 333 套（三分之二）采用了英伟达的技术。</p>
<p>挖矿和深度学习撑起了英伟达的市值。</p>
<h2 id="现场可编程门阵列FPGA（Field-Programmable-Gate-Array）"><a href="#现场可编程门阵列FPGA（Field-Programmable-Gate-Array）" class="headerlink" title="现场可编程门阵列FPGA（Field-Programmable Gate Array）"></a>现场可编程门阵列FPGA（Field-Programmable Gate Array）</h2><p>设计芯片十分复杂，还要不断验证。</p>
<p>那么不用单独制造一块专门的芯片来验证硬件设计呢？能不能设计一个硬件，通过不同的程序代码，来操作这个硬件之前的电路连线，通过“编程”让这个硬件变成我们设计的电路连线的芯片呢？这就是FPGA</p>
<ul>
<li>P 代表 Programmable，这个很容易理解。也就是说这是一个可以通过编程来控制的硬件。</li>
<li>G 代表 Gate 也很容易理解，它就代表芯片里面的门电路。我们能够去进行编程组合的就是这样一个一个门电路。</li>
<li>A 代表的 Array，叫作阵列，说的是在一块 FPGA 上，密密麻麻列了大量 Gate 这样的门电路。</li>
<li>最后一个 F，不太容易理解。它其实是说，一块 FPGA 这样的板子，可以在“现场”多次进行编程。它不像 PAL（Programmable Array Logic，可编程阵列逻辑）这样更古老的硬件设备，只能“编程”一次，把预先写好的程序一次性烧录到硬件里面，之后就不能再修改了。</li>
</ul>
<p>FPGA 通过“软件”来控制“硬件”</p>
<h2 id="专用集成电路ASIC（Application-Specific-Integrated-Circuit）"><a href="#专用集成电路ASIC（Application-Specific-Integrated-Circuit）" class="headerlink" title="专用集成电路ASIC（Application-Specific Integrated Circuit）"></a>专用集成电路ASIC（Application-Specific Integrated Circuit）</h2><p>为解决特定应用问题而定制设计的集成电路，就是 ASIC（Application Specific IC）。当 ASIC 规模够大，逐渐通用起来，某类 ASIC 就会有一个专有名称，成为一个品类。例如现在用来解决人工智能问题的神经网络处理器。</p>
<p>除了 CPU、GPU，以及刚刚的 FPGA，我们其实还需要用到很多其他芯片。比如，现在手机里就有专门用在摄像头里的芯片；录音笔里会有专门处理音频的芯片。尽管一个 CPU 能够处理好手机拍照的功能，也能处理好录音的功能，但是我们直接在手机或者录音笔里塞上一个 Intel CPU，显然比较浪费。</p>
<p>因为 ASIC 是针对专门用途设计的，所以它的电路更精简，单片的制造成本也比 CPU 更低。而且，因为电路精简，所以通常能耗要比用来做通用计算的 CPU 更低。而我们所说的早期的图形加速卡，其实就可以看作是一种 ASIC。</p>
<p>因为 ASIC 的生产制造成本，以及能耗上的优势，过去几年里，有不少公司设计和开发 ASIC 用来“挖矿”。这个“挖矿”，说的其实就是设计专门的数值计算芯片，用来“挖”比特币、ETH 这样的数字货币。</p>
<p>如果量产的ASIC比较小的话可以直接用FPGA来实现，FPGA介于ASIC和PLA之间，PLA（可编程控制器）太简单，直接上ASIC又过于复杂、能耗高、成本高。</p>
<h2 id="张量处理器TPU-（tensor-processing-unit）"><a href="#张量处理器TPU-（tensor-processing-unit）" class="headerlink" title="张量处理器TPU （tensor processing unit）"></a>张量处理器TPU （tensor processing unit）</h2><p><strong>张量处理器</strong>（英语：tensor processing unit，缩写：TPU）是<a href="https://baike.baidu.com/item/Google" target="_blank" rel="noopener">Google</a>为<a href="https://baike.baidu.com/item/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" target="_blank" rel="noopener">机器学习</a>定制的专用芯片（ASIC），专为Google的<a href="https://baike.baidu.com/item/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" target="_blank" rel="noopener">深度学习</a>框架<a href="https://baike.baidu.com/item/TensorFlow" target="_blank" rel="noopener">TensorFlow</a>而设计。</p>
<p>在性能上，TPU 比现在的 CPU、GPU 在深度学习的推断任务上，要快 15～30 倍。而在能耗比上，更是好出 30～80 倍。另一方面，Google 已经用 TPU 替换了自家数据中心里 95% 的推断任务，可谓是拿自己的实际业务做了一个明证。</p>
<h2 id="其它基础知识"><a href="#其它基础知识" class="headerlink" title="其它基础知识"></a>其它基础知识</h2><p><strong>晶振频率</strong>：控制CPU上的晶体管开关切换频率。一次晶振就是一个cycle。</p>
<p>从最简单的单指令周期 CPU 来说，其实时钟周期应该是放下最复杂的一条指令的时间长度。但是，我们现在实际用的都没有单指令周期 CPU 了，而是采用了流水线技术。采用了流水线技术之后，单个时钟周期里面，能够执行的就不是一个指令了。我们会把一条机器指令，拆分成很多个小步骤。不同的指令的步骤数量可能还不一样。不同的步骤的执行时间，也不一样。所以，一个时钟周期里面，能够放下的是最耗时间的某一个指令步骤。</p>
<p>不过没有pipeline，一条指令最少也要N个circle（N就是流水线深度）；但是理想情况下流水线跑满的话一个指令也就只需要一个circle了，也就是IPC能到理论最大值1； 加上超标流水线一般IPC都能4，就是一般CPU的超标量。</p>
<p><strong>制程</strong>：7nm、14nm、4nm都是指的晶体大小，用更小的晶体可以在相同面积CPU上集成更多的晶体数量，那么CPU的运算能力也更强。增加晶体管可以增加硬件能够支持的指令数量，增加数字通路的位数，以及利用好电路天然的并行性，从硬件层面更快地实现特定的指。打个比方，比如我们最简单的电路可以只有加法功能，没有乘法功能。乘法都变成很多个加法指令，那么实现一个乘法需要的指令数就比较多。但是如果我们增加晶体管在电路层面就实现了这个，那么需要的指令数就变少了，执行时间也可以缩短。</p>
<blockquote>
<p>功耗 ~&#x3D; 1&#x2F;2 ×负载电容×电压的平方×开关频率×晶体管数量</p>
</blockquote>
<p>功耗和电压的平方是成正比的。这意味着电压下降到原来的 1&#x2F;5，整个的功耗会变成原来的 1&#x2F;25。</p>
<p>堆栈溢出：函数调用用压栈来保存地址、变量等相关信息。没有选择直接嵌套扩展代码是避免循环调用下嵌套是个无尽循环，inline函数内联就是一种嵌套代码扩展优化。</p>
<p>windows下的exe文件之所以没法放到linux上运行（都是intel x86芯片），是因为可执行程序要经过链接，将所依赖的库函数调用合并进来形成可执行文件。这个可执行文件在Linux 下的 ELF（Execuatable and Linkable File Format） 文件格式，而 Windows 的可执行文件格式是一种叫作 PE（Portable Executable Format）的文件格式。Linux 下的装载器只能解析 ELF 格式而不能解析 PE 格式。而且windows和linux的库函数必然不一样，没法做到兼容。</p>
<p><strong>链接器</strong>: 扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。这也是为什么，可执行文件里面的函数调用的地址都是正确的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/997341ed0fa9018561c7120c19cfa2a7.jpg" alt="img"></p>
<p><strong>虚拟内存地址</strong>：应用代码可执行地址必须是连续，这也就意味着一个应用的内存地址必须连续，实际一个OS上会运行多个应用，没办法保证地址连续，所以可以通过虚拟地址来保证连续，虚拟地址再映射到实际零散的物理地址上（可以解决碎片问题），这个零散地址的最小组织形式就是Page。虚拟地址本来是连续的，使用一阵后数据部分也会变成碎片，代码部分是不可变的，一直连续。另外虚拟地址也方便了OS层面的库共享。</p>
<p>为了扩大虚拟地址到物理地址的映射范围同时又要尽可能少地节约空间，虚拟地址到物理地址的映射一般分成了四级Hash，这样4Kb就能管理256T内存。但是带来的问题就是要通过四次查找使得查找慢，这时引入TLAB来换成映射关系。</p>
<p><strong>共享库</strong>：在 Windows 下，这些共享库文件就是.dll 文件，也就是 Dynamic-Link Libary（DLL，动态链接库）。在 Linux 下，这些共享库文件就是.so 文件，也就是 Shared Object（一般我们也称之为动态链接库). 不同的进程，调用同样的 lib.so，各自 全局偏移表（GOT，Global Offset Table） 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的, 各个程序各自维护好自己的 GOT，能够找到对应的动态库就好了, 有点像函数指针。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1144d3a2d4f3f4f87c349a93429805c8.jpg" alt="img"></p>
<p>符号表：&#x2F;boot&#x2F;System.map 和 &#x2F;proc&#x2F;kallsyms </p>
<p><strong>超线程（Hyper-Threading）</strong>: 在CPU内部增加寄存器等硬件设施，但是ALU、译码器等关键单元还是共享。在一个物理 CPU 核心内部，会有双份的 PC 寄存器、指令寄存器乃至条件码寄存器。超线程的目的，是在一个线程 A 的指令，在流水线里停顿的时候，让另外一个线程去执行指令。因为这个时候，CPU 的译码器和 ALU 就空出来了，那么另外一个线程 B，就可以拿来干自己需要的事情。这个线程 B 可没有对于线程 A 里面指令的关联和依赖。</p>
<h2 id="宏观认识集成电路半导体行业"><a href="#宏观认识集成电路半导体行业" class="headerlink" title="宏观认识集成电路半导体行业"></a>宏观认识集成电路半导体行业</h2><p>先从市场分布和市场占有率等几个行业宏观概念来了解半导体行业</p>
<h3 id="半导体产业的产值分布"><a href="#半导体产业的产值分布" class="headerlink" title="半导体产业的产值分布"></a>半导体产业的产值分布</h3><p>下图中的处理器就是我们日常所说的CPU，当然还包含了GPU等</p>
<p>我们常说的内存、固态硬盘这些存储器也是数字IC，后面你会看到一个CPU core里面还会有用于存储的cache电路</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/be159461be7c0a5569be21b30a24db50.png" alt="img"></p>
<h3 id="从一台iPhone来看集成电路和芯片"><a href="#从一台iPhone来看集成电路和芯片" class="headerlink" title="从一台iPhone来看集成电路和芯片"></a>从一台iPhone来看集成电路和芯片</h3><p>先看一台iPhone X拆解分析里面的所有芯片：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/8bbc7b771359dfc07c81ca2a064cb30c.jpg" alt="img"></p>
<h3 id="全球半导体营收分布"><a href="#全球半导体营收分布" class="headerlink" title="全球半导体营收分布"></a>全球半导体营收分布</h3><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/d3a2690aaf6be233d08404c108fc4449.png" alt="img"></p>
<p>美光：美国；Hynix海力士：韩国现代；美国双通：高通(CDMA)、博通(各种买买买、并购，网络设备芯片)；欧洲双雄(汽车芯片)：恩智浦和英飞凌</p>
<p>半导体行业近 5 年的行业前十的公司列了如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/639990db9d26a8a54d1baaf3d6e513d4.png" alt="img"></p>
<h4 id="半导体产品的十大买家"><a href="#半导体产品的十大买家" class="headerlink" title="半导体产品的十大买家"></a>半导体产品的十大买家</h4><p>BBK是步步高集团，包含vivo、oppo、oneplus、realme等</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/3bb8531b7ab4c503436838ab15434310.png" alt="img"></p>
<h3 id="国内半导体市场情况"><a href="#国内半导体市场情况" class="headerlink" title="国内半导体市场情况"></a>国内半导体市场情况</h3><p>中国半导体协会总结过国产芯片的比例，2014 年出台的《国家集成电路产业发展纲要》和 2015 年的《中国制造 2025》文件中有明确提出：到 2020 年，集成电路产业与国际先进水平的差距逐步缩小；2020 年中国芯片自给率要达到 40%，2025 年要达到 50%。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/a37bd5e13f2920fb2e85a7907cdc852a.jpeg" alt="img"></p>
<p>国产化国家主导：紫光， 紫光的策略从收购转为自建，2016 年 12 月，合并武汉新芯，成立长江存储，与西数合资成立紫光西数。</p>
<p>长江存储在量产 64 层 NAND Flash 之后，2020 年首发 192 层 3D NAND，被预测 2021 会拿下 8% 的 NAND Flash 份额。同时，在存储芯片领域，中国还有一家公司叫做长鑫存储，长鑫存储以唯一一家中国公司的名号，杀入 DRAM 领域。在世界著名的行业分析公司 Yole 公司的报告上，显示长江存储和长鑫存储与三星、SK 海力士、美光和 Intel 齐头并进。</p>
<p>市场份额上，国产存储芯片市场，也许还有望达到 2025 的目标。</p>
<p>以上是我们对集成电路半导体行业的宏观认识。接下来我们从一颗CPU的生产制造开始讲</p>
<h3 id="工艺"><a href="#工艺" class="headerlink" title="工艺"></a>工艺</h3><p>光刻的粒度越来越细，玩家也越来越少，基本主流都是代工模式：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/beebe27eacd37075dyy37a4182169f04.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/5eb09cde20395b84ff8c746c27d9f7b7.jpg" alt="img"></p>
<p>晶体管密度比较</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210728095829384.png" alt="image-20210728095829384"></p>
<h2 id="计算机芯片发展总结和展望"><a href="#计算机芯片发展总结和展望" class="headerlink" title="计算机芯片发展总结和展望"></a><a href="https://weibo.com/ttarticle/p/show?id=2309404745052319777615" target="_blank" rel="noopener">计算机芯片发展总结和展望</a></h2><p>从最早集成工艺驱动了CPU的性能符合摩尔定律发展，到现在工艺受限于物理上的客观因素：门延迟、电路间的绝缘层越薄漏电越严重–高温导致漏电呈指数级增加、电压无法随着尺寸降低而线性降低–130nm之前电压随线宽(工艺)而线性下降，到90nm工艺之后工作电压始终在1V左右无法进一步下降，越来越难进一步优化，导致摩尔定律基本已经做不到了。</p>
<p>下图显示最近几年CPU性能改进都在3%左右了（红色部分）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f6.jpg" alt="f6.jpg"></p>
<p>从上图可以看到性能的优化从最早CISC每年22%来自于指令本身优化，然后RISC（CISC内部也学习RISC将复杂指令编译成简单指令来适应流水线）每年52%，再到简单多核，然后到大规模多核，最后到红色无所改进。</p>
<p><strong>登纳德缩放定律</strong>（Dennard scaling）指出，随着晶体管密度的增加，每个晶体管的能耗将降低，因此硅芯片上每平方毫米上的能耗几乎保持恒定。由于每平方毫米硅芯片的计算能力随着技术的迭代而不断增强，计算机将变得更加节能。登纳德缩放定律从 2007 年开始大幅放缓，2012 年左右接近失效（见下图）。</p>
<blockquote>
<p>Dennard缩放定律（摩尔定律是经济定律，Dennard才是半导体专业定律）:晶体管的尺寸在每一代技术中都缩小了30% (0.7倍)，因此它们的面积减少了50%。这意味着电路减少了30% (0.7倍)的延迟，因此增加了约40% (1.4倍)的工作频率。最后，为了保持电场恒定，电压降低了30%，能量降低了65%，功率降低了50%。因此，在每一代技术中，晶体管密度增加一倍，电路速度提高40%，功耗(晶体管数量增加一倍)保持不变。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f3.jpg" alt="f3.jpg"></p>
<p><strong>阿姆达尔定律（Amdahl’s Law）</strong>认为，并行计算机的加速受限于串行计算的部分。如下图假设只在一个处理器上执行时的串行执行的部分所占比例不同，与单个内核相比，最多 64 个内核的应用程序运行速度能快多少。例如，如果只有 1% 的时间是串行的，那么 64 核配置可加速大约 35 倍，但所需能量与 64 个处理器成正比，因此大约有 45% 的能量被浪费了。核数越多多核带来的提升效果越来越差（程序总有地方是串行的）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f5.jpg" alt="f5.jpg"></p>
<p>大概从2000年左右CPU的性能增长开始放缓，到2018年实际性能比摩尔定律预估的差了15倍（注意纵坐标是指数级），因为CMOS技术已经接近极限</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f2.jpg" alt="f2.jpg"></p>
<blockquote>
<p><a href="https://baike.baidu.com/item/CMOS" target="_blank" rel="noopener">CMOS</a>电路是互补型金属<a href="https://baike.baidu.com/item/%E6%B0%A7%E5%8C%96%E7%89%A9%E5%8D%8A%E5%AF%BC%E4%BD%93/6199658" target="_blank" rel="noopener">氧化物半导体</a>电路(Complementary Metal-Oxide-Semiconductor)的英文字头缩写，它由绝缘<a href="https://baike.baidu.com/item/%E5%9C%BA%E6%95%88%E5%BA%94%E6%99%B6%E4%BD%93%E7%AE%A1/2293646" target="_blank" rel="noopener">场效应晶体管</a>组成，由于只有一种<a href="https://baike.baidu.com/item/%E8%BD%BD%E6%B5%81%E5%AD%90/7163305" target="_blank" rel="noopener">载流子</a>，因‘而是一种<a href="https://baike.baidu.com/item/%E5%8D%95%E6%9E%81%E5%9E%8B%E6%99%B6%E4%BD%93%E7%AE%A1/9003337" target="_blank" rel="noopener">单极型晶体管</a>集成电路，其基本结构是一个N沟道<a href="https://baike.baidu.com/item/MOS%E7%AE%A1/8703611" target="_blank" rel="noopener">MOS管</a>和一个P沟道MOS管</p>
</blockquote>
<p>过去一些对性能或者便利性的改进以及对这些改进的打分：</p>
<blockquote>
<p>虚拟地址在计算机体系结构里可以评为特优的一项技术，非性能上的改进，甚至对性能有负面影响；</p>
<p>超线程、流水线、多发射只是优；</p>
<p>cache 只是良好（成本高），cache整体肯定比超线程对性能提升要大，但是因为高成本导致得分不高</p>
</blockquote>
<h3 id="计算机架构的未来机遇"><a href="#计算机架构的未来机遇" class="headerlink" title="计算机架构的未来机遇"></a><a href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext#body-6" target="_blank" rel="noopener">计算机架构的未来机遇</a></h3><p>当实际集成度（性能）已经不再增长后，我们必须找到新的办法</p>
<p>如下图是用Python实现的矩阵相乘的性能优化过程，简单地将 Python 语言代码重写为 C 代码就可以将性能提升 46 倍（Python 是典型的高级、动态类型语言）。在多核上运行并行循环（parallel loops）又将性能提升接近 7 倍。优化内存配置又将性能提升了近 19 倍，而通过单指令多数据（SIMD）并行化操作（一个指令执行 16 个 32-bit 运算）的硬件扩展，性能又提升了 8 倍多。也就是说，最终的高度优化版本在多核英特尔处理器上的运行速度是初始 Python 版本的 62,000 多倍。这当然只是一个很小的例子，但我们会期望程序员使用优化库。尽管这夸大了常见的性能差距，但很多程序的性能差距可能达到 100 到 1000 倍。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/f7.jpg" alt="f7.jpg"></p>
<h4 id="特定领域的体系结构（DSA）"><a href="#特定领域的体系结构（DSA）" class="headerlink" title="特定领域的体系结构（DSA）"></a>特定领域的体系结构（DSA）</h4><p>特定领域的体系结构（DSA）–针对具体领域的特定优化和改进可以能是一个大的改进方向。比如SIMD，同时DSA和cache、内存的层次结构更匹配。</p>
<p>对特定领域降低精度，通用任务的 CPU 通常支持 32 和 64 位整型数和浮点数数据。对于很多机器学习和图像应用来说，这种准确率有点浪费了。例如在深度神经网络中（DNN），推理通常使用 4、8 或 16 位整型数，从而提高数据和计算吞吐量。同样，对于 DNN 训练程序，浮点数很有意义，但 32 位就够了，16 为经常也能用。</p>
<p>还可以在特定领域通过<strong>特定领域语言（DSL）编写的目标程序，这些程序可以实现更高的并行性</strong>（比如TPU、GPU）</p>
<h4 id="开放式架构（Open-Architectures）"><a href="#开放式架构（Open-Architectures）" class="headerlink" title="开放式架构（Open Architectures）"></a>开放式架构（Open Architectures）</h4><p>RISC-V</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Wafer：晶圆，一片大的纯硅圆盘，新闻里常说的12寸、30寸晶圆厂说的就是它，光刻机在晶圆上蚀刻出电路</p>
<p>Die：从晶圆上切割下来的裸片(包含多个core、北桥、GPU等)，Die的大小可以自由决定，得考虑成本和性能, Die做成方形便于切割和测试</p>
<p>封装：将一个或多个Die封装成一个物理上可以售卖的CPU</p>
<p>路：就是socket、也就是封装后的物理CPU</p>
<p>node：同一个Die下的多个core以及他们对应的内存，对应着NUMA</p>
<p>现在计算机系统的CPU和芯片组内核Die都是先封装到一个印制板上（PCB，printed circuit board），再通过LGA等等插槽（Socket）连上主板或直接焊接在主板上。这个过程叫做封装（Package），相关技术叫做封装技术。</p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&mid=2247585454&idx=1&sn=9fc69896305578539b1679ec1624f150" target="_blank" rel="noopener">多元 CPU 性能调优的技术挑战、产品设计和业务实践</a> – 2024 百度对AMD、Ampere和Intel 的一些差异进行了比较</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line和性能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/16/CPU_Cache_Line和性能/" itemprop="url">CPU 性能和Cache Line</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-05-16T12:30:03+08:00">
                2021-05-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU-性能和Cache-Line"><a href="#CPU-性能和Cache-Line" class="headerlink" title="CPU 性能和Cache Line"></a>CPU 性能和Cache Line</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>CPU为什么要CACHE，请看这篇</p>
<h2 id="什么是-cache-line"><a href="#什么是-cache-line" class="headerlink" title="什么是 cache_line"></a>什么是 cache_line</h2><p>CPU从内存中读取数据的时候是一次读一个cache_line到 cache中以提升效率，一般情况下cache_line的大小是64 byte（64Bytes也就是16个32位的整型）这就是CPU从内存中捞数据上来的最小数据单位，按照热点逻辑还是大概率会依次被访问到（详见后面的例子）。</p>
<p>比如L1 Cache 有32KB，那么它可以分成32KB &#x2F; 64 &#x3D; 512 条 Cache Line。</p>
<p>Cache Line 是 CPU 和主存之间数据传输的最小单位。当一行 Cache Line 被从内存拷贝到 Cache 里，Cache 里会为这个 Cache Line 创建一个条目。这个 Cache 条目里既包含了拷贝的内存数据，即 Cache Line，又包含了这行数据在内存里的位置等元数据信息。</p>
<p>处理器都实现了 Cache 一致性 (Cache Coherence）协议。如历史上 x86 曾实现了<a href="https://en.wikipedia.org/wiki/MESI_protocol" target="_blank" rel="noopener"> MESI 协议</a>，以及 MESIF 协议。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220928160819468.png" alt="image-20220928160819468"></p>
<p>先看下如上一张图，其中</p>
<p>tag：一般虚拟地址高位多bit表示；</p>
<p>index: 虚拟地址中间多bit表示；</p>
<p>offset: 虚拟地址多bit表示；</p>
<p>但是这三者的值是多少呢，只能说和cache缓存的的大小息息相关。</p>
<p>举个例子，录入cache缓存大小为64K, 有4路， 服务器寻址为64bit。</p>
<ul>
<li>offset的值为 2^ &#x3D; 64; offset &#x3D; 6;</li>
<li>index的值为 64k &#x2F; (64 * 4) &#x3D; 256 &#x3D; 2 ^ 8; 所以index的值为8bit；</li>
<li>tag的值为 64 - 8 - 6 &#x3D; 50bit;</li>
</ul>
<p>注:此计算完全按照理论方式计算，实际情况需要考虑TLB别名以及其他情况影响。</p>
<p>了解以上概念后，此处用一张图去介绍TLB转换获取数据的过程。</p>
<h3 id="cache-失效"><a href="#cache-失效" class="headerlink" title="cache 失效"></a>cache 失效</h3><p>假设两个处理器 A 和 B, 都在各自本地 Cache Line 里有同一个变量的拷贝时，此时该 Cache Line 处于 Shared 状态。当处理器 A 在本地修改了变量，除去把本地变量所属的 Cache Line 置为 Modified 状态以外，还必须在另一个处理器 B 读同一个变量前，对该变量所在的 B 处理器本地 Cache Line 发起 Invaidate 操作，标记 B 处理器的那条 Cache Line 为 Invalidate 状态。随后，若处理器 B 在对变量做读写操作时，如果遇到这个标记为 Invalidate 的状态的 Cache Line，即会引发 Cache Miss，从而将内存中最新的数据拷贝到 Cache Line 里，然后处理器 B 再对此 Cache Line 对变量做读写操作。</p>
<p>cache ping-pong(cache-line ping-ponging) 是指不同的CPU共享位于同一个cache-line里边的变量，当不同的CPU频繁的对该变量进行读写时，会导致其他CPU cache-line的失效。</p>
<p>显而易见的是一旦cache失效就需要访问内存重新从内存中读取数据到CPU cache中，这个过程会很慢。</p>
<h2 id="查看-cache-line"><a href="#查看-cache-line" class="headerlink" title="查看 cache_line"></a>查看 cache_line</h2><p>如下 Linux <code>getconf</code> 命令的输出，除了 <code>*_LINESIZE</code> 指示了系统的 Cache Line 的大小是 64 字节外，还给出了 Cache 类别，大小。 其中 <code>*_ASSOC</code> 则指示了该 Cache 是几路关联 (Way Associative) 的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$sudo getconf -a |grep CACHE</span><br><span class="line">LEVEL1_ICACHE_SIZE                 32768</span><br><span class="line">LEVEL1_ICACHE_ASSOC                8</span><br><span class="line">LEVEL1_ICACHE_LINESIZE             64</span><br><span class="line">LEVEL1_DCACHE_SIZE                 32768</span><br><span class="line">LEVEL1_DCACHE_ASSOC                8</span><br><span class="line">LEVEL1_DCACHE_LINESIZE             64</span><br><span class="line">LEVEL2_CACHE_SIZE                  262144</span><br><span class="line">LEVEL2_CACHE_ASSOC                 4</span><br><span class="line">LEVEL2_CACHE_LINESIZE              64</span><br><span class="line">LEVEL3_CACHE_SIZE                  3145728</span><br><span class="line">LEVEL3_CACHE_ASSOC                 12</span><br><span class="line">LEVEL3_CACHE_LINESIZE              64</span><br><span class="line">LEVEL4_CACHE_SIZE                  0</span><br><span class="line">LEVEL4_CACHE_ASSOC                 0</span><br><span class="line">LEVEL4_CACHE_LINESIZE              0</span><br></pre></td></tr></table></figure>

<p>比如，对于下面的FT2500 ARM芯片下，L1D是32K，是因为32K&#x3D;256*2*64（64就是cache_line大小，16个int）, 这32K是256个组，每组2行（x86一般是每组8行），每行就是一个cache_line</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210914175307651.png" alt="image-20210914175307651"></p>
<h2 id="cache-line-影响性能的案例"><a href="#cache-line-影响性能的案例" class="headerlink" title="cache_line 影响性能的案例"></a>cache_line 影响性能的案例</h2><p>如下两个循环执行次数循环2是循环1的十六分之一。但是在x86和arm下执行时间都是循环2是循环1的四分之一左右。</p>
<p>之所以执行时间不是十六分之一是因为循环一重用了cache_line. </p>
<p>Xeon(R) Platinum 8260跑这个程序的性能是鲲鹏920的2倍左右。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;stdio.h&quot;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;time.h&gt;</span><br><span class="line"></span><br><span class="line">long timediff(clock_t t1, clock_t t2) &#123;</span><br><span class="line">    long elapsed;</span><br><span class="line">    elapsed = ((double)t2 - t1) / CLOCKS_PER_SEC * 1000;</span><br><span class="line">    return elapsed;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">	long length=64*1024*1024;</span><br><span class="line">	int* arr=malloc(64*1024*1024 * sizeof(int));</span><br><span class="line">	long i=0;</span><br><span class="line">	long j=0;</span><br><span class="line">	for (i = 0; i &lt; length; i++) arr[i] = i;</span><br><span class="line"></span><br><span class="line">	clock_t start=clock();</span><br><span class="line">	// 循环1</span><br><span class="line">	for(j=0; j&lt;10; j++)&#123;</span><br><span class="line">	    for (i = 0; i &lt; length; i++) arr[i] *= 3; //每取一次arr[i], 通过cache_line顺便把后面15个arr[i]都取过来了</span><br><span class="line">	&#125;</span><br><span class="line">  clock_t end =clock();</span><br><span class="line">	printf(&quot;%lu\n&quot;, timediff(start,end));</span><br><span class="line"></span><br><span class="line">  start=clock();</span><br><span class="line">	// 循环2</span><br><span class="line">	for(j=0; j&lt;10; j++)&#123;</span><br><span class="line">	    for (i = 0; i &lt; length; i += 16) arr[i] *= 3;</span><br><span class="line">	&#125;</span><br><span class="line">  end =clock();</span><br><span class="line">  printf(&quot;%lu\n&quot;, timediff(start,end));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>鲲鹏920上循环一的perf结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -- ./cache_line_loop.out</span><br><span class="line">2790</span><br><span class="line"></span><br><span class="line">failed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;./cache_line_loop.out&apos;:</span><br><span class="line"></span><br><span class="line">       3238.892820      task-clock (msec)         #    1.000 CPUs utilized</span><br><span class="line">                 4      context-switches          #    0.001 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            65,582      page-faults               #    0.020 M/sec</span><br><span class="line">     8,420,900,487      cycles                    #    2.600 GHz</span><br><span class="line">        23,284,432      stalled-cycles-frontend   #    0.28% frontend cycles idle</span><br><span class="line">     4,709,527,283      stalled-cycles-backend    #   55.93% backend  cycles idle</span><br><span class="line">    14,553,892,976      instructions              #    1.73  insns per cycle</span><br><span class="line">                                                  #    0.32  stalled cycles per insn //因为有cache_line的命中，stall是循环二的四分之一</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">           141,482      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       3.239729660 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>鲲鹏920上循环二的perf结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -- ./cache_line_loop.out</span><br><span class="line">730</span><br><span class="line">failed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &apos;./cache_line_loop.out&apos;:</span><br><span class="line"></span><br><span class="line">       1161.126720      task-clock (msec)         #    0.999 CPUs utilized</span><br><span class="line">                 1      context-switches          #    0.001 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            65,583      page-faults               #    0.056 M/sec</span><br><span class="line">     3,018,882,346      cycles                    #    2.600 GHz</span><br><span class="line">        21,846,222      stalled-cycles-frontend   #    0.72% frontend cycles idle</span><br><span class="line">     2,456,150,941      stalled-cycles-backend    #   81.36% backend  cycles idle</span><br><span class="line">     1,970,906,199      instructions              #    0.65  insns per cycle</span><br><span class="line">                                                  #    1.25  stalled cycles per insn</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">           138,051      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       1.161791340 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p> 在Xeon(R) Platinum 8260 CPU @ 2.40GHz 上运行上面两个循环的时间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -- ./cache_line_loop.out</span><br><span class="line">1770</span><br><span class="line">370</span><br></pre></td></tr></table></figure>

<p>更多案例请参考7个示例科普CPU CACHE：<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></p>
<p>如下图，表示的是for循环每次跳K个int，在K小于16的时候虽然循环次数逐渐减少到原来的1&#x2F;16, 但是总时间没变，因为一直是访问的同一个cache里面的数据。 到16个之后就会产生突变（跨了cache_line），再后面32、64、128的时间减少来源于循环次数的减少，因为如论如何每次循环都需要访问内存加载数据到cache_line中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; arr.Length; i += K) arr[i] *= 3;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image6.png" alt="running times of this loop for different step values (K)"></p>
<p>更典型的案例是对一个二维数组逐行遍历和逐列遍历的时间差异，变量次数一样，但是因为二维数组按行保存，所以逐行遍历对cache line 更友好</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">const int row = 1024;</span><br><span class="line">const int col = 512</span><br><span class="line">int matrix[row][col];</span><br><span class="line">//逐行遍历  0.081ms</span><br><span class="line">int sum_row=0;</span><br><span class="line">for(int _r=0; _r&lt;row; _r++) &#123;</span><br><span class="line">    for(int _c=0; _c&lt;col; _c++)&#123;</span><br><span class="line">        sum_row += matrix[_r][_c];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">//逐列遍历 1.069ms</span><br><span class="line">int sum_col=0;</span><br><span class="line">for(int _c=0; _c&lt;col; _c++) &#123;</span><br><span class="line">    for(int _r=0; _r&lt;row; _r++)&#123;</span><br><span class="line">        sum_col += matrix[_r][_c];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="四线程竞争下的cache-line影响"><a href="#四线程竞争下的cache-line影响" class="headerlink" title="四线程竞争下的cache_line影响"></a>四线程竞争下的cache_line影响</h2><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220613103011120.png" alt="image-20220613103011120"></p>
<p>上图是每个线程对内存中自己的int进行++ (每个线程绑定在自己的core上，机器有4个P4 core)， 蓝色部分是每个线程的变量分配在线程内部，也就是每个变量有独立的cache_line，红色部分(含蓝色)是将变量放在一个cache_line（必然会出现伪共享）</p>
<h2 id="Disruptor"><a href="#Disruptor" class="headerlink" title="Disruptor"></a><a href="https://lmax-exchange.github.io/disruptor/disruptor.html" target="_blank" rel="noopener">Disruptor</a></h2><p>Disruptor论文中讲述了我们所做的一个实验。这个测试程序调用了一个函数，该函数会对一个64位的计数器循环自增5亿次。当单线程无锁时，程序耗时300ms。如果增加一个锁（仍是单线程、没有竞争、仅仅增加锁），程序需要耗时10000ms，慢了两个数量级。更令人吃惊的是，如果增加一个线程（简单从逻辑上想，应该比单线程加锁快一倍），耗时224000ms。使用两个线程对计数器自增5亿次比使用无锁单线程慢1000倍。<strong>并发很难而锁的性能糟糕。</strong>单线程使用CAS耗时5700ms。所以它比使用锁耗时少，但比不需要考虑竞争的单线程耗时多。</p>
<p>We will illustrate the cost of locks with a simple demonstration. The focus of this experiment is to call a function which increments a 64-bit counter in a loop 500 million times. This can be executed by a single thread on a 2.4Ghz Intel Westmere EP in just 300ms if written in Java. The language is unimportant to this experiment and results will be similar across all languages with the same basic primitives.</p>
<p>Once a lock is introduced to provide mutual exclusion, even when the lock is as yet un-contended, the cost goes up significantly. The cost increases again, by orders of magnitude, when two or more threads begin to contend. The results of this simple experiment are shown in the table below:</p>
<p><em>Table 1. Comparative costs of contention</em></p>
<table>
<thead>
<tr>
<th align="left">Method</th>
<th align="left">Time (ms)</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Single thread</td>
<td align="left">300</td>
</tr>
<tr>
<td align="left">Single thread with lock</td>
<td align="left">10,000</td>
</tr>
<tr>
<td align="left">Two threads with lock</td>
<td align="left">224,000</td>
</tr>
<tr>
<td align="left">Single thread with CAS</td>
<td align="left">5,700</td>
</tr>
<tr>
<td align="left">Two threads with CAS</td>
<td align="left">30,000</td>
</tr>
<tr>
<td align="left">Single thread with volatile write</td>
<td align="left">4,700</td>
</tr>
</tbody></table>
<p>如下测试代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">package test;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.atomic.AtomicLong;</span><br><span class="line">import java.util.concurrent.locks.Lock;</span><br><span class="line">import java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"></span><br><span class="line">public class LockBenchmark&#123;</span><br><span class="line">    public static void runIncrement()</span><br><span class="line">    &#123;</span><br><span class="line">        long counter = 0;</span><br><span class="line">        long max  = 50000000000L;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        while (counter &lt; max) &#123;</span><br><span class="line">            counter++;</span><br><span class="line">        &#125;</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms without lock&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void runIncrementWithLock()</span><br><span class="line">    &#123;</span><br><span class="line">        Lock lock = new ReentrantLock();</span><br><span class="line">        long counter = 0;</span><br><span class="line">        long max = 500000000L;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        while (counter &lt; max) &#123;</span><br><span class="line">            if (lock.tryLock())&#123;</span><br><span class="line">                counter++;</span><br><span class="line">                lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms with lock&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        runIncrement();</span><br><span class="line">	      System.out.println(&quot;start runIncrementWithLock.&quot;);</span><br><span class="line">        runIncrementWithLock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[root@ARM 14:14 /root]</span><br><span class="line">#java test.LockBenchmark</span><br><span class="line">Time spent is 19261ms without lock</span><br><span class="line">start runIncrementWithLock.</span><br><span class="line">Time spent is 17267ms with lock</span><br><span class="line"></span><br><span class="line">//单线程加锁在没有任何竞争的情况下慢了两个数量级是因为加锁动作本身需要几十个指令</span><br><span class="line">reentrantLock.tryLock()实现：</span><br><span class="line"> 11   final boolean nonfairTryAcquire(int);</span><br><span class="line"> 12     Code:</span><br><span class="line"> 13        0: invokestatic  #2                  // Method java/lang/Thread.currentThread:()Ljava/lang/Thread;</span><br><span class="line"> 14        3: astore_2</span><br><span class="line"> 15        4: aload_0</span><br><span class="line"> 16        5: invokevirtual #3                  // Method getState:()I</span><br><span class="line"> 17        8: istore_3</span><br><span class="line"> 18        9: iload_3</span><br><span class="line"> 19       10: ifne          29</span><br><span class="line"> 20       13: aload_0</span><br><span class="line"> 21       14: iconst_0</span><br><span class="line"> 22       15: iload_1</span><br><span class="line"> 23       16: invokevirtual #4                  // Method compareAndSetState:(II)Z</span><br><span class="line"> 24       19: ifeq          65</span><br><span class="line"> 25       22: aload_0</span><br><span class="line"> 26       23: aload_2</span><br><span class="line"> 27       24: invokevirtual #5                  // Method setExclusiveOwnerThread:(Ljava/lang/Thread;)V</span><br><span class="line"> 28       27: iconst_1</span><br><span class="line"> 29       28: ireturn</span><br><span class="line"> 30       29: aload_2</span><br><span class="line"> 31       30: aload_0</span><br><span class="line"> 32       31: invokevirtual #6                  // Method getExclusiveOwnerThread:()Ljava/lang/Thread;</span><br><span class="line"> 33       34: if_acmpne     65</span><br><span class="line"> 34       37: iload_3</span><br><span class="line"> 35       38: iload_1</span><br><span class="line"> 36       39: iadd</span><br><span class="line"> 37       40: istore        4</span><br><span class="line"> 38       42: iload         4</span><br><span class="line"> 39       44: ifge          57</span><br><span class="line"> 40       47: new           #7                  // class java/lang/Error</span><br><span class="line"> 41       50: dup</span><br><span class="line"> 42       51: ldc           #8                  // String Maximum lock count exceeded</span><br><span class="line"> 43       53: invokespecial #9                  // Method java/lang/Error.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V</span><br><span class="line"> 44       56: athrow</span><br><span class="line"> 45       57: aload_0</span><br><span class="line"> 46       58: iload         4</span><br><span class="line"> 47       60: invokevirtual #10                 // Method setState:(I)V</span><br><span class="line"> 48       63: iconst_1</span><br><span class="line"> 49       64: ireturn</span><br><span class="line"> 50       65: iconst_0</span><br><span class="line"> 51       66: ireturn</span><br></pre></td></tr></table></figure>

<p>不加锁的循环执行500亿次循环，加锁的只执行5亿次，最终耗时差不多。对应两个阶段的IPC数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#perf stat -p 92098</span><br><span class="line"> Performance counter stats for process id &apos;92098&apos;:</span><br><span class="line"></span><br><span class="line">       3978.381920      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               121      context-switches          #    0.030 K/sec</span><br><span class="line">                 7      cpu-migrations            #    0.002 K/sec</span><br><span class="line">                71      page-faults               #    0.018 K/sec</span><br><span class="line">    10,343,414,319      cycles                    #    2.600 GHz</span><br><span class="line">         2,091,748      stalled-cycles-frontend   #    0.02% frontend cycles idle</span><br><span class="line">        11,011,682      stalled-cycles-backend    #    0.11% backend  cycles idle</span><br><span class="line">    41,311,635,225      instructions              #    3.99  insns per cycle      //不加锁循环++</span><br><span class="line">                                                  #    0.00  stalled cycles per insn</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">            32,675      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       3.972534070 seconds time elapsed</span><br><span class="line"></span><br><span class="line">[root@ARM 13:55 /root]</span><br><span class="line">#perf stat -p 92098</span><br><span class="line">^Cfailed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for process id &apos;92098&apos;:</span><br><span class="line"></span><br><span class="line">      10599.558340      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               292      context-switches          #    0.028 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">               202      page-faults               #    0.019 K/sec</span><br><span class="line">    27,557,631,981      cycles                    #    2.600 GHz</span><br><span class="line">     1,079,785,178      stalled-cycles-frontend   #    3.92% frontend cycles idle</span><br><span class="line">    15,669,652,101      stalled-cycles-backend    #   56.86% backend  cycles idle</span><br><span class="line">    14,456,635,493      instructions              #    0.52  insns per cycle     //加锁循环++</span><br><span class="line">                                                  #    1.08  stalled cycles per insn</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">            69,722      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">      10.592190690 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>可以看到最终时间差了100倍，IPC差了8倍，从指令数来看加锁后指令数会略多，但是加锁造成了stall（即使没有实际竞争）。</p>
<p>上述代码如果是在：Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz 上运行，差距要小很多，也可以看出intel x86芯片优化比较好。不加锁的循环X86比ARM要慢一点点是因为ARM芯片的主频是2.6G，要高一点点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#java test.LockBenchmark  //x86</span><br><span class="line">Time spent is 20135ms without lock</span><br><span class="line">start runIncrementWithLock.</span><br><span class="line">Time spent is 13056ms with lock</span><br></pre></td></tr></table></figure>

<p><strong>此时Intel CPU上对应的IPC分别是3.99和1.</strong></p>
<p>这里加锁和不加锁最终性能差了将近2个数量级，但是IPC只差了8倍，另外的差异在加锁后增加了很多的指令、函数调用等。如果两个函数都增加每个循环里面的指令数量，那么他们的时间差距会缩小。如果增加的指令是乘法、除法会大幅降低IPC</p>
<p>比如代码改成如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">#cat LockBenchmark.java</span><br><span class="line">package test;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.atomic.AtomicLong;</span><br><span class="line">import java.util.concurrent.locks.Lock;</span><br><span class="line">import java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"></span><br><span class="line">public class LockBenchmark&#123;</span><br><span class="line">    public static void runIncrement()</span><br><span class="line">    &#123;</span><br><span class="line">        long counter = 0;</span><br><span class="line">        long max  = 500000000L;</span><br><span class="line">				double sum =100.0;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        while (counter &lt; max) &#123;</span><br><span class="line">            counter++;</span><br><span class="line">						sum=3.251;</span><br><span class="line">						for(int i=0; i&lt;10; ++i)&#123;</span><br><span class="line">							sum += sum*3.75/3;</span><br><span class="line">						&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms without lock:&quot;+sum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void runIncrementWithLock()</span><br><span class="line">    &#123;</span><br><span class="line">        Lock lock = new ReentrantLock();</span><br><span class="line">        long counter = 0;</span><br><span class="line">				double sum=100.0;</span><br><span class="line">        long max = 500000000L;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        while (counter &lt; max) &#123;</span><br><span class="line">            if (lock.tryLock())&#123;</span><br><span class="line">		    			counter++;</span><br><span class="line">							sum=3.253;</span><br><span class="line">							for(int i=0; i&lt;10; ++i)&#123;</span><br><span class="line">								sum += sum*3.75/3;</span><br><span class="line">							&#125;</span><br><span class="line">              lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms with lock:&quot;+sum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        runIncrement();</span><br><span class="line">	    	System.out.println(&quot;start runIncrementWithLock.&quot;);</span><br><span class="line">        runIncrementWithLock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在Intel芯片下，加锁运行时间慢了1倍，IPC差不多，运行时间和IPC 分别为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#java test.LockBenchmark  //如上代码循环次数都是5亿次， intel cpu</span><br><span class="line">Time spent is 11884ms without lock:10810.40962948895</span><br><span class="line">start runIncrementWithLock.</span><br><span class="line">Time spent is 22662ms with lock:10817.060142949109</span><br><span class="line"></span><br><span class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</span><br><span class="line">^C</span><br><span class="line"> Performance counter stats for process id &apos;117862&apos;:</span><br><span class="line"></span><br><span class="line">       7144.193030      task-clock (msec)         #    1.002 CPUs utilized            (100.00%)</span><br><span class="line">               227      context-switches          #    0.032 K/sec                    (100.00%)</span><br><span class="line">                26      cpu-migrations            #    0.004 K/sec                    (100.00%)</span><br><span class="line">               199      page-faults               #    0.028 K/sec</span><br><span class="line">    17,842,543,877      cycles                    #    2.497 GHz                      (100.00%)</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">    17,153,665,963      instructions              #    0.96  insns per cycle          (100.00%)</span><br><span class="line">     2,408,676,080      branches                  #  337.152 M/sec                    (100.00%)</span><br><span class="line">            39,593      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       7.133030625 seconds time elapsed</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</span><br><span class="line">^C</span><br><span class="line"> Performance counter stats for process id &apos;117862&apos;:</span><br><span class="line"></span><br><span class="line">       3962.496661      task-clock (msec)         #    1.002 CPUs utilized            (100.00%)</span><br><span class="line">               123      context-switches          #    0.031 K/sec                    (100.00%)</span><br><span class="line">                 3      cpu-migrations            #    0.001 K/sec                    (100.00%)</span><br><span class="line">                77      page-faults               #    0.019 K/sec</span><br><span class="line">     9,895,900,342      cycles                    #    2.497 GHz                      (100.00%)</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">    10,504,412,147      instructions              #    1.06  insns per cycle          (100.00%)</span><br><span class="line">     1,925,721,763      branches                  #  485.987 M/sec                    (100.00%)</span><br><span class="line">            55,018      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       3.955251872 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>在鲲鹏920下的运行时间和IPC，两个循环最终执行时间一样，但是加锁的循环 IPC 反而要高，应该是加锁指令简单，比乘法对流水线更友好</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">#java test.LockBenchmark  //鲲鹏920</span><br><span class="line">Time spent is 37037ms without lock:10810.40962948895</span><br><span class="line">start runIncrementWithLock.</span><br><span class="line">Time spent is 37045ms with lock:10817.060142949109  //极低的概率这里能跑出来15秒，应该是偷鸡优化了</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</span><br><span class="line">^Cfailed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for process id &apos;104166&apos;:</span><br><span class="line"></span><br><span class="line">       3459.850580      task-clock (msec)         #    1.002 CPUs utilized</span><br><span class="line">               122      context-switches          #    0.035 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">               257      page-faults               #    0.074 K/sec</span><br><span class="line">     8,995,482,376      cycles                    #    2.600 GHz</span><br><span class="line">       344,461,881      stalled-cycles-frontend   #    3.83% frontend cycles idle</span><br><span class="line">     7,060,741,196      stalled-cycles-backend    #   78.49% backend  cycles idle</span><br><span class="line">     2,667,443,624      instructions              #    0.30  insns per cycle         //不带Lock 乘除法拉低了IPC</span><br><span class="line">                                                  #    2.65  stalled cycles per insn</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">        93,302,896      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       3.453102950 seconds time elapsed</span><br><span class="line">       </span><br><span class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</span><br><span class="line">^Cfailed to read counter branches</span><br><span class="line"></span><br><span class="line"> Performance counter stats for process id &apos;100351&apos;:</span><br><span class="line"></span><br><span class="line">       3205.548380      task-clock (msec)         #    1.002 CPUs utilized</span><br><span class="line">                97      context-switches          #    0.030 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">                93      page-faults               #    0.029 K/sec</span><br><span class="line">     8,334,345,888      cycles                    #    2.600 GHz</span><br><span class="line">        10,217,474      stalled-cycles-frontend   #    0.12% frontend cycles idle</span><br><span class="line">     6,389,615,752      stalled-cycles-backend    #   76.67% backend  cycles idle</span><br><span class="line">     4,374,642,352      instructions              #    0.52  insns per cycle         //带lock</span><br><span class="line">                                                  #    1.46  stalled cycles per insn</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         2,053,478      branch-misses             #    0.00% of all branches</span><br><span class="line"></span><br><span class="line">       3.199261610 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>这个代码加锁后指令多了1倍，所以intel CPU下体现出来的时间就差了一倍（IPC一样的）；鲲鹏 CPU下时间差不多是因为没加锁的IPC太低了（乘除法对流水线没优化好），最终IPC差了一倍，就把执行时间拉平了。另外就就是Intel和鲲鹏的执行时间对比和IPC也是一致的，IPC高执行就快。</p>
<h3 id="Disruptor中对cache-line的使用"><a href="#Disruptor中对cache-line的使用" class="headerlink" title="Disruptor中对cache_line的使用"></a>Disruptor中对cache_line的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">abstract class RingBufferPad</span><br><span class="line">&#123;</span><br><span class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">abstract class RingBufferFields&lt;E&gt; extends RingBufferPad</span><br><span class="line">&#123;</span><br><span class="line">    ......    </span><br><span class="line">    private final long indexMask;</span><br><span class="line">    private final Object[] entries;</span><br><span class="line">    protected final int bufferSize;</span><br><span class="line">    protected final Sequencer sequencer;</span><br><span class="line">    ......    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">    ......    </span><br><span class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重点留意上述代码中的p1-p7这几个没有用的long变量，实际使用来占位，占住实际变量前后的位置，这样避免这些变量被其他变量的修改而失效。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1620984677390-81694fd0-0323-4052-98d1-32be39a02248-4505908.png" alt="image.png"></p>
<p>队列大部分时候都是空的（head挨着tail），也就导致head 和 tail在一个cache line中，读和写会造成没必要的cache ping-pong，一般可以通过将head 和 tail 中间填充其它内容来实现错开到不同的cache line中</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/1577093636588-6b58c36c-1617-4f2c-aba9-156c52972689.png" alt="image"></p>
<p>数组(RingBuffer)基本能保证元素在内存中是连续的，但是Queue（链表）就不一定了，连续的话更利于CPU cache</p>
<h2 id="Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"><a href="#Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的" class="headerlink" title="Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"></a>Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</h2><p>MySQL利用Intel 的Pause指令在spinlock(自旋锁)的时候尽量避免cache line ping-pong，但是不同的Intel芯片每个Pause指令背后实际执行的circle是不一样的，从而导致MySQL性能差异很大</p>
<p>详细请看：</p>
<p>[《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<h3 id="pause-和-spinlock"><a href="#pause-和-spinlock" class="headerlink" title="pause 和 spinlock"></a>pause 和 spinlock</h3><p><a href="http://linuxperf.com/?p=138" target="_blank" rel="noopener">spinlock(自旋锁)</a>是内核中最常见的锁，它的特点是：等待锁的过程中不休眠，而是占着CPU空转，优点是避免了上下文切换的开销，缺点是该CPU空转属于浪费, 同时还有可能导致cache ping-pong，<strong>spinlock适合用来保护快进快出的临界区</strong>。持有spinlock的CPU不能被抢占，持有spinlock的代码不能休眠</p>
<h2 id="ECS-cache-line-miss导致整个物理机响应慢"><a href="#ECS-cache-line-miss导致整个物理机响应慢" class="headerlink" title="ECS cache_line miss导致整个物理机响应慢"></a>ECS cache_line miss导致整个物理机响应慢</h2><p><a href="https://topic.atatech.org/articles/100065" target="_blank" rel="noopener">如果一台ECS运行大量的cache_line miss逻辑</a>，也就是利用spinlock所保护的区域没有按照cacheline对齐的时候，CPU为了保证数据一致性，会触发Super Queue lock splits，将总线锁住，哪怕是其他socket，而这个时候，其他CPU CORE访问L2cache、L3cahe、以及内存就会阻塞，直到Super Queue lock splits释放。</p>
<p>这个影响不是socket、node内部，而是整个物理机总线被锁，所以影响的是整个物理机。</p>
<h3 id="从地址不对齐访问到split-lock"><a href="#从地址不对齐访问到split-lock" class="headerlink" title="从地址不对齐访问到split lock"></a><a href="https://kernel.taobao.org/2019/07/Detecting-and-handling-split-locks/" target="_blank" rel="noopener">从地址不对齐访问到split lock</a></h3><p>Intel CPU微架构允许不对齐的内存访问，但ARM、RISC-V等架构却不允许。在众多的不对齐中，一个特殊的场景是：<a href="https://lwn.net/Articles/790464/" target="_blank" rel="noopener">原子操作的操作数（由于地址不对齐）跨越两个cache lines，Intel将之叫做split lock。</a>它有两个特征：</p>
<ol>
<li>原子操作，即汇编指令包含Lock前缀；</li>
<li>操作数地址不对齐，还跨越两个cache lines；</li>
</ol>
<p>其实大部分吃瓜群众都不知道这个特性，但是它却对应用性能影响极大。Intel工程师Fenghua Yu同学正在开发一组内核补丁，用于检测和处理split lock，现在已经发出了第8版<a href="https://lwn.net/ml/linux-kernel/1556134382-58814-1-git-send-email-fenghua.yu%40intel.com/" target="_blank" rel="noopener">code review</a>。阿里巴巴在多年前就意识到split lock的危害，在线上实施了大规模监控，并采取必要隔离措施。</p>
<p>学过体系结构的同学都应该知道，缓存一制性协议MESI只能保证cache line粒度的一致性。同时访问两个cache lines不是常见操作，为保证split lock的原子性，设计硬件时使用特殊逻辑（冷路径）来处理：<strong>锁住整个访存总线，阻止其它逻辑cpu访存</strong>。</p>
<p>从原理出发，我们很容易想到，锁住总线将导致其它core上访存操作受阻，宏观表现为平均访存延时显著上升。为不让各位看官白走一趟，小编在自己的skylake机器上测了一组数据，随着split lock速率的增加，访存延迟呈指数恶化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1.png" alt="img"></p>
<h2 id="分支预测案例"><a href="#分支预测案例" class="headerlink" title="分支预测案例"></a>分支预测案例</h2><p>这个案例总循环次数一样多，但是里外循环次数不一样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;stdio.h&quot;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;time.h&gt;</span><br><span class="line"></span><br><span class="line">long timediff(clock_t t1, clock_t t2) &#123;</span><br><span class="line">    long elapsed;</span><br><span class="line">    elapsed = ((double)t2 - t1) / CLOCKS_PER_SEC * 1000;</span><br><span class="line">    return elapsed;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    int j=0;</span><br><span class="line">    int k=0;</span><br><span class="line">    int c=0;</span><br><span class="line">    clock_t start=clock();</span><br><span class="line">    for(j=0; j&lt;100000; j++)&#123;</span><br><span class="line">        for(k=0; k&lt;1000; k++)&#123;</span><br><span class="line">					for(c=0; c&lt;100; c++)&#123;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    clock_t end =clock();</span><br><span class="line">    printf(&quot;%lu\n&quot;, timediff(start,end));    //case1</span><br><span class="line"></span><br><span class="line">    start=clock();</span><br><span class="line">    for(j=0; j&lt;100; j++)&#123;</span><br><span class="line">        for(k=0; k&lt;1000; k++)&#123;</span><br><span class="line">					for(c=0; c&lt;100000; c++)&#123;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    end =clock();</span><br><span class="line">    printf(&quot;%lu\n&quot;, timediff(start,end));   //case2</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>x86_64下的执行结果，确实是case2略快</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#taskset -c 0 ./for_prediction.out</span><br><span class="line">25560</span><br><span class="line">23420</span><br><span class="line"></span><br><span class="line">#taskset -c 0 ./for_prediction.out</span><br><span class="line">25510</span><br><span class="line">23410</span><br></pre></td></tr></table></figure>

<p>case1的branch miss大概接近1%（看0 core上的 BrchMiss%， 数据由 xperf 1.3.8采集）</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210517111209985.png" alt="image-20210517111209985"></p>
<p>case2的branch miss降到了0，不过两者在x86上的IPC都是0.49，所以最终的执行时间差异不大</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210517111244550.png" alt="image-20210517111244550"></p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210512133536939.png" alt="image-20210512133536939"></p>
<p>在arm下case1反而更快，如截图</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210512132121856.png" alt="image-20210512132121856"></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1001&context=etd_projects" target="_blank" rel="noopener">Analysis of False Cache Line Sharing Effects on Multicore CPUs</a></p>
<p><a href="https://software.intel.com/content/www/us/en/develop/articles/avoiding-and-identifying-false-sharing-among-threads.html" target="_blank" rel="noopener">Avoiding and Identifying False Sharing Among Threads</a></p>
<p><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></p>
<p><a href="https://coolshell.cn/articles/10249.html" target="_blank" rel="noopener">7个示例科普CPU CACHE</a></p>
<p><a href="http://stackoverflow.com/questions/11413855/why-is-transposing-a-matrix-of-512x512-much-slower-than-transposing-a-matrix-of?spm=ata.21736010.0.0.43c1e11aGARvVj" target="_blank" rel="noopener">Why is transposing a matrix of 512×512 much slower than transposing a matrix of 513×513 ?</a> 矩阵倒置的时候因为同一个cache_line的数据频繁被update导致cache_line失效，也就是FALSE share</p>
<p><a href="https://zhuanlan.zhihu.com/p/58881925" target="_blank" rel="noopener">CPU时间都去哪了：一步步定位数据库代码中的性能瓶颈(SAP)</a></p>
<p><a href="https://coolshell.cn/articles/20793.html" target="_blank" rel="noopener">与程序员相关的CPU缓存知识</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="twitter @plantegg">
          <p class="site-author-name" itemprop="name">twitter @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">186</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">275</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
