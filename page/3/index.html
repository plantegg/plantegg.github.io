<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"plantegg.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/page/3/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="twitter @plantegg">
<meta property="article:tag" content="技术,编程,博客">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://plantegg.github.io/page/3/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>plantegg</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">plantegg</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twitter @plantegg</p>
  <div class="site-description" itemprop="description">java mysql tcp performance network docker Linux</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">185</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">274</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/08/28/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E6%80%9D%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/28/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E6%80%9D%E8%B7%AF/" class="post-title-link" itemprop="url">解决Java/MySQL性能问题的思路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-28 10:30:03" itemprop="dateCreated datePublished" datetime="2023-08-28T10:30:03+08:00">2023-08-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="解决-Java-MySQL-性能问题的思路"><a href="#解决-Java-MySQL-性能问题的思路" class="headerlink" title="解决 Java&#x2F;MySQL 性能问题的思路"></a>解决 Java&#x2F;MySQL 性能问题的思路</h1><p>10年前写的，重新发一下</p>
<h2 id="系统性能问题"><a href="#系统性能问题" class="headerlink" title="系统性能问题"></a>系统性能问题</h2><ul>
<li>CPU（基本上WEB服务器没有多少IO，主要是CPU有瓶颈）<ul>
<li>top&#x2F;vmstat 观察CPU使用率，Load负载，r&#x2F;b线程数量等；</li>
<li>IO（数据库大多数时候瓶颈是IO，主要是索引没建好；如果数据库CPU紧张的话，检查一下是不是order by&#x2F;group by 等操作太多）</li>
<li>vmstat 观察IO&#x2F;Util吞吐，磁盘最怕随机读写了（比如：索引命中后，需要离散地从磁盘读数据）</li>
<li>对于数据库来说最怕内存不够的时候使用Swap了，所以尽量增大分配给数据库的内存，一旦有Swap就要引起注意了</li>
</ul>
</li>
</ul>
<h2 id="Java程序问题（运行慢）"><a href="#Java程序问题（运行慢）" class="headerlink" title="Java程序问题（运行慢）"></a>Java程序问题（运行慢）</h2><p>​    先通过 top 查看整个CPU资源使用情况；<br>​    通过top -Hp pid查看java进程的每一个线程占用CPU的情况；<br>​        如果有一个线程占用CPU过高，有两种可能：<br>​            没有内存了，Java垃圾回收线程不停地运行尝试回收内存，但是每次无法收回，确认：<br>​                jstat -gcutil pid 1s   观察10多秒钟就能发现了，看是不是内存使用率接近100%了<br>​            类似于死循环（hash冲突攻击），就是一个线程一直占用一个核的所有CPU资源（其实一个线程总是占用一个核超过50%的资源都是不太正常的），解决：<br>​                用我的checkPerf脚本，定位这个线程具体执行的任务（能具体到某一行），对应看代码解决。            </p>
<pre><code>    如果有很多线程，每个线程占用的CPU都不多(基本都在10%以下)，那基本是正常的，只是程序并发确实很高。

如果死锁：
    jstack -l pid 多执行几次，统计一下stack中总是在等待哪些锁，可以对锁id进行排序统计（sort uniq grep）
上面列出来的都是明显的瓶颈，最可怕的是哪里都没有明显的瓶颈，哪里都要偷一点点CPU资源走，这是可以试试JProfiler这样更专业一点的工具，同时要配合自己对业务的了解来解决。

一旦触发频繁地抛出异常，CPU占用率会急剧地上升（抛异常比正常情况下会慢2个数量级）主要是由于：Throwable的构造函数中会调用native的fillInStackTrace()，这个方法就会构造整个异常栈了。
</code></pre>
<p>Java内存的问题，如果有内存泄露（就是执行完fgc&#x2F;old gc后不能回收的内存不断地增加）：<br>    怎么确认没有内存了：<br>        jps -lmv pid 先确认你的参数，也就是你给JVM分配了多大的堆(-Xmx 比如1G); 然后jstat -gcutil pid 1s 看看GC运行情况，如果(O&#x2F;E 两列基本接近100%的话就是内存不够了)<br>            内存不够分两种：一种是真的不够，就是你们的系统很庞大需要1G以上的内存，而你只分配了1G，这个没什么好说的，增大内存，物理内存不够就投钱买；<br>            第二一种是你们的代码写的烂，有内存泄露，这样的话分配多少内存都不够，得找出是否有内存泄露，看接下的解决方案        </p>
<pre><code>快速解决：jmap -histo:live pid  来统计所有对象的个数（String/char/Integer/HashEntry 这样的对象很多很正常，主要是盯着你们公司的包名下的那些对象）
每隔一分钟执行一次上面的命令，执行5次以上，看看你们公司报名下的对象数量哪个在一直增加，那基本上就是这个对象引起了泄露；
用课堂上的工具HouseMD(java -Xbootclasspath/a:/usr/java/jdk1.6.0_29/lib/tools.jar -jar housemd-assembly-0.2.2.jar pid)来动态监控创建这个对象的地方（一般来说很多时候创建了这些对象把他们丢到一个HashMap然后就不管了），分析一下有没有释放！
    &gt;trace -s -d ClassName

上面的方法实在没法定位就用: jmap -dump:live,format=b,file=heap.bin pid 导出整个内存（耗时间，需要很大的内存的机器才能对这个导出文件进行分析，会将JVM锁住一段时间）
    在Eclipse的插件EMA中打开这个文件（2G的物理文件需要4G以上的内存，5G以上的需要将近20G的内存来分析了）
    盯着你们公司报名的那些对象，看看引用关系，谁拿着这些对象没释放（是否是必要的），可以一直追查的RootReference
</code></pre>
<h2 id="MySQL-数据库的性能问题"><a href="#MySQL-数据库的性能问题" class="headerlink" title="MySQL 数据库的性能问题"></a>MySQL 数据库的性能问题</h2><p>大部分情况下是磁盘IO的问题（索引没建好、查询太复杂）；</p>
<ul>
<li><p>索引问题的话分析慢查询日志，explain 他们挨个解决。</p>
</li>
<li><p>偶尔也有数据库CPU不够的情况，如果并发高CPU不够很正常，如果并发不高，那很可能就是group by&#x2F;order by&#x2F;random之类的操作严重消耗了数据库的CPU</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql -e &quot;show full processlist&quot; | grep -v Sleep | sort -rnk6 查看那些SQL语句执行的太长</span><br><span class="line">拿出这个SQL语句分析他们的执行计划: explain SQL 然后改进；</span><br><span class="line">分析慢查询日志，统计top10性能杀手的语句，挨个explain他们，然后改进（具体改进办法具体分析，这里只谈思路）</span><br></pre></td></tr></table></figure></li>
</ul>
<p>总结一下数据库问题就只有这三招：show full processlist&#x2F;分析慢查询日志&#x2F;explain（然后建好联合索引）</p>
<p>补充一个数据库连接数不够的问题，很多人碰到了，不知道怎么解决：</p>
<ul>
<li>在mysql 命令行里执行：show variables like ‘%max_connections%’;  看看你们的数据实际配置是多少（比如1000）</li>
<li>show full processlist 数一下多少行，一行代表一个连接，比如这里是1000行，那基本上就是连接数不够了，你要解决的为什么你的数据库需要这么多连接</li>
<li>接下来分析这些连接是从哪来的IP，然后问你自己：根据你们的服务类型的特点需要这么多连接吗？</li>
</ul>
<h3 id="数据库性能问题提问请给出："><a href="#数据库性能问题提问请给出：" class="headerlink" title="数据库性能问题提问请给出："></a>数据库性能问题提问请给出：</h3><ul>
<li>show full processlist;</li>
<li>查询语句;</li>
<li>表结构(包括索引结构);</li>
<li>数据库引擎类型;</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/08/23/%E5%A6%82%E4%BD%95%E4%BB%8E%E5%87%A0%E7%99%BE%E4%B8%87%E4%B8%AA%E6%8A%93%E5%8C%85%E4%B8%AD%E6%89%BE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%BC%82%E5%B8%B8%E7%9A%84%E5%8C%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/23/%E5%A6%82%E4%BD%95%E4%BB%8E%E5%87%A0%E7%99%BE%E4%B8%87%E4%B8%AA%E6%8A%93%E5%8C%85%E4%B8%AD%E6%89%BE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%BC%82%E5%B8%B8%E7%9A%84%E5%8C%85/" class="post-title-link" itemprop="url">如何从几百万个抓包中找到一个异常的包</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-23 12:30:03" itemprop="dateCreated datePublished" datetime="2023-08-23T12:30:03+08:00">2023-08-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/tcpdump/" itemprop="url" rel="index"><span itemprop="name">tcpdump</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="如何从几百万个抓包中找到一个异常的包"><a href="#如何从几百万个抓包中找到一个异常的包" class="headerlink" title="如何从几百万个抓包中找到一个异常的包"></a>如何从几百万个抓包中找到一个异常的包</h1><p>这篇算是对抓包定位原因在哪里的落地篇，没什么高深的技术，都是很low但是你一定可以照着操作的，算是星球内必须学会和带走的内容</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p><img src="/images/951413iMgBlog/image-20230620150119963.png" alt="image-20230620150119963"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>一次业务请求包含160个拖数据的SQL查询，通过160个连接，发给160个Database，但是过几分钟后总有报错。几分钟抓包文件10G左右，网络包几百万个，怎么找到报错的那个？</p>
<p>几个麻烦的地方</p>
<ul>
<li>虽然问题每次稳定重现，但是每次重现的Database不是固定的；</li>
<li>从开始拖到出现问题需要几分钟不等，抓包量巨大</li>
<li>有一个连接报错后剩下的其它连接也会断开</li>
<li>这么多端口怎么解析成MySQL协议，请看：<a target="_blank" rel="noopener" href="https://t.zsxq.com/0f7nMlKax">https://t.zsxq.com/0f7nMlKax</a></li>
</ul>
<h3 id="问题发生条件"><a href="#问题发生条件" class="headerlink" title="问题发生条件"></a>问题发生条件</h3><ul>
<li>一个Client同时开160条连接，发160个类似的SQL去160个MySQL Database上拖数据时必现</li>
<li>如果将拖数据的SQL拖取数量改小一点就不再出现——拖取少执行更快，没达到触发bug条件</li>
<li>网络传输得慢一点、JDBC streaming 模式下发生，比如streaming流模式拖数据是几MB每秒，去掉流模式拖数据是几十MB每秒且不报错。这里可以通过设置内核 tcp rmem&#x2F;加大rtt延时来模拟重现——和我们的<a target="_blank" rel="noopener" href="https://wx.zsxq.com/dweb2/index/topic_detail/181428425525182">必做实验callback一下</a>，无时不刻不展示下我们必做实验的用途。</li>
</ul>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>分析技巧和步骤：</p>
<ol>
<li>抓包，从握手到报错断开全抓下来，时间跨度3分多钟，抓下来10个G左右，怎么分析？</li>
<li>editcap -c 200000 把抓包切小，每个文件20万个包，保证wireshark打开不太慢（editcap 是安装wireshark附带的小命令，附带的还有tshark、capinfos等）</li>
<li>wireshark打开切小后的最后一个文件，搜reset&#x2F;fin 找到<strong>第一个</strong>断开的连接(如下图)，找到9913&#x2F;42909这对连接端口</li>
<li>回到10个G的抓包中，用 tshark -r .&#x2F;big.pcap -Y “tcp.port&#x3D;&#x3D;42909”   -w 42909.pcap 把42909这条连接所有包过滤出来，-r 读，-w 写</li>
<li>wireshark 打开42909.pcap 傻子也能看到问题在哪里了</li>
</ol>
<p>切完后的包，切完后的文件会加时间戳，时间戳可以和报错时间对应：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-rw-r--r--  1 root  root   329M Jun 16 17:46 big00_00000_20230616170456.pcap</span><br><span class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00001_20230616170524.pcap</span><br><span class="line">-rw-r--r--  1 root  root  1022M Jun 16 17:46 big00_00002_20230616170546.pcap</span><br><span class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00003_20230616170608.pcap</span><br><span class="line">-rw-r--r--  1 root  root  1012M Jun 16 17:46 big00_00004_20230616170630.pcap</span><br><span class="line">-rw-r--r--  1 root  root   982M Jun 16 17:46 big00_00005_20230616170652.pcap</span><br><span class="line">-rw-r--r--  1 root  root   938M Jun 16 17:46 big00_00006_20230616170714.pcap</span><br><span class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00007_20230616170735.pcap</span><br><span class="line">-rw-r--r--  1 root  root   661M Jun 16 17:46 big00_00008_20230616170759.pcap</span><br></pre></td></tr></table></figure>

<p>搜reset&#x2F;fin 找到第一个断开的连接，第一个断开的连接才是罪魁祸首：</p>
<p><img src="/images/951413iMgBlog/image-20230620143248344.png" alt="image-20230620143248344"></p>
<h3 id="进一步分析发生问题的连接"><a href="#进一步分析发生问题的连接" class="headerlink" title="进一步分析发生问题的连接"></a>进一步分析发生问题的连接</h3><p>知识点：</p>
<blockquote>
<p>MySQL 协议是一来一回，也就是client发查询然后等查询结果全部返回，然后再发下一个</p>
<p>按协议在一个SQL查询的数据传输完毕前client不能再发任何请求，MySQL Server负责一直发送查询结果直到发送完毕。</p>
</blockquote>
<p>如下两个截图是从42909.pcap文件中过滤到的抓包从握手到断开的全过程，图1过滤条件：tcp.srcport eq 42909 and tcp.len&gt;0  (42909是客户端，9913是MySQL端口)，可以看到客户端 login（连数据库肯定得要user、password认证），然后是client查了MySQL的一堆服务端参数(下图第二行)，再然后是client设置了几个参数(set 那些)。关键的是倒数第二行client发了一个SQL给MySQL需要拉取大量数据(建立连接17.98秒的时候)，然后是数据传数据过程，第190秒的时候client发了 Quit断开连接</p>
<p><img src="/images/951413iMgBlog/image-20230620140921134.png" alt="image-20230620140921134"></p>
<p>上图因为加了过滤条件，只看client端并去掉ack后的所有包，没看到全貌，这个过程9913的MySQL 服务端又做了啥呢？因为太长前面漫长的传数据就不截图了，只看最后连接的断开。</p>
<p>但是下图红框所示的地方可以看到MySQL Server 传着传着居然带了个 fin 包在里面，表示MySQL Server要断开连接了，无奈Client只能也发送quit 断开连接。红框告诉我们一个无比有力的证据MySQL Server 在不应该断开的地方断开了连接，问题在 MySQL Server 端</p>
<p><img src="/images/951413iMgBlog/image-20230620141017987.png" alt="image-20230620141017987"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>就抓包结论来看是 MySQL 在不应该断开的时候发送了 fin 主动断开连接，可能是MySQL的bug</p>
<p>题外话，这个包证据抓了有一周了，但是MySQL研发同学始终绕来绕去(比如我的代码没记录下这个SQL就是没收到，我的代码没问题——熟悉的味道)跟我打了一周太极(异地)，我一查发现我和他老板认识且在一层楼，赶紧面对面找他老板讲清楚这个问题，且签字画押承认是MySQL的问题，然后继续推进排查，最终结果是为啥我跟你们一起期待吧，有了结果我再来update。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>找个MySQL，然后开始抓包，用mysql-client连一下MySQL Server随便发几个SQL，然后看看一来一回的响应</p>
<p>如果哪怕在星球一年你只要好好掌握这一篇用到的技能也能帮助你在日常工作中互相扯皮的时候快速给出精准定位和分析，值回星球票价，加油</p>
<p>比如这个案例我同时打开了5&#x2F;6个wireshark分析不同的流、整体搜索等</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>这些技巧不只是用在MySQL 上，其它微服务、redis等涉及网络调用场景的扯皮的地方都可以用</p>
<p><a href="https://plantegg.github.io/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">wireshark 附带的一些小工具</a></p>
<blockquote>
<p>capinfos rsb2.cap</p>
</blockquote>
<blockquote>
<p>tshark -q -n -r rsb2.cap  -z “conv,ip”   分析流量总况</p>
</blockquote>
<blockquote>
<p>tshark -q -n -r rsb2.cap  -z “conv,tcp”  分析每一个连接的流量、rtt、响应时间、丢包率、重传率等等</p>
</blockquote>
<blockquote>
<p>editcap -c 100000 .&#x2F;rsb2.cap  rsb00.cap  &#x2F;&#x2F;把大文件rsb2.cap按每个文件100000个package切成小文件</p>
</blockquote>
<p>存放在这里：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/usr/sbin/capinfos</span><br><span class="line">/usr/sbin/dftest</span><br><span class="line">/usr/sbin/dumpcap</span><br><span class="line">/usr/sbin/editcap</span><br><span class="line">/usr/sbin/mergecap</span><br><span class="line">/usr/sbin/randpkt</span><br><span class="line">/usr/sbin/rawshark</span><br><span class="line">/usr/sbin/reordercap</span><br><span class="line">/usr/sbin/text2pcap</span><br><span class="line">/usr/sbin/tshark</span><br></pre></td></tr></table></figure>

<h2 id="net-write-timeout-报错"><a href="#net-write-timeout-报错" class="headerlink" title="net_write_timeout 报错"></a>net_write_timeout 报错</h2><p>最后回答一下<a target="_blank" rel="noopener" href="https://t.zsxq.com/0ftY9WNVv">上一篇</a>中提到的流模式下 net_write_timeout 报错</p>
<p>如下图，JDBC 在 streaming 模式下，不断读取下一行，如果这个过程只要报错抛出的异常就是 StreamingNotifiable 异常</p>
<p><img src="/images/951413iMgBlog/image-20230620173111706.png" alt="image-20230620173111706"></p>
<p>错误信息定义如下，这个报错误导太严重，从以上JDBC 代码可以看到只要读取下一行报错了就会报调大 net_write_timeout 错误，但是实际原因却是连接异常断开，和 timeout 没有一点关系，你看久经考验的 JDBC  代码也不是那么完善还得你会 Debug</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CommunicationsException.ClientWasStreaming=Application was streaming results when the connection failed. Consider raising value of &#x27;&#x27;net_write_timeout&#x27;&#x27; on the server.</span><br></pre></td></tr></table></figure>

<p>这个报错误导了排查分析方向，不知道坑了多少人了！当然如果MySQL 因为net_write_timeout 超时断开连接当然应该报如上错误，但是 JDBC 搞不清楚MySQL 为啥断开，就瞎猜是 timeout 了，然后只要是连接异常读数据错误(包含断开)就报这个错误。希望你们不要被坑</p>
<p>记住这个坑人的报错堆栈：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Application was streaming results when the connection failed. Consider raising value of &#x27;net_write_timeout&#x27; on the server.</span><br><span class="line">    at sun.reflect.GeneratedConstructorAccessor150.newInstance(Unknown Source)</span><br><span class="line">    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">    at com.mysql.jdbc.Util.handleNewInstance(Util.java:425)</span><br><span class="line">    at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3749)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3649)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4090)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:972)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:2123)</span><br><span class="line">    at com.mysql.jdbc.RowDataDynamic.nextRecord(RowDataDynamic.java:374)</span><br><span class="line">    at com.mysql.jdbc.RowDataDynamic.next(RowDataDynamic.java:354)</span><br><span class="line">    at com.mysql.jdbc.RowDataDynamic.close(RowDataDynamic.java:155)</span><br><span class="line">    at com.mysql.jdbc.ResultSetImpl.realClose(ResultSetImpl.java:6726)</span><br><span class="line">    at com.mysql.jdbc.ResultSetImpl.close(ResultSetImpl.java:865)</span><br><span class="line">    at com.alibaba.druid.pool.DruidPooledResultSet.close(DruidPooledResultSet.java:86)</span><br></pre></td></tr></table></figure>

<p>不过你要仔细看的话，它还是有caused by，如下，但是绝大部分工程师看到这个堆栈会忽视，上面都有 net_write_timeout 我还管个屁 Can not read response from server, 不过要是结合抓包的话就能理解：at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3186) 这个根本的原因是 JDBC 从服务端读取数据的时候报错了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.io.EOFException: Can not read response from server. Expected to read 405 bytes, read 272 bytes before connection was unexpectedly lost.</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3186)</span><br><span class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3709)</span><br><span class="line">    ... 40 common frames omitted</span><br></pre></td></tr></table></figure>

<p>最后希望你没被绕晕，再去看看<a target="_blank" rel="noopener" href="https://t.zsxq.com/0ftY9WNVv">上一篇</a>中推荐的流模式原理，把代码和网络应用层完美地结合起来</p>
<p>完整堆栈也可以参考网络上别人碰到的：<a target="_blank" rel="noopener" href="https://github.com/brettwooldridge/HikariCP/issues/1771">https://github.com/brettwooldridge/HikariCP/issues/1771</a> </p>
<p>看 Google 里面对这个问题的分析基本都没入门：<a target="_blank" rel="noopener" href="https://www.google.com/search?q=Caused+by:+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException:+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&hl=en&sxsrf=APwXEddTwJGjFpkKuWHyXjlTvwTo2OUMhA:1687226872136&ei=-AmRZI7gB6-C0PEPmOGbwAE&ved=0ahUKEwiOvPny4dD_AhUvATQIHZjwBhgQ4dUDCBE&uact=5&oq=Caused+by:+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException:+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAF4AIABAIgBAJIBAJgBAKABAqABAQ&sclient=gws-wiz-serp">https://www.google.com/search?q=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;hl=en&amp;sxsrf=APwXEddTwJGjFpkKuWHyXjlTvwTo2OUMhA%3A1687226872136&amp;ei=-AmRZI7gB6-C0PEPmOGbwAE&amp;ved=0ahUKEwiOvPny4dD_AhUvATQIHZjwBhgQ4dUDCBE&amp;uact=5&amp;oq=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAF4AIABAIgBAJIBAJgBAKABAqABAQ&amp;sclient=gws-wiz-serp</a></p>
<p>下次在你们的业务代码里如果出现查询结果太大导致JVM OOM的话你可以站出来说把拉取数据改成 流 模式会有奇效 :) , 当然随之而来的是会有 net_write_timeout 报错，嗯，你的机会来了，业务技术上按照你的指引发展，出了问题你能顶得上</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">扑朔迷离的根因分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-07-23 12:30:03" itemprop="dateCreated datePublished" datetime="2023-07-23T12:30:03+08:00">2023-07-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="扑朔迷离的根因分析"><a href="#扑朔迷离的根因分析" class="headerlink" title="扑朔迷离的根因分析"></a>扑朔迷离的根因分析</h1><h2 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h2><p>追着RT 跑，不断加压力，到瓶颈前随着并发的增加RT很稳定。</p>
<p>但是你要对你的RT怎么来的，包含哪些环节的消耗，这样才不会出错。</p>
<p>如下图左边是QPS不停地增加，每一次台阶(增加20%流量)都是一次加压过程，右边是对应的 RT，可以看到在绿线阶段几乎是平稳的，直到最后的红色箭头 RT略微有一点点提升，但是整体也还好，说明基本没到瓶颈</p>
<p><img src="/images/951413iMgBlog/image-20230520101758175.png" alt="image-20230520101758175"></p>
<p>当然这个图是经过长时间调优的结果，来之不易，是理想的期望系统状态，但在这之前是长时间的痛苦分析和瓶颈在哪里的定位过程。</p>
<p>凡是复杂的实际业务总是有很多干扰项出现在你的理论图上，你得很好地识别他们</p>
<h2 id="业务结构"><a href="#业务结构" class="headerlink" title="业务结构"></a>业务结构</h2><p><img src="/images/951413iMgBlog/image-20230517113148916.png" alt="image-20230517113148916"></p>
<p>概念说明：</p>
<p>黑色&#x3D;Database&#x3D;被依赖业务&#x3D;物理</p>
<p>蓝色&#x3D;Tomcat&#x3D;上游业务&#x3D;逻辑</p>
<p>上游响应时间&#x3D;下游业务响应时间+网络时间+上游自身处理耗时</p>
<p>响应时间&#x3D;RT&#x3D;耗时监控</p>
<p>tcprt：从内核网络取Database的响应时间</p>
<p>实际很魔幻的是同样流量有时候压测很稳定，有时候又不稳定，性能上不去(稳定时可能是压测数据、没有触发Database雪崩之类的问题)，所以导致问题</p>
<p><strong>所有压测过程中肯定是没有任何资源上的瓶颈(CPU、内存、网络带宽、磁盘等等)</strong></p>
<h2 id="监控数据"><a href="#监控数据" class="headerlink" title="监控数据"></a>监控数据</h2><p>如图，蓝线表示Tomcat，黑线表示Database被调用方，可以看到每次黑色 RT上升QPS下跌很猛(符合预期)，奇怪的是黑色RT很快降下来后蓝色RT还会维持较高一段时间，监控频率每5秒采集一次，以下所有监控图时间范围是一样的，但采集频率不一样</p>
<p><img src="/images/951413iMgBlog/image-20230516150350614.png" alt="image-20230516150350614"></p>
<p>(图1)</p>
<p>上图的两个 RT 监控数据都是Tomcat的业务代码记录下来的，比如Database的响应时间就包含网络+Database的处理时间</p>
<p>如下图通过网络监控看响应时间(tcprt <a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/181331.html">阿里云文档</a>，从OS 内核中取到网络包的响应时间)，蓝线表示Tomcat，紫线表示Database，监控力度每1分钟采集一次，有被平均</p>
<p><img src="/images/951413iMgBlog/image-20230516150812485.png" alt="image-20230516150812485"></p>
<p>以上两个监控图的矛盾点：如果从网络层面记录的Database RT 可以看到上升幅度不明显，但是Tomcat 的RT上升很明显，但是Tomcat记录的RT则又是Database 上升明显。</p>
<h4 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a><a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/181331.html">补充知识</a></h4><p>tcprt和tomcat业务进程记录的 Database rt差异，tcprt记录到的是RDS&#x2F;Database的响应时间+网络时间，tomcat在这个基础上还要加入自己进程调出处理时间，比如tomcat进程取到数据库连接的时候连接需要排队等待1秒钟(后面有分析)，那么这个一秒钟对tcprt来说是不会记录进去的，但是客户端感知到的这次调用是1秒以上。当然业务记录的Database 还可以更精准，比如在连接池Druid(或者其它连接池的实现)内取记录，但是无论如何从业务进程到OS内核这里的差距总是存在的。</p>
<p><img src="/images/951413iMgBlog/6f6862dec810933f34b7793018cfb0da.png" alt="image.png"></p>
<h3 id="Tomcat-CPU-监控"><a href="#Tomcat-CPU-监控" class="headerlink" title="Tomcat CPU 监控"></a>Tomcat CPU 监控</h3><p><img src="/images/951413iMgBlog/image-20230516150950383.png" alt="image-20230516150950383"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>可以很清楚看到 QPS 下降是因为 RT上升，那么究竟是Database的RT上升导致的还是Tomcat的RT上升导致的。</p>
<p>但是我们从监控图也能看到Database RT降下来后Tomcat RT还维持高水位，所以有点迷惑了。</p>
<p>继续看另外案例</p>
<h2 id="案例2-yy"><a href="#案例2-yy" class="headerlink" title="案例2 yy"></a>案例2 yy</h2><p>两次压测监控数据，左右两个图标是同一时间的QPS和RT，蓝线表示Tomcat，黑线表示Database被调用方</p>
<p><img src="/images/951413iMgBlog/image-20230519170255718.png" alt="image-20230519170255718"></p>
<p><img src="/images/951413iMgBlog/image-20230519172225890.png" alt="image-20230519172225890"></p>
<p>从两个图来看，随着并发加高(QPS加高) 黑色RT增加明显，但是跑着跑着降下去了，可以理解成突发流量导致黑色RT增加，但是很快黑色RT稳住了阵脚，降回去了，但是蓝色 RT没降，所以表面看起来是蓝色(Tomcat)处理能力到了瓶颈</p>
<p>上图时间点内核监控的tcprt，可以看到还是Database 处理耗时增加，和上图的黑色RT下降根本不匹配，上图黑色RT最后在2.96ms，下图内核监控到的Database的tcprt在8.49，差异矛盾点</p>
<p><img src="/images/951413iMgBlog/image-20230519172519802.png" alt="image-20230519172519802"></p>
<p>第三次压测图</p>
<p><img src="/images/951413iMgBlog/image-20230519165825977.png" alt="image-20230519165825977"></p>
<p>从第一个图来看，随着并发加高(QPS加高) 黑色RT增加明显，蓝色 RT去掉黑色部分也有增加，并且黑色、蓝色都没降回去，看起来主要是黑色(Database)处理能力到了瓶颈</p>
<p>纠结的时候就在Tomcat上抓包确认一下，如下图黑色 Database服务端口是5493，可以看到Tomcat 发request总是很快，但是Database 响应都是几十毫秒(下图红色框)，和监控一致。其实监控可以说明问题，但是我担心业务记录时间不准，以及建连接时间都考虑在内，所以想抓包微观上印证一下，这种项目牵扯到很多人你搞错了方向丢人不说，大家合作联调浪费很大，所以必须稳！</p>
<p><img src="/images/951413iMgBlog/image-20230519203620163.png" alt="image-20230519203620163"></p>
<p>如果说问题在Database上，那为什么会有Database RT忽上忽下，Database RT降下去了Tomcat RT不降？我们要继续分析一下 Tomcat RT以及Database RT是怎么记录和实现的</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>问题解决后的原因分析以及数据整理</p>
<p>这个时候我们再把Tomcat部分的业务调用和RT记录再细化一下，如下图：</p>
<p><img src="/images/951413iMgBlog/image-20230520111102697.png" alt="image-20230520111102697"></p>
<h3 id="Druid分析"><a href="#Druid分析" class="headerlink" title="Druid分析"></a><a target="_blank" rel="noopener" href="https://github.com/alibaba/druid">Druid分析</a></h3><p>创建和回收逻辑：<a target="_blank" rel="noopener" href="https://exceting.github.io/2019/08/28/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%80%EF%BC%89Druid%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E7%9A%84%EF%BC%9F/#%E4%B9%9D%E3%80%81%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E5%9B%9E%E6%94%B6%E8%BF%9E%E6%8E%A5">https://exceting.github.io/2019/08/28/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%80%EF%BC%89Druid%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E7%9A%84%EF%BC%9F/#%E4%B9%9D%E3%80%81%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E5%9B%9E%E6%94%B6%E8%BF%9E%E6%8E%A5</a></p>
<p>作为Tomcat和Database的连接点、枢纽点搞清楚Druid的逻辑对理解Tomcat和Database之间的问题的理解很关键。</p>
<p><img src="/images/951413iMgBlog/image-20240523084559029.png" alt="image-20240523084559029"></p>
<p>比如以下要说的三个Druid 错误状态如果你不放到一起比较，看到这个错误你最多反应就是连接池不够了，什么原因不知道。但是如果放到一次比较一次后你以后对详细错误提示会积极敏感，进而发现第四、第五种错误提示</p>
<p>这就是综合比较、总结的好处。</p>
<p>Druid 最核心的类是 DruidDataSource，连接的构建，入池，获取，收缩，销毁，以及核心监控数据都在这个类维护</p>
<p><img src="/images/951413iMgBlog/image-20230721170334688.png" alt="image-20230721170334688"></p>
<p>连接池初始化流程：初始化驱动实例 -&gt; 加锁 -&gt; 初始化属性 -&gt; 初始化过滤器 -&gt; 校验参数 -&gt; <strong>创建初始化连接并校验后加入池中</strong> -&gt; 创建logStatsThread、createConnectionThread和destroyConnectionThread -&gt; 注册MBean，用于支持JMX -&gt; 如果设置了keepAlive，通知createConnectionThread创建连接对象 -&gt; 解锁</p>
<p>Druid 创建连接的堆栈如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&quot;Druid-ConnectionPool-Create-1647809146&quot; #265 daemon prio=5 os_prio=0 tid=0x00007fbcdfd5f000 nid=0x1a0 runnable [0x00007fbcdf9fd000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line">        at java.net.SocketInputStream.socketRead0(Native Method)</span><br><span class="line">        at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:171)</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:141)</span><br><span class="line">        at com.mysql.jdbc.util.ReadAheadInputStream.fill(ReadAheadInputStream.java:101)</span><br><span class="line">        at com.mysql.jdbc.util.ReadAheadInputStream.readFromUnderlyingStreamIfNecessary(ReadAheadInputStream.java:144)</span><br><span class="line">        at com.mysql.jdbc.util.ReadAheadInputStream.read(ReadAheadInputStream.java:174)</span><br><span class="line">        - locked &lt;0x00000000e71ca648&gt; (a com.mysql.jdbc.util.ReadAheadInputStream)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3001)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.readPacket(MysqlIO.java:567)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.doHandshake(MysqlIO.java:1018)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2253)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2284)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2083)</span><br><span class="line">        - locked &lt;0x00000000e7f898f0&gt; (a com.mysql.jdbc.JDBC4Connection)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:806)</span><br><span class="line">        at com.mysql.jdbc.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:47)</span><br><span class="line">        at sun.reflect.GeneratedConstructorAccessor196.newInstance(Unknown Source)</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">        at com.mysql.jdbc.Util.handleNewInstance(Util.java:404)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:410)</span><br><span class="line">        at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:328)</span><br><span class="line">        at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1558)</span><br><span class="line">        at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1623)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2468)       </span><br><span class="line">        </span><br><span class="line">&quot;Druid-ConnectionPool-Create-1823047135&quot; #160 daemon prio=5 os_prio=0 tid=0x00007fbd60cf0000 nid=0x142 waiting on condition [0x00007fbd043fe000]</span><br><span class="line">   java.lang.Thread.State: WAITING (parking)</span><br><span class="line">        at sun.misc.Unsafe.park0(Native Method)</span><br><span class="line">        - parking to wait for  &lt;0x00000000c448b348&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class="line">        at sun.misc.Unsafe.park(Unsafe.java:1036)</span><br><span class="line">        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:176)</span><br><span class="line">        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2047)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2443)        </span><br></pre></td></tr></table></figure>



<h4 id="Druid-报错1"><a href="#Druid-报错1" class="headerlink" title="Druid 报错1"></a>Druid 报错1</h4><p>获取连接排队是基本不消耗CPU，下图右上角是获取失败的日志打堆栈消耗，可以看到异常非常多。</p>
<p><img src="/images/951413iMgBlog/image-20230519174633172.png" alt="image-20230519174633172"></p>
<p><img src="/images/951413iMgBlog/image-20230519175029396.png" alt="image-20230519175029396"></p>
<p>Druid最大连接数默认是30，多次调大，30-&gt;60-&gt;120-&gt;160，一直调下去对调大能解决问题都没有信心了，总是报错</p>
<blockquote>
<p>maxWaitThreadCount 30, current wait Thread count 0 </p>
</blockquote>
<p>调大到160后的报错堆栈，<a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/alibaba/druid/-/blob/core/src/main/java/com/alibaba/druid/pool/DruidDataSource.java?L1733:92">对应源码 </a> 这个报错说明报错时已经有160个线程在等连接了，别等了，先快速报错返回吧</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.sql.SQLException: maxWaitThreadCount 160, current wait Thread count 0</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnectionInternal(DruidDataSource.java:1620)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:1404)</span><br><span class="line">        at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:5059)</span><br><span class="line">        at com.alibaba.druid.filter.FilterAdapter.dataSource_getConnection(FilterAdapter.java:2756)</span><br><span class="line">        at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:5055)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1382)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1374)</span><br><span class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:98)</span><br><span class="line"></span><br><span class="line">对应代码：</span><br><span class="line">                   final Lock lock = this.lock;</span><br><span class="line">                    lock.lock();</span><br><span class="line">                    try &#123;</span><br><span class="line">                        if (activeCount &lt; maxActive) &#123;</span><br><span class="line">                            activeCount++;</span><br><span class="line">                            holder.active = true;</span><br><span class="line">                            if (activeCount &gt; activePeak) &#123;</span><br><span class="line">                                activePeak = activeCount;</span><br><span class="line">                                activePeakTime = System.currentTimeMillis();</span><br><span class="line">                            &#125;</span><br><span class="line">                            break;</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                            discard = true;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; finally &#123;</span><br><span class="line">                        lock.unlock();</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    if (discard) &#123;</span><br><span class="line">                        JdbcUtils.close(pyConnInfo.getPhysicalConnection());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            final ReentrantLock lock = this.lock;</span><br><span class="line">            try &#123;</span><br><span class="line">                lock.lockInterruptibly();</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                connectErrorCountUpdater.incrementAndGet(this);</span><br><span class="line">                throw new SQLException(&quot;interrupt&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            try &#123;</span><br><span class="line">                if (maxWaitThreadCount &gt; 0</span><br><span class="line">                        &amp;&amp; notEmptyWaitThreadCount &gt;= maxWaitThreadCount) &#123;</span><br><span class="line">                    connectErrorCountUpdater.incrementAndGet(this);</span><br><span class="line">                    throw new SQLException(&quot;maxWaitThreadCount &quot; + maxWaitThreadCount + &quot;, current wait Thread count &quot;</span><br><span class="line">                            + lock.getQueueLength());//bug? lock.getQueueLength()永远为0，应该改成：lock.getWaitQueueLength(notEmpty)</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure>



<p>以下两个Druid 报错这次压测没有出现但是可以放一起比较一下，其它项目场景经常出现</p>
<h4 id="Druid-报错2"><a href="#Druid-报错2" class="headerlink" title="Druid 报错2"></a>Druid 报错2</h4><p>Druid类似报错，明显是等了5秒最大等待时间还没有获取到连接：<img src="/images/951413iMgBlog/image-20230519191317489.png" alt="image-20230519191317489"></p>
<p>红色错误信息表示等了5006毫秒（设置的5000毫秒超时）还没有取到连接，所以超时了，然后抛出错误堆栈。</p>
<p>红色信息还提示我们当前连接池最大10，目前 active 0, 说明不是连接池满了取不到，而是连接池里一直是空的。</p>
<p>看到这个错误不能说明数据库、访问数据库有啥问题，只能说明Druid 连接池取不到连接，要继续分析Druid创建连接的线程栈。或者比如Druid 参数设置不合理，可以把min、init、max 连接数设置为相同的值，避免压力高峰期再去创建连接。</p>
<p>Druid通过另外一个task（thread）异步给连接池补充连接，也就是这里可能是Druid创建连接失败，比如密码错误、比如连不上数据库，比如创建的thread卡死了、报其他异常了</p>
<p><strong>Druid创建 连接 和业务取连接是两个线程，所以业务取连接报错是看不到创建连接报错的堆栈和原因的</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#grep CreateConnectionThread.run stack4.log</span><br><span class="line">	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2818)</span><br><span class="line">	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2813)</span><br></pre></td></tr></table></figure>



<h4 id="Druid-报错3"><a href="#Druid-报错3" class="headerlink" title="Druid 报错3"></a>Druid 报错3</h4><p><img src="/images/951413iMgBlog/image-20230520092224080.png" alt="image-20230520092224080"></p>
<p>借出连接为0(active 0)，creating也是0，没有新连接正在创建。</p>
<p>分析方法：</p>
<ol>
<li>dump Java应用内存，用MAT内存分析工具打开dump文件</li>
<li>使用OQL，select * from com.alibaba.druid.pool.DruidDataSource where createTaskCount&#x3D;3</li>
<li>选出来的DruidDataSource即为有问题的datasource</li>
</ol>
<p>原因</p>
<p>Druid中有个计数器createTaskCount，用来记录每个连接池当前正在创建连接的任务数，默认不能超过3。Druid中，在keepAlive&#x3D;true的情况下，这个计数器有bug，存在加了但没减的情况，导致这个值涨到3之后没有减回去，从而无法提交新的创建连接任务。</p>
<p> 注意，进入这个状态后的连接池，是无法自动恢复的。Druid升级到1.1.24可以修复这个问题。</p>
<h3 id="Druid-报错-4"><a href="#Druid-报错-4" class="headerlink" title="Druid 报错 4"></a>Druid 报错 4</h3><p>下图这个堆栈很有意思，栈顶是连接不够触发 Druid 创建新连接，但是建新连接报错了，于是需要记录日志，但是有些场景(比如任务流) 要求，错误信息要往数据库存，于是记录日志触发取连接，然后就死锁了：</p>
<p><img src="/Users/ren/case/951413iMgBlog/image-20250306153320704.png" alt="image-20250306153320704"></p>
<h3 id="分片逻辑"><a href="#分片逻辑" class="headerlink" title="分片逻辑"></a>分片逻辑</h3><p>因为数据量太大，一台Database存放不下，自然会分片，或者说单表几千万之后也是建议分片。</p>
<p>分片逻辑是取业务id最后两位的字符去取string hashcode，再对16个Database分片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">如果对id后两位字符(从00-99供100个数字，因为不排除id里面有字符，但实际主要是0-9的数字)的ascii码取hash然后按16取模的结果：</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9  --开始不正常，10-14号分片没有直接跳到15号分片</span><br><span class="line">15</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">……</span><br><span class="line"></span><br><span class="line">//分片求模代码</span><br><span class="line">for(int i=0;i&lt;10;++i) //0的ascii码是48，依此类推</span><br><span class="line">	for(int j=0;j&lt;10;++j)</span><br><span class="line">		 int value=((48+i)*31+j) mod 16;</span><br></pre></td></tr></table></figure>

<p>补充个小八卦</p>
<blockquote>
<p>为什么取某几位尾数来求模？比如很多业务按user_id拆分片，然后希望这个用户的所有订单拆分也落在一个分片内。于是他们想到的办法是在订单id最后几位上追加进去下单人的user_id后几位，对订单拆分会取订单id后几位hash，这样同一个用户肯定到同一个分片</p>
<p>这样查询某个用户的所有订单时(高频需求)就只需要查一个分片，否则就要扫描所有分片。</p>
<p>掏出你的某宝、某东看看你的订单后几位</p>
</blockquote>
<p>分片后的数据，明显两头的多中间的少，这必然导致后面的 Database 负载不均衡：</p>
<p><img src="/images/951413iMgBlog/image-20230519181628114.png" alt="image-20230519181628114"></p>
<p>Java源码：</p>
<p><img src="/images/951413iMgBlog/image-20230519181451384.png" alt="image-20230519181451384"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>问题的根本原因？</p>
<p>多个Database中的某几个瓶颈，为什么会这样见数据分布部分的分析</p>
<p>为什么Database RT监控能降下来？</p>
<p>业务Tomcat 帮Database拦截了流量，一旦Database响应慢 Druid 连接就会不够，请求都堵在Tomcat中，导致Tomcat RT升高(包含等待连接时间)——替人堵了枪眼，很好，Tomcat crash总比 Database crash要好，但是业务要清楚这是替人挨枪子，该往哪里去查瓶颈。</p>
<p>比如加流量20%，开始Database RT升高，很快连接不可用，可能有接近20%的流量被Tomcat拦截，这个时候Database RT能稳定，也有可能拦截的不够多，这个时候Database RT还是很高，但Tomcat RT更高，进入一种平衡状态</p>
<p>为什么有时候压测能过？</p>
<p>应该是数据分布比较巧，刚好压测流里面的数据分布没那么不均衡，没触发数据库雪崩</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E7%9A%84%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90--%E6%8A%96%E5%8A%A8%E5%92%8C%E5%B9%B6%E5%8F%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E7%9A%84%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90--%E6%8A%96%E5%8A%A8%E5%92%8C%E5%B9%B6%E5%8F%91/" class="post-title-link" itemprop="url">扑朔迷离的根因分析--抖动和并发</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-07-23 12:30:03" itemprop="dateCreated datePublished" datetime="2023-07-23T12:30:03+08:00">2023-07-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="扑朔迷离的根因分析–抖动和并发"><a href="#扑朔迷离的根因分析–抖动和并发" class="headerlink" title="扑朔迷离的根因分析–抖动和并发"></a>扑朔迷离的根因分析–抖动和并发</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们之前说过根因分析第一就是要追着 RT跑，随着并发的增加哪里RT增加快哪里就是瓶颈，这是我们的基本原则，但总有一些例外，我们今天想说说例外</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>如下图，应用是多个Tomcat集群，Tomcat节点可以随意增加，后端是一组DB集群，有几百个Database实例，每一次业务请求都会对应多个Database查询</p>
<p><img src="/images/951413iMgBlog/image-20230609204957690.png" alt="image-20230609204957690"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>开始的时候客户端压2个Tomcat集群，QPS 700，Tomcat节点CPU 90%，Database每个节点CPU 20%左右，于是增加1个Tomcat 节点这个时候QPS 还是700，Tomcat的RT增加了50%，Tomcat CPU 降低到60%，继续增加Tomcat 节点 RT、QPS保持稳定，CPU使用率下降。</p>
<p>所以这里要搞清楚哪里是瓶颈，如果Tomcat是瓶颈加Tomcat节点为什么没有效果。如果Database是瓶颈但是增加Tomcat节点的时候Database 的RT有一点点增加，远远没有到增加50%的RT 程度</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>首先最容易想到的是Tomcat 和 Database之间的网络、网关、LVS 等资源到了瓶颈，但是经过排查分析这些环节都排除了，另外也排除了Tomcat到Database的连接池、Database的磁盘等瓶颈，另外Tomcat 访问Database全是查询，没有事务。</p>
<p><img src="/images/951413iMgBlog/20230609210244.jpg" alt="image.png"></p>
<p>看起来事情比想象的复杂，于是进行了如下压测：</p>
<p>先用一个压力端压3个Tomcat中的2个，QPS 跑到700，然后新开一个压力端压第三个Tomcat(新开压力端是排查压力机的问题，新开Tomcat是想排除Tomcat 的问题)，如果Tomcat是瓶颈的话QPS应该上去，或者说后端没有问题的话那两个Tomcat 的700 QPS得保持基本稳定不变或略微下降才对。</p>
<p>实际上第二个压力端跑起来后，前两个Tomcat的QPS 铛就掉下去了，总QPS 保持稳定不变，也就是随着Tomcat给后端并发压力的增加后端肯定给了一个负反馈给那两Tomcat，导致那两Tomcat QPS掉下去了。这个负反馈明显得是Database的RT在增加，但是从监控来看Database的RT 从0.6增加到了0.8，但是Tomcat 的RT 增加更快从19.7增加到了29.8.</p>
<p>单独压DB，DB的QPS能高5倍，CPU 也可以跑到100%。看起来单压都没问题，一组合就不行了</p>
<h3 id="问题在Database"><a href="#问题在Database" class="headerlink" title="问题在Database"></a>问题在Database</h3><p>绕过Tomcat 用相同的SQL 压Database QPS 一下子就能上去，Database 的CPU 也跑到了100%，但是只要走Tomcat 就会上不去。</p>
<p>打开Tomcat 日志将所有Database的响应时间拉出来分析，发现随着并发的增加 100 ms的响应也多了很多，实际上这些查询都是1ms就应该返回</p>
<p>具体分析过程看这里：<a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/</a></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>当压力增加的时候MySQL端等锁导致的 RT 抖动或者说长尾越来越多，虽然没有数据库的写，但是查询的时候优化器也需要统计行数等数据来为查询优化器做选择依据，这个统计动作会触发加锁排队(极短)，但是因为这一代Intel CPU指令的变化导致这个锁被放大了10 被，所以最终Tomcat 端看到的长尾就多了</p>
<h2 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h2><h4 id="为什么同样的环境、同样的SQL-绕过Tomcat-就能压上去？"><a href="#为什么同样的环境、同样的SQL-绕过Tomcat-就能压上去？" class="headerlink" title="为什么同样的环境、同样的SQL 绕过Tomcat 就能压上去？"></a>为什么同样的环境、同样的SQL 绕过Tomcat 就能压上去？</h4><p>绕过后的压测场景没有业务逻辑，每次请求就是一条SQL，虽然有抖动但是对平均RT拉升不明显。</p>
<h4 id="走业务逻辑压Tomcat-为什么不行？"><a href="#走业务逻辑压Tomcat-为什么不行？" class="headerlink" title="走业务逻辑压Tomcat 为什么不行？"></a>走业务逻辑压Tomcat 为什么不行？</h4><p>业务逻辑是一次请求会发256条SQL，等这256条SQL全部返回来了业务请求才会返回！请反复读这句话3遍再往下看</p>
<p>如果256条SQL 中有一条花了100 ms返回那么整个业务逻辑的RT 就是100ms，假设1%的概率一条SQL是100ms，99%的SQL 是 1ms，你可以先停下来算一算这种业务模型下的平均RT是多少</p>
<h4 id="计算抖动下的平均RT"><a href="#计算抖动下的平均RT" class="headerlink" title="计算抖动下的平均RT"></a>计算抖动下的平均RT</h4><p>关于这个抖动对整体rt的影响计算：</p>
<p><img src="/images/951413iMgBlog/1575880425321-79c7ea4a-fcf1-41f9-afb9-6e553d9eaf8f.png" alt="img"></p>
<p>注:假设正常查询rt 1ms，逻辑平均rt&#x3D;(1-power(1-抖动概率,物理查询次数))*抖动大小+(power(1-抖动概率,物理查询次数))*1ms </p>
<p>当前场景下，逻辑QPS:物理QPS&#x3D;1:256，假如每次查询有1%的物理（RDS）rt抖动到100ms，则会导致逻辑平均rt恶化到92.44ms.</p>
<p>在一次逻辑查询里，只有所有物理查询都不抖整体才是不抖，RT正常；如果有一个或多个物理查询抖了，那么逻辑RT就是抖动RT。</p>
<p>所以一次逻辑查询不抖的概率是： power(1-抖动概率, 物理查询次数)</p>
<p>反过来想这256条SQL都不碰上抖动这次业务请求才会1ms返回(概率极低)，否则就是256ms返回</p>
<h4 id="为什么要讲这个案例"><a href="#为什么要讲这个案例" class="headerlink" title="为什么要讲这个案例"></a>为什么要讲这个案例</h4><p>倒不是出于原因分析，这个原因几年前就分析清楚了，但是这个场景：一次业务请求会涉及多次SQL、Redis、MQ的调用，只要其中有一个有短板、抖动这次业务请求就慢了。这简直太常见了</p>
<p>但难在别人的抖动很低被平均掉了，但是业务(Tomcat) 就要替别人背锅了，因为别人的RT 几乎没有增加或者加很少，但是Tomcat RT增加很明显，瓶颈当然看着像是在Tomcat 上。背锅吧也不可怕可怕的是你增加Tomcat 节点也不能解决问题，这才是你要从这个案例里学到的。</p>
<p>如果你的Tomcat 调后端因为短板(抖动)导致压力打不到后端，因为抖动导致Tomcat不能快速返回</p>
<h5 id="上游影响下游："><a href="#上游影响下游：" class="headerlink" title="上游影响下游："></a>上游影响下游：</h5><p>和本文无关但是可以放一起综合来看上下游互相影响的复杂性</p>
<p>以前认为事务不提交的主要代价是行锁持有时间变长(这确实是个问题)，今天见识到了新代价，事务不提交会导致事务活跃链表变长，增加copy readview的代价，进而导致DB的RT 增高，实际导致DB RT高的根本原因是DB前面的业务早到了瓶颈，来不及发送commit，导致DB端事务堆积严重。也就是业务瓶颈导致了后端DB RT高，只看RT就会被蒙蔽——怎么解决？可以抓包看commit发送慢</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/06/30/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB--%E5%86%99%E5%9C%BA%E6%99%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/30/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB--%E5%86%99%E5%9C%BA%E6%99%AF/" class="post-title-link" itemprop="url">实战瓶颈定位-我的MySQL为什么压不上去--写场景</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-30 17:30:03" itemprop="dateCreated datePublished" datetime="2023-06-30T17:30:03+08:00">2023-06-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="实战瓶颈定位-我的MySQL为什么压不上去–写场景"><a href="#实战瓶颈定位-我的MySQL为什么压不上去–写场景" class="headerlink" title="实战瓶颈定位-我的MySQL为什么压不上去–写场景"></a>实战瓶颈定位-我的MySQL为什么压不上去–写场景</h1><p>纠结好久要不要写这篇，因为原因非常坑爹，你们基本不会遇到，想了很久觉得思路还是有些价值，所以还是写一下，我尽量简单</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>继续上文 <a href="https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/">https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/</a> ，纯读场景问题解决后，继续压纯写场景，比另外一套类似环境差了很多，大概是2折。</p>
<p>纯写肯定有预期：会有锁、磁盘瓶颈等问题</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>先看top，结果很明显CPU上不去，并且有一个单核长时间 100%，然后 top -Hp mysqld-pid 展开所有线程，果然一直有一个线程几乎一直 100%，这就太明显了，这个线程遇到了瓶颈，导致整体上不去。</p>
<p><img src="/images/951413iMgBlog/image-20230515083125494.png" alt="image-20230515083125494"></p>
<p>top -Hp mysqld-pid 看到165935 线程一直几乎是 100% 的CPU 状态</p>
<p><img src="/images/951413iMgBlog/image-20230515083309083.png" alt="image-20230515083309083"></p>
<p>所以接下来要搞清楚这个线程在忙什么，刷盘？抢锁？</p>
<p>如果是Java应用就简单了，直接jstack一看就很清楚了，但是MySQLD没这么容易，另外环境里没有 pstack也没法安装，所以这条路走不通。</p>
<p>但是大概率能猜出来和磁盘有点关系，于是iostat -x -d 看看磁盘情况，好家伙果然ioutil 100%，磁盘 IO TPS 好几万。如下nvme0n1是MySQLD 使用的SSD 数据盘，vdb 是OS 系统盘</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#iostat  -d vdb nvme0n1 3</span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">nvme0n1       45317.33        37.33    322150.67        112     966452</span><br><span class="line">vdb               0.00         0.00         0.00          0          0</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">nvme0n1       45215.33        37.33    319228.00        112     957684</span><br><span class="line">vdb               0.00         0.00         0.00          0          0</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">nvme0n1       45146.00        42.67    320677.33        128     962032</span><br><span class="line">vdb               0.00         0.00         0.00          0          0</span><br></pre></td></tr></table></figure>

<p>通过 ：iostat -x -d vdb nvme0n1 3 可以看到如下图</p>
<p><img src="/images/951413iMgBlog/image-20230515083645463.png" alt="image-20230515083645463"></p>
<p>但这是不是正常情况不好说，于是找到家里同样的环境跑起来(没有单线程 100%问题，QPS 比问题环境高了 5倍)，于是也看一下 iostat 做一个对比，对比发现 ioutil 很小，然后磁盘 IO TPS 才我问题环境的30%，在QPS 5倍，IO TPS才 30%的情况下傻子也能看出来这两场景肯定不一样。一个QPS触发的IO TPS差了 15倍了。</p>
<p>不啰嗦，将问题环境的sysbench 脚本复制到正常环境，这下问题重现了，再diff看看两个脚本果然被人改了。问题环境使用的sysbench是别人装的，经过分析后发现里面被改动过一些东西。</p>
<p>之所以一直没有怀疑 sysbench 的问题，也有之前测试只读场景的时候符合预期，所以忽视了sysbench的差异。</p>
<p>这让我想起贝尔实验室Ken Thompson’s “cc hack” 的八卦(有兴趣的同学可以自行查证一下)：</p>
<blockquote>
<p>当年在贝尔实验室，人们都用Unix系统，但是只有Ken可以绕过密码直接登录，让其他人百思不得其解。按理说整个Unix系统是开源的，很多人检查了系统代码，尤其是登录部分， 并没有发现任何漏洞或者后门。</p>
<p>Ken的同事们不断重新编译Unix， 但是Ken依旧如幽灵一般来去自如。</p>
<p>有人怀疑编译Unix的编译器里面有代码，但是当他们反复检查编译器源码，甚至重新编译c编译器后，依旧没有任何发现。</p>
<p>多年后，在Turing Award Lecture中，Ken终于道出了事情真相，登录源码和编译器源码都是干净的。事实上，这个幽灵般的木马在编译器的可执行文件中。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这里的思路是：单线程100%-&gt;磁盘IO TPS非常高-&gt;和正常环境对比(常用手段，也要运气好有两个环境可以对比)-&gt;一个QPS 对应的IO TPS差异巨大-&gt;压测脚本问题</p>
<p>这算是个坑爹的小问题，大家也不会碰到，比网络限速难查多了，网络限速那里我们有放之四海而皆准的 RT 逻辑+抓包，所以很好定位。但是查证分析过程我觉得有一定的参考性，所以记录下。</p>
<p>如果MySQLD能提供一个内部任何一个操作的时间就好了，实际很难实现。当然通过火焰图去看异常偏高的调用是另外一个方向。</p>
<p>跨网络我们有抓包很好界定，但是问题到进程内部的时候反而没了抓包这种一锤定影的工具了</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/06/30/%E7%AD%89%E9%A2%9D%E6%9C%AC%E9%87%91%E5%92%8C%E7%AD%89%E9%A2%9D%E6%9C%AC%E6%81%AF%E4%BB%A5%E5%8F%8A%E6%8F%90%E5%89%8D%E8%BF%98%E8%B4%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/30/%E7%AD%89%E9%A2%9D%E6%9C%AC%E9%87%91%E5%92%8C%E7%AD%89%E9%A2%9D%E6%9C%AC%E6%81%AF%E4%BB%A5%E5%8F%8A%E6%8F%90%E5%89%8D%E8%BF%98%E8%B4%B7/" class="post-title-link" itemprop="url">等额本息和等额本金以及提前还贷误区</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-30 12:30:03" itemprop="dateCreated datePublished" datetime="2023-06-30T12:30:03+08:00">2023-06-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E5%B7%A7/" itemprop="url" rel="index"><span itemprop="name">技巧</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="等额本息和等额本金以及提前还贷误区"><a href="#等额本息和等额本金以及提前还贷误区" class="headerlink" title="等额本息和等额本金以及提前还贷误区"></a>等额本息和等额本金以及提前还贷误区</h1><h5 id="1-等额本金和等额本息的差异"><a href="#1-等额本金和等额本息的差异" class="headerlink" title="1 等额本金和等额本息的差异"></a>1 等额本金和等额本息的差异</h5><p>没有差异。等额本金&#x3D;等额本息+每月提前还贷一点点()</p>
<h5 id="2-为什么等额本金总利息少"><a href="#2-为什么等额本金总利息少" class="headerlink" title="2 为什么等额本金总利息少"></a>2 为什么等额本金总利息少</h5><p>因为每个月等额本金还款多，第一个月后欠本金少了，后面每个月都是这样，所还本金更多，最终总利息自然更少</p>
<blockquote>
<p>其实可以用极限思维来分析他们的差异：假设等额本息和等额本金都借100万，周期一个月(没看错，一个月还清，极限假设)，所以一个月后他们还钱一样多！所以这个时候没有任何区别；现在继续假设，假如还款周期是2个月，那么等额本金在第一个月还钱多，导致等额本金在第二个月的时候欠钱少了，到第二个月月底还清所有欠款的时候利息要少(本金少了)——这才是他们的差异，所以是没区别的。等额本金这两个月相当于欠了银行150万一个月(第一个月欠100万，第二个月欠50万) 应还利息就是150万 乘以 月利率；等额本息相当于欠了银行 151万（第一个月欠100万，第二个月51万，因为第一个月还钱的时候只还了49万本金），所以应还利息就是 151万 乘以 月利率；欠得多利息就多天经地义这里没有投机、没有人吃亏</p>
<p>再或者换个思路：第一个月借100万，月底都还清，此时利息一样多；然后再借出来99.X万，这时等额本金借得少这个X更小，所以从第二个月开始等额本金还的利息少，归根结底换利息少是因为借得少(即现实中的还本金多)</p>
</blockquote>
<p>把上面的极限思维图形化就是下图中的灰色部分面积代表你的欠款(每个月的欠款累加)，等额本息的方式欠得多，自然利息多：</p>
<p><img src="/images/951413iMgBlog/image-20230704214346239.png" alt="image-20230704214346239"></p>
<h5 id="3-为什么总有等额本金划得来的说法"><a href="#3-为什么总有等额本金划得来的说法" class="headerlink" title="3 为什么总有等额本金划得来的说法"></a>3 为什么总有等额本金划得来的说法</h5><p>同样贷款金额下等额本金总还款额少，也就是总利息少，所以给了很多人划得来的感觉，或者给人感觉利息便宜。其实这都是错的，解释如上第二个问题</p>
<h5 id="4-利息的计算方式"><a href="#4-利息的计算方式" class="headerlink" title="4 利息的计算方式"></a>4 利息的计算方式</h5><p>利息每个月计算一次，这个月所欠本金*月利率。所以利息只和你欠钱多少有关（我们假设所有人的利率都一样）。每个月的月供，都是先还掉这个月的利息，多余的再还本金</p>
<p>等额本金因为每个月还掉的本金多，所以计算下来每个月的利息更少</p>
<h5 id="5-如何理解等额本金和等额本息"><a href="#5-如何理解等额本金和等额本息" class="headerlink" title="5 如何理解等额本金和等额本息"></a>5 如何理解等额本金和等额本息</h5><p>同样贷款额+利率的话等额本金开始还款一定比等额本息要多一些，那么你可以把等额本金分成两块，一块和等额本息一样，多出来的部分你把他看成这个月额外做了一次提前还款。你提前还款了后面的总利息自然也会更少一些，然后每个月的等额本息也会减少，以此类推每个月都是这样额外做一次提前还款直到最后一个月。</p>
<p>总结：等额本金&#x3D;等额本息+提前还贷</p>
<p>额本金开始还款一定比等额本息要多一些，可以把等额本金分成两块，一块和等额本息一样，多出来的部分把他看成这个月额外做了一次提前还款。提前还款后总利息也会更少一些，然后每个月的等额本息也会减少，以此类推每个月都是这样额外做一次提前还款直到最后一个月。</p>
<h5 id="6-提前还款划不划得来"><a href="#6-提前还款划不划得来" class="headerlink" title="6 提前还款划不划得来"></a>6 提前还款划不划得来</h5><p>钱在你手里没法赚到比利息更高的收益的话(99%的人属于这种)提前还贷划得来，之所以以前不建议大家提前还贷，是因为以前普遍涨薪快、通胀厉害、房价涨得块，把钱留出来继续买二套、三套更赚钱。另外钱留在手里会有主动权和应急方便</p>
<h5 id="7-提前还贷会多付利息吗？"><a href="#7-提前还贷会多付利息吗？" class="headerlink" title="7 提前还贷会多付利息吗？"></a>7 提前还贷会多付利息吗？</h5><p>不会，见第四条利息的计算方式。担心提前还贷的时候这比贷款把后面10年的利息收走了的是脑子不好使的人。但有些银行提前还贷会有违约金</p>
<h5 id="8-为什么等额本金和等额本息给了这么多人错觉"><a href="#8-为什么等额本金和等额本息给了这么多人错觉" class="headerlink" title="8 为什么等额本金和等额本息给了这么多人错觉"></a>8 为什么等额本金和等额本息给了这么多人错觉</h5><p>从知识的第一性出发，他们都没理解第4条，受社会普遍意识影响都预先留下了错误经验。本质就是利息只和贷款额、利率有关。</p>
<h5 id="9-贷款30年和10年利率有差异吗？"><a href="#9-贷款30年和10年利率有差异吗？" class="headerlink" title="9 贷款30年和10年利率有差异吗？"></a>9 贷款30年和10年利率有差异吗？</h5><p>没有</p>
<h5 id="10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？"><a href="#10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？" class="headerlink" title="10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？"></a>10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？</h5><p>不会，你前6年只是还了前6年的利息，没为之后的6年多付一分利息</p>
<h5 id="11-那为什么利率不变我每个月利息越来越少"><a href="#11-那为什么利率不变我每个月利息越来越少" class="headerlink" title="11 那为什么利率不变我每个月利息越来越少"></a>11 那为什么利率不变我每个月利息越来越少</h5><p>因为你欠的钱越来越少了，不是你提前还了利息，是你一直在还本金</p>
<h5 id="12-网购分期合适吗？"><a href="#12-网购分期合适吗？" class="headerlink" title="12 网购分期合适吗？"></a>12 网购分期合适吗？</h5><p>大部分小贷公司的套路就是利用你每个月已经在还本金的差异，利息自然越来越少，然后计算一个大概5%的年息误导你，实际这种网购分期的实际利息要是他计算的2倍……好好想想</p>
<p>等额本金、本息都搞不清楚的人就不要去搞分期了，你的脑瓜子在这方面不好使。</p>
<p>聪明人只看第4条就能在大脑里得出所有结论，普通人除了要有第4条还需要去看每个月的还款额、还款额里面的本金、还款额里的利息等实践输入才能理解这个问题，这就是差异</p>
<p><img src="/images/951413iMgBlog/%E6%88%BF%E8%B4%B7.jpg" alt="房贷"></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161405128">https://zhuanlan.zhihu.com/p/161405128</a></p>
<h2 id="提前还贷"><a href="#提前还贷" class="headerlink" title="提前还贷"></a>提前还贷</h2><h5 id="要不要提前还贷"><a href="#要不要提前还贷" class="headerlink" title="要不要提前还贷"></a>要不要提前还贷</h5><p>要</p>
<h5 id="提前还贷划得来吗？"><a href="#提前还贷划得来吗？" class="headerlink" title="提前还贷划得来吗？"></a>提前还贷划得来吗？</h5><p>划不划得来要看这笔钱在你手里能否获得比房贷利息更高的收入以及你对流动资金的需要。其实万一有个啥事也可以走消费贷啥的，现在利息都很低</p>
<h5 id="等额本息比等额本金提前还贷更划得来？"><a href="#等额本息比等额本金提前还贷更划得来？" class="headerlink" title="等额本息比等额本金提前还贷更划得来？"></a>等额本息比等额本金提前还贷更划得来？</h5><p>一样的，你这个问题等价于我欠100万，老婆欠50万，所以我提前还贷比朋友合算吗？显然你两谁提前还贷合算只和你两的贷款利率是否有差别</p>
<p>等额本息和等额本金利率一样的，所以没有差别</p>
<h5 id="20年的房贷我已经还了15年了是不是不值得提前还贷了？"><a href="#20年的房贷我已经还了15年了是不是不值得提前还贷了？" class="headerlink" title="20年的房贷我已经还了15年了是不是不值得提前还贷了？"></a>20年的房贷我已经还了15年了是不是不值得提前还贷了？</h5><p>错误！利率还是那个利率，跟你还剩10年和还剩5年没关系，提前还贷都是等价的。记住有闲钱就提前还</p>
<h5 id="问题的本质"><a href="#问题的本质" class="headerlink" title="问题的本质"></a>问题的本质</h5><p>搞清楚每个月的利息怎么计算出来的  利息&#x3D;欠款额*月利率，月供都是把本月利息还掉多出来的还本金，也就是每个月欠款额会变少</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>每个领域都有一些核心知识点代表着这些问题的本质，你只有把核心知识点或者说问题本质搞懂了才能化繁为简、不被忽悠！</p>
<p>那贷款这里的本质是什么？就是利息只和你每个月欠款以及利率有关！这简直是屁话，太简单了，但你不能理解他，就容易被套上等额本金、等额本息、提前还贷的外壳给忽悠了。</p>
<p>再或者说这里的本质就是：你去搞清楚每个月的还款是怎么计算的。月供&#x3D;本月所欠X利率+本月还掉的本金  这是个核心公式，差别在每个月还掉的本金不一样！</p>
<p>就这样吧该懂的也该看懂了，看不懂的大概怎么样也看不懂！只能说是蠢，这些人肯定理科不好、逻辑不行，必定做不了程序员。</p>
<p>比如网上流传的如图总结的所有结论都是错的：</p>
<p><img src="/images/951413iMgBlog/image-20230704215506179.png" alt="image-20230704215506179"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/" class="post-title-link" itemprop="url">实战瓶颈定位-我的MySQL为什么压不上去</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-20 17:30:03" itemprop="dateCreated datePublished" datetime="2023-06-20T17:30:03+08:00">2023-06-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="实战瓶颈定位-我的MySQL为什么压不上去"><a href="#实战瓶颈定位-我的MySQL为什么压不上去" class="headerlink" title="实战瓶颈定位-我的MySQL为什么压不上去"></a>实战瓶颈定位-我的MySQL为什么压不上去</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>环境两台云上相同 128C的EC2(有点豪)，一台当压力机一台当服务器，用Sysbench测试MySQL纯读场景，不存在任何修改，也就几乎没有锁</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#uname -r</span><br><span class="line">5.10.84.aarch64</span><br><span class="line"></span><br><span class="line">Server:            MySQL</span><br><span class="line">Server version:        8.0.18 Source distribution</span><br></pre></td></tr></table></figure>

<p>EC2机器128核，故意只给MySQLD绑定了其中的24Core，网卡32队列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#ethtool -l eth0</span><br><span class="line">Channel parameters for eth0:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:        0</span><br><span class="line">TX:        0</span><br><span class="line">Other:        0</span><br><span class="line">Combined:    32</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:        0</span><br><span class="line">TX:        0</span><br><span class="line">Other:        0</span><br><span class="line">Combined:    32</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/FlDlXFTuGa0BPv1YxR3KQZaP40de.png" alt="img"></p>
<h2 id="压测过程"><a href="#压测过程" class="headerlink" title="压测过程"></a>压测过程</h2><p>走同一交换机内网IP压MySQL跑不满CPU，跑压力和不跑压力时ping rtt 分别是 0.859&#x2F;0.053(RTT 有增加–注意点), 此时TPS：119956.67 1000并发 RT 8.33</p>
<p>下图是压测时 htop 看到的MySQLD 所在EC2的 CPU使用情况，右边65-88是MySQLD进程(绿色表示us, 红色表示sys+si CPU)</p>
<p><img src="/images/951413iMgBlog/image-20230511125934259.png" alt="image-20230511125934259"></p>
<p>用top查看详细的每个 core 使用(只展示MySQLD使用的24core ，top 然后按1–还可以试试2&#x2F;3，有惊喜)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">top - 13:49:55 up 160 days, 18:10,  3 users,  load average: 555.26, 720.12, 462.21</span><br><span class="line">Tasks: 1065 total,   1 running, 499 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Node1 : 10.1 us,  5.3 sy,  0.0 ni, 83.3 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st</span><br><span class="line">%Cpu64 : 29.3 us, 16.5 sy,  0.0 ni, 54.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu65 : 37.0 us, 18.5 sy,  0.0 ni, 26.9 id,  0.0 wa,  0.0 hi, 17.5 si,  0.0 st</span><br><span class="line">%Cpu66 : 34.2 us, 17.8 sy,  0.0 ni, 47.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu67 : 26.0 us, 15.1 sy,  0.0 ni, 58.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu68 : 26.1 us, 14.8 sy,  0.0 ni, 59.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu69 : 27.2 us, 13.8 sy,  0.0 ni, 59.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu70 : 25.7 us, 11.8 sy,  0.0 ni, 62.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu71 : 18.3 us, 10.6 sy,  0.0 ni, 71.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu72 : 29.7 us, 12.6 sy,  0.0 ni, 57.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu73 : 21.2 us, 13.0 sy,  0.0 ni, 65.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu74 : 18.9 us, 10.8 sy,  0.0 ni, 70.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu75 : 28.9 us, 15.1 sy,  0.0 ni, 36.1 id,  0.0 wa,  0.0 hi, 19.9 si,  0.0 st</span><br><span class="line">%Cpu76 : 30.3 us, 15.5 sy,  0.0 ni, 54.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu77 : 25.1 us, 13.2 sy,  0.0 ni, 61.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu78 : 18.2 us, 10.3 sy,  0.0 ni, 71.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu79 : 14.9 us,  8.8 sy,  0.0 ni, 76.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu80 : 23.4 us, 12.2 sy,  0.0 ni, 64.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu81 : 35.3 us, 17.6 sy,  0.0 ni, 30.2 id,  0.0 wa,  0.0 hi, 16.9 si,  0.0 st</span><br><span class="line">%Cpu82 : 28.2 us, 16.1 sy,  0.0 ni, 55.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu83 : 37.5 us, 16.9 sy,  0.0 ni, 27.0 id,  0.0 wa,  0.0 hi, 18.6 si,  0.0 st</span><br><span class="line">%Cpu84 : 35.4 us, 18.5 sy,  0.0 ni, 46.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu85 : 27.9 us, 16.8 sy,  0.0 ni, 55.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu86 : 28.2 us, 13.7 sy,  0.0 ni, 58.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu87 : 27.2 us, 11.0 sy,  0.0 ni, 61.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu88 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br></pre></td></tr></table></figure>

<p>继续尝试用2000并发，TPS、CPU、ping rtt都和1000并发没有区别，当然按照我们以前QPS、RT理论2000并发的时候RT应该翻倍，实际确实是16.66，<strong>所以这里的问题就是翻倍的 RT哪里来的瓶颈就在哪里</strong>。</p>
<p>也试过用两个压力机每个压力机分别用1000并发同时压，QPS一样稳定——目的快速排除压力端、链路上有瓶颈。</p>
<p>写到这里RT 刚好翻倍16.66&#x3D;8.33*2 数字精准得好像编故事一样，不得不贴一下原始数据证实一下：</p>
<p><img src="/images/951413iMgBlog/image-20230511130851332.png" alt="image-20230511130851332"></p>
<p>1000 并发和2000并发时的ping RTT对比(ttl 64说明内网直达)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#ping mysqld27</span><br><span class="line">PING yt27 (mysqld217) 56(84) bytes of data.</span><br><span class="line">---以下是2000并发</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=1 ttl=64 time=0.867 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=2 ttl=64 time=0.952 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=3 ttl=64 time=0.849 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=4 ttl=64 time=0.857 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=5 ttl=64 time=0.987 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=6 ttl=64 time=0.860 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=7 ttl=64 time=0.909 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=8 ttl=64 time=0.875 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=9 ttl=64 time=0.979 ms  </span><br><span class="line">---终止压测，无无压力的rtt</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=10 ttl=64 time=0.104 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=11 ttl=64 time=0.079 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=12 ttl=64 time=0.075 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=13 ttl=64 time=0.075 ms </span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=14 ttl=64 time=0.074 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=15 ttl=64 time=0.078 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=16 ttl=64 time=0.075 ms</span><br><span class="line">---开启1000并发时的rtt</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=17 ttl=64 time=0.872 ms </span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=18 ttl=64 time=0.969 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=19 ttl=64 time=0.862 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=20 ttl=64 time=0.877 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=21 ttl=64 time=0.961 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=22 ttl=64 time=0.828 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=23 ttl=64 time=0.098 ms</span><br><span class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=24 ttl=64 time=0.083 ms</span><br></pre></td></tr></table></figure>

<h3 id="抓包证明"><a href="#抓包证明" class="headerlink" title="抓包证明"></a>抓包证明</h3><p>在抓保证明前推荐一个工具快速绕过抓包(原理也是通过pcap lib去分析网络包，tcpdump也会调用pcap lib)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/y123456yz/tcprstat">监控tcprstat</a>，从网络层抓包来对比两个并发下的RT：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#tcprstat -p 14822 -t 1 -n 0 -l mysqld217 -f &quot;%T\t\t%n\t\t%a\n&quot;</span><br><span class="line">timestamp        count        avg</span><br><span class="line">1683785023        50743        626</span><br><span class="line">1683785024        120004        100</span><br><span class="line">1683785025        120051        103</span><br><span class="line">1683785026        120042        102</span><br><span class="line">1683785027        120031        103</span><br><span class="line">1683785028        120034        104</span><br><span class="line">1683785029        120034        104</span><br><span class="line">1683785030         55209        103    ---以上是2000并发</span><br><span class="line">1683785038        0        0</span><br><span class="line">1683785039        0        0</span><br><span class="line">1683785040         55224        614    ---以下是1000并发</span><br><span class="line">1683785041        119998        104</span><br><span class="line">1683785042        120039        105</span><br><span class="line">1683785043        120039        105</span><br><span class="line">1683785044        120026        107</span><br><span class="line">1683785045        120039        108</span><br><span class="line">1683785046        120047        108</span><br><span class="line">1683785047        120037        108</span><br><span class="line">1683785048        120032        108</span><br><span class="line">1683785049        120041        108</span><br></pre></td></tr></table></figure>

<p>也就是网卡层面<strong>确认了压不上去瓶颈不在MySQL</strong> 上，加并发后网卡的RT没变(网卡RT包含MySQLD RT)，因为ping RTT 在1000和2000并发也没有差异，推测交换机不是瓶颈，大概率出网卡的虚拟层面</p>
<p>在客户端的机器上抓包，上面我们说过了1000并发的RT是8.33毫秒：</p>
<p><img src="/images/951413iMgBlog/image-20230511141508811.png" alt="image-20230511141508811"></p>
<p>注意上图，我把RT排序了，明显看到5ms到17ms 中间没有这个RT范围的包，但是有很多25ms的RT，平均下来确实是8.33毫秒，留下一个疑问：RT分布不符合正态，而且中间有很大一段范围镂空了！这是不应该的。</p>
<p>同样我们再到MySQLD 所在机器抓包分析(注：正常路径先抓MySQLD上的包就行了)：</p>
<p><img src="/images/951413iMgBlog/image-20230511141925557.png" alt="image-20230511141925557"></p>
<p>同样是对RT 排序了，但是慢的RT都是对端发慢了(注意最右边的select， MySQL相应是 response)，同样对这个抓包求平均时间就是tcprstat 看到的103微秒，也就是0.1毫秒。如下图红框是请求，请求的间隔是11毫米，绿框是响应，响应的间隔都是0.2ms不到</p>
<p><img src="/images/951413iMgBlog/image-20230513084610300.png" alt="image-20230513084610300"></p>
<p>同样在2000并发时也对MySQLD所在网卡抓包对比，response 的RT 没有变化，从这里可以看出瓶颈点在sysbench 和 MySQLD 的网卡之间的链路上，似乎有限流、管控</p>
<img src="/images/951413iMgBlog/image-20230512084446715.png" alt="image-20230512084446715" style="zoom:35%;" />

<h3 id="快速验证"><a href="#快速验证" class="headerlink" title="快速验证"></a>快速验证</h3><p>到这里我们已经找到了有力的证据，RT是在离开MySQLD网卡后增加上去的，先验证下走走本机127.0.0.1快速压一把，让sysbench 跑在0-7 core上，这时可以看到MySQL跑满了CPU，下图左边1-8核是压力进程，右边65-88是业务进程，TPS：239969.91 1000并发 RT 4.16</p>
<p>htop状态：</p>
<p><img src="/images/951413iMgBlog/image-20230511125346066.png" alt="image-20230511125346066"></p>
<p>各CPU 详细分析：</p>
<ul>
<li>us MySQL解析SQL、处理查询</li>
<li>si  网络软中断</li>
<li>sy OS 的sys API 消耗，一般用户进程会调用系统 API, 比如读写文件、分配内存、网络访问等</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">//sysbench</span><br><span class="line">top - 13:44:27 up 160 days, 18:04,  3 users,  load average: 792.17, 619.09, 311.58</span><br><span class="line">Tasks: 1073 total,   1 running, 500 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu0  : 14.0 us, 29.1 sy,  0.0 ni, 33.3 id,  0.0 wa,  0.0 hi, 23.5 si,  0.0 st</span><br><span class="line">%Cpu1  : 12.5 us, 33.0 sy,  0.0 ni, 33.7 id,  0.0 wa,  0.0 hi, 20.8 si,  0.0 st</span><br><span class="line">%Cpu2  : 11.2 us, 32.7 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 21.9 si,  0.0 st</span><br><span class="line">%Cpu3  : 13.4 us, 31.2 sy,  0.0 ni, 34.4 id,  0.0 wa,  0.0 hi, 21.0 si,  0.0 st</span><br><span class="line">%Cpu4  : 12.1 us, 31.3 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 22.4 si,  0.0 st</span><br><span class="line">%Cpu5  : 10.5 us, 31.8 sy,  0.0 ni, 33.6 id,  0.0 wa,  0.0 hi, 24.1 si,  0.0 st</span><br><span class="line">%Cpu6  : 12.9 us, 31.3 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 21.6 si,  0.0 st</span><br><span class="line">%Cpu7  : 12.3 us, 31.4 sy,  0.0 ni, 34.3 id,  0.0 wa,  0.0 hi, 22.0 si,  0.0 st</span><br><span class="line">%Cpu8  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line"></span><br><span class="line">//MySQLD</span><br><span class="line">Tasks: 1073 total,   1 running, 505 sleeping,   0 stopped,   1 zombie</span><br><span class="line">%Node1 : 22.6 us, 10.1 sy,  0.0 ni, 62.4 id,  0.0 wa,  0.0 hi,  4.8 si,  0.0 st</span><br><span class="line">%Cpu64 : 57.9 us, 29.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.9 si,  0.0 st</span><br><span class="line">%Cpu65 : 60.3 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.6 si,  0.0 st</span><br><span class="line">%Cpu66 : 57.6 us, 28.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.2 si,  0.0 st</span><br><span class="line">%Cpu67 : 60.9 us, 25.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.6 si,  0.0 st</span><br><span class="line">%Cpu68 : 59.9 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.9 si,  0.0 st</span><br><span class="line">%Cpu69 : 57.9 us, 27.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.6 si,  0.0 st</span><br><span class="line">%Cpu70 : 61.3 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</span><br><span class="line">%Cpu71 : 64.0 us, 23.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.5 si,  0.0 st</span><br><span class="line">%Cpu72 : 61.3 us, 26.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.9 si,  0.0 st</span><br><span class="line">%Cpu73 : 63.0 us, 22.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.2 si,  0.0 st</span><br><span class="line">%Cpu74 : 61.4 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.2 si,  0.0 st</span><br><span class="line">%Cpu75 : 63.9 us, 26.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  9.6 si,  0.0 st</span><br><span class="line">%Cpu76 : 61.3 us, 27.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.6 si,  0.0 st</span><br><span class="line">%Cpu77 : 55.0 us, 30.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.6 si,  0.0 st</span><br><span class="line">%Cpu78 : 60.9 us, 26.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.3 si,  0.0 st</span><br><span class="line">%Cpu79 : 58.4 us, 26.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.9 si,  0.0 st</span><br><span class="line">%Cpu80 : 58.7 us, 29.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.2 si,  0.0 st</span><br><span class="line">%Cpu81 : 62.6 us, 27.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 10.3 si,  0.0 st</span><br><span class="line">%Cpu82 : 61.9 us, 25.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</span><br><span class="line">%Cpu83 : 58.7 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.9 si,  0.0 st</span><br><span class="line">%Cpu84 : 59.4 us, 27.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.9 si,  0.0 st</span><br><span class="line">%Cpu85 : 58.9 us, 28.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</span><br><span class="line">%Cpu86 : 58.4 us, 28.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.2 si,  0.0 st</span><br><span class="line">%Cpu87 : 61.1 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.6 si,  0.0 st</span><br></pre></td></tr></table></figure>

<p>就以上sysbench VS  MySQLD 的CPU 消耗来看，因为sysbench 处理逻辑简单，就是发SQL给MySQLD，所以 sysbench自身US很少，大部分都是调用OS的网络操作，而MySQLD有 60% CPU用于US，也就是自身业务逻辑，MySQLD收到SQL要做SQL解析，要去查找数据，这些都是用户态消耗，找到数据后走网络发给Sysbench，这部分是sy </p>
<p>到这里可以拿着证据去VIP通道(土豪+专业的客户得有VIP通道)找做网络管控的了，不会再有撕逼和甩锅</p>
<h3 id="sysbench-结果不是正态分布"><a href="#sysbench-结果不是正态分布" class="headerlink" title="sysbench 结果不是正态分布"></a>sysbench 结果不是正态分布</h3><p>把所有请求RT 分布进行图形化，此时平均 RT 8.33，理论上是一个正态分布，下图是有限速时：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"> 3.615 |                                         2177</span><br><span class="line"> 3.681 |**                                       14738</span><br><span class="line"> 3.748 |*******                                  55690</span><br><span class="line"> 3.816 |*************                            109713</span><br><span class="line"> 3.885 |***************                          121830</span><br><span class="line"> 3.956 |***************                          124851</span><br><span class="line"> 4.028 |*******************                      154927</span><br><span class="line"> 4.101 |***********************                  188826</span><br><span class="line"> 4.176 |***************************              226206</span><br><span class="line"> 4.252 |************************************     302617</span><br><span class="line"> 4.329 |**************************************** 333310  //这里以4.329为中心符合正态</span><br><span class="line"> 4.407 |*******************************          257048</span><br><span class="line"> 4.487 |********************                     163100</span><br><span class="line"> 4.569 |************                             101785</span><br><span class="line"> 4.652 |********                                 63871</span><br><span class="line"> 4.737 |*****                                    43998</span><br><span class="line"> 4.823 |*****                                    40854</span><br><span class="line"> 4.910 |*****                                    42189</span><br><span class="line"> 4.999 |*****                                    41182</span><br><span class="line"> 5.090 |****                                     35652</span><br><span class="line"> 5.183 |****                                     30343</span><br><span class="line"> 5.277 |***                                      28573</span><br><span class="line"> 5.373 |***                                      24763</span><br><span class="line"> 5.470 |***                                      22210</span><br><span class="line"> 5.570 |***                                      21808</span><br><span class="line"> 5.671 |***                                      25606</span><br><span class="line"> 5.774 |***                                      26994</span><br><span class="line"> 5.879 |***                                      24672</span><br><span class="line"> 5.986 |***                                      22087</span><br><span class="line"> 6.095 |**                                       18466</span><br><span class="line"> 6.205 |**                                       14822</span><br><span class="line"> 6.318 |**                                       13688</span><br><span class="line"> 6.433 |**                                       15381</span><br><span class="line"> 6.550 |**                                       13573</span><br><span class="line"> 6.669 |*                                        11325</span><br><span class="line"> 6.790 |*                                        9442</span><br><span class="line"> 6.913 |*                                        7412</span><br><span class="line"> 省略一大堆</span><br><span class="line">20.736 |*                                        11407</span><br><span class="line">21.112 |*                                        9755</span><br><span class="line">21.496 |*                                        8957</span><br><span class="line">21.886 |*                                        9434</span><br><span class="line">22.284 |*                                        9715</span><br><span class="line">22.689 |**                                       12774</span><br><span class="line">23.101 |**                                       17000</span><br><span class="line">23.521 |***                                      22937</span><br><span class="line">23.948 |*****                                    40401</span><br><span class="line">24.384 |********                                 65370</span><br><span class="line">24.827 |**********                               82186</span><br><span class="line">25.278 |**********                               85505</span><br><span class="line">25.737 |***********                              94347 //以25.7附近大概又是一个新正态</span><br><span class="line">26.205 |**********                               82958</span><br><span class="line">26.681 |****                                     30760</span><br><span class="line">27.165 |                                         2222</span><br><span class="line">27.659 |                                         69</span><br><span class="line">28.162 |                                         16</span><br><span class="line">28.673 |                                         15</span><br><span class="line">29.194 |                                         20</span><br><span class="line">29.725 |                                         17       </span><br></pre></td></tr></table></figure>

<p>去掉限速后平均 RT 3.26(比下图中大概的中位数2.71大了不少)  完美正态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">1.857 |**                                       19894</span><br><span class="line">1.891 |***                                      23569</span><br><span class="line">1.925 |***                                      27912</span><br><span class="line">1.960 |****                                     33720</span><br><span class="line">1.996 |****                                     39892</span><br><span class="line">2.032 |*****                                    48289</span><br><span class="line">2.069 |******                                   57649</span><br><span class="line">2.106 |********                                 69437</span><br><span class="line">2.145 |*********                                83611</span><br><span class="line">2.184 |***********                              99507</span><br><span class="line">2.223 |*************                            119275</span><br><span class="line">2.264 |****************                         141013</span><br><span class="line">2.305 |*******************                      165450</span><br><span class="line">2.347 |**********************                   191778</span><br><span class="line">2.389 |*************************                219706</span><br><span class="line">2.433 |****************************             250885</span><br><span class="line">2.477 |*******************************          278379</span><br><span class="line">2.522 |**********************************       303931</span><br><span class="line">2.568 |*************************************    325777</span><br><span class="line">2.615 |***************************************  342948</span><br><span class="line">2.662 |**************************************** 354029</span><br><span class="line">2.710 |**************************************** 356295</span><br><span class="line">2.760 |**************************************** 353068</span><br><span class="line">2.810 |**************************************   341345</span><br><span class="line">2.861 |************************************     324600</span><br><span class="line">2.913 |**********************************       303525</span><br><span class="line">2.966 |*******************************          280221</span><br><span class="line">3.020 |*****************************            255042</span><br><span class="line">3.075 |**************************               230861</span><br><span class="line">3.130 |***********************                  206909</span><br><span class="line">3.187 |*********************                    184616</span><br><span class="line">3.245 |*******************                      164903</span><br><span class="line">3.304 |****************                         146199</span><br><span class="line">3.364 |***************                          131427</span><br><span class="line">3.425 |*************                            117059</span><br><span class="line">3.488 |************                             104954</span><br><span class="line">3.551 |***********                              94404</span><br><span class="line">3.615 |*********                                83739</span><br><span class="line">3.681 |********                                 75705</span><br><span class="line">3.748 |********                                 67944</span><br><span class="line">3.816 |*******                                  60727</span><br><span class="line">3.885 |******                                   53757</span><br><span class="line">3.956 |*****                                    47053</span><br><span class="line">4.028 |*****                                    42130</span><br><span class="line">4.101 |****                                     38069</span><br><span class="line">4.176 |****                                     33666</span><br><span class="line">4.252 |***                                      30048</span><br><span class="line">4.329 |***                                      26923</span><br><span class="line">4.407 |***                                      23886</span><br><span class="line">4.487 |**                                       21615</span><br><span class="line">4.569 |**                                       19897</span><br><span class="line">4.652 |**                                       18458</span><br><span class="line">4.737 |**                                       17729</span><br><span class="line">4.823 |**                                       17041</span><br><span class="line">4.910 |**                                       16011</span><br><span class="line">4.999 |**                                       16099</span><br><span class="line">5.090 |**                                       16090</span><br><span class="line">5.183 |**                                       16393</span><br><span class="line">5.277 |**                                       16729</span><br><span class="line">5.373 |**                                       17412</span><br></pre></td></tr></table></figure>

<h2 id="用其他网络业务验证"><a href="#用其他网络业务验证" class="headerlink" title="用其他网络业务验证"></a>用其他网络业务验证</h2><p>先测试一下网络下载时的ping：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">--无流量</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=11 ttl=64 time=0.075 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=12 ttl=64 time=0.080 ms</span><br><span class="line">--从有网络限速的机器下载，带宽100MB</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=13 ttl=64 time=0.738 ms </span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=14 ttl=64 time=0.873 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=15 ttl=64 time=0.993 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=16 ttl=64 time=0.859 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=17 ttl=64 time=0.892 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=18 ttl=64 time=0.972 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=19 ttl=64 time=1.05 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=20 ttl=64 time=0.973 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=21 ttl=64 time=0.997 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=22 ttl=64 time=0.915 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=23 ttl=64 time=0.892 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=24 ttl=64 time=0.960 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=25 ttl=64 time=1.05 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=26 ttl=64 time=0.089 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=27 ttl=64 time=0.097 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=28 ttl=64 time=0.081 ms </span><br><span class="line">--从没有网络限速的机器下载，带宽1000MB</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=29 ttl=64 time=0.078 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=30 ttl=64 time=0.077 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=31 ttl=64 time=0.073 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=32 ttl=64 time=0.072 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=33 ttl=64 time=0.079 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=34 ttl=64 time=0.074 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=35 ttl=64 time=0.080 ms</span><br><span class="line">64 bytes from 172.16.0.205: icmp_seq=36 ttl=64 time=0.077 ms</span><br></pre></td></tr></table></figure>

<p>有限速方向，尝试了BBR和cubic 拥塞算法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#tcpperf -c 172.16.0.205 -t 100</span><br><span class="line">Connected mysqld217:51254 -&gt; 172.16.0.205:2009, congestion control: cubic</span><br><span class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</span><br><span class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki  85.0Ki    2048Mi     0   0  65.2Mi  427us/213</span><br><span class="line">  1.029s    122MB/s    975Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/8</span><br><span class="line">  2.005s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/10</span><br><span class="line">  3.010s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/17</span><br><span class="line">  4.016s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/13</span><br><span class="line">  5.022s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/14</span><br><span class="line">  6.028s    105MB/s    842Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/17</span><br><span class="line">  7.003s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/15</span><br><span class="line">  8.009s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/13</span><br><span class="line"> #tcpperf -c 172.16.0.205 -t 100</span><br><span class="line">Connected mysqld217:51932 -&gt; 172.16.0.205:2009, congestion control: bbr</span><br><span class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</span><br><span class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki   128Ki    2048Mi     0   0  98.0Mi  406us/203</span><br><span class="line">  1.011s    120MB/s    957Mbps   271Ki  2281Ki  10.4Mi     560Ki  2244   0   108Mi  2427us/11</span><br><span class="line">  2.033s    104MB/s    831Mbps   271Ki  2281Ki  10.4Mi     560Ki  1056   0   109Mi  2417us/18</span><br><span class="line">  3.021s    104MB/s    830Mbps   274Ki  2281Ki  10.4Mi     560Ki  1056   0   109Mi  2428us/18</span><br><span class="line">  4.014s    103MB/s    827Mbps   271Ki  2281Ki  10.4Mi     560Ki  1452   0   108Mi  2423us/19</span><br><span class="line">  5.031s    104MB/s    835Mbps   274Ki  2281Ki  10.4Mi     560Ki   660   0  80.2Mi  2435us/22</span><br><span class="line">  6.033s    102MB/s    818Mbps   271Ki  2272Ki  10.4Mi     560Ki  2112   0   109Mi  2426us/17</span><br><span class="line">  7.030s    103MB/s    823Mbps   274Ki  2281Ki  10.4Mi     560Ki  1716   0   117Mi  2430us/18</span><br><span class="line">  8.023s    103MB/s    826Mbps   274Ki  2281Ki  10.4Mi     560Ki  1452   0   109Mi  2428us/20</span><br><span class="line">  9.016s    103MB/s    827Mbps   271Ki  2281Ki  10.4Mi     560Ki  1452   0   108Mi  2423us/15   </span><br></pre></td></tr></table></figure>

<p>跑tcpperf触发限速时的监控(上下两个窗口是同一台机器)，红色是丢包率挺高的，绿色丢包就没了，应该是拥塞算法和限速管控达成了平衡</p>
<p><img src="/images/951413iMgBlog/image-20230511215940306.png" alt="image-20230511215940306"></p>
<p>反过来限速被我去掉了(限速可以进出双向单独控制)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#tcpperf -c mysqld217 -t 1000</span><br><span class="line">Connected 172.16.0.205:32186 -&gt; mysqld217:2009, congestion control: bbr</span><br><span class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</span><br><span class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki   128Ki    2048Mi     0   0   100Mi  397us/198</span><br><span class="line">  1.001s   1107MB/s   8859Mbps   471Ki   985Ki  4641Ki     277Ki     0   0  1083Mi  390us/22</span><br><span class="line">  2.001s   1103MB/s   8823Mbps   465Ki   985Ki  4641Ki     277Ki     0   0  1089Mi  393us/16</span><br><span class="line">  3.000s   1111MB/s   8892Mbps   465Ki   985Ki  4641Ki     277Ki     0   0  1072Mi  403us/25</span><br><span class="line">  4.000s   1099MB/s   8789Mbps   459Ki   985Ki  4794Ki     277Ki     0   0   799Mi  399us/18</span><br><span class="line">  5.001s   1098MB/s   8786Mbps   459Ki   985Ki  4794Ki     277Ki     0   0  1066Mi  387us/12</span><br><span class="line">  6.000s   1100MB/s   8799Mbps   462Ki   974Ki  4794Ki     277Ki     0   0  1069Mi  399us/16</span><br><span class="line">  7.001s   1135MB/s   9078Mbps   453Ki   985Ki  4794Ki     277Ki     0   0  1059Mi  377us/19</span><br></pre></td></tr></table></figure>

<p>查看限速配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;txcmbps:844.000, txckpps:120.000&#125;</span><br><span class="line"></span><br><span class="line">//限速解释</span><br><span class="line">0-31 我猜这是网卡队列(可以修改);</span><br><span class="line">txcmbps:844.000 105.5MB/s     每秒带宽105.5MB</span><br><span class="line">txckpps:120.000 120K packet/s 每秒12万网络包</span><br></pre></td></tr></table></figure>

<p>sysbench(主键查询-小包) 12万QPS 正好命中 txckpps:120，tcpperf (大包)稳定的105MB带宽命中txcmbps:844</p>
<p>去掉后长这样：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#ovsctl -n set_out_pps -v -1  //把pps限制为-1==不限制</span><br><span class="line">#ovsctl set_tx -p &#123;&#125; -r -1;   //带宽不限制</span><br><span class="line"></span><br><span class="line">&#123;vport:  2 &#123;map:  0, prio:L, weight:   0&#125;meter: &#123;-&#125;queue: [  0- 31L]&#125;</span><br></pre></td></tr></table></figure>

<p>对这块网络管控感兴趣可以去了解一下 ovs 这个开源项目(open virtual switch)</p>
<h3 id="去掉网卡限速后的结果"><a href="#去掉网卡限速后的结果" class="headerlink" title="去掉网卡限速后的结果"></a>去掉网卡限速后的结果</h3><p>实际结构如下：</p>
<p><img src="/images/951413iMgBlog/image-20230513132101185.png" alt="image-20230513132101185"></p>
<p>放开所有网络控制后，1000并发压力 30万QPS，RT 3.28，此时从sysbench 以及空闲机器ping MySQLD机器的 RTT和没压力基本一致</p>
<p><img src="/images/951413iMgBlog/image-20230512090205685.png" alt="image-20230512090205685"></p>
<p>top状态：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">%Node1 : 23.4 us, 12.3 sy,  0.0 ni, 61.4 id,  0.0 wa,  0.0 hi,  3.0 si,  0.0 st</span><br><span class="line">%Cpu64 : 63.2 us, 36.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu65 : 44.4 us, 21.9 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 33.8 si,  0.0 st</span><br><span class="line">%Cpu66 : 66.6 us, 33.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu67 : 63.4 us, 36.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu68 : 64.2 us, 35.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu69 : 64.9 us, 35.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu70 : 66.6 us, 33.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu71 : 65.3 us, 34.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu72 : 67.7 us, 32.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu73 : 63.6 us, 36.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu74 : 66.7 us, 33.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu75 : 42.4 us, 19.9 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 37.7 si,  0.0 st</span><br><span class="line">%Cpu76 : 63.9 us, 36.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu77 : 67.0 us, 33.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu78 : 68.3 us, 31.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu79 : 64.9 us, 35.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu80 : 65.2 us, 34.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu81 : 44.4 us, 21.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 34.1 si,  0.0 st</span><br><span class="line">%Cpu82 : 63.9 us, 36.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu83 : 44.2 us, 23.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 32.3 si,  0.0 st</span><br><span class="line">%Cpu84 : 65.7 us, 34.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu85 : 68.3 us, 31.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu86 : 67.5 us, 32.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu87 : 62.4 us, 37.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu88 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/image-20230512092713141.png" alt="image-20230512092713141"></p>
<p>小思考：</p>
<blockquote>
<p>我们中间尝试走本机127.0.0.1 压测时QPS 是24万，比跨机器压的 30万打了8折，想想为什么？网络延时消耗完全没影响？</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>简单可复制的证明办法：抓包，快速撕逼和分析</p>
<p>肯定有很多人想到：内存、磁盘、线程池、队列、网络等等原因，但是这些所有原因有一个共同的爹：RT，所有这些影响因素最后体现出来就是RT 高了，你CPU资源不够、内存慢最后总表现就是在客户端看来你的 RT 太高。</p>
<p>所以我们去掉这些复杂因素先在MySQLD所在EC2 的网卡上抓一个包看看RT，再对比一下1000&#x2F;2000并发时抓包看到的 RT 有没有升高，如果有升高说明问题在MySQLD这端(含OS、MySQLD的问题)，如果 RT 不变那么问题不在MySQLD这端，并且从EC2网卡出去都是很快的，那么问题只能是在路上或者客户端的sysbench自己慢了。</p>
<p>这是我们星球里说的无招胜有招–抓包大法，扯皮过程中我还没见过几个不认网络抓包的，也有那么一两个扯上是不是网卡驱动有问题，我的代码不会有问题</p>
<p>两个限速条件：pps 120k(每秒最多12万网络包)，带宽 844mbps&#x3D;105.5MB&#x2F;s</p>
<p>Sysbench 查询都是小包，触发第一个条件，tcpperf触发第二个条件</p>
<p>ping ping神功失效了吗？也没有，我后来又测试了100、200并发，rtt 0.2ms和0.4ms，也就是说随着并发的增加rtt 增加到0.8ms后就不再增加了。上来1000并发已经到了天花板</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=159 ttl=64 time=0.226 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=160 ttl=64 time=0.334 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=161 ttl=64 time=0.336 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=162 ttl=64 time=0.213 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=163 ttl=64 time=0.104 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=164 ttl=64 time=0.096 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=165 ttl=64 time=0.101 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=166 ttl=64 time=0.116 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=167 ttl=64 time=0.104 ms--以上 100并发，QPS 119K</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=168 ttl=64 time=0.093 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=169 ttl=64 time=0.088 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=170 ttl=64 time=0.405 ms--以下 200并发，QPS 119K</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=171 ttl=64 time=0.419 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=172 ttl=64 time=0.386 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=173 ttl=64 time=0.474 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=174 ttl=64 time=0.462 ms</span><br><span class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=175 ttl=64 time=0.410 ms</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/06/08/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/08/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/" class="post-title-link" itemprop="url">Nginx reuseport 导致偶发性卡顿</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-08 17:30:03" itemprop="dateCreated datePublished" datetime="2023-06-08T17:30:03+08:00">2023-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Nginx-reuseport-导致偶发性卡顿"><a href="#Nginx-reuseport-导致偶发性卡顿" class="headerlink" title="Nginx reuseport 导致偶发性卡顿"></a>Nginx reuseport 导致偶发性卡顿</h1><p>by @橘橘球</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>从2018年开始，我们有个业务陆续接到反馈 Nginx 线上集群经常出现不响应或者偶发性的“超慢”请求。这种卡顿每天都有少量出现。而只有多个集群中的一个出现，其他压力更大的集群皆未出现。<br>业务结构比较简单：LVS-&gt;Nginx-&gt;后端，如图<br><img src="/images/951413iMgBlog/image-20230607103449616.png" alt="image-20230607103449616"></p>
<p>一些观察到的现象：</p>
<ul>
<li>出问题前不久升级 Nginx 配置，打开了 reuseport 功能</li>
<li>在压力大的后端（upstream）服务环境不容易出现，后端压力轻对应的Nginx卡顿概率更高</li>
<li>关闭 reuseport 后 问题少了很多</li>
<li>失败的请求响应时间都是 0ms（Nginx日志不靠谱了）</li>
<li>从 Nginx 日志上看，所有失败的健康检查请求都是0ms 的499 错误码（健康检查设置超时是2秒），但实际出问题的时候有5s-2分钟没有任何日志输出（Nginx卡了这么久）要么是Nginx卡住没去accept，要么是accept了没响应</li>
<li>所有超时来自同一个worker(一个Nginx服务一般按照机器核数开启多个worker)</li>
</ul>
<p>并且已知，卡顿的原因是打开 reuseport 后，新进来的请求可以由内核 hash 派发给一个 Nginx woker ，避免了锁争抢以及惊群。但如果网络条件足够好，压力足够低，Nginx worker 一直来不及读完 receive buffer 中的内容时，就无法切换并处理其他的 request，于是在新请求的客户端会观测不间断的卡顿，而压力大的后端由于网络传输慢，经常卡顿，Nginx worker 反而有时间能处理别的请求。在调小 receive buffer 人为制造卡顿后该问题得以解决。</p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>由于所述场景比较复杂，缺乏直接证据，打算通过构造一个较简单的环境来复现这个问题，并且在这个过程中抓包、观测Nginx worker的具体行为，验证这个假设。</p>
<h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><h3 id="快连接和慢连接"><a href="#快连接和慢连接" class="headerlink" title="快连接和慢连接"></a>快连接和慢连接</h3><ul>
<li>快连接：通常是传输时间短、传输量小的连接，耗时通常是ms级别</li>
<li>慢连接：通常是传输时间长、传输量大的连接，可以维持传输状态一段时间（如30s, 1min）</li>
</ul>
<p>在本次场景复现过程中，这两种连接都是短连接，每次请求开始前都需要三次握手建立连接，结束后都需要四次挥手销毁连接</p>
<h3 id="Epoll"><a href="#Epoll" class="headerlink" title="Epoll"></a>Epoll</h3><p>Nginx使用了epoll模型，epoll 是多路复用的一种实现。在多路复用的场景下，一个task（process）会批量处理多个socket，哪个来了数据就去读那个。这就意味着要公平对待所有这些socket，不能阻塞在任何socket的”数据读”上，也就是说不能在阻塞模式下针对任何socket调用recv&#x2F;recvfrom。  </p>
<p>epoll 每次循环为O(1) 操作，循环前会得到一个就绪队列，其中包含所有已经准备好的 socket stream（有数据可读），不需要循环全部 socket stream 读取数据，在循环后会将被读取数据的 stream 重新放回睡眠队列。睡眠队列中的 socket stream 有数据可读时，再唤醒加入到 就绪队列中。</p>
<p>epoll 伪代码 （不包含唤醒、睡眠）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while(true) &#123;  </span><br><span class="line">    streamArr = getEpollReadyStream(); // 找到准备好的stream</span><br><span class="line">    for(Stream i: streamArr) &#123;         // 循环准备好的stream</span><br><span class="line">        doSomething();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="reuseport与惊群"><a href="#reuseport与惊群" class="headerlink" title="reuseport与惊群"></a>reuseport与惊群</h3><p>Nginx reuseport 选项解决惊群的问题：在 TCP 多进程&#x2F;线程场景中（B 图），服务端如果所有新连接只保存在一个 listen socket 的全连接队列中，那么多个进程&#x2F;线程去这个队列里获取（accept）新的连接，势必会出现多个进程&#x2F;线程对一个公共资源的争抢，争抢过程中，大量资源的损耗，也就会发生惊群现象。<br><img src="/images/951413iMgBlog/reuseport-explained.jpg" alt="img"><br>而开启reuseport后（C 图)，有多个 listener 共同 bind&#x2F;listen 相同的 IP&#x2F;PORT，也就是说每个进程&#x2F;线程有一个独立的 listener，相当于每个进程&#x2F;线程独享一个 listener 的全连接队列，新的连接请求由内核hash分配，不需要多个进程&#x2F;线程竞争某个公共资源，能充分利用多核，减少竞争的资源消耗，效率自然提高了。  </p>
<p>但同时也是由于这个分配机制，避免了上下文切换，在服务压力不大，网络情况足够好的情况下，进程&#x2F;线程更有可能专注于持续读取某个慢连接数据而忽视快连接建立的请求，从而造成快连接方卡顿。  </p>
<h2 id="复现过程"><a href="#复现过程" class="headerlink" title="复现过程"></a>复现过程</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ol>
<li>整体的架构是N个client-&gt;1个Nginx-&gt;N个server。因为卡顿原因和reuseport机制有关，和server数量无关，server数量设为任意数字都能复现，这里为了方便设成1。client数量设为2，为了将快连接和慢连接区分开便于抓包观测</li>
<li>用慢连接制造卡顿环境，用快连接观测卡顿。在快连接客户端进行观测和抓包</li>
<li>进程数量要足够少，使得同一个 worker 有几率分配到多个连接 <code>worker_processes 2</code></li>
<li>连接数目要足够多，慢连接数目&gt;&#x3D;进程数量，使得快连接在分配时，有一定概率分配到一个正在处理慢连接的worker上</li>
<li>reuseport: 这个配置要开启，卡顿现象才能观测到。<code>listen 8000 reuseport</code></li>
</ol>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">linux kernal version: 6.1  </span><br><span class="line">linux image: amazon/al2023-ami-2023.0.20230419.0-kernel-6.1-x86_64  </span><br><span class="line">instance type:  </span><br><span class="line">1X AWS t2.micro (1 vCPU, 1GiB RAM) – Nginx client(fast request)  </span><br><span class="line">3X AWS t3.micro (2 vCPU, 1GiB RAM) – Http server, Nginx server, Nginx client(slow request)  </span><br></pre></td></tr></table></figure>



<h3 id="复现操作"><a href="#复现操作" class="headerlink" title="复现操作"></a>复现操作</h3><ol>
<li>在server instance上放置一个 2GiB 大文件（0000000000000000.data）和一个 3MiB 小文件（server.pcap），并开启一个http server</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python -m http.server 8000</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>在Nginx instance上安装、配置好Nginx，并启动Nginx (注意要绑核！)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"># install</span><br><span class="line">sudo yum install nginx</span><br><span class="line"># config (/etc/nginx/nginx.conf)</span><br><span class="line">user nginx;</span><br><span class="line">worker_processes 2;</span><br><span class="line">error_log /var/log/nginx/error.log notice;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line"></span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &#x27;$remote_addr [$time_local] &quot;$request&quot; &#x27;</span><br><span class="line">                      &#x27;status=$status body_bytes_sent=$body_bytes_sent &#x27;</span><br><span class="line">                      &#x27;rt=$request_time uct=&quot;$upstream_connect_time&quot; uht=&quot;$upstream_header_time&quot; urt=&quot;$upstream_response_time&quot;&#x27;;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    keepalive_timeout   60;</span><br><span class="line">    types_hash_max_size 4096;</span><br><span class="line"></span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</span><br><span class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</span><br><span class="line">    # for more information.</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       8000 reuseport;</span><br><span class="line">        server_name  server1;</span><br><span class="line">        root         /usr/share/nginx/html;</span><br><span class="line"></span><br><span class="line">        # Load configuration files for the default server block.</span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line">        </span><br><span class="line">        location / &#123;</span><br><span class="line">        proxy_pass http://172.31.86.252:8000; # server ip</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">        location = /404.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># start nginx</span><br><span class="line">sudo taskset -c 0 nginx</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>启动慢连接client，开启4个下载进程并计时，测试脚本<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/script/get_big_file.sh">在此</a> </li>
<li>启动快连接client，开启1个下载进程并计时，抓包，测试脚本<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/script/get_small_file.sh">在此</a><br>需要注意的是此处使用了curl –max-time 1，意味着即使1s内文件没有下载完，也会自动终止。</li>
<li>进入Nginx instance观察access.log</li>
<li>关掉reuseport或者调小recv buffer大小，重试一次</li>
</ol>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>ip maping:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">172.31.86.252: http server</span><br><span class="line">172.31.89.152: nginx server</span><br><span class="line">172.31.91.109: 快连接 client</span><br><span class="line">172.31.92.10:  慢连接 client</span><br></pre></td></tr></table></figure>
<ol>
<li>快连接client端：下载同一个小文件的下载时长有快有慢，方差很大，完整日志<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/client-runtime.txt">在此</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[2023-05-31 08:27:32,127] runtime=1010</span><br><span class="line">[2023-05-31 08:27:33,140] runtime=1009</span><br><span class="line">[2023-05-31 08:27:34,152] runtime=38</span><br><span class="line">[2023-05-31 08:27:34,192] runtime=1011</span><br><span class="line">[2023-05-31 08:27:35,205] runtime=37</span><br><span class="line">[2023-05-31 08:27:35,245] runtime=1008</span><br><span class="line">[2023-05-31 08:27:36,256] runtime=57</span><br><span class="line">[2023-05-31 08:27:36,315] runtime=1011</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>快连接client：无论耗时长短，抓包结果都显示存在不同程度卡顿，抓包文件<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/nginx-case-client.pcap">在此</a>  耗时长的下载过程<br><img src="/images/951413iMgBlog/benchmark-pkg-cature1.png" alt="img"><br>耗时短的下载过程<br><img src="/images/951413iMgBlog/benchmark-pkg-cature2.png" alt="img"></p>
</li>
<li><p>Nginx access.log 存在大量未下载完的200请求，和少量499请求，且499请求的耗时为0，access.log文件<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/access.log.txt">在此</a><br>卡顿的日志建立连接时长（utc）在0.3-0.4ms左右，超过1s的就出现499了</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">172.31.91.109 [31/May/2023:08:27:49 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.790 uct=&quot;0.413&quot; uht=&quot;0.592&quot; urt=&quot;0.791&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:50 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.058 uct=&quot;0.000&quot; uht=&quot;0.002&quot; urt=&quot;0.053&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:51 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:51 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.763 uct=&quot;0.400&quot; uht=&quot;0.580&quot; urt=&quot;0.763&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:52 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.767 uct=&quot;0.480&quot; uht=&quot;0.768&quot; urt=&quot;0.768&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:53 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=580007 rt=0.773 uct=&quot;0.330&quot; uht=&quot;0.431&quot; urt=&quot;0.773&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:55 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</span><br><span class="line">172.31.91.109 [31/May/2023:08:27:55 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</span><br></pre></td></tr></table></figure>
<p>下载中途被关闭的连接（200），可以观测到Nginx server在客户端已经请求FIN并被ACK之后仍然在发送一些网络数据包，客户端非常迷惑，向Nginx发送RST<br><img src="/images/951413iMgBlog/benchmark-pkg-cature3.png" alt="img"><br>未和Nginx建立连接就被关闭的连接（499），可以观测到连接始终没有被建立，在等待1s后客户端超时，主动请求关连接<br><img src="/images/951413iMgBlog/benchmark-pkg-cature4.png" alt="img"></p>
<ol start="4">
<li>限制Nginx server所在的instance的recv buffer大小，重新进行实验，可以观测到仍然有少量停顿，但整体耗时好了很多，不再有长达1s的卡顿，也不再有RST，完整日志<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp1/">在此</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.tcp_rmem=&quot;40960 40960 40960&quot;</span><br></pre></td></tr></table></figure>
<p>client runtime log: 耗时稳定在50-100ms，比无慢连接、纯跑快连接时要大一倍（25-50ms）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[2023-06-05 06:13:22,791] runtime=120</span><br><span class="line">[2023-06-05 06:13:22,913] runtime=82</span><br><span class="line">[2023-06-05 06:13:22,997] runtime=54</span><br><span class="line">[2023-06-05 06:13:23,054] runtime=61</span><br><span class="line">[2023-06-05 06:13:23,118] runtime=109</span><br><span class="line">[2023-06-05 06:13:23,229] runtime=58</span><br><span class="line">[2023-06-05 06:13:23,290] runtime=55</span><br><span class="line">[2023-06-05 06:13:23,347] runtime=79</span><br><span class="line">[2023-06-05 06:13:23,429] runtime=65</span><br><span class="line">[2023-06-05 06:13:23,497] runtime=53</span><br></pre></td></tr></table></figure>
<p>client 抓包结果：<br><img src="/images/951413iMgBlog/exp1-pkg-cature1.png" alt="img"><br>Nginx access.log: 都发完了，而且发得很流畅，建立连接时间（utc)非常短</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">172.31.91.109 [05/Jun/2023:06:13:22 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.101 uct=&quot;0.001&quot; uht=&quot;0.004&quot; urt=&quot;0.101&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:22 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.064 uct=&quot;0.001&quot; uht=&quot;0.002&quot; urt=&quot;0.064&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.044 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.044&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.047 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.047&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.100 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.099&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.047 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.047&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.045 uct=&quot;0.001&quot; uht=&quot;0.002&quot; urt=&quot;0.045&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.066 uct=&quot;0.000&quot; uht=&quot;0.002&quot; urt=&quot;0.066&quot;</span><br></pre></td></tr></table></figure>
<p>对于慢连接大文件下载时长略有影响：46s (无限制) vs 53s (有限制)</p>
<ol start="5">
<li>关闭nginx reuseport</li>
</ol>
<p>卡顿依然大量存在，但大多以连接能够建立但是下载不完的形式（200）出现，499较少，并且存在惊群现象，完整日志<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp2/">在此</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 8000;</span><br></pre></td></tr></table></figure>
<p>client runtime log：存在卡顿，和benchmark没有区别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[2023-06-05 06:38:06,682] runtime=1008</span><br><span class="line">[2023-06-05 06:38:07,692] runtime=1008</span><br><span class="line">[2023-06-05 06:38:08,703] runtime=220</span><br><span class="line">[2023-06-05 06:38:08,926] runtime=112</span><br><span class="line">[2023-06-05 06:38:09,040] runtime=60</span><br><span class="line">[2023-06-05 06:38:09,103] runtime=865</span><br><span class="line">[2023-06-05 06:38:09,970] runtime=1009</span><br><span class="line">[2023-06-05 06:38:10,982] runtime=1008</span><br><span class="line">[2023-06-05 06:38:11,992] runtime=1009</span><br></pre></td></tr></table></figure>
<p>client抓包结果：存在卡顿，存在RST，和benchmark没有区别<br><img src="/images/951413iMgBlog/exp2-pkg-cature1.png" alt="img"><br><img src="/images/951413iMgBlog/exp2-pkg-cature2.png" alt="img"><br>access.log：卡顿的日志连接时间比benchmark略短，在0.2-0.3s左右，出现499的情况少了但是依然会有</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">172.31.91.109 [05/Jun/2023:06:38:02 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.844 uct=&quot;0.362&quot; uht=&quot;0.539&quot; urt=&quot;0.845&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:03 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.907 uct=&quot;0.334&quot; uht=&quot;0.476&quot; urt=&quot;0.906&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:04 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=543900 rt=0.836 uct=&quot;0.319&quot; uht=&quot;0.504&quot; urt=&quot;0.836&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:05 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.831 uct=&quot;0.161&quot; uht=&quot;0.480&quot; urt=&quot;0.830&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:06 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=552849 rt=0.820 uct=&quot;0.180&quot; uht=&quot;0.329&quot; urt=&quot;0.819&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:07 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.800 uct=&quot;0.122&quot; uht=&quot;0.462&quot; urt=&quot;0.800&quot;</span><br><span class="line">172.31.91.109 [05/Jun/2023:06:38:08 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=543900 rt=0.871 uct=&quot;0.251&quot; uht=&quot;0.380&quot; urt=&quot;0.871&quot;</span><br></pre></td></tr></table></figure>
<p>存在惊群现象，以下是Nginx worker进程的cpu使用率和上下文切换频率对比</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 每5s输出一次统计结果</span><br><span class="line">pidstat -w -u 5</span><br></pre></td></tr></table></figure>
<p>两者的cpu使用率和上下文切换频率差不多，但关闭reuseport后花在wait上的cpu时间明显增加（1.3-1.6% vs 2.8-2.9%），这就是惊群带来的性能损耗。原始文件：<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/pidstat.txt">开启reuseport</a>，<a target="_blank" rel="noopener" href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp2/pidstat.txt">关闭reuseport</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 开启reuseport</span><br><span class="line">Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</span><br><span class="line">Average:      992      2590    1.77    9.57    0.00    1.25   11.35     -  nginx</span><br><span class="line">Average:      992      2591    1.37    5.75    0.00    1.62    7.12     -  nginx</span><br><span class="line"></span><br><span class="line">Average:      UID       PID   cswch/s nvcswch/s  Command</span><br><span class="line">Average:      992      2590    179.18     49.64  nginx</span><br><span class="line">Average:      992      2591    342.51      9.87  nginx</span><br><span class="line"></span><br><span class="line"># 关闭reuseport</span><br><span class="line">Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</span><br><span class="line">Average:      992      2788    1.02    8.02    0.00    2.80    9.04     -  nginx</span><br><span class="line">Average:      992      2789    0.92    9.07    0.00    2.97    9.99     -  nginx</span><br><span class="line"></span><br><span class="line">Average:      UID       PID   cswch/s nvcswch/s  Command</span><br><span class="line">Average:      992      2788    159.06     28.68  nginx</span><br><span class="line">Average:      992      2789    250.26     22.93  nginx</span><br></pre></td></tr></table></figure>
<p>惊群对于慢连接大文件下载时长略有影响：46s (开reuseport) vs 53s (关reuseport)</p>
<ol start="6">
<li>其他的观察</li>
</ol>
<p>最初复现的场景是所有的instance都是t2.micro，但开2个慢连接进程时比较难复现，开4个进程又太容易触发限流，所以开始考虑用大一些又没那么容易限流的instance型号。考虑到aws是通过间歇掉包来限速的，慢连接进程数量并非越大越好，引发限速后反而会造成网络连接不畅，造成慢连接卡顿，使得快连接卡顿反而不容易观测。最后选择将慢连接全链路改成t3.micro，结果好复现多了.  </p>
<p>可以观察到有一些access.log上499的连接，各种计时也是0，这其实是因为计时也是通过worker进行的，只有进行epoll和上下文切换才会在日志上打入时间信息，worker如果一直不进行切换，那么计时就会失真，就会看到日志上计时也是0的现象。  </p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li>reuseport是Nginx避免惊群的优秀feature，应该开启</li>
<li>开启reuseport后如果网络情况非常好且后端服务压力不大，且存在大量慢连接时，会造成快连接卡顿，这是Nginx的worker-epoll架构带来的，原因是recv buffer一直读不完，NGINX采用的epoll ET 触发模式在这种情况下一直无法触发暂停导致worker无法响应其它请求</li>
<li>减小recv buffer通过人为制造卡顿，提供了epoll ET切换连接的条件，可以很大程度上缓解这个问题，同时带来的负面效果是有一定性能损耗。但卡顿无法根除，只能控制在可接受范围内</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://wenfh2020.com/2021/09/29/nginx-thundering-herd/">Nginx 惊群 – wenfh2020</a></li>
<li><a target="_blank" rel="noopener" href="https://wenfh2020.com/2021/10/12/thundering-herd-tcp-reuseport/">Nginx reuseport – wenfh2020</a></li>
<li><a target="_blank" rel="noopener" href="https://wenfh2020.com/2021/11/21/question-nginx-epoll-et/">Epoll – wenfh2020</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/my_captain/p/12667016.html">上下文切换的案例以及CPU使用率 – cnhkzyy</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/05/26/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8D%A1%E9%A1%BF%E9%87%8D%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/26/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8D%A1%E9%A1%BF%E9%87%8D%E7%8E%B0/" class="post-title-link" itemprop="url">MySQL线程池卡顿重现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-26 17:30:03" itemprop="dateCreated datePublished" datetime="2023-05-26T17:30:03+08:00">2023-05-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MySQL线程池卡顿重现"><a href="#MySQL线程池卡顿重现" class="headerlink" title="MySQL线程池卡顿重现"></a>MySQL线程池卡顿重现</h1><p>by @wych42 </p>
<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>为了激励大家多动手少空想，我在推特发起了白嫖我的<a target="_blank" rel="noopener" href="http://t.zsxq.com/0cz93XUPj">知识星球活动</a>：</p>
<blockquote>
<p>白嫖我星球的机会来了，总有人说贵、没有优惠券，这次直接来一个完全100%免费的机会，要求： 在MySQL的基础上重现某个线程池卡的现象，给出可复制的重现过程。就是因为某个线程池满了导致落到这个池里的查询一定都慢，否则都快。 不愿意出钱就动手吧</p>
</blockquote>
<p>参考现象：<a href="https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/">https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/</a></p>
<hr>
<p>感谢推友<a target="_blank" rel="noopener" href="https://twitter.com/wych42">王鱼翅</a>同学，以下是他的教科书级的细致重现，你复制粘贴就能和他一样重现了</p>
<h2 id="这个案例的重要性"><a href="#这个案例的重要性" class="headerlink" title="这个案例的重要性"></a>这个案例的重要性</h2><p>这个现象对应我们年度四大案例之一，如下图左下角</p>
<p><img src="/images/951413iMgBlog/image-20230517082106489.png" alt="image-20230517082106489"></p>
<p>重现后请思考：</p>
<ol>
<li>MySQL为什么要将多个线程分成小池子，小池子肯定容易局部资源不足</li>
<li>Nginx 一个连接固定在一个worker上，那么同样多个Worker也会有不均衡(有的worker很闲，有的很卡)</li>
<li>动手实验一下将多个小池子改成一个大线程池会怎么样</li>
<li>Java ConcurrentHashMap为什么能够高性能</li>
</ol>
<p>由 @wych42 重现 </p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>根据 <a target="_blank" rel="noopener" href="https://www.brendangregg.com/usemethod.html">USE</a> 分析套路。看到服务端执行快，但是整体RT慢的现象，大概率是中间哪个位置有排队。根据文章里的描述，原因是在thread pool group中出现了排队。</p>
<p>排队的主要原因是服务端拒绝创建新的thread（worker），导致新进来的SQL需要等待前面的执行完成。那么就需要重点分析thread(worker)的创建过程和约束条件。根据文章和文档的说明，重点在thread_pool_size, thread_pool_oversubscribe, thread_pool_max_threads, thread_pool_stall_limit这几个参数上。</p>
<p>跟据文档分析和实际执行结果，这几个参数在MySQL不同的发型版中的行为逻辑是不尽相同的。核心差异在对创建新worker的限制条件上，后面复现也会根据两个发型版的特点分别执行。</p>
<h2 id="mariadb"><a href="#mariadb" class="headerlink" title="mariadb"></a>mariadb</h2><p><a target="_blank" rel="noopener" href="https://mariadb.com/kb/en/thread-groups-in-the-unix-implementation-of-the-thread-pool/">文档</a></p>
<ul>
<li>通常情况下，新worker由listener worker创建</li>
<li>当timer worker检测到thread group 有stall时，可能会选择创建一个新的worker</li>
<li>worker的数量上限由thread_pool_max_threads限制</li>
<li>thread_pool_oversubscribe约束的是被额外创建出来的worker，在执行完任务后，最多能保留active状态的数量<blockquote>
<p>To clarify, the thread_pool_oversubscribe system variable does not play any part in the creation of new worker threads. The thread_pool_oversubscribe system variable is only used to determine how many worker threads should remain active in a thread group, once a thread group is already oversubscribed due to stalls.</p>
</blockquote>
</li>
</ul>
<h2 id="percona"><a href="#percona" class="headerlink" title="percona"></a>percona</h2><p><a target="_blank" rel="noopener" href="https://docs.percona.com/percona-server/8.0/performance/threadpool.html">文档</a></p>
<p>percona的行为更符合原文章里的说明：</p>
<ul>
<li>如果线程执行超过时间 thread_pool_stall_limit 的值，会被任务stalled，会创建一个新的线程执行排队的任务</li>
<li>thread_pool_oversubscribe 约束了每个thread group的线程数上限。</li>
</ul>
<h2 id="尝试复现"><a href="#尝试复现" class="headerlink" title="尝试复现"></a>尝试复现</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>并发向DB发起请求，观察客户端耗时，这些请求应当符合这些条件：</p>
<ul>
<li>可控的并发数量：以对比数据库服务端不同参数值的情况</li>
<li>有稳定的、相同的服务端执行耗时：以对比客户端在不同场景下的耗时</li>
<li>对服务端的硬件压力较小：避免因为并发不同时，因IO、CPU资源占用，影响服务端执行耗时</li>
</ul>
<p>综合考虑使用 <code>select sleep(2); </code>作为测试SQL。并发控制使用下面的golang代码实现。</p>
<p>再控制数据库服务端参数，运行同一个并发程序进行对比，mariadb和percona分析执行运行过程：</p>
<h2 id="复现执行"><a href="#复现执行" class="headerlink" title="复现执行"></a>复现执行</h2><h3 id="mariadb-1"><a href="#mariadb-1" class="headerlink" title="mariadb"></a>mariadb</h3><p>由上面分析可以，mariadb 中造成排队的约束是thread_pool_max_threads。</p>
<h4 id="执行方案"><a href="#执行方案" class="headerlink" title="执行方案"></a>执行方案</h4><ul>
<li>DB配置</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">| thread_pool_max_threads                 | 6               |</span><br><span class="line">| thread_pool_oversubscribe               | 1               |</span><br><span class="line">| thread_pool_size                        | 1               |</span><br><span class="line">| thread_pool_stall_limit                 | 500             |</span><br></pre></td></tr></table></figure>
<ul>
<li>执行SQL <code>select sleep(2)</code></li>
<li>执行并发：8</li>
</ul>
<p>预期结果： 6个SQL执行的客户端观察耗时为2s；2个SQL为4s</p>
<p>若调整 thread_pool_max_threads&#x3D;8，则8个SQL的执行客户端观察耗时都为2s</p>
<h4 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h4><ol>
<li>thread_pool_max_threads&#x3D;6;concurrency&#x3D;8</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">go run ./main.go</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_3</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_1</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_6</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_4</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_0</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_7</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_2</span><br><span class="line">2023/05/16 13:34:51 starting taskId:task_5</span><br><span class="line">2023/05/16 13:34:53 taskId:task_0 exec cost : 2.021305666s</span><br><span class="line">2023/05/16 13:34:53 taskId:task_6 exec cost : 2.021421041s</span><br><span class="line">2023/05/16 13:34:53 taskId:task_3 exec cost : 2.021258917s</span><br><span class="line">2023/05/16 13:34:53 taskId:task_2 exec cost : 2.021275458s</span><br><span class="line">2023/05/16 13:34:53 taskId:task_4 exec cost : 2.021254083s</span><br><span class="line">2023/05/16 13:34:53 taskId:task_7 exec cost : 2.02146725s</span><br><span class="line">2023/05/16 13:34:55 taskId:task_5 exec cost : 4.021478584s</span><br><span class="line">2023/05/16 13:34:55 taskId:task_1 exec cost : 4.02192s</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>thread_pool_max_threads&#x3D;8;concurrency&#x3D;8</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">go run ./main.go</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_7</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_3</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_1</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_5</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_0</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_6</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_4</span><br><span class="line">2023/05/16 13:36:17 starting taskId:task_2</span><br><span class="line">2023/05/16 13:36:19 taskId:task_6 exec cost : 2.045480167s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_2 exec cost : 2.045405667s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_7 exec cost : 2.045507334s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_1 exec cost : 2.04553075s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_3 exec cost : 2.04554975s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_0 exec cost : 2.045697375s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_4 exec cost : 2.046417375s</span><br><span class="line">2023/05/16 13:36:19 taskId:task_5 exec cost : 2.046453792s</span><br></pre></td></tr></table></figure>

<p>均符合预期。</p>
<h3 id="percona-1"><a href="#percona-1" class="headerlink" title="percona"></a>percona</h3><p>由上面分析可以，percona中造成排队的约束是thread_pool_oversubscribe。</p>
<h4 id="执行方案-1"><a href="#执行方案-1" class="headerlink" title="执行方案"></a>执行方案</h4><ul>
<li>DB配置: thread_pool_max_threads设置一个较大的值，以排除影响。</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">| thread_pool_max_threads                 | 1000               |</span><br><span class="line">| thread_pool_oversubscribe               | 1               |</span><br><span class="line">| thread_pool_size                        | 1               |</span><br><span class="line">| thread_pool_stall_limit                 | 500             |</span><br></pre></td></tr></table></figure>
<ul>
<li>执行SQL <code>select sleep(2)</code></li>
<li>执行并发：8</li>
</ul>
<p>预期结果： 客户端观察到的耗时分四个批次输出，每个批次2个SQL，耗时分别为2s,4s,6s,8s.</p>
<p>若调整 thread_pool_oversubscribe&#x3D;2，则三个批次输出，分别为3条SQL耗时均为2s，3条SQL耗时均为4s，2条SQL耗时均为6s</p>
<h4 id="执行结果-1"><a href="#执行结果-1" class="headerlink" title="执行结果"></a>执行结果</h4><ol>
<li>thread_pool_oversubscribe&#x3D;1,concurrency&#x3D;8</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">go run ./main.go</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_2</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_4</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_3</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_5</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_6</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_0</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_1</span><br><span class="line">2023/05/16 13:39:35 starting taskId:task_7</span><br><span class="line">2023/05/16 13:39:37 taskId:task_7 exec cost : 2.063547416s</span><br><span class="line">2023/05/16 13:39:37 taskId:task_0 exec cost : 2.064091541s</span><br><span class="line">2023/05/16 13:39:39 taskId:task_5 exec cost : 4.06672125s</span><br><span class="line">2023/05/16 13:39:39 taskId:task_6 exec cost : 4.066822583s</span><br><span class="line">2023/05/16 13:39:41 taskId:task_3 exec cost : 6.067720292s</span><br><span class="line">2023/05/16 13:39:41 taskId:task_2 exec cost : 6.069995s</span><br><span class="line">2023/05/16 13:39:43 taskId:task_4 exec cost : 8.069296042s</span><br><span class="line">2023/05/16 13:39:43 taskId:task_1 exec cost : 8.071391709s</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>thread_pool_oversubscribe&#x3D;2,concurrency&#x3D;8</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">go run ./main.go</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_7</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_1</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_3</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_2</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_5</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_6</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_4</span><br><span class="line">2023/05/16 13:41:02 starting taskId:task_0</span><br><span class="line">2023/05/16 13:41:04 taskId:task_1 exec cost : 2.057093667s</span><br><span class="line">2023/05/16 13:41:04 taskId:task_3 exec cost : 2.057156334s</span><br><span class="line">2023/05/16 13:41:04 taskId:task_5 exec cost : 2.057170667s</span><br><span class="line">2023/05/16 13:41:06 taskId:task_6 exec cost : 4.066917041s</span><br><span class="line">2023/05/16 13:41:06 taskId:task_7 exec cost : 4.066944125s</span><br><span class="line">2023/05/16 13:41:06 taskId:task_2 exec cost : 4.066976875s</span><br><span class="line">2023/05/16 13:41:08 taskId:task_4 exec cost : 6.070653125s</span><br><span class="line">2023/05/16 13:41:08 taskId:task_0 exec cost : 6.070612083s</span><br></pre></td></tr></table></figure>

<p>均符合预期。</p>
<h3 id="real-world-模拟（percona）版本"><a href="#real-world-模拟（percona）版本" class="headerlink" title="real-world 模拟（percona）版本"></a>real-world 模拟（percona）版本</h3><p>现实场景中，很少会有大批量的2s在SQL在生产环境执行（限互联网业务)，上述的分析过程能否在真实场景中验证呢？尝试用一个执行200ms的SQL来模拟下：</p>
<ul>
<li>DB配置: thread_pool_max_threads设置一个较大的值，以排除影响。</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">| thread_pool_max_threads                 | 1000               |</span><br><span class="line">| thread_pool_oversubscribe               | 1               |</span><br><span class="line">| thread_pool_size                        | 1               |</span><br><span class="line">| thread_pool_stall_limit                 | 500             |</span><br></pre></td></tr></table></figure>
<ul>
<li>执行SQL <code>select sleep(0.2)</code></li>
<li>执行并发：10</li>
</ul>
<p>从执行结果中可以看到，只有第一条SQL按照预期的时间执行完成了。<br>从抓包结果中可以看到，所有SQL几乎是同时发出。观察最慢的一条SQL,但是从客户端发包到服务端响应包发出的耗时，与客户端观察到的耗时也能对应上。</p>
<p>可以验证上述分析过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2023/05/16 14:47:47 taskId:task_1 exec cost : 239.34925ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_9 exec cost : 239.560833ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_5 exec cost : 453.795084ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_3 exec cost : 458.0005ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_6 exec cost : 659.441541ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_8 exec cost : 659.660917ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_0 exec cost : 862.526375ms</span><br><span class="line">2023/05/16 14:47:47 taskId:task_7 exec cost : 864.450042ms</span><br><span class="line">2023/05/16 14:47:48 taskId:task_2 exec cost : 1.063766875s</span><br><span class="line">2023/05/16 14:47:48 taskId:task_4 exec cost : 1.066266041s</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/238557399-c92e2c4e-436f-4f89-ba87-48c49b5393ac.png" alt="send_sql"></p>
<p><img src="/images/951413iMgBlog/238557635-1209f057-0c3c-4cfd-9072-12bfc112b4c6.png" alt="response_delay"></p>
<h3 id="复现文章中部分线程池卡的现象"><a href="#复现文章中部分线程池卡的现象" class="headerlink" title="复现文章中部分线程池卡的现象"></a>复现文章中部分线程池卡的现象</h3><p>配置两个线程池，在其中一个线程池上,通过<code>select sleep()</code>较长时间模拟线程池被慢SQL或者大量任务堵塞的情况，具体配置方案如下：</p>
<ul>
<li>thread_pool_size&#x3D;2: 保留两个线程池，验证一个卡顿，一个不卡</li>
<li>thread_pool_oversubscribe&#x3D;1: 允许多创建一个线程，每个线程池中可以同时运行1+1&#x3D;2个线程</li>
<li>thread_pool_max_threads&#x3D;2: 每个线程池的线程数量上限，为thread_pool_oversubscribe的配置约束加一个硬限制，每个线程池中最多允许运行2个线程</li>
</ul>
<p>操作步骤如下:</p>
<ul>
<li>通过mysql client在终端发起链接，通过 <code>show processlist</code>语句获取到链接Id, 该链接会分配到 id%2 的线程池中。</li>
<li>用偶数id的链接验证卡顿线程池，用奇数id的链接验证不卡的线程池，链接情况如下:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">  show processlist;</span><br><span class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</span><br><span class="line">| Id  | User            | Host           | db   | Command | Time  | State                  | Info             | Time_ms  | Rows_sent | Rows_examined |</span><br><span class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</span><br><span class="line">|   5 | event_scheduler | localhost      | NULL | Daemon  | 23664 | Waiting on empty queue | NULL             | 23663650 |         0 |             0 |</span><br><span class="line">| 404 | root            | _gateway:51310 | NULL | Sleep   |  7256 |                        | NULL             |  7256057 |         1 |             1 |</span><br><span class="line">| 405 | root            | _gateway:48860 | NULL | Sleep   |  7295 |                        | NULL             |  7295342 |         1 |             1 |</span><br><span class="line">| 406 | root            | _gateway:41144 | NULL | Sleep   |  7254 |                        | NULL             |  7254236 |         1 |             1 |</span><br><span class="line">| 410 | root            | _gateway:46794 | NULL | Sleep   |  7196 |                        | NULL             |  7196042 |         1 |             1 |</span><br><span class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</span><br></pre></td></tr></table></figure>

<ul>
<li>在 id&#x3D;404, id&#x3D;406的链接上，执行 <code>select sleep(30)</code>，再到 id&#x3D;410 的链接上执行 <code>select 1</code>，预计 <code>select &#39;slow&#39;</code>会直接卡顿约30s再执行完成。</li>
<li>同时，在id&#x3D;405的链接上，反复执行 <code>select &#39;fast&#39;</code>,都可以很快执行完成。</li>
</ul>
<p>执行结果:</p>
<ul>
<li>id&#x3D;410 上的语句执行约25s返回结果（终端操作手速影响导致了5s误差）,语句执行时数据库实例输出报错日志，提示线程不足:<blockquote>
<p>2023-05-16T11:27:09.997916Z 406 [ERROR] [MY-000000] [Server] Threadpool could not create additional thread to handle queries, because the number of allowed threads was reached. Increasing ‘thread_pool_max_threads’ parameter can help in this situation.  If ‘admin_port’ parameter is set, you can still connect to the database with superuser account (it must be TCP connection using admin_port as TCP port) and troubleshoot the situation. A likely cause of pool blocks are clients that lock resources for long time. ‘show processlist’ or ‘show engine innodb status’ can give additional hints.</p>
</blockquote>
</li>
<li>id&#x3D;405链接上的执行都行快。可参考下面抓包截图。</li>
</ul>
<p>抓包结果:</p>
<p>id&#x3D;410 上的阻塞SQL,可以看到:</p>
<ol>
<li>三条语句在3s内接连发出,但是由于线程池阻塞， <code>select &#39;slow&#39;</code>原本应该很快返回结果，被卡住</li>
<li>在30s时，第一个<code>select sleep(30)</code>语句执行完成，空出的线程立刻执行了 <code>select &#39;slow&#39;</code>并返回结果<br><img src="/images/951413iMgBlog/238638548-c4161d72-b94c-43ef-b698-3acc1002eb43.png" alt="slow query"></li>
</ol>
<p>id&#x3D;405链接上的执行结果可以看到，每条语句执行都很快。<br><img src="/images/951413iMgBlog/238637635-323fca3b-edf1-4ae7-8d68-d9db9811c692.png" alt="fast query"></p>
<h1 id="参数合理值-已知参数的容量评估"><a href="#参数合理值-已知参数的容量评估" class="headerlink" title="参数合理值&#x2F;已知参数的容量评估"></a>参数合理值&#x2F;已知参数的容量评估</h1><p>percona 的默认配置中，thread_pool_size&#x3D;核心数，thread_pool_oversubscribe&#x3D;3.假设在一台 16core 的服务器上运行percona，默认配置下最多可以有 16*(1+3)&#x3D;64个worker同时接受请求。也就是最大可并行处理的SQL数量为 64 个。</p>
<p>假设同时有65个执行耗时为10ms的SQL到达服务端，理论上，会有一个进入排队。排查网络、解析等阶段，在客户端观察到的64个SQL执行耗时10ms，1个SQL执行耗时约20ms。这也会导致耗时监控中出现毛刺、耗时分布不符合正态分布。</p>
<p>反之，根据硬件配置、查询的量、耗时等特点，也可以推算合理的参数值。</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="过程回顾"><a href="#过程回顾" class="headerlink" title="过程回顾"></a>过程回顾</h2><h3 id="阶段一-确定原因"><a href="#阶段一-确定原因" class="headerlink" title="阶段一 确定原因"></a>阶段一 确定原因</h3><p>看到文章时，基本确认问题根源在执行线程(worker)不够，导致排队，出于以下几点分析:</p>
<ul>
<li>开头提到的 <a target="_blank" rel="noopener" href="https://www.brendangregg.com/usemethod.html">USE</a> 分析套路，结合排查过类似问题(非SQL)的经验</li>
<li>看到文章作者调大thread_pool_oversubscribe便解决问题, 结合文章中对该参数作用的文档引用，基本可以确定</li>
</ul>
<h3 id="阶段二-走上弯路"><a href="#阶段二-走上弯路" class="headerlink" title="阶段二 走上弯路"></a>阶段二 走上弯路</h3><p>尝试复现时，要先启动一个DB实例，便查询文档该参数如何在配置文件中配置，查了MySQL的文档，似乎只在enterprise版本中才有该配置项，便转头去看mariadb的配置说明(这一步给走弯路埋下了伏笔)。</p>
<p>用docker在本地启动了mariadb实例(thread_pool_size&#x3D;2 thread_pool_oversubscribe&#x3D;1)</p>
<p>先尝试用 <code>select sleep(30)</code> 模拟阻塞，用 sysbench 模拟正常流量，结果失败：</p>
<ol>
<li>正常流量中有慢的，但是整体还符合正态分布，没有出现都卡的情况。</li>
<li>加大了  <code>select sleep(30)</code> 查询的并发量，现象同上。</li>
</ol>
<p>又翻阅了一些文档，看到DB在调度时，对不同类型的SQL调度优先级会有所区别，类似sleep这种啥也不干的SQL，会不会被降低调度优先级，才导致了没有复现呢？(走上了弯路)</p>
<p>尝试人工制造慢查询:</p>
<ol>
<li>用 sysbench 制造百万量级的表</li>
<li>执行 offset limit 的排序查询，并且不走索引</li>
</ol>
<p>复现结果仍不满意：</p>
<ol>
<li>整体耗时上升了，出现几笔长尾的耗时特别长的请求</li>
<li>但是整体仍然符合正态分布</li>
</ol>
<p>此时分析了下，整体耗时上升是人工制造的慢查询，占用了过多IO和CPU资源，影响了sysbench SQL执行的效率。</p>
<h3 id="阶段三-柳岸花明"><a href="#阶段三-柳岸花明" class="headerlink" title="阶段三 柳岸花明"></a>阶段三 柳岸花明</h3><p>回头又仔细看了下 mariadb关于线程池的<a target="_blank" rel="noopener" href="https://mariadb.com/kb/en/thread-groups-in-the-unix-implementation-of-the-thread-pool/">文档</a>，注意到文档中提到 thread_pool_oversubscribe 不决定同时有多少线程池被创建出来并执行任务，这个行为逻辑与文章中作者引用的并不相同。<br>又去查看了另一个MySQL发行版 percona 的文档，对该配置的行为描述与文章中的相符，基本就确定前面复现失败的原因了。</p>
<p>确定了前面提到的复现思路：用有稳定服务端执行耗时、并且不消耗大量硬件资源的SQL,用可控的并发进行模拟流量，到具体执行时：</p>
<ul>
<li>SQL就用 <code>select sleep(N)</code></li>
<li>可控的并发就用 golang写个小脚本(事后看直接在终端手动操作也是可以的,不过写个脚本也不费事就是了)</li>
</ul>
<h2 id="mariadb-启动命令和配置"><a href="#mariadb-启动命令和配置" class="headerlink" title="mariadb 启动命令和配置"></a>mariadb 启动命令和配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir mariadb</span><br><span class="line">cat &gt; mariadb/my.cnf &lt;&lt; EOF</span><br><span class="line">[mariadb]</span><br><span class="line">#thread pool</span><br><span class="line">thread_handling=pool-of-threads</span><br><span class="line">thread_pool_oversubscribe=1</span><br><span class="line">thread_pool_size=1</span><br><span class="line">thread_pool_max_threads=6</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">docker run --name mariadb -v ./mariadb:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=password -p3306:3306 mariadb:10.3</span><br></pre></td></tr></table></figure>


<h2 id="percona-启动命令和配置"><a href="#percona-启动命令和配置" class="headerlink" title="percona 启动命令和配置"></a>percona 启动命令和配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir percona</span><br><span class="line">cat &gt; percona/my.cnf &lt;&lt; EOF</span><br><span class="line">[mysqld]</span><br><span class="line">#thread pool</span><br><span class="line">thread_handling=pool-of-threads</span><br><span class="line">thread_pool_oversubscribe=1</span><br><span class="line">thread_pool_size=1</span><br><span class="line">thread_pool_max_threads=1000</span><br><span class="line">default_authentication_plugin=mysql_native_password</span><br><span class="line">EOF</span><br><span class="line">docker run --name percona -v ./percona:/etc/my.cnf.d -e MYSQL_ROOT_PASSWORD=123 -p33060:3306 percona:ps-8</span><br></pre></td></tr></table></figure>

<p>注：Mac M1启动percona时，需要在 docker run 后面添加 <code>--platform linux/x86_64</code> 参数。(percona 未提供arm架构的image)</p>
<h2 id="其他人的重现和分析"><a href="#其他人的重现和分析" class="headerlink" title="其他人的重现和分析"></a>其他人的重现和分析</h2><p><a target="_blank" rel="noopener" href="https://lotabout.me/2023/Verification-of-Percona-Thread-Pool-Behavior/">https://lotabout.me/2023/Verification-of-Percona-Thread-Pool-Behavior/</a>  从源代码debug上来分析</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">程序员案例星球介绍</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-10 17:30:03" itemprop="dateCreated datePublished" datetime="2023-05-10T17:30:03+08:00">2023-05-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/others/" itemprop="url" rel="index"><span itemprop="name">others</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="程序员案例星球介绍"><a href="#程序员案例星球介绍" class="headerlink" title="程序员案例星球介绍"></a>程序员案例星球介绍</h1><h2 id="【星球宗旨】"><a href="#【星球宗旨】" class="headerlink" title="【星球宗旨】"></a>【星球宗旨】</h2><p>平时一学就懂，但是实践总是不会，这是因为学习时<strong>缺少实践案例</strong>、场景导致学起来没有体感。我们总是习惯通过课程、教科书想要一次系统性地掌握很多东西，但最终什么都没掌握好。所以星球想通过案例打透一个或几个知识点，让你通过这几个知识点再去生长发芽形成体系</p>
<p><img src="/images/951413iMgBlog/image-20230510191422496.png" alt="image-20230510191422496"></p>
<h2 id="【关于案例】"><a href="#【关于案例】" class="headerlink" title="【关于案例】"></a>【关于案例】</h2><p>本星球剖析各种程序员疑难经典案例，搞清楚一个案例基本能横扫一个领域，其次在一个案例后再带3&#x2F;5个相关小案例可以帮你丰富场景，多角度理解。用做会来解决学不会的问题。 案例典型普适性强，代表基础组件基本原理等知识。分析手段尽量通用，分析过程一定要逻辑合理每个疑问都能回答清晰。 最终实现在新领域用旧知识旧工具解决疑难问题，无招胜有招</p>
<p><img src="/images/951413iMgBlog/image-20230510191512744.png" alt="image-20230510191512744"></p>
<h2 id="【关于星主】"><a href="#【关于星主】" class="headerlink" title="【关于星主】"></a>【关于星主】</h2><p>星主20多年的编程实践经历，疑难问题无数，擅长网络，性能，复杂系统的疑难问题分析，BAT背景，目前还在一线撕逼，作者的故事： <a href="https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/">https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/</a></p>
<h2 id="【星球成员成果】"><a href="#【星球成员成果】" class="headerlink" title="【星球成员成果】"></a>【星球成员成果】</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://yishenggong.com/2023/05/06/why-does-my-network-speed-drop-cn/">强龙难压地头蛇的故事</a> 这位星球成员刚大学毕业几个月，加入星球不到2个月</p>
</li>
<li><p>成员故事 <a target="_blank" rel="noopener" href="https://liarlee.site/2023/05/08/Linux/Linux_RDS%20QPS%20%E4%B8%8B%E9%99%8D%E5%BC%95%E5%8F%91%E7%9A%84%E7%BD%91%E7%BB%9C%E6%B5%81%E6%8E%A7%E5%88%86%E6%9E%90%E8%AE%B0%E5%BD%95/">tcp协议和 os 网络系统的分析我之前真是一句都说不出来， 这次确实完整的走了一遍网络的部分。</a> 这位星球成员目前是 AWS 中国区员工</p>
</li>
</ul>
<p>强龙难压地头蛇的故事也引起各路技术大佬纷纷下场教年轻人如何学习：<a target="_blank" rel="noopener" href="https://t.co/IBLCRzJem2">treeverse.app&#x2F;view&#x2F;RDzsOXjO</a></p>
<img src="/images/951413iMgBlog/image-20230510193840999.png" alt="image-20230510193840999" style="zoom: 33%;" />

<h2 id="【加入星球】"><a href="#【加入星球】" class="headerlink" title="【加入星球】"></a>【加入星球】</h2><p>知识星球：<a target="_blank" rel="noopener" href="https://t.zsxq.com/0cSFEUh2J">https://t.zsxq.com/0cSFEUh2J</a></p>
<img src="/images/951413iMgBlog/image-20230407232314969.png" alt="image-20230407232314969" style="zoom:50%;" />






      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
