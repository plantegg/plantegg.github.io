<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"plantegg.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/page/18/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="twitter @plantegg">
<meta property="article:tag" content="技术,编程,博客">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://plantegg.github.io/page/18/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/18/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>plantegg</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">plantegg</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twitter @plantegg</p>
  <div class="site-description" itemprop="description">java mysql tcp performance network docker Linux</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">185</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">274</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/" class="post-title-link" itemprop="url">就是要你懂TCP--半连接队列和全连接队列</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-07 17:30:03" itemprop="dateCreated datePublished" datetime="2017-06-07T17:30:03+08:00">2017-06-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TCP/" itemprop="url" rel="index"><span itemprop="name">TCP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="关于TCP-半连接队列和全连接队列"><a href="#关于TCP-半连接队列和全连接队列" class="headerlink" title="关于TCP 半连接队列和全连接队列"></a>关于TCP 半连接队列和全连接队列</h1><blockquote>
<p>最近碰到一个client端连接异常问题，然后定位分析发现是因为全连接队列满了导致的。查阅各种资料文章和通过一系列的实验对TCP连接队列有了更深入的理解</p>
<p>查资料过程中发现没有文章把这两个队列以及怎么观察他们的指标说清楚，希望通过这篇文章能说清楚:</p>
<ol>
<li>这两个队列是干什么用的；</li>
</ol>
<p>2）怎么设置和观察他们的最大值；</p>
<p>3）怎么查看这两个队列当前使用到了多少；</p>
<p>4）一旦溢出的后果和现象是什么</p>
</blockquote>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><pre><code>场景：JAVA的client和server，使用socket通信。server使用NIO。

1.间歇性的出现client向server建立连接三次握手已经完成，但server的selector没有响应到这连接。
2.出问题的时间点，会同时有很多连接出现这个问题。
3.selector没有销毁重建，一直用的都是一个。
4.程序刚启动的时候必会出现一些，之后会间歇性出现。
</code></pre>
<h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><h3 id="正常TCP建连接三次握手过程："><a href="#正常TCP建连接三次握手过程：" class="headerlink" title="正常TCP建连接三次握手过程："></a>正常TCP建连接三次握手过程：</h3><p><img src="/images/oss/159a331ff8cdd4b8994dfe6a209d035f.png" alt="image.png"></p>
<ul>
<li>第一步：client 发送 syn 到server 发起握手；</li>
<li>第二步：server 收到 syn后回复syn+ack给client；</li>
<li>第三步：client 收到syn+ack后，回复server一个ack表示收到了server的syn+ack（此时client的56911端口的连接已经是established）</li>
</ul>
<p>从问题的描述来看，有点像TCP建连接的时候全连接队列（accept队列，后面具体讲）满了，尤其是症状2、4. 为了证明是这个原因，马上通过 netstat -s | egrep “listen” 去看队列的溢出统计数据：</p>
<pre><code>667399 times the listen queue of a socket overflowed
</code></pre>
<p>反复看了几次之后发现这个overflowed 一直在增加，那么可以明确的是server上全连接队列一定溢出了</p>
<p>接着查看溢出后，OS怎么处理：</p>
<pre><code># cat /proc/sys/net/ipv4/tcp_abort_on_overflow
0
</code></pre>
<p><strong>tcp_abort_on_overflow 为0表示如果三次握手第三步的时候全连接队列满了那么 server 扔掉 client 发过来的ack（在server端认为连接还没建立起来）</strong></p>
<p>为了证明客户端应用代码的异常跟全连接队列满有关系，我先把tcp_abort_on_overflow修改成 1，1表示第三步的时候如果全连接队列满了，server发送一个reset包给client，表示废掉这个握手过程和这个连接（本来在server端这个连接就还没建立起来）。</p>
<p>接着测试，这时在客户端异常中可以看到很多connection reset by peer的错误，<strong>到此证明客户端错误是这个原因导致的（逻辑严谨、快速证明问题的关键点所在）</strong>。</p>
<p>于是开发同学翻看java 源代码发现socket 默认的backlog（这个值控制全连接队列的大小，后面再详述）是50，于是改大重新跑，经过12个小时以上的压测，这个错误一次都没出现了，同时观察到 overflowed 也不再增加了。</p>
<p>到此问题解决，<strong>简单来说TCP三次握手后有个accept队列，进到这个队列才能从Listen变成accept，默认backlog 值是50，很容易就满了</strong>。满了之后握手第三步的时候server就忽略了client发过来的ack包（隔一段时间server重发握手第二步的syn+ack包给client），如果这个连接一直排不上队就异常了。</p>
<blockquote>
<p>但是不能只是满足问题的解决，而是要去复盘解决过程，中间涉及到了哪些知识点是我所缺失或者理解不到位的；这个问题除了上面的异常信息表现出来之外，还有没有更明确地指征来查看和确认这个问题。</p>
</blockquote>
<h2 id="深入理解TCP握手过程中建连接的流程和队列"><a href="#深入理解TCP握手过程中建连接的流程和队列" class="headerlink" title="深入理解TCP握手过程中建连接的流程和队列"></a>深入理解TCP握手过程中建连接的流程和队列</h2><p><img src="/images/oss/bcf463efeb677d5749d8d7571274ee79.png" alt="image.png"></p>
<p>如上图所示，这里有两个队列：syns queue(半连接队列）；accept queue（全连接队列）</p>
<p>三次握手中，在第一步server收到client的syn后，把这个连接信息放到半连接队列中，同时回复syn+ack给client（第二步）；</p>
<pre><code>题外话，比如syn floods 攻击就是针对半连接队列的，攻击方不停地建连接，但是建连接的时候只做第一步，第二步中攻击方收到server的syn+ack后故意扔掉什么也不做，导致server上这个队列满其它正常请求无法进来
</code></pre>
<p>第三步的时候server收到client的ack，如果这时全连接队列没满，那么从半连接队列拿出这个连接的信息放入到全连接队列中，同时将连接状态从 SYN_RECV 改成 ESTABLISHED 状态，否则按tcp_abort_on_overflow指示的执行。</p>
<p>这时如果全连接队列满了并且tcp_abort_on_overflow是0的话，server会扔掉三次握手中第三步收到的ack（假装没有收到一样），过一段时间再次发送syn+ack给client（也就是重新走握手的第二步），如果client超时等待比较短，就很容易异常了。其实这个时候client认为连接已经建立了，可以发数据或者可以断开，而实际server上连接还没建立好（还没能力）。</p>
<p>在我们的os中retry 第二步的默认次数是2（centos默认是5次）：</p>
<pre><code>net.ipv4.tcp_synack_retries = 2
</code></pre>
<h2 id="如果TCP连接队列溢出，有哪些指标可以看呢？"><a href="#如果TCP连接队列溢出，有哪些指标可以看呢？" class="headerlink" title="如果TCP连接队列溢出，有哪些指标可以看呢？"></a>如果TCP连接队列溢出，有哪些指标可以看呢？</h2><p>上述解决过程有点绕，听起来蒙，那么下次再出现类似问题有什么更快更明确的手段来确认这个问题呢？</p>
<p>（<em>通过具体的、可见的东西来强化我们对知识点的理解和吸收</em>）</p>
<h3 id="netstat-s"><a href="#netstat-s" class="headerlink" title="netstat -s"></a>netstat -s</h3><pre><code>[root@server ~]#  netstat -s | egrep &quot;listen|LISTEN&quot; 
667399 times the listen queue of a socket overflowed  //全连接队列溢出
//以下两行是一个意思， netstat 版本不同导致显示不同，新版本显示为 dropped
667399 SYNs to LISTEN sockets ignored                 //含全连接/半连接队列溢出+PAWSPassive 等
905080 SYNs to LISTEN sockets dropped                 //含全连接/半连接队列溢出+PAWSPassive 等
 
//和本文无关的一些其它指标 
919614 passive connections rejected because of time stamp //tcp_recycle 丢 syn 包，对应/proc/net/netstat 中 PAWSPassive
TCPTimeWaitOverflow: 65000                                //tcp_max_tw_buckets 溢出
</code></pre>
<p>比如上面看到的 667399 times ，表示全连接队列溢出的次数，隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了</p>
<p>ignored 和 dropped：</p>
<p><img src="/Users/ren/case/951413iMgBlog/image-20240807112156872.png" alt="image-20240807112156872"></p>
<p>这些指标都是从 &#x2F;proc&#x2F;net&#x2F;netstat 中采集，含义可以参考 <a target="_blank" rel="noopener" href="https://github.com/ecki/net-tools.git">net-tool 工具(netstat 命令来源)中的源码</a>：</p>
<p><img src="/Users/ren/case/951413iMgBlog/image-20240807112356787.png" alt="image-20240807112356787"></p>
<h3 id="ss-命令"><a href="#ss-命令" class="headerlink" title="ss 命令"></a>ss 命令</h3><pre><code>[root@server ~]# ss -lnt
Recv-Q Send-Q Local Address:Port  Peer Address:Port 
0        50               *:3306             *:* 
</code></pre>
<p><strong>上面看到的第二列Send-Q 值是50，表示第三列的listen端口上的全连接队列最大为50，第一列Recv-Q为全连接队列当前使用了多少</strong></p>
<p><strong>全连接队列的大小取决于：min(backlog, somaxconn) . backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数</strong></p>
<p>《Unix Network Programming》中关于backlog的描述</p>
<blockquote>
<p>The backlog argument to the listen function has historically specified the maximum value for the sum of both queues.</p>
<p>There has never been a formal definition of what the backlog means. The 4.2BSD man page says that it “defines the maximum length the queue of pending connections may grow to.” Many man pages and even the POSIX specification copy this definition verbatim, but this definition does not say whether a pending connection is one in the SYN_RCVD state, one in the ESTABLISHED state that has not yet been accepted, or either. The historical definition in this bullet is the Berkeley implementation, dating back to 4.2BSD, and copied by many others.</p>
</blockquote>
<p>关于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/19f92a030ca6d772ab44b22ee6a01378a8cb32d4">somaxconn 终于在2019年将默认值从128调整到了2048</a>, 这个调整合并到了kernel 5.17中</p>
<blockquote>
<p>SOMAXCONN is &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn default value.</p>
<p>It has been defined as 128 more than 20 years ago.</p>
<p>Since it caps the listen() backlog values, the very small value has<br>caused numerous problems over the years, and many people had<br>to raise it on their hosts after beeing hit by problems.</p>
<p>Google has been using 1024 for at least 15 years, and we increased<br>this to 4096 after TCP listener rework has been completed, more than<br>4 years ago. We got no complain of this change breaking any<br>legacy application.</p>
<p>Many applications indeed setup a TCP listener with listen(fd, -1);<br>meaning they let the system select the backlog.</p>
<p>Raising SOMAXCONN lowers chance of the port being unavailable under<br>even small SYNFLOOD attack, and reduces possibilities of side channel<br>vulnerabilities.</p>
</blockquote>
<p>这个时候可以跟我们的代码建立联系了，比如Java创建ServerSocket的时候会让你传入backlog的值：</p>
<pre><code>ServerSocket()
	Creates an unbound server socket.
ServerSocket(int port)
	Creates a server socket, bound to the specified port.
ServerSocket(int port, int backlog)
	Creates a server socket and binds it to the specified local port number, with the specified backlog.
ServerSocket(int port, int backlog, InetAddress bindAddr)
	Create a server with the specified port, listen backlog, and local IP address to bind to.
</code></pre>
<p>（来自JDK帮助文档：<a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/7/docs/api/java/net/ServerSocket.html%EF%BC%89">https://docs.oracle.com/javase/7/docs/api/java/net/ServerSocket.html）</a></p>
<p><strong>半连接队列的大小取决于：max(64,  &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;tcp_max_syn_backlog)。 <a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/804896">不同版本的os会有些差异</a></strong></p>
<blockquote>
<p>我们写代码的时候从来没有想过这个backlog或者说大多时候就没给他值（那么默认就是50），直接忽视了他，首先这是一个知识点的忙点；其次也许哪天你在哪篇文章中看到了这个参数，当时有点印象，但是过一阵子就忘了，这是知识之间没有建立连接，不是体系化的。但是如果你跟我一样首先经历了这个问题的痛苦，然后在压力和痛苦的驱动自己去找为什么，同时能够把为什么从代码层推理理解到OS层，那么这个知识点你才算是比较好地掌握了，也会成为你的知识体系在TCP或者性能方面成长自我生长的一个有力抓手</p>
</blockquote>
<h4 id="netstat-命令"><a href="#netstat-命令" class="headerlink" title="netstat 命令"></a>netstat 命令</h4><p>netstat跟ss命令一样也能看到Send-Q、Recv-Q这些状态信息，不过如果这个连接不是<strong>Listen状态</strong>的话，Recv-Q就是指收到的数据还在缓存中，还没被进程读取，这个值就是还没被进程读取的 bytes；而 Send 则是发送队列中没有被远程主机确认的 bytes 数</p>
<pre><code>$netstat -tn  
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address   Foreign Address State  
tcp    0  0 server:8182  client-1:15260 SYN_RECV   
tcp    0 28 server:22    client-1:51708  ESTABLISHED
tcp    0  0 server:2376  client-1:60269 ESTABLISHED
</code></pre>
<p><strong>netstat -tn 看到的 Recv-Q 跟全连接半连接中的Queue没有关系，这里特意拿出来说一下是因为容易跟 ss -lnt 的 Recv-Q 搞混淆</strong>  </p>
<p>所以ss看到的 Send-Q、Recv-Q是目前全连接队列使用情况和最大设置<br>netstat看到的 Send-Q、Recv-Q，如果这个连接是Established状态的话就是发出的bytes并且没有ack的包、和os接收到的bytes还没交给应用</p>
<p>我们看到的 Recv-Q、Send-Q获取源代码如下（ net&#x2F;ipv4&#x2F;tcp_diag.c ）：   </p>
<pre><code>static void tcp_diag_get_info(struct sock *sk, struct inet_diag_msg *r,
  void *_info)
{
    const struct tcp_sock *tp = tcp_sk(sk);
    struct tcp_info *info = _info;
    
    if (sk-&gt;sk_state == TCP_LISTEN) {  //LISTEN状态下的 Recv-Q、Send-Q
	    r-&gt;idiag_rqueue = sk-&gt;sk_ack_backlog;
	    r-&gt;idiag_wqueue = sk-&gt;sk_max_ack_backlog; //Send-Q 最大backlog
    } else {						   //其它状态下的 Recv-Q、Send-Q
	    r-&gt;idiag_rqueue = max_t(int, tp-&gt;rcv_nxt - tp-&gt;copied_seq, 0);
	    r-&gt;idiag_wqueue = tp-&gt;write_seq - tp-&gt;snd_una;
    }
    if (info != NULL)
    	tcp_get_info(sk, info);
}
</code></pre>
<p>比如如下netstat -t 看到的Recv-Q有大量数据堆积，那么一般是CPU处理不过来导致的：</p>
<p><img src="/images/oss/77ed9ba81f70f7940546f0a22dabf010.png" alt="image.png"></p>
<h4 id="netstat看到的listen状态的Recv-Q-Send-Q"><a href="#netstat看到的listen状态的Recv-Q-Send-Q" class="headerlink" title="netstat看到的listen状态的Recv-Q&#x2F;Send-Q"></a>netstat看到的listen状态的Recv-Q&#x2F;Send-Q</h4><p>netstat 看到的listen状态下的Recv-Q&#x2F;Send-Q意义跟 ss -lnt看到的完全不一样。上面的 netstat 对非listen的描述没问题，但是listen状态似乎Send-Q这个值总是0，这要去看netstat的代码了，实际上Listen状态它不是一个连接，所以肯定统计不到流量，netstat似乎只是针对连接的统计</p>
<p>从网上找了两个Case，server的8765端口故意不去读取对方发过来的2000字节，所看到的是：</p>
<pre><code>$ netstat -ano | grep 8765  
tcp0  0 0.0.0.0:87650.0.0.0:*   LISTEN  off (0.00/0/0)  
tcp 2000  0 10.100.70.140:8765  10.100.70.139:43634 ESTABLISHED off (0.00/0/0)
</code></pre>
<p>第二个Case，8000端口的半连接满了（129），但是这个时候Send-Q还是看到的0</p>
<pre><code>$ netstat -ntap | grep 8000 
tcp      129      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      1526/XXXXX- 
tcp        0      0 9.11.6.36:8000          9.11.6.37:48306         SYN_RECV    - 
tcp        0      0 9.11.6.36:8000          9.11.6.34:44936         SYN_RECV    - 
tcp      365      0 9.11.6.36:8000          9.11.6.37:58446         CLOSE_WAIT  -  
</code></pre>
<h2 id="案列：如果TCP连接队列溢出，抓包是什么现象呢？"><a href="#案列：如果TCP连接队列溢出，抓包是什么现象呢？" class="headerlink" title="案列：如果TCP连接队列溢出，抓包是什么现象呢？"></a>案列：如果TCP连接队列溢出，抓包是什么现象呢？</h2><p><img src="/images/oss/c0849615ae52531887ce6b0313d7d2d1.png" alt="image.png"></p>
<p>如上图server端8989端口的服务全连接队列已经满了（设置最大5，已经6了，通过后面步骤的ss -lnt可以验证）， 所以 server尝试过一会假装继续三次握手的第二步，跟client说我们继续谈恋爱吧。可是这个时候client比较性急，忙着分手了，server觉得都没恋上那什么分手啊。所以接下来两边自说自话也就是都不停滴重传</p>
<h3 id="通过ss和netstat所观察到的状态"><a href="#通过ss和netstat所观察到的状态" class="headerlink" title="通过ss和netstat所观察到的状态"></a>通过ss和netstat所观察到的状态</h3><p><img src="/images/oss/ec25ccb6cce8f554b7ef6927f05bd530.png" alt="image.png"></p>
<p><img src="/images/oss/2fbdd05162e9fd51e803682b8a18cc51.png" alt="image.png"></p>
<p><a href="/2019/08/31/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP%E9%98%9F%E5%88%97--%E9%80%9A%E8%BF%87%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%B1%95%E7%A4%BA%E9%97%AE%E9%A2%98/">另外一个案例，虽然最终的锅不是TCP全连接队列太小，但是也能从重传、队列溢出找到根因</a></p>
<h2 id="实践验证一下上面的理解"><a href="#实践验证一下上面的理解" class="headerlink" title="实践验证一下上面的理解"></a>实践验证一下上面的理解</h2><p>上面是通过一些具体的工具、指标来认识全连接队列，接下来结合文章开始的问题来具体验证一下 </p>
<p>把java中backlog改成10（越小越容易溢出），继续跑压力，这个时候client又开始报异常了，然后在server上通过 ss 命令观察到：</p>
<pre><code>Fri May  5 13:50:23 CST 2017
Recv-Q Send-QLocal Address:Port  Peer Address:Port
11         10         *:3306               *:*
</code></pre>
<p>按照前面的理解，这个时候我们能看到3306这个端口上的服务全连接队列最大是10，但是现在有11个在队列中和等待进队列的，肯定有一个连接进不去队列要overflow掉，同时也确实能看到overflow的值在不断地增大。</p>
<p><strong>能够进入全连接队列的 Socket 最大数量始终比配置的全连接队列最大长度 + 1</strong>，结合内核代码，发现<strong>内核在判断全连接队列是否满的情况下，使用的是 &gt; 而非 &gt;&#x3D;</strong> </p>
<blockquote>
<p>Linux下发SIGSTOP信号发给用户态进程，就可以让进程stop不再accept，模拟accept溢出的效果</p>
<p>kill -19 pid 即可； kill -18 pid 恢复暂停进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define SIGKILL     9    /* Kill, unblockable (POSIX). */</span><br><span class="line">#define SIGCONT     18   /* Continue (POSIX).  */</span><br><span class="line">#define SIGSTOP     19   /* Stop, unblockable (POSIX). */</span><br></pre></td></tr></table></figure></blockquote>
<p>tsar监控accept队列的溢出</p>
<blockquote>
<p>tsar –tcpx -s&#x3D;lisove -li 1</p>
</blockquote>
<h3 id="Tomcat和Nginx中的Accept队列参数"><a href="#Tomcat和Nginx中的Accept队列参数" class="headerlink" title="Tomcat和Nginx中的Accept队列参数"></a>Tomcat和Nginx中的Accept队列参数</h3><p>Tomcat 默认短连接，backlog（Tomcat里面的术语是Accept count）Ali-tomcat默认是200, Apache Tomcat默认100. </p>
<pre><code>#ss -lnt
Recv-Q Send-Q   Local Address:Port Peer Address:Port
0       100                 *:8080            *:*
</code></pre>
<p>Nginx默认是511</p>
<pre><code>$sudo ss -lnt
State  Recv-Q Send-Q Local Address:PortPeer Address:Port
LISTEN    0     511              *:8085           *:*
LISTEN    0     511              *:8085           *:*
</code></pre>
<p>因为Nginx是多进程模式，所以看到了多个8085，也就是多个进程都监听同一个端口以尽量避免上下文切换来提升性能   </p>
<p><img src="/images/oss/01dc036aca4b445ed86e3e295bf245b8.png" alt="image.png"></p>
<h2 id="进一步思考-client-fooling-问题"><a href="#进一步思考-client-fooling-问题" class="headerlink" title="进一步思考 client fooling 问题"></a>进一步思考 client fooling 问题</h2><p>如果client走完第三步在client看来连接已经建立好了，但是server上的对应的连接有可能因为accept queue满了而仍然是syn_recv状态，这个时候如果client发数据给server，server会怎么处理呢？（有同学说会reset，还是实践看看）</p>
<p>先来看一个例子：</p>
<p><img src="/images/oss/9179e08ac24ce3d53e74b92dbd044906.png" alt="image.png"></p>
<p>如上图，图中3号包是三次握手中的第三步，client发送ack给server，这个时候在client看来握手完成，然后4号包中client发送了一个长度为238的包给server，因为在这个时候client认为连接建立成功，但是server上这个连接实际没有ready，所以server没有回复，一段时间后client认为丢包了然后重传这238个字节的包，等到server reset了该连接（或者client一直重传这238字节到超时，client主动发fin包断开该连接，如下图）</p>
<p><img src="/images/oss/3f5f1eeb0646a3af8afd6bbff2a9ea0b.png" alt="image.png"></p>
<p>这个问题也叫client fooling，可以看这个patch在4.10后修复了：<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/5ea8ea2cb7f1d0db15762c9b0bb9e7330425a071">https://github.com/torvalds/linux/commit/5ea8ea2cb7f1d0db15762c9b0bb9e7330425a071</a> ，修复的逻辑就是，如果全连接队列满了就不再回复syn+ack了，免得client误认为这个连接建立起来了，这样client端收不到syn+ack就只能重发syn。</p>
<p><strong>从上面的实际抓包来看不是reset，而是server忽略这些包，然后client重传，一定次数后client认为异常，然后断开连接。</strong></p>
<p>如果这个连接已经放入了全连接队列但是应用没有accept（比如应用卡住了），那么这个时候client发过来的包是不会被扔掉，OS会先收下放到接收buffer中，知道buffer满了再扔掉新进来的。</p>
<h2 id="过程中发现的一个奇怪问题"><a href="#过程中发现的一个奇怪问题" class="headerlink" title="过程中发现的一个奇怪问题"></a>过程中发现的一个奇怪问题</h2><pre><code>[root@server ~]# date; netstat -s | egrep &quot;listen|LISTEN&quot; 
Fri May  5 15:39:58 CST 2017
1641685 times the listen queue of a socket overflowed  # 全连接队列溢出
1641685 SYNs to LISTEN sockets ignored                 # 半连接队列溢出

[root@server ~]# date; netstat -s | egrep &quot;listen|LISTEN&quot; 
Fri May  5 15:39:59 CST 2017
1641906 times the listen queue of a socket overflowed
1641906 SYNs to LISTEN sockets ignored
</code></pre>
<p>如上所示：<br>overflowed 和 ignored 总是一样多，并且都是同步增加，overflowed 表示全连接队列溢出次数，SYNs to LISTEN socket ignored 表示半连接队列溢出等等指标的次数，没这么巧吧。</p>
<p>翻看内核源代码（<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v6.13-rc6/net/ipv4/tcp_ipv4.c#L1849">https://github.com/torvalds/linux/blob/v6.13-rc6/net/ipv4/tcp_ipv4.c#L1849</a> ）：</p>
<p><img src="/images/oss/a5616904df3a505572d99d557b534db2.png" alt="image.png"></p>
<p>可以看到overflow的时候一定会drop++（socket ignored），也就是drop一定大于等于overflow。</p>
<p>同时我也查看了另外几台server的这两个值来证明drop一定大于等于overflow：</p>
<pre><code>server1
150 SYNs to LISTEN sockets dropped

server2
193 SYNs to LISTEN sockets dropped

server3
16329 times the listen queue of a socket overflowed
16422 SYNs to LISTEN sockets dropped

server4
20 times the listen queue of a socket overflowed
51 SYNs to LISTEN sockets dropped

server5
984932 times the listen queue of a socket overflowed
988003 SYNs to LISTEN sockets dropped
</code></pre>
<p>总结：SYNs to LISTEN sockets dropped(ListenDrops)表示：全连接&#x2F;半连接队列溢出<strong>以及PAWSPassive</strong> 等造成的 SYN 丢包</p>
<blockquote>
<p>ListenDrops 表示： SYNs to LISTEN sockets dropped</p>
</blockquote>
<h2 id="那么全连接队列满了会影响半连接队列吗？"><a href="#那么全连接队列满了会影响半连接队列吗？" class="headerlink" title="那么全连接队列满了会影响半连接队列吗？"></a>那么全连接队列满了会影响半连接队列吗？</h2><p>来看三次握手第一步的源代码（<a target="_blank" rel="noopener" href="http://elixir.free-electrons.com/linux/v2.6.33/source/net/ipv4/tcp_ipv4.c#L1249%EF%BC%89%EF%BC%9A">http://elixir.free-electrons.com/linux/v2.6.33/source/net/ipv4/tcp_ipv4.c#L1249）：</a></p>
<p><img src="/images/oss/0c6bbb5d4a10f40c8b3c4ba6cab82292.png" alt="image.png"></p>
<p>TCP 三次握手第一步的时候如果全连接队列满了会影响第一步drop 半连接的发生，流程的如下：</p>
<pre><code>tcp_v4_do_rcv-&gt;tcp_rcv_state_process-&gt;tcp_v4_conn_request
//如果accept backlog队列已满，且未超时的request socket的数量大于1，则丢弃当前请求  
  if(sk_acceptq_is_full(sk) &amp;&amp; inet_csk_reqsk_queue_yong(sk)&gt;1)
      goto drop;
</code></pre>
<h2 id="半连接队列的长度"><a href="#半连接队列的长度" class="headerlink" title="半连接队列的长度"></a>半连接队列的长度</h2><p><strong>半连接队列的长度由三个参数指定：</strong></p>
<ul>
<li><strong>调用</strong> <strong>listen</strong> <strong>时，传入的 backlog</strong></li>
<li><strong>&#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn</strong> <strong>默认值为 128</strong></li>
<li><em>&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;tcp_max_syn_backlog</em>* <strong>默认值为 1024</strong></li>
</ul>
<p>假设 listen 传入的 backlog &#x3D; 128，其他配置采用默认值，来计算下半连接队列的最大长度</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">backlog = min(somaxconn, backlog) = min(128, 128) = 128</span><br><span class="line">nr_table_entries = backlog = 128</span><br><span class="line">nr_table_entries = min(backlog, sysctl_max_syn_backlog) = min(128, 1024) = 128</span><br><span class="line">nr_table_entries = max(nr_table_entries, 8) = max(128, 8) = 128</span><br><span class="line">nr_table_entries = roundup_pow_of_two(nr_table_entries + 1) = 256</span><br><span class="line">max_qlen_log = max(3, log2(nr_table_entries)) = max(3, 8) = 8</span><br><span class="line">max_queue_length = 2^max_qlen_log = 2^8 = 256</span><br></pre></td></tr></table></figure>

<p>可以得到半队列大小是 256，以上计算方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">backlog = min(somaxconn, backlog)</span><br><span class="line">nr_table_entries = backlog</span><br><span class="line">nr_table_entries = min(backlog, sysctl_max_syn_backlog)</span><br><span class="line">nr_table_entries = max(nr_table_entries, 8)</span><br><span class="line">// roundup_pow_of_two: 将参数向上取整到最小的 2^n，注意这里存在一个 +1</span><br><span class="line">nr_table_entries = roundup_pow_of_two(nr_table_entries + 1)</span><br><span class="line">max_qlen_log = max(3, log2(nr_table_entries))</span><br><span class="line">max_queue_length = 2^max_qlen_log</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/5f63b8e0-952c-47a2-8179-48793034f86b.png"></p>
<p>没开启tcp_syncookies的话，到tcp_max_syn_backlog 75%水位就开始drop syn包了</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Linux内核就引入半连接队列（用于存放收到SYN，但还没收到ACK的连接）和全连接队列（用于存放已经完成3次握手，但是<strong>应用层代码还没有完成 accept() 的连接</strong>）两个概念，用于存放在握手中的连接。</p>
<p>全连接队列、半连接队列溢出这种问题很容易被忽视，但是又很关键，特别是对于一些短连接应用（比如Nginx、PHP，当然他们也是支持长连接的）更容易爆发。 一旦溢出，从cpu、线程状态看起来都比较正常，但是压力上不去，在client看来rt也比较高（rt&#x3D;网络+排队+真正服务时间），但是从server日志记录的真正服务时间来看rt又很短。</p>
<p>另外就是jdk、netty等一些框架默认backlog比较小，可能有些情况下导致性能上不去，比如 @毕玄 碰到的这个 <a target="_blank" rel="noopener" href="https://www.atatech.org/articles/12919">《netty新建连接并发数很小的case》 </a><br>都是类似原因</p>
<p>希望通过本文能够帮大家理解TCP连接过程中的半连接队列和全连接队列的概念、原理和作用，更关键的是有哪些指标可以明确看到这些问题。</p>
<p>另外每个具体问题都是最好学习的机会，光看书理解肯定是不够深刻的，请珍惜每个具体问题，碰到后能够把来龙去脉弄清楚。</p>
<h2 id="为什么-netstat-看到的-listen-状态的-SEND-Q-总是0"><a href="#为什么-netstat-看到的-listen-状态的-SEND-Q-总是0" class="headerlink" title="为什么 netstat 看到的 listen 状态的 SEND-Q 总是0"></a>为什么 netstat 看到的 listen 状态的 SEND-Q 总是0</h2><p><a target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=e7073830cc8b52ef3df7dd150e4dac7706e0e104">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=e7073830cc8b52ef3df7dd150e4dac7706e0e104</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#netstat -ntap | grep 8000</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State</span><br><span class="line">tcp      129      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      1526/XXXXX- //第三列总是0</span><br><span class="line">tcp        0      0 9.11.6.36:8000          9.11.6.37:48306         SYN_RECV    -</span><br><span class="line">tcp        0      0 9.11.6.36:8000          9.11.6.34:44936         SYN_RECV    -</span><br><span class="line">tcp      365      0 9.11.6.36:8000          9.11.6.37:58446         CLOSE_WAIT  -</span><br></pre></td></tr></table></figure>

<p>如下图代码，最开始 2 边一起支持了 LISTEN socket 显示 accept 队列当前长度，后来右边支持显示最大长度时，左边没有加。netstat 是读取的 &#x2F;proc&#x2F;net&#x2F;tcp，然后 ss 走了 diag 接口去拿的：</p>
<p><img src="/images/951413iMgBlog/image-20240506134119413.png" alt="image-20240506134119413"></p>
<hr>
<p>也就是改了 tcp_diag_get_info ，但是忘了改 get_tcp4_sock，但是写 man netstat 自己也没验证过就以讹传讹</p>
<p>d31d2480d9840f0d88739941bed0654d5b581dcb ?</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p>星球同学最详细的实践(代码、抓包等等，共13篇，含<a target="_blank" rel="noopener" href="https://github.com/xiaodongQ/prog-playground/tree/main/network">演示代码</a>) <a target="_blank" rel="noopener" href="https://xiaodongq.github.io/2024/05/30/tcp_syn_queue/">https://xiaodongq.github.io/2024/05/30/tcp_syn_queue/</a>  <a target="_blank" rel="noopener" href="https://xiaodongq.github.io/2024/06/26/libbpf-trace-tcp_connect/">https://xiaodongq.github.io/2024/06/26/libbpf-trace-tcp_connect/</a></p>
<p>X推友实验：<a target="_blank" rel="noopener" href="https://wgzhao.github.io/notes/troubleshooting/deep-in-tcp-connect/">https://wgzhao.github.io/notes/troubleshooting/deep-in-tcp-connect/</a></p>
<p>张师傅：<a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904071367753736">https://juejin.cn/post/6844904071367753736</a></p>
<p>详细的实验以及分析，附Go 实验代码：<a target="_blank" rel="noopener" href="https://www.51cto.com/article/687595.html">https://www.51cto.com/article/687595.html</a> </p>
<p><a target="_blank" rel="noopener" href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/zengkefu/p/5606696.html">http://www.cnblogs.com/zengkefu/p/5606696.html</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnxct.com/something-about-phpfpm-s-backlog/">http://www.cnxct.com/something-about-phpfpm-s-backlog/</a></p>
<p><a target="_blank" rel="noopener" href="http://jaseywang.me/2014/07/20/tcp-queue-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/">http://jaseywang.me/2014/07/20/tcp-queue-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</a></p>
<p><a target="_blank" rel="noopener" href="http://jin-yang.github.io/blog/network-synack-queue.html#">http://jin-yang.github.io/blog/network-synack-queue.html#</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.chinaunix.net/uid-20662820-id-4154399.html">http://blog.chinaunix.net/uid-20662820-id-4154399.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.atatech.org/articles/12919">https://www.atatech.org/articles/12919</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.cloudflare.com/syn-packet-handling-in-the-wild/">https://blog.cloudflare.com/syn-packet-handling-in-the-wild/</a></p>
<p><a target="_blank" rel="noopener" href="https://ops.tips/blog/how-linux-tcp-introspection/">How Linux allows TCP introspection The inner workings of bind and listen on Linux.</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaolincoding/p/12995358.html">https://www.cnblogs.com/xiaolincoding/p/12995358.html</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/804896">从一次线上问题说起，详解 TCP 半连接队列、全连接队列–详细的实验验证各种溢出</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/YWzuKBK3TMclejeN2ziAvQ">案例三：诡异的幽灵连接，全连接队列满后4.10内核不再回复syn+ack, 但是3.10会回syn+ack</a></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">commit <span class="number">5</span>ea8ea2cb7f1d0db15762c9b0bb9e7330425a071</span><br><span class="line">Author: Eric Dumazet &lt;edumazet@google.com&gt;</span><br><span class="line">Date:   Thu Oct <span class="number">27</span> <span class="number">00</span>:<span class="number">27</span>:<span class="number">57</span> <span class="number">2016</span></span><br><span class="line"></span><br><span class="line"> tcp/dccp: drop SYN packets <span class="keyword">if</span> accept <span class="built_in">queue</span> is full</span><br><span class="line"></span><br><span class="line"> Per <span class="title function_">listen</span><span class="params">(fd, backlog)</span> rules, there is really no point accepting a SYN,</span><br><span class="line"> sending a SYNACK, and dropping the following ACK packet <span class="keyword">if</span> accept <span class="built_in">queue</span></span><br><span class="line"> is full, because application is not draining accept <span class="built_in">queue</span> fast enough.</span><br><span class="line"></span><br><span class="line"> This behavior is fooling TCP clients that believe they established a</span><br><span class="line"> flow, <span class="keyword">while</span> there is nothing at server side. They might then send about</span><br><span class="line"> 10 <span class="title function_">MSS</span> <span class="params">(<span class="keyword">if</span> using IW10)</span> that will be dropped anyway <span class="keyword">while</span> server is under</span><br><span class="line"> stress.</span><br><span class="line"></span><br><span class="line">   -       <span class="comment">/* Accept backlog is full. If we have already queued enough</span></span><br><span class="line"><span class="comment">   -        * of warm entries in syn queue, drop request. It is better than</span></span><br><span class="line"><span class="comment">   -        * clogging syn queue with openreqs with exponentially increasing</span></span><br><span class="line"><span class="comment">   -        * timeout.</span></span><br><span class="line"><span class="comment">   -        */</span></span><br><span class="line">   -       <span class="title function_">if</span> <span class="params">(sk_acceptq_is_full(sk) &amp;&amp; inet_csk_reqsk_queue_young(sk) &gt; <span class="number">1</span>)</span> &#123;</span><br><span class="line">   +       <span class="keyword">if</span> (sk_acceptq_is_full(sk)) &#123;</span><br><span class="line">                   NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);</span><br><span class="line">                   <span class="keyword">goto</span> drop;</span><br><span class="line">           &#125;</span><br></pre></td></tr></table></figure>

<p>Client 不断地 connect 建新连接：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;stdlib.h&gt;</span><br><span class="line">#include&lt;string.h&gt;</span><br><span class="line">#include&lt;errno.h&gt;</span><br><span class="line">#include&lt;sys/types.h&gt;</span><br><span class="line">#include&lt;sys/socket.h&gt;</span><br><span class="line">#include&lt;netinet/in.h&gt;</span><br><span class="line">#include&lt;arpa/inet.h&gt;</span><br><span class="line">#include&lt;unistd.h&gt;</span><br><span class="line">#define MAXLINE 4096</span><br><span class="line"></span><br><span class="line">int main(int argc, char** argv)</span><br><span class="line">&#123;</span><br><span class="line">    int sockfd, n;</span><br><span class="line">    char recvline[4096], sendline[4096];</span><br><span class="line">    struct sockaddr_in servaddr;</span><br><span class="line"></span><br><span class="line">    memset(&amp;servaddr, 0, sizeof(servaddr));</span><br><span class="line">    servaddr.sin_family = AF_INET;</span><br><span class="line">    servaddr.sin_port = htons(6666);</span><br><span class="line">    inet_pton(AF_INET, &quot;127.0.0.1&quot;, &amp;servaddr.sin_addr);</span><br><span class="line"></span><br><span class="line">    for (n = 0; n &lt; 100; n++)</span><br><span class="line">    &#123;</span><br><span class="line">        if( (sockfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0)&#123;</span><br><span class="line">            printf(&quot;create socket error: %s(errno: %d)\n&quot;, strerror(errno),errno);</span><br><span class="line">            return 0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //客户端不停的向服务端发起新连接，成功之后继续发，没成功会阻塞在这里        //--------------</span><br><span class="line">        if(connect(sockfd, (struct sockaddr*)&amp;servaddr, sizeof(servaddr)) &lt; 0)</span><br><span class="line">        &#123;</span><br><span class="line">            printf(&quot;connect error: %s(errno: %d)\n&quot;,strerror(errno),errno);</span><br><span class="line">            return 0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        printf(&quot;connected to server: %d\n&quot;, n);</span><br><span class="line">        close(sockfd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>server 故意不accept：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;stdlib.h&gt;</span><br><span class="line">#include&lt;string.h&gt;</span><br><span class="line">#include&lt;errno.h&gt;</span><br><span class="line">#include&lt;sys/types.h&gt;</span><br><span class="line">#include&lt;sys/socket.h&gt;</span><br><span class="line">#include&lt;netinet/in.h&gt;</span><br><span class="line">#include&lt;unistd.h&gt;</span><br><span class="line"></span><br><span class="line">#define MAXLINE 4096</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[])</span><br><span class="line">&#123;</span><br><span class="line">    int listenfd, connfd;</span><br><span class="line">    struct sockaddr_in servaddr;</span><br><span class="line">    char buff[4096];</span><br><span class="line">    int  n;</span><br><span class="line"></span><br><span class="line">    if( (listenfd = socket(AF_INET, SOCK_STREAM, 0)) == -1 )</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;create socket error: %s(errno: %d)\n&quot;, strerror(errno), errno);</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    memset(&amp;servaddr, 0, sizeof(servaddr));</span><br><span class="line">    servaddr.sin_family = AF_INET;</span><br><span class="line">    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class="line">    servaddr.sin_port = htons(6666);</span><br><span class="line"></span><br><span class="line">    if(bind(listenfd, (struct sockaddr*)&amp;servaddr, sizeof(servaddr)) == -1)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;bind socket error: %s(errno: %d)\n&quot;, strerror(errno), errno);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    //全连接队列设置为10    //--------------</span><br><span class="line">    if(listen(listenfd, 10) == -1)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;listen socket error: %s(errno: %d)\n&quot;, strerror(errno), errno);</span><br><span class="line">        return 2;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if( (connfd = accept(listenfd, (struct sockaddr*)NULL, NULL)) == -1)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;accept socket error: %s(errno: %d)&quot;, strerror(errno), errno);</span><br><span class="line">        return 3;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printf(&quot;accepet a socket\n&quot;);</span><br><span class="line">    </span><br><span class="line">    //服务端仅accept一次，之后就不再accept，此时全连接队列会被堆满    //----------------------------------</span><br><span class="line">    sleep(1000);</span><br><span class="line">        </span><br><span class="line">    close(connfd);</span><br><span class="line">    close(listenfd);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/" class="post-title-link" itemprop="url">就是要你懂TCP--握手和挥手</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-02 17:30:03" itemprop="dateCreated datePublished" datetime="2017-06-02T17:30:03+08:00">2017-06-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TCP/" itemprop="url" rel="index"><span itemprop="name">TCP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="就是要你懂TCP–握手和挥手"><a href="#就是要你懂TCP–握手和挥手" class="headerlink" title="就是要你懂TCP–握手和挥手"></a>就是要你懂TCP–握手和挥手</h1><blockquote>
<p>看过太多tcp相关文章，但是看完总是不过瘾，似懂非懂，反复考虑过后，我觉得是那些文章太过理论，看起来没有体感，所以吸收不了。</p>
<p>希望这篇文章能做到言简意赅，帮助大家透过案例来理解原理</p>
</blockquote>
<h2 id="tcp的特点"><a href="#tcp的特点" class="headerlink" title="tcp的特点"></a>tcp的特点</h2><p>这个大家基本都能说几句，面试的时候候选人也肯定会告诉你这些：</p>
<ul>
<li>三次握手</li>
<li>四次挥手</li>
<li>可靠连接</li>
<li>丢包重传</li>
<li>速度自我调整</li>
</ul>
<p>但是我只希望大家记住一个核心的：<strong>tcp是可靠传输协议，它的所有特点都为这个可靠传输服务</strong>。</p>
<h3 id="那么tcp是怎么样来保障可靠传输呢？"><a href="#那么tcp是怎么样来保障可靠传输呢？" class="headerlink" title="那么tcp是怎么样来保障可靠传输呢？"></a>那么tcp是怎么样来保障可靠传输呢？</h3><p>tcp在传输过程中都有一个ack，接收方通过ack告诉发送方收到那些包了。这样发送方能知道有没有丢包，进而确定重传</p>
<h3 id="tcp建连接的三次握手"><a href="#tcp建连接的三次握手" class="headerlink" title="tcp建连接的三次握手"></a>tcp建连接的三次握手</h3><p>来看一个java代码连接数据库的三次握手过程</p>
<p><img src="/images/oss/6d66dadecb72e11e3e5ab765c6c3ea2e.png" alt="image.png"></p>
<p>三个红框表示建立连接的三次握手：</p>
<ul>
<li>第一步：client 发送 syn 到server 发起握手；</li>
<li>第二步：server 收到 syn后回复syn+ack给client；</li>
<li>第三步：client 收到syn+ack后，回复server一个ack表示收到了server的syn+ack（此时client的48287端口的连接已经是established）</li>
</ul>
<p>握手的核心目的是告知对方seq（绿框是client的初始seq，蓝色框是server 的初始seq），对方回复ack（收到的seq+包的大小），这样发送端就知道有没有丢包了</p>
<p>握手的次要目的是告知和协商一些信息，图中黄框。</p>
<ul>
<li>MSS–最大传输包</li>
<li>SACK_PERM–是否支持Selective ack(用户优化重传效率）</li>
<li>WS–窗口计算指数（有点复杂的话先不用管）</li>
</ul>
<p><img src="/images/oss/1423013fe76719cfa3088ebc4704c023.png" alt="image.png"></p>
<p>全连接队列（accept queue）的长度是由 listen(sockfd, backlog) 这个函数里的 backlog 控制的，而该 backlog 的最大值则是 somaxconn。somaxconn 在 5.4 之前的内核中，默认都是 128（5.4 开始调整为了默认 4096）</p>
<p>当服务器中积压的全连接个数超过该值后，新的全连接就会被丢弃掉。Server 在将新连接丢弃时，有的时候需要发送 reset 来通知 Client，这样 Client 就不会再次重试了。不过，默认行为是直接丢弃不去通知 Client。至于是否需要给 Client 发送 reset，是由 tcp_abort_on_overflow 这个配置项来控制的，该值默认为 0，即不发送 reset 给 Client。推荐也是将该值配置为 0</p>
<blockquote>
<p>net.ipv4.tcp_abort_on_overflow &#x3D; 0</p>
</blockquote>
<p><strong>这就是tcp为什么要握手建立连接，就是为了解决tcp的可靠传输</strong></p>
<p>物理上没有一个连接的东西在这里，udp也类似会占用端口、ip，但是大家都没说过udp的连接。而本质上我们说tcp的连接是指tcp是拥有和维护一些状态信息的，这个状态信息就包含seq、ack、窗口&#x2F;buffer，tcp握手就是协商出来这些初始值。这些状态才是我们平时所说的tcp连接的本质。</p>
<h3 id="unres-qlen-和-握手"><a href="#unres-qlen-和-握手" class="headerlink" title="unres_qlen  和 握手"></a>unres_qlen  和 握手</h3><p>tcp connect 的本地流程是这样的：</p>
<p>1、tcp发出SYN建链报文后，报文到ip层需要进行路由查询</p>
<p>2、路由查询完成后，报文到arp层查询下一跳mac地址</p>
<p>3、如果本地没有对应网关的arp缓存，就需要缓存住这个报文，发起arp报文请求</p>
<p>4、arp层收到arp回应报文之后，从缓存中取出SYN报文，完成mac头填写并发送给驱动。</p>
<p>问题在于，arp层报文缓存队列长度默认为3。如果你运气不好，刚好赶上缓存已满，这个报文就会被丢弃。</p>
<p>TCP层发现SYN报文发出去3s（默认值）还没有回应，就会重发一个SYN。这就是为什么少数连接会3s后才能建链。</p>
<p>幸运的是，arp层缓存队列长度是可配置的，用 sysctl -a | grep unres_qlen 就能看到，默认值为3。</p>
<h3 id="建连接失败经常碰到的问题"><a href="#建连接失败经常碰到的问题" class="headerlink" title="建连接失败经常碰到的问题"></a>建连接失败经常碰到的问题</h3><p>内核扔掉syn的情况（握手失败，建不上连接）：</p>
<ul>
<li>rp_filter 命中(rp_filter&#x3D;1, 多网卡环境）， troubleshooting:  netstat -s | grep -i filter ;</li>
<li>snat&#x2F;dnat的时候宿主机port冲突，内核会扔掉 syn包。 troubleshooting: sudo conntrack -S | grep  insert_failed &#x2F;&#x2F;有不为0的</li>
<li>全连接队列满的情况</li>
<li>syn flood攻击</li>
<li>若远端服务器的内核参数 net.ipv4.tcp_tw_recycle 和 net.ipv4.tcp_timestamps 的值都为 1，则远端服务器会检查每一个报文中的时间戳（Timestamp），若 Timestamp 不是递增的关系，不会响应这个报文。配置 NAT 后，远端服务器看到来自不同的客户端的源 IP 相同，但 NAT 前每一台客户端的时间可能会有偏差，报文中的 Timestamp 就不是递增的情况。nat后的连接，开启timestamp。因为快速回收time_wait的需要，会校验时间该ip上次tcp通讯的timestamp大于本次tcp(nat后的不同机器经过nat后ip一样，保证不了timestamp递增）</li>
<li>NAT 哈希表满导致 ECS 实例丢包 nf_conntrack full</li>
</ul>
<h3 id="tcp断开连接的四次挥手"><a href="#tcp断开连接的四次挥手" class="headerlink" title="tcp断开连接的四次挥手"></a>tcp断开连接的四次挥手</h3><p>再来看java连上mysql后，执行了一个SQL： select sleep(2); 然后就断开了连接</p>
<p><img src="/images/oss/b6f4a952cdf8ffbb8f6e9434d1432e05.png" alt="image.png"></p>
<p>四个红框表示断开连接的四次挥手：</p>
<ul>
<li>第一步： client主动发送fin包给server</li>
<li>第二步： server回复ack（对应第一步fin包的ack）给client，表示server知道client要断开了</li>
<li>第三步： server发送fin包给client，表示server也可以断开了</li>
<li>第四部： client回复ack给server，表示既然双发都发送fin包表示断开，那么就真的断开吧</li>
</ul>
<p><img src="/images/oss/321f96243eef2f6437fe4e1559c15efe.png" alt="image.png"></p>
<p>除了 CLOSE_WAIT 状态外，其余两个状态都有对应的系统配置项来控制。</p>
<p>我们首先来看 FIN_WAIT_2 状态，TCP 进入到这个状态后，如果本端迟迟收不到对端的 FIN 包，那就会一直处于这个状态，于是就会一直消耗系统资源。Linux 为了防止这种资源的开销，设置了这个状态的超时时间 tcp_fin_timeout，默认为 60s，超过这个时间后就会自动销毁该连接。</p>
<p>至于本端为何迟迟收不到对端的 FIN 包，通常情况下都是因为对端机器出了问题，或者是因为太繁忙而不能及时 close()。所以，通常我们都建议将 tcp_fin_timeout 调小一些，以尽量避免这种状态下的资源开销。对于数据中心内部的机器而言，将它调整为 2s 足以：</p>
<blockquote>
<p>net.ipv4.tcp_fin_timeout &#x3D; 2</p>
</blockquote>
<p>TIME_WAIT 状态存在的意义是：最后发送的这个 ACK 包可能会被丢弃掉或者有延迟，这样对端就会再次发送 FIN 包。如果不维持 TIME_WAIT 这个状态，那么再次收到对端的 FIN 包后，本端就会回一个 Reset 包，这可能会产生一些异常。</p>
<p><img src="/images/oss/9fbe15fa8b913ba76048f3b2ad2b923a.png" alt="image.png"></p>
<h3 id="为什么握手三次、挥手四次"><a href="#为什么握手三次、挥手四次" class="headerlink" title="为什么握手三次、挥手四次"></a>为什么握手三次、挥手四次</h3><p>这个问题太恶心，面试官太喜欢问，其实大部分面试官只会背诵：因为TCP是双向的，所以关闭需要四次挥手……。</p>
<p>你要是想怼面试官的话可以问他握手也是双向的但是只需要三次呢？</p>
<p>我也不知道怎么回答。网上都说tcp是双向的，所以断开要四次。但是我认为建连接也是双向的（双向都协调告知对方自己的seq号），为什么不需要四次握手呢，所以网上说的不一定精准。</p>
<p>你再看三次握手的第二步发 syn+ack，如果拆分成两步先发ack再发syn完全也是可以的（效率略低），这样三次握手也变成四次握手了。</p>
<p>看起来挥手的时候多一次，主要是收到第一个fin包后单独回复了一个ack包，如果能回复fin+ack那么四次挥手也就变成三次了。 来看一个案例：</p>
<p><img src="/images/oss/9db33f9304f8236b1ebcb215064bb2af.png" alt="image.png"></p>
<p>图中第二个红框就是回复的fin+ack，这样四次挥手变成三次了（如果一个包就是一次的话）。</p>
<p>我的理解：之所以绝大数时候我们看到的都是四次挥手，是因为收到fin后，知道对方要关闭了，然后OS通知应用层要关闭，这里应用层可能需要做些准备工作，可能还有数据没发送完，所以内核先回ack，等应用准备好了主动调close时再发fin 。 握手过程没有这个准备过程所以可以立即发送syn+ack（把这里的两步合成一步了）。 内核收到对方的fin后，只能ack，不能主动替应用来fin，因为他不清楚应用能不能关闭。</p>
<h3 id="ack-seq-len"><a href="#ack-seq-len" class="headerlink" title="ack&#x3D;seq+len"></a>ack&#x3D;seq+len</h3><p>ack总是seq+len（包的大小），这样发送方明确知道server收到那些东西了</p>
<p>但是特例是三次握手和四次挥手，虽然len都是0，但是syn和fin都要占用一个seq号，所以这里的ack都是seq+1</p>
<p><img src="/images/oss/45c6d36ce8b17a5c0442e66fce002ab4.png" alt="image.png"></p>
<p>看图中左边红框里的len+seq就是接收方回复的ack的数字，表示这个包接收方收到了。然后下一个包的seq就是前一个包的len+seq，依次增加，一旦中间发出去的东西没有收到ack就是丢包了，过一段时间（或者其他方式）触发重传，保障了tcp传输的可靠性。</p>
<h3 id="三次握手中协商的其它信息"><a href="#三次握手中协商的其它信息" class="headerlink" title="三次握手中协商的其它信息"></a>三次握手中协商的其它信息</h3><p>MSS 最大一个包中能传输的信息（不含tcp、ip包头），MSS+包头就是MTU（最大传输单元），如果MTU过大可能在传输的过程中被卡住过不去造成卡死（这个大小的包一直传输不过去），跟丢包还不一样</p>
<p>MSS的问题具体可以看我这篇文章： <a target="_blank" rel="noopener" href="https://www.atatech.org/articles/60633">scp某个文件的时候卡死问题的解决过程</a></p>
<p>SACK_PERM 用于丢包的话提升重传效率，比如client一次发了1、2、3、4、5 这5个包给server，实际server收到了 1、3、4、5这四个包，中间2丢掉了。这个时候server回复ack的时候，都只能回复2，表示2前面所有的包都收到了，给我发第二个包吧，如果server 收到3、4、5还是没有收到2的话，也是回复ack 2而不是回复ack 3、4、5、6的，表示快点发2过来。</p>
<p>但是这个时候client虽然知道2丢了，然后会重发2，但是不知道3、4、5有没有丢啊，实际3、4、5 server都收到了，如果支持sack，那么可以ack 2的时候同时告诉client 3、4、5都收到了，这样client重传的时候只重传2就可以，如果没有sack的话那么可能会重传2、3、4、5，这样效率就低了。</p>
<p>来看一个例子：</p>
<p><img src="/images/oss/5322d0cf77a3a1ae6c87a972cc5843d0.png" alt="image.png"></p>
<p>图中的红框就是SACK。</p>
<p>知识点：ack数字表示这个数字前面的数据<strong>都</strong>收到了</p>
<h2 id="TIME-WAIT-和-CLOSE-WAIT"><a href="#TIME-WAIT-和-CLOSE-WAIT" class="headerlink" title="TIME_WAIT 和 CLOSE_WAIT"></a>TIME_WAIT 和 CLOSE_WAIT</h2><p>假设服务端和客户端跑在同一台机器上，服务端监听在 18080端口上，客户端使用18089端口建立连接。</p>
<p>如果client主动断开连接那么就会看到client端的连接在 TIME_WAIT：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># netstat -ant |grep 1808</span><br><span class="line">tcp        0      0 0.0.0.0:18080           0.0.0.0:*               LISTEN      </span><br><span class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:18080      TIME_WAIT </span><br></pre></td></tr></table></figure>

<p>如果Server主动断开连接(也就是18080）那么就会看到client端的连接在CLOSE_WAIT 而Server在FIN_WAIT2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># netstat -ant |grep 1808</span><br><span class="line">tcp    0      0 192.168.1.79:18080      192.168.1.79:18089      FIN_WAIT2  --&lt;&lt; server</span><br><span class="line">tcp    0      0 192.168.1.79:18089      192.168.1.79:18080      CLOSE_WAIT --&lt;&lt; client</span><br></pre></td></tr></table></figure>

<p><strong>TIME_WAIT是主动断连方出现的状态（ 2MSL）</strong></p>
<h3 id="被动关闭方收到fin后有两种选择"><a href="#被动关闭方收到fin后有两种选择" class="headerlink" title="被动关闭方收到fin后有两种选择"></a>被动关闭方收到fin后有两种选择</h3><p>如下描述是server端主动关闭的情况</p>
<p>1 如果client也立即断开，那么Server的这个连接会进入 TIME_WAIT状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># netstat -ant |grep 1808</span><br><span class="line">tcp    0      0 0.0.0.0:18080           0.0.0.0:*            LISTEN  --&lt;&lt; server还在  </span><br><span class="line">tcp    0      0 192.168.1.79:18080      192.168.1.79:18089   TIME_WAIT --&lt;&lt; server</span><br></pre></td></tr></table></figure>

<p>2 client 坚持不断开过 Server 一段时间后（3.10：net.netfilter.nf_conntrack_tcp_timeout_fin_wait &#x3D; 120， 4.19：net.ipv4.tcp_fin_timeout &#x3D; 15）会结束这个连接但是client还是会 在CLOSE_WAIT 直到client进程退出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># netstat -ant |grep 1808</span><br><span class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:18080      CLOSE_WAIT </span><br></pre></td></tr></table></figure>

<h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE_WAIT"></a>CLOSE_WAIT</h3><p><strong>CLOSE_WAIT是被动关闭端在等待应用进程的关闭</strong></p>
<p>通常，CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：</p>
<ul>
<li><strong>程序问题</strong>：如果代码层面忘记了 close 相应的 socket 连接，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。</li>
<li>响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。</li>
<li>BACKLOG 太大：此处的 backlog 不是 syn backlog，而是 accept 的 backlog，如果 backlog 太大的话，设想突然遭遇大访问量的话，即便响应速度不慢，也可能出现来不及消费的情况，导致多余的请求还在<a target="_blank" rel="noopener" href="http://jaseywang.me/2014/07/20/tcp-queue-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/">队列</a>里就被对方关闭了。</li>
</ul>
<p>如果你通过「netstat -ant」或者「ss -ant」命令发现了很多 CLOSE_WAIT 连接，请注意结果中的「Recv-Q」和「Local Address」字段，通常「Recv-Q」会不为空，它表示应用还没来得及接收数据，而「Local Address」表示哪个地址和端口有问题，我们可以通过「lsof -i:<PORT>」来确认端口对应运行的是什么程序以及它的进程号是多少。</p>
<p>如果是我们自己写的一些程序，比如用 HttpClient 自定义的蜘蛛，那么八九不离十是程序问题，如果是一些使用广泛的程序，比如 Tomcat 之类的，那么更可能是响应速度太慢或者 timeout 设置太小或者 BACKLOG 设置过大导致的故障。</p>
<h4 id="server端大量close-wait案例"><a href="#server端大量close-wait案例" class="headerlink" title="server端大量close_wait案例"></a>server端大量close_wait案例</h4><p>看了这么多理论，下面用个案例来检查自己对close_wait理论（tcp握手本质）的掌握。同时也可以看看自己从知识到问题的推理能力（跟文章最后的知识效率呼应一下）。</p>
<p>问题描述：</p>
<blockquote>
<p>服务端出现大量CLOSE_WAIT 个数正好 等于somaxconn（调整somaxconn后 CLOSE_WAIT 也会跟着变成一样的值）</p>
</blockquote>
<p>根据这个描述先不要往下看，自己推理分析下可能的原因。</p>
<p>我的推理如下：</p>
<p>从这里看起来，client跟server成功建立了somaxconn个连接（somaxconn小于backlog，所以accept queue只有这么大），但是应用没有accept这个连接，导致这些连接一直在accept queue中。但是这些连接的状态已经是ESTABLISHED了，也就是client可以发送数据了，数据发送到server后OS ack了，并放在os的tcp buffer中，应用一直没有accept也就没法读取数据。client于是发送fin（可能是超时、也可能是简单发送数据任务完成了得结束连接），这时Server上这个连接变成了CLOSE_WAIT .</p>
<p>也就是从开始到结束这些连接都在accept queue中，没有被应用accept，很快他们又因为client 发送 fin 包变成了CLOSE_WAIT ，所以始终看到的是服务端出现大量CLOSE_WAIT 并且个数正好等于somaxconn（调整somaxconn后 CLOSE_WAIT 也会跟着变成一样的值）。</p>
<p>如下图所示，在连接进入accept queue后状态就是ESTABLISED了，也就是可以正常收发数据和fin了。client是感知不到server是否accept()了，只是发了数据后server的os代为保存在OS的TCP buffer中，因为应用没来取自然在CLOSE_WAIT 后应用也没有close()，所以一直维持CLOSE_WAIT 。</p>
<p>得检查server 应用为什么没有accept。</p>
<p><img src="/images/oss/2703fc07dfc4dd5b6e1bb4c2ce620e59.png" alt="image.png"></p>
<p>结论：</p>
<blockquote>
<p>这个case的最终原因是因为<strong>OS的open files设置的是1024,达到了上限</strong>，进而导致server不能accept，但这个时候的tcp连接状态已经是ESTABLISHED了（这个状态变换是取决于内核收发包，跟应用是否accept()无关）。</p>
<p>同时从这里可以推断 netstat 即使看到一个tcp连接状态是ESTABLISHED也不能代表占用了 open files句柄。此时client可以正常发送数据了，只是应用服务在accept之前没法receive数据和close连接。</p>
</blockquote>
<h2 id="TCP连接状态图"><a href="#TCP连接状态图" class="headerlink" title="TCP连接状态图"></a>TCP连接状态图</h2><p><img src="/images/oss/b3d075782450b0c8d2615c5d2b75d923.png" alt="image.png"></p>
<h2 id="总结下"><a href="#总结下" class="headerlink" title="总结下"></a>总结下</h2><p>tcp所有特性基本上核心都是为了<strong>可靠传输</strong>这个目标来服务的，然后有一些是出于优化性能的目的</p>
<p>三次握手建连接的详细过程可以参考我这篇： <a target="_blank" rel="noopener" href="https://www.atatech.org/articles/78858">关于TCP 半连接队列和全连接队列</a></p>
<p>后续希望再通过几个案例来深化一下上面的知识。</p>
<hr>
<p>为什么要案例来深化一下上面的知识，说点关于学习的题外话</p>
<h2 id="什么是工程效率，什么是知识效率"><a href="#什么是工程效率，什么是知识效率" class="headerlink" title="什么是工程效率，什么是知识效率"></a>什么是工程效率，什么是知识效率</h2><p>有些人纯看理论就能掌握好一门技能，还能举三反一，这是知识效率，这种人非常少；</p>
<p>大多数普通人都是看点知识然后结合实践来强化理解理论，要经过反反复复才能比较好地掌握一个知识，这就是工程效率，讲究技巧、工具来达到目的。</p>
<p>对于费曼（参考费曼学习法）这样的聪明人就是很容易看到一个理论知识就能理解这个理论知识背后的本质。</p>
<p>肯定知识效率最牛逼，但是拥有这种能力的人毕竟非常少。从小我们周边那种不怎么学的学霸型基本都是这类，这种学霸都还能触类旁通非常快地掌握一个新知识。剩下的绝大部分只能拼时间(刷题)+方法+总结等也能掌握一些知识</p>
<p>非常遗憾我就是工程效率型，只能羡慕那些知识效率型的学霸。但是这事又不能独立看待有些人在某些方向上是工程效率型，有些方向就又是知识效率型（有一种知识效率型是你掌握的实在太多也就比较容易触类旁通了，这算灰色知识效率型）</p>
<p>使劲挖掘自己在知识效率型方面的能力吧，即使灰色地带也行啊。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--wireshark-dup-ack-issue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--wireshark-dup-ack-issue/" class="post-title-link" itemprop="url">就是要你懂TCP--wireshark-dup-ack-issue</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-02 15:30:03" itemprop="dateCreated datePublished" datetime="2017-06-02T15:30:03+08:00">2017-06-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TCP/" itemprop="url" rel="index"><span itemprop="name">TCP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="就是要你懂TCP–wireshark-dup-ack-issue"><a href="#就是要你懂TCP–wireshark-dup-ack-issue" class="headerlink" title="就是要你懂TCP–wireshark-dup-ack-issue"></a>就是要你懂TCP–wireshark-dup-ack-issue</h1><h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><p>很多同学学会抓包后，经常拿着这样一个抓包来问我是怎么回事：</p>
<p>在wireshark中看到一个tcp会话中的两台机器突然一直互相发dup ack包，但是没有触发重传。每次重复ack都是间隔精确的20秒</p>
<h2 id="如下截图："><a href="#如下截图：" class="headerlink" title="如下截图："></a>如下截图：</h2><p><img src="/images/951413iMgBlog/bm3W68Q.png"></p>
<p>client都一直在回复收到2号包（ack&#x3D;2）了，可是server跟傻了一样居然还发seq&#x3D;1的包（按理，应该发比2大的包啊）</p>
<h2 id="系统配置："><a href="#系统配置：" class="headerlink" title="系统配置："></a>系统配置：</h2><pre><code>net.ipv4.tcp_keepalive_time = 20
net.ipv4.tcp_keepalive_probes = 5
net.ipv4.tcp_keepalive_intvl = 3
</code></pre>
<h2 id="原因："><a href="#原因：" class="headerlink" title="原因："></a>原因：</h2><p>抓包不全的话wireshark有缺陷，把keepalive包识别成了dup ack包，看内容这种dup ack和keepalive似乎是一样的，flags都是0x010。keep alive的定义的是后退一格(seq少1）。</p>
<p>2、4、6、8……号包，都有一个“tcp acked unseen segment”。这个一般表示它ack的这个包，没有被抓到。Wirshark如何作出此判断呢？前面一个包是seq&#x3D;1, len&#x3D;0，所以正常情况下是ack &#x3D; seq + len &#x3D; 1，然而Wireshark看到的确是ack &#x3D; 2, 它只能判断有一个seq &#x3D;1, len &#x3D; 1的包没有抓到。<br>dup ack也是类似道理，这些包完全符合dup ack的定义，因为“ack &#x3D; ” 某个数连续多次出现了。</p>
<p>这一切都是因为keep alive的特殊性导致的。打开66号包的tcp层（见后面的截图），可以看到它的 next sequence number &#x3D; 12583，表示正常情况下server发出的下一个包应该是seq &#x3D; 12583。可是在下一个包，也就是68号包中，却是seq &#x3D; 12582。keep alive的定义的确是这样，即后退一格。<br>Wireshark只有在抓到数据包（66号包）和keep alive包的情况下才有可能正确识别，前面的抓包中恰好在keep alive之前丢失了数据包，所以Wireshark就蒙了。</p>
<h2 id="构造重现"><a href="#构造重现" class="headerlink" title="构造重现"></a>构造重现</h2><p>如果用“frame.number &gt;&#x3D; 68” 过滤这个包，然后File–&gt;export specified packets保存成一个新文件，再打开那个新文件，就会发现Wireshark又蒙了。本来能够正常识别的keep alive包又被错看成dup ack了，所以一旦碰到这种情况不要慌要稳</p>
<p>下面是知识点啦</p>
<h2 id="Keepalive"><a href="#Keepalive" class="headerlink" title="Keepalive"></a>Keepalive</h2><p>TCP报文接收方必须回复的场景：</p>
<p>TCP携带字节数据<br>没有字节数据，携带SYN状态位<br>没有字节数据，携带FIN状态位</p>
<p>keepalive 提取历史发送的最后一个字节，充当心跳字节数据，依然使用该字节的最初序列号。也就是前面所说的seq回退了一个</p>
<p>对方收到后因为seq小于TCP滑动窗口的左侧，被判定为duplicated数据包，然后扔掉了，并回复一个duplicated ack</p>
<p>所以keepalive跟duplicated本质是一回事，就看wireshark能够正确识别了。</p>
<h2 id="Duplication-ack是指："><a href="#Duplication-ack是指：" class="headerlink" title="Duplication ack是指："></a>Duplication ack是指：</h2><p>server收到了3和8号包，但是没有收到中间的4&#x2F;5&#x2F;6&#x2F;7，那么server就会ack 3，如果client还是继续发8&#x2F;9号包，那么server会继续发dup ack 3#1 ; dup ack 3#2 来向客户端说明只收到了3号包，不要着急发后面的大包，把4&#x2F;5&#x2F;6&#x2F;7给我发过来</p>
<h2 id="TCP-Window-Update"><a href="#TCP-Window-Update" class="headerlink" title="TCP Window Update"></a>TCP Window Update</h2><p><img src="/images/oss/1558941016099-bc4504f1-e9c7-4d84-85e1-a7f5c6554306.png"></p>
<p>如上图，当接收方的tcp Window Size不足一个MSS的时候，为了避免 Silly Window Syndrome，Client不再发小包，而是发送探测包（跟keepalive一样，发一个回退一格的包，触发server ack同时server ack的时候会带过来新的window size）探测包间隔时间是200&#x2F;400&#x2F;800&#x2F;1600……ms这样</p>
<h2 id="正常的keep-alive-Case："><a href="#正常的keep-alive-Case：" class="headerlink" title="正常的keep-alive Case："></a>正常的keep-alive Case：</h2><p><img src="/images/951413iMgBlog/DsTWFZr.png"></p>
<p>keep-alive 通过发一个比实际seq小1的包，比如server都已经 ack 12583了，client故意发一个seq 12582来标识这是一个keep-Alive包</p>
<h2 id="Duplication-ack是指：-1"><a href="#Duplication-ack是指：-1" class="headerlink" title="Duplication ack是指："></a>Duplication ack是指：</h2><p>server收到了3和8号包，但是没有收到中间的4&#x2F;5&#x2F;6&#x2F;7，那么server就会ack 3，如果client还是继续发8&#x2F;9号包，那么server会继续发dup ack 3#1 ; dup ack 3#2 来向客户端说明只收到了3号包，不要着急发后面的大包，把4&#x2F;5&#x2F;6&#x2F;7给我发过来</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/03/24/docker%20swarm%E7%9A%84Label%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/24/docker%20swarm%E7%9A%84Label%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">docker、swarm的Label使用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-24 17:30:03" itemprop="dateCreated datePublished" datetime="2017-03-24T17:30:03+08:00">2017-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="docker、swarm的Label使用"><a href="#docker、swarm的Label使用" class="headerlink" title="docker、swarm的Label使用"></a>docker、swarm的Label使用</h1><h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><p>广发银行需要把方舟集群部署在多个机房（多个机房组成一个大集群），这样物理机和容器vlan没法互相完全覆盖，</p>
<p>也就是可能会出现A机房的网络subnet:192.168.1.0&#x2F;24, B 机房的网络subnet：192.168.100.0&#x2F;24 但是他们属于同一个vlan，要求如果容器在A机房的物理机拉起，分到的是192.168.1.0&#x2F;24中的IP，B机房的容器分到的IP是：192.168.100.0&#x2F;24</p>
<p><strong>功能实现：</strong></p>
<ul>
<li><strong>本质就是对所有物理机打标签，同一个asw下的物理机用同样的标签，不同asw下的物理机标签不同；</strong></li>
<li><strong>创建容器网络的时候也加标签，不同asw下的网络标签不一样，同时跟这个asw下的物理机标签匹配；</strong></li>
<li><strong>创建容器的时候使用 –net&#x3D;driver:vlan 来动态选择多个vlan网络中的任意一个，然后swarm根据网络的标签要和物理机的标签一致，从而把容器调度到正确的asw下的物理机上。</strong></li>
</ul>
<p><strong>分为如下三个改造点</strong></p>
<p><strong>1：</strong></p>
<p>daemon启动的时候增加标签（其中一个就行）：</p>
<table>
<thead>
<tr>
<th>上联交换机组的名称，多个逗号隔开</th>
<th>com.alipay.acs.engine.asw.hostname</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><strong>2：</strong><br>创建网络的时候使用对应的标签：</p>
<table>
<thead>
<tr>
<th>网络域交换机组asw列表的名称，多个逗号隔开</th>
<th>com.alipay.acs.network.asw.hostname</th>
</tr>
</thead>
<tbody><tr>
<td>该VLAN网络是否必须显式指定，默认为0即不必须，此时当传入–net driver:vlan时ACS会根据调度结果自行选择一个可用的VLAN网络并拼装到参数中</td>
<td>com.alipay.acs.network.explicit</td>
</tr>
</tbody></table>
<p><strong>3：</strong></p>
<p>Swarm manager增加可选启动选项netarch.multiscope，值为true</p>
<h3 id="功能实现逻辑"><a href="#功能实现逻辑" class="headerlink" title="功能实现逻辑"></a>功能实现逻辑</h3><ol>
<li>Swarm manager增加可选启动选项netarch.multiscope，当为1时，network create时强制要求必须指定label描述配置VLAN的ASW信息</li>
<li>Swarm manager在创建容器时检查网络类型，VLAN网络时则将网络ASW的label放入过滤器中，在调度时按照机器的ASW标签过滤</li>
<li>如果使用者如果不关心具体使用哪个VLAN，则可以指定–net&#x3D;”driver:vlan”，会自动查找driver&#x3D;vlan的network，并根据调度结果（Node所关联的ASW）自动选择合适的network填入Config.HostConfig.NetworkMode传递给Docker daemon.</li>
</ol>
<p>如果是现存的环境，修改zk来更新网络标签：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 21] get /Cluster/docker/network/v1.0/network/c79e533e4444294ac9cb7838608115c961c6e403d3610367ff4b197ef6b981fc </span><br><span class="line">&#123;&quot;addrSpace&quot;:&quot;GlobalDefault&quot;,&quot;enableIPv6&quot;:false,&quot;generic&quot;:&#123;&quot;com.docker.network.enable_ipv6&quot;:false,&quot;com.docker.network.generic&quot;:&#123;&quot;VlanId&quot;:&quot;192&quot;&#125;&#125;,&quot;id&quot;:&quot;c79e533e4444294ac9cb7838608115c961c6e403d3610367ff4b197ef6b981fc&quot;,&quot;inDelete&quot;:false,&quot;internal&quot;:false,&quot;ipamOptions&quot;:&#123;&quot;VlanId&quot;:&quot;192&quot;&#125;,&quot;ipamType&quot;:&quot;default&quot;,&quot;ipamV4Config&quot;:&quot;[&#123;\&quot;PreferredPool\&quot;:\&quot;192.168.8.0/24\&quot;,\&quot;SubPool\&quot;:\&quot;\&quot;,\&quot;Gateway\&quot;:\&quot;192.168.8.1\&quot;,\&quot;AuxAddresses\&quot;:null&#125;]&quot;,&quot;ipamV4Info&quot;:&quot;[&#123;\&quot;IPAMData\&quot;:\&quot;&#123;\\\&quot;AddressSpace\\\&quot;:\\\&quot;\\\&quot;,\\\&quot;Gateway\\\&quot;:\\\&quot;192.168.8.1/24\\\&quot;,\\\&quot;Pool\\\&quot;:\\\&quot;192.168.8.0/24\\\&quot;&#125;\&quot;,\&quot;PoolID\&quot;:\&quot;GlobalDefault/192.168.8.0/24\&quot;&#125;]&quot;,&quot;labels&quot;:&#123;&#125;,&quot;name&quot;:&quot;vlan192-8&quot;,&quot;networkType&quot;:&quot;vlan&quot;,&quot;persist&quot;:true,&quot;postIPv6&quot;:false,&quot;scope&quot;:&quot;global&quot;&#125;</span><br><span class="line">cZxid = 0x4100008cce</span><br><span class="line">ctime = Fri Mar 09 12:46:44 CST 2018</span><br><span class="line">mZxid = 0x4100008cce</span><br><span class="line">mtime = Fri Mar 09 12:46:44 CST 2018</span><br><span class="line">pZxid = 0x4100008cce</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 716</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>

<p>&#x2F;&#x2F;注意上面的网络还没有标签，修改如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 28] set /Cluster/docker/network/v1.0/network/c79e533e4444294ac9cb7838608115c961c6e403d3610367ff4b197ef6b981fc &#123;&quot;addrSpace&quot;:&quot;GlobalDefault&quot;,&quot;enableIPv6&quot;:false,&quot;generic&quot;:&#123;&quot;com.docker.network.enable_ipv6&quot;:false,&quot;com.docker.network.generic&quot;:&#123;&quot;VlanId&quot;:&quot;192&quot;&#125;&#125;,&quot;id&quot;:&quot;c79e533e4444294ac9cb7838608115c961c6e403d3610367ff4b197ef6b981fc&quot;,&quot;inDelete&quot;:false,&quot;internal&quot;:false,&quot;ipamOptions&quot;:&#123;&quot;VlanId&quot;:&quot;192&quot;&#125;,&quot;ipamType&quot;:&quot;default&quot;,&quot;ipamV4Config&quot;:&quot;[&#123;\&quot;PreferredPool\&quot;:\&quot;192.168.8.0/24\&quot;,\&quot;SubPool\&quot;:\&quot;\&quot;,\&quot;Gateway\&quot;:\&quot;192.168.8.1\&quot;,\&quot;AuxAddresses\&quot;:null&#125;]&quot;,&quot;ipamV4Info&quot;:&quot;[&#123;\&quot;IPAMData\&quot;:\&quot;&#123;\\\&quot;AddressSpace\\\&quot;:\\\&quot;\\\&quot;,\\\&quot;Gateway\\\&quot;:\\\&quot;192.168.8.1/24\\\&quot;,\\\&quot;Pool\\\&quot;:\\\&quot;192.168.8.0/24\\\&quot;&#125;\&quot;,\&quot;PoolID\&quot;:\&quot;GlobalDefault/192.168.8.0/24\&quot;&#125;]&quot;,**&quot;labels&quot;:&#123;&quot;com.alipay.acs.network.asw.hostname&quot;:&quot;238&quot;&#125;,**&quot;name&quot;:&quot;vlan192-8&quot;,&quot;networkType&quot;:&quot;vlan&quot;,&quot;persist&quot;:true,&quot;postIPv6&quot;:false,&quot;scope&quot;:&quot;global&quot;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>example：</p>
<p>创建网络：&#x2F;&#x2F;–label&#x3D;”com.alipay.acs.network.asw.hostname&#x3D;vlan902-63”<br>docker network create -d vlan –label&#x3D;”com.alipay.acs.network.asw.hostname&#x3D;vlan902-63” –subnet&#x3D;11.162.63.0&#x2F;24  –gateway&#x3D;11.162.63.247  –opt VlanId&#x3D;902 –ipam-opt VlanId&#x3D;902 hanetwork2<br>跟daemon中的标签：com.alipay.acs.engine.asw.hostname&#x3D;vlan902-63 对应，匹配调度</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$sudo cat /etc/docker/daemon.json</span><br><span class="line">&#123;&quot;labels&quot;:[&quot;com.alipay.acs.engine.hostname=11.239.142.46&quot;,&quot;com.alipay.acs.engine.ip=11.239.142.46&quot;,&quot;com.alipay.acs.engine.device_type=Server&quot;,&quot;com.alipay.acs.engine.status=free&quot;,&quot;ark.network.vlan.range=vlan902-63&quot;,&quot;com.alipay.acs.engine.asw.hostname=vlan902-63&quot;,&quot;com.alipay.acs.network.asw.hostname=vlan902-63&quot;]&#125;</span><br><span class="line">//不指定具体网络，有多个网络的时候自动调度  --net driver:vlan 必须是network打过标签了</span><br><span class="line">docker run -d -it --name=&quot;udp10&quot; --net driver:vlan --restart=always reg.docker.alibaba-inc.com/middleware.udp </span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/03/24/docker%20daemon%E6%B7%BB%E5%8A%A0label/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/24/docker%20daemon%E6%B7%BB%E5%8A%A0label/" class="post-title-link" itemprop="url">如何手动为docker daemon添加label</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-24 17:30:03" itemprop="dateCreated datePublished" datetime="2017-03-24T17:30:03+08:00">2017-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="如何手动为docker-daemon添加label"><a href="#如何手动为docker-daemon添加label" class="headerlink" title="如何手动为docker daemon添加label"></a>如何手动为docker daemon添加label</h1><ol>
<li><p>编辑或创建&#x2F;etc&#x2F;docker&#x2F;daemon.json</p>
</li>
<li><p>将一个或多个lable以json格式写入文件，示例如下</p>
</li>
</ol>
  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 为docker分配两个label，分别是nodetype和red</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;nodetype=dbpaas&quot;</span><span class="punctuation">,</span> <span class="string">&quot;color=red&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>重启docker daemon</li>
</ol>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker restart</span><br></pre></td></tr></table></figure>

<p>4 &#x2F;etc&#x2F;docker&#x2F;daemon.json 参考</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;api-cors-header&quot;: &quot;&quot;,</span><br><span class="line">    &quot;authorization-plugins&quot;: [],</span><br><span class="line">    &quot;bip&quot;: &quot;&quot;,</span><br><span class="line">    &quot;bridge&quot;: &quot;&quot;,</span><br><span class="line">    &quot;cgroup-parent&quot;: &quot;&quot;,</span><br><span class="line">    &quot;cluster-store&quot;: &quot;&quot;,</span><br><span class="line">    &quot;cluster-store-opts&quot;: &#123;&#125;,</span><br><span class="line">    &quot;cluster-advertise&quot;: &quot;&quot;,</span><br><span class="line">    &quot;debug&quot;: true,</span><br><span class="line">    &quot;default-gateway&quot;: &quot;&quot;,</span><br><span class="line">    &quot;default-gateway-v6&quot;: &quot;&quot;,</span><br><span class="line">    &quot;default-runtime&quot;: &quot;runc&quot;,</span><br><span class="line">    &quot;default-ulimits&quot;: &#123;&#125;,</span><br><span class="line">    &quot;disable-legacy-registry&quot;: false,</span><br><span class="line">    &quot;dns&quot;: [],</span><br><span class="line">    &quot;dns-opts&quot;: [],</span><br><span class="line">    &quot;dns-search&quot;: [],</span><br><span class="line">    &quot;exec-opts&quot;: [],</span><br><span class="line">    &quot;exec-root&quot;: &quot;&quot;,</span><br><span class="line">    &quot;fixed-cidr&quot;: &quot;&quot;,</span><br><span class="line">    &quot;fixed-cidr-v6&quot;: &quot;&quot;,</span><br><span class="line">    &quot;graph&quot;: &quot;&quot;,</span><br><span class="line">    &quot;group&quot;: &quot;&quot;,</span><br><span class="line">    &quot;hosts&quot;: [],</span><br><span class="line">    &quot;icc&quot;: false,</span><br><span class="line">    &quot;insecure-registries&quot;: [],</span><br><span class="line">    &quot;ip&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">    &quot;iptables&quot;: false,</span><br><span class="line">    &quot;ipv6&quot;: false,</span><br><span class="line">    &quot;ip-forward&quot;: false,</span><br><span class="line">    &quot;ip-masq&quot;: false,</span><br><span class="line">    &quot;labels&quot;: [&quot;nodetype=drds-server&quot;, &quot;ark.ip=11.239.155.83&quot;],</span><br><span class="line">    &quot;live-restore&quot;: true,</span><br><span class="line">    &quot;log-driver&quot;: &quot;&quot;,</span><br><span class="line">    &quot;log-level&quot;: &quot;&quot;,</span><br><span class="line">    &quot;log-opts&quot;: &#123;&#125;,</span><br><span class="line">    &quot;max-concurrent-downloads&quot;: 3,</span><br><span class="line">    &quot;max-concurrent-uploads&quot;: 5,</span><br><span class="line">    &quot;mtu&quot;: 0,</span><br><span class="line">    &quot;oom-score-adjust&quot;: -500,</span><br><span class="line">    &quot;pidfile&quot;: &quot;&quot;,</span><br><span class="line">    &quot;raw-logs&quot;: false,</span><br><span class="line">    &quot;registry-mirrors&quot;: [],</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;runc&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;runc&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;custom&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/usr/local/bin/my-runc-replacement&quot;,</span><br><span class="line">            &quot;runtimeArgs&quot;: [</span><br><span class="line">                &quot;--debug&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;selinux-enabled&quot;: false,</span><br><span class="line">    &quot;storage-driver&quot;: &quot;&quot;,</span><br><span class="line">    &quot;storage-opts&quot;: [],</span><br><span class="line">    &quot;swarm-default-advertise-addr&quot;: &quot;&quot;,</span><br><span class="line">    &quot;tls&quot;: true,</span><br><span class="line">    &quot;tlscacert&quot;: &quot;&quot;,</span><br><span class="line">    &quot;tlscert&quot;: &quot;&quot;,</span><br><span class="line">    &quot;tlskey&quot;: &quot;&quot;,</span><br><span class="line">    &quot;tlsverify&quot;: true,</span><br><span class="line">    &quot;userland-proxy&quot;: false,</span><br><span class="line">    &quot;userns-remap&quot;: &quot;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Daemon.json 指定 ulimit等参考</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;data-root&quot;: &quot;/var/lib/docker&quot;,</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;200m&quot;,</span><br><span class="line">    &quot;max-file&quot;: &quot;5&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;default-ulimits&quot;: &#123;</span><br><span class="line">    &quot;nofile&quot;: &#123;</span><br><span class="line">      &quot;Name&quot;: &quot;nofile&quot;,</span><br><span class="line">      &quot;Hard&quot;: 655360,</span><br><span class="line">      &quot;Soft&quot;: 655360</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;nproc&quot;: &#123;</span><br><span class="line">      &quot;Name&quot;: &quot;nproc&quot;,</span><br><span class="line">      &quot;Hard&quot;: 655360,</span><br><span class="line">      &quot;Soft&quot;: 655360</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;live-restore&quot;: true,</span><br><span class="line">  &quot;oom-score-adjust&quot;: -1000,</span><br><span class="line">  &quot;max-concurrent-downloads&quot;: 10,</span><br><span class="line">  &quot;max-concurrent-uploads&quot;: 10,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;storage-opts&quot;: [&quot;overlay2.override_kernel_check=true&quot;],</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://yssx4sxy.mirror.aliyuncs.com/&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/03/24/%E6%96%B9%E8%88%9F%E7%8E%AF%E5%A2%83%E5%AE%B9%E5%99%A8%E8%B0%83%E5%BA%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/24/%E6%96%B9%E8%88%9F%E7%8E%AF%E5%A2%83%E5%AE%B9%E5%99%A8%E8%B0%83%E5%BA%A6/" class="post-title-link" itemprop="url">方舟环境容器调度</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-24 17:30:03" itemprop="dateCreated datePublished" datetime="2017-03-24T17:30:03+08:00">2017-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/docker/" itemprop="url" rel="index"><span itemprop="name">docker</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="方舟环境容器调度"><a href="#方舟环境容器调度" class="headerlink" title="方舟环境容器调度"></a>方舟环境容器调度</h1><h2 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h2><ul>
<li>恢复宿主机死机或者断网后上面需要调度的所有容器</li>
<li>恢复非正常的容器状态到正常</li>
<li>调度的容器能够支持vlan网络和Host模式</li>
<li>调度容器本身通过Leader-Follower的模式保证高可用性</li>
<li>调度容器支持cron定时任务（精确到秒级）</li>
<li>查询哪个节点是Leader</li>
<li>停止或者打开调度（方便容器维护、正常启停）</li>
</ul>
<h2 id="通过-ark-schedule-镜像启动调度"><a href="#通过-ark-schedule-镜像启动调度" class="headerlink" title="通过 ark-schedule 镜像启动调度"></a>通过 ark-schedule 镜像启动调度</h2><p>必须在swarm manager节点上以 docker 容器的方式来启动，下面的 -e 参数对应后面的 export 参数和作用注释</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart=always --name=ark-schedule -e ACS_CLUSTER_SECURITY_GROUP=false -e ACS_CLUSTER_SCHEME=tcp -e ACS_CLUSTER_ENDPOINT=11.239.155.112:3376 -e ACS_NETWORK_NAME=vlan701 -e ACS_CRONTAB=&quot;7 * * * * *&quot; -e ACS_PORT=3375 -e ACS_ADVERTISE=11.239.155.112:3375 -e ACS_NETWORK_STORE_CLUSTER=zk://11.239.155.112:2181,11.239.155.103:2181,11.239.155.97:2181/Cluster -e affinity:container==swarm-manager --net=host reg.docker.alibaba-inc.com/ark/ark-schedule:0.6-20180530-68e7bed /ark-schedule/ark-schedule --debug start</span><br></pre></td></tr></table></figure>

<p>如果需要调度容器本身高可以用，需要在不同的宿主机上启动多个 ark-schedule 容器， 同时可以给调度容器自己增加调度标签</p>
<h3 id="环境变量参数说明"><a href="#环境变量参数说明" class="headerlink" title="环境变量参数说明"></a>环境变量参数说明</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export ACS_CLUSTER_ENDPOINT=10.125.14.238:3376; //跟自己在同一台宿主机的swarm-manager</span><br><span class="line">export ACS_NETWORK_NAME=vlan192;  //方舟网络名称 docker network ls 看到vlan开头的名字</span><br><span class="line">export ACS_NETWORK_STORE_CLUSTER=zk://10.125.26.108:2181,10.125.14.238:2181,10.125.1.45:2181/Cluster; //方舟zk集群，同部署的ark.properties中的</span><br><span class="line">export ACS_CRONTAB=&quot;*/7 * * * * *&quot; </span><br><span class="line">export ACS_PORT=&quot;3375&quot; //schedule 自身api暴露端口</span><br><span class="line">export ACS_ADVERTISE=&quot;10.125.14.238:3375&quot; //宿主机ip+自身api暴露端口 多个schedule容器唯一</span><br><span class="line">./ark-schedule --debug start</span><br></pre></td></tr></table></figure>

<p>ark-schedule 容器默认占用3375端口，如果要用别的端口需要通过 -e ACS_PORT 参数传入</p>
<p><code>-e ACS_CRONTAB=&quot;7 * * * * *&quot; （秒 分 时 天 月 星期）</code></p>
<p>这个参数如果没有，那么需要外部来触发调度API（见下面）</p>
<p>ACS_ADVERTISE&#x3D;”10.125.26.108:3375”  这个参数是多容器选举用的，每个容器用自己的IP+PORT来标识</p>
<p>容器日志主要在 &#x2F;root&#x2F;logs&#x2F;ark-schedule-container-2017-12-12.log 中， 可以映射到宿主机上，查看更方便</p>
<h3 id="镜像版本"><a href="#镜像版本" class="headerlink" title="镜像版本"></a>镜像版本</h3><p>0.1 带cron功能，自动定时扫描并恢复容器<br>0.2-election 有多个ark-schedule节点选举功能，抢到主的开始cron，没有抢到或者失去主的stop cron<br>0.3-election 在0.2的基础上修复了docker&#x2F;libkv的bug，能够在弱网络、断网的条件下正常运行<br>0.4-switch 增加查询leader节点和cron是否开始的API，增加对Leader的cron启停的API<br>0.5-labels 增加对restart&#x2F;recreate 标签的支持<br>0.6 去掉了对多个zk的支持，简化启动参数<br>0.7 修复了重复endpoint导致的容器的域名不通、inspect notfound（集群多个同名容器的时候）等各种问题</p>
<h2 id="所有需要调度的容器增加调度标志标签"><a href="#所有需要调度的容器增加调度标志标签" class="headerlink" title="所有需要调度的容器增加调度标志标签"></a>所有需要调度的容器增加调度标志标签</h2><p>在docker run中增加一个标签： –label “ark.labels.schedule&#x3D;haproxy”</p>
<p>详细命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker update --label-add=&quot;ark.labels.schedule=haproxy&quot; --label-add=&quot;ark.enable_restart=true&quot; --label-add=&quot;ark.enable_recreate=true&quot; 容器名1 容器名2</span><br></pre></td></tr></table></figure>

<p><strong>上述命令不需要重启容器，但是要重新调snapshot API 做一次快照，让他们生效</strong></p>
<p>ark-schedule容器在调度容器的时候，先检查快照中的容器，如果容器不见了或者状态不是up，又包含如上标签，就会重新在其它机器上把这个容器拉起来</p>
<ul>
<li><p>ark.enable_restart<br>是否允许通过重启来恢复容器（默认是true）。true为可以，false不可以</p>
</li>
<li><p>ark.enable_recreate<br>是否允许将消失的容器在其他宿主机重建（默认是true）。true为可以，false不可以</p>
</li>
</ul>
<h2 id="API-（如下ip：10-125-14-238-在现场换成客户物理机IP）"><a href="#API-（如下ip：10-125-14-238-在现场换成客户物理机IP）" class="headerlink" title="API （如下ip：10.125.14.238 在现场换成客户物理机IP）"></a>API （如下ip：10.125.14.238 在现场换成客户物理机IP）</h2><ol>
<li>中间件部署完毕，并检查无误，调用： curl -v “<a target="_blank" rel="noopener" href="http://10.125.14.238:3375/schedule/snapshot">http://10.125.14.238:3375/schedule/snapshot</a>“ 对中间件做快照，将来会按快照的状态来进行恢复，执行一次就可以</li>
<li>手动恢复容器不见了，调用 curl -v “<a target="_blank" rel="noopener" href="http://10.125.14.238:3375/schedule/snapshot/restore">http://10.125.14.238:3375/schedule/snapshot/restore</a>“ 会将所有异常容器恢复回来</li>
<li>schedule 容器本身的健康检查接口 curl <a target="_blank" rel="noopener" href="http://10.125.14.238:3375/schedule/leader">http://10.125.14.238:3375/schedule/leader</a> http code 值是 200,说明schedule容器是健康的</li>
<li>查询哪个节点是Leader curl 以及是否是停止调度（维护时）： “<a target="_blank" rel="noopener" href="http://10.125.14.238:3375/schedule/leader">http://10.125.14.238:3375/schedule/leader</a>“</li>
<li>停止调度，先查询谁是leader，然后调： “<a target="_blank" rel="noopener" href="http://leader-ip:3375/schedule/stop">http://leader-ip:3375/schedule/stop</a>“</li>
</ol>
<h2 id="维护状态"><a href="#维护状态" class="headerlink" title="维护状态"></a>维护状态</h2><p>通过调度容器API停止调度，所有容器都不再被调度了，维护完毕再调snapshot、start API恢复调度。</p>
<p>如果只想对某个容器进行维护，其它容器还是希望被调度监控、调度可以通过下面的方式来实现：</p>
<p><code>docker update --label-rm=&quot;ark.labels.schedule=haproxy&quot; 容器1 容器2 //还可以跟多个容器名  </code><br><strong>然后调 snapshot API让刚刚的update生效</strong></p>
<p>运维完毕，恢复运维后的容器进入可以调度状态，具体命令如下：</p>
<p><code>docker update --label-add=&quot;ark.labels.schedule=haproxy&quot; 容器1 容器2 //还可以跟多个容器名  </code></p>
<p><strong>然后调 snapshot API让刚刚的update生效</strong></p>
<p><img src="/images/oss/b055cf8f275749491fc768fab1ffd1a5.png" alt="image.png"></p>
<h2 id="升级ark-schedule步骤："><a href="#升级ark-schedule步骤：" class="headerlink" title="升级ark-schedule步骤："></a>升级ark-schedule步骤：</h2><h3 id="下载并导入新镜像"><a href="#下载并导入新镜像" class="headerlink" title="下载并导入新镜像"></a>下载并导入新镜像</h3><p>下载镜像：<a target="_blank" rel="noopener" href="http://fzpackages.oss-cn-shanghai.aliyuncs.com/ark%2Fpatch%2Fark-schedule-0.6-20180530-68e7bed.tgz">http://fzpackages.oss-cn-shanghai.aliyuncs.com/ark%2Fpatch%2Fark-schedule-0.6-20180530-68e7bed.tgz</a><br>sudo docker load -i ark-schedule-0.6-20180530-68e7bed.tgz</p>
<h3 id="停止原来的ark-schedule"><a href="#停止原来的ark-schedule" class="headerlink" title="停止原来的ark-schedule"></a>停止原来的ark-schedule</h3><p>停止两个crontab(新的ark-schedule自带crontab，每分钟执行一次调度)</p>
<p>停止两个ark-schedule容器</p>
<h3 id="启动新的ark-schdule"><a href="#启动新的ark-schdule" class="headerlink" title="启动新的ark-schdule"></a>启动新的ark-schdule</h3><p>在停止的两个ark-schedule的两台机器上启动两个新的ark-schedule容器，启动参数需要修改参考前面的描述(用现场环境信息替换下面的信息)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export ACS_CLUSTER_ENDPOINT=10.125.14.238:3376; //跟自己在同一台宿主机的swarm-manager</span><br><span class="line">export ACS_NETWORK_NAME=vlan192;  //方舟网络名称 docker network ls 看到vlan开头的名字</span><br><span class="line">export ACS_NETWORK_STORE_CLUSTER=zk://10.125.26.108:2181,10.125.14.238:2181,10.125.1.45:2181/Cluster; //方舟zk集群，同部署的ark.properties中的</span><br><span class="line">export ACS_CRONTAB=&quot;*/7 * * * * *&quot;  ----不需要改</span><br><span class="line">export ACS_PORT=&quot;3375&quot; //schedule 自身api暴露端口----不需要改</span><br><span class="line">export ACS_ADVERTISE=&quot;10.125.14.238:3375&quot; //宿主机ip+自身api暴露端口 多个schedule容器唯一</span><br><span class="line">./ark-schedule --debug start //----不需要改</span><br></pre></td></tr></table></figure>

<h2 id="检查调度日志"><a href="#检查调度日志" class="headerlink" title="检查调度日志"></a>检查调度日志</h2><p>检查两个ark-schedule 谁是主： curl <a target="_blank" rel="noopener" href="http://ark-schedule所在的宿主机-ip:3375/schedule/leader">http://ark-schedule所在的宿主机-ip:3375/schedule/leader</a> </p>
<p>进到是主的ark-schedule容器中看日志：cat &#x2F;root&#x2F;logs&#x2F;ark-schedule-2018-日期.log</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>如何打标签 <a target="_blank" rel="noopener" href="http://panama.alibaba-inc.com/qa/faq?id=1124" title="http:&#x2F;&#x2F;panama.alibaba-inc.com&#x2F;qa&#x2F;faq?id&#x3D;1124">http://panama.alibaba-inc.com/qa/faq?id=1124</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/03/24/%E7%89%A9%E7%90%86%E6%9C%BA%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E5%8E%BB%E5%93%AA%E4%BA%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/24/%E7%89%A9%E7%90%86%E6%9C%BA%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E5%8E%BB%E5%93%AA%E4%BA%86/" class="post-title-link" itemprop="url">物理机磁盘空间都去哪里了</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-24 17:30:03" itemprop="dateCreated datePublished" datetime="2017-03-24T17:30:03+08:00">2017-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="磁盘爆掉的几种情况"><a href="#磁盘爆掉的几种情况" class="headerlink" title="磁盘爆掉的几种情况"></a>磁盘爆掉的几种情况</h1><ol>
<li>系统磁盘没有空间，解决办法：删掉 &#x2F;var&#x2F;log&#x2F; 下边的带日期的日志，清空 &#x2F;var&#x2F;log&#x2F;messages 内容</li>
<li>容器使用的大磁盘空间不够，又有三个地方会使用大量的磁盘<ul>
<li>容器内部日志非常大，处理办法见方法一</li>
<li>容器内部产生非常多或者非常大的文件，但是这个文件的位置又通过volume 挂载到了物理机上，处理办法见方法二</li>
<li>对特别老的部署环境，还有可能是容器的系统日志没有限制大小，处理办法见方法三</li>
</ul>
</li>
</ol>
<h2 id="现场的同学按如下方法依次检查"><a href="#现场的同学按如下方法依次检查" class="headerlink" title="现场的同学按如下方法依次检查"></a>现场的同学按如下方法依次检查</h2><h3 id="方法零：-检查系统根目录下每个文件夹的大小"><a href="#方法零：-检查系统根目录下每个文件夹的大小" class="headerlink" title="方法零： 检查系统根目录下每个文件夹的大小"></a>方法零： 检查系统根目录下每个文件夹的大小</h3><p><code>sudo du / -lh --max-depth=1 --exclude=overlay --exclude=proc</code></p>
<p>看看除了容器之外有没有其它目录使用磁盘特别大，如果有那么一层层进去通过du命令来查看，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#sudo du / -lh --max-depth=1 --exclude=overlay --exclude=proc</span><br><span class="line">16K	/dev</span><br><span class="line">16K	/lost+found</span><br><span class="line">4.0K	/media</span><br><span class="line">17G	/home</span><br><span class="line">136M	/boot</span><br><span class="line">832K	/run</span><br><span class="line">1.9G	/usr</span><br><span class="line">75M	/tmp</span><br><span class="line">12K	/log</span><br><span class="line">8.5G	/var</span><br><span class="line">4.0K	/srv</span><br><span class="line">0	/proc</span><br><span class="line">22M	/etc</span><br><span class="line">84G	/root</span><br><span class="line">4.0K	/mnt</span><br><span class="line">508M	/opt</span><br><span class="line">0	/sys</span><br><span class="line">112G	/</span><br></pre></td></tr></table></figure>
<p>那么这个案例中应该查看 &#x2F;root下为什么用掉了84G（总共用了112G）， 先 cd &#x2F;root 然后执行： sudo du . -lh –max-depth&#x3D;1 –exclude&#x3D;overlay 进一步查看 &#x2F;root 目录下每个文件夹的大小</p>
<p><strong>如果方法零没找到占用特别大的磁盘文件，那么一般来说是容器日志占用太多的磁盘空间，请看方法一</strong></p>
<h3 id="方法一：-容器内部日志非常大（请确保先按方法零检查过了）"><a href="#方法一：-容器内部日志非常大（请确保先按方法零检查过了）" class="headerlink" title="方法一： 容器内部日志非常大（请确保先按方法零检查过了）"></a>方法一： 容器内部日志非常大（请确保先按方法零检查过了）</h3><p>在磁盘不够的物理机上执行如下脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo docker ps -a -q &gt;containers.list</span><br><span class="line"></span><br><span class="line">sudo cat containers.list | xargs sudo docker inspect $1 | grep merged | awk -F \&quot; &#x27;&#123; print $4 &#125;&#x27; | sed &#x27;s/\/merged//g&#x27; | xargs sudo du  --max-depth=0 $1 &gt;containers.size </span><br><span class="line"></span><br><span class="line">sudo paste containers.list containers.size | awk &#x27;&#123; print $1, $2 &#125;&#x27;  | sort -nk2 &gt;real_size.log</span><br><span class="line"></span><br><span class="line">sudo tail -10 real_size.log  | awk &#x27;BEGIN &#123;print &quot;\tcontainer     size\tunit&quot;&#125; &#123; print NR&quot;:\t&quot; $0&quot;\t kB&quot; &#125;&#x27; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="执行完后会输出如下格式："><a href="#执行完后会输出如下格式：" class="headerlink" title="执行完后会输出如下格式："></a>执行完后会输出如下格式：</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">   	container     size	unit</span><br><span class="line">1:	22690f16822f 3769980	 kb</span><br><span class="line">2:	82b4ae98eeed 4869324	 kb</span><br><span class="line">3:	572a1b7c8ef6 10370404	 kb</span><br><span class="line">4:	9f9250d98df6 10566776	 kb</span><br><span class="line">5:	7fab70481929 13745648	 kb</span><br><span class="line">6:	4a14b58e3732 29873504	 kb</span><br><span class="line">7:	8a01418b6df2 30432068	 kb</span><br><span class="line">8:	83dc85caaa5c 31010960	 kb</span><br><span class="line">9:	433e51df88b1 35647052	 kb</span><br><span class="line">10:	4b42818a8148 61962416	 kb</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>第二列是容器id，第三列是磁盘大小，第四列是单位， 占用最大的排在最后面</p>
<h5 id="然后进到容器后通过-du-–max-depth-2-快速发现大文件"><a href="#然后进到容器后通过-du-–max-depth-2-快速发现大文件" class="headerlink" title="然后进到容器后通过 du &#x2F; –max-depth&#x3D;2 快速发现大文件"></a>然后进到容器后通过 du &#x2F; –max-depth&#x3D;2 快速发现大文件</h5><h3 id="方法二：-容器使用的volume使用过大"><a href="#方法二：-容器使用的volume使用过大" class="headerlink" title="方法二： 容器使用的volume使用过大"></a>方法二： 容器使用的volume使用过大</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$sudo du -l /data/lib/docker/defaultVolumes --max-depth=1 | sort -rn</span><br><span class="line">456012884	/data/lib/docker/defaultVolumes</span><br><span class="line">42608332	/data/lib/docker/defaultVolumes/task_3477_g0_ark-metadb_miniDBPaaS-MetaDB_1</span><br><span class="line">32322220	/data/lib/docker/defaultVolumes/task_3477_g0_dbpaas-metadb_dbpaas_1</span><br><span class="line">27461120	/data/lib/docker/defaultVolumes/task_3001_g0_ark-metadb_miniDBPaaS-MetaDB_1</span><br><span class="line">27319360	/data/lib/docker/defaultVolumes/task_36000_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27313836	/data/lib/docker/defaultVolumes/task_3600_g0_dbpaas-metadb_minidbpaas</span><br><span class="line">27278692	/data/lib/docker/defaultVolumes/task_3604_g0_ark-metadb_miniDBPaaS-MetaDB_1</span><br><span class="line">27277004	/data/lib/docker/defaultVolumes/task_3603_g0_ark-metadb_miniDBPaaS-MetaDB_1</span><br><span class="line">27275736	/data/lib/docker/defaultVolumes/task_3542_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27271428	/data/lib/docker/defaultVolumes/task_3597_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27270840	/data/lib/docker/defaultVolumes/task_3603_g0_dbpaas-metadb_minidbpaas_1</span><br><span class="line">27270492	/data/lib/docker/defaultVolumes/task_3603_g0_dbpaas-metadb_minidbpaas</span><br><span class="line">27270468	/data/lib/docker/defaultVolumes/task_3600_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27270252	/data/lib/docker/defaultVolumes/task_3535_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27270244	/data/lib/docker/defaultVolumes/task_3538_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">27270244	/data/lib/docker/defaultVolumes/task_3536_g0_ark-metadb_miniDBPaaS-MetaDB</span><br><span class="line">25312404	/data/lib/docker/defaultVolumes/task_3477_g0_dncs-server_middleware-dncs_2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>&#x2F;data&#x2F;lib&#x2F;docker&#x2F;defaultVolumes 参数是方舟默认volume存放的目录（一般是docker的存储路径下 –graph&#x3D;&#x2F;data&#x2F;lib&#x2F;docker) ，第一列是大小，后面是容器名</p>
<p>volume路径在物理机上也有可能是 &#x2F;var&#x2F;lib&#x2F;docker 或者 &#x2F;mw&#x2F;mvdocker&#x2F; 之类的路径下，这个要依据安装参数来确定，可以用如下命令来找到这个路径：</p>
<p><code>sudo systemctl status docker -l | grep --color graph </code></p>
<p>结果如下，红色参数后面的路径就是docker 安装目录，到里面去找带volume的字眼：</p>
<p><img src="https://plantegg.oss-cn-beijing.aliyuncs.com/images/oss/9b7e489576840f72a5bd13e969abce39.png" alt="image.png"></p>
<p>找到 volume很大的文件件后同样可以进到这个文件夹中执行如下命令快速发现大文件：</p>
<p><code>du . --max-depth=2 </code></p>
<h3 id="方法三-容器的系统日志没有限制大小"><a href="#方法三-容器的系统日志没有限制大小" class="headerlink" title="方法三 容器的系统日志没有限制大小"></a>方法三 容器的系统日志没有限制大小</h3><p>这种情况只针对2017年上半年之前的部署环境，后面部署的环境默认都控制了这些日志不会超过150M</p>
<p>按照方法二的描述先找到docker 安装目录，cd 进去，然后 ： </p>
<p><code>du ./containers --max-depth=2 </code></p>
<p>就很快找到那个大json格式的日志文件了,然后执行清空这个大文件的内容：</p>
<p><code>echo &#39;&#39; | sudo tee 大文件名  </code></p>
<h3 id="一些其他可能占用空间的地方"><a href="#一些其他可能占用空间的地方" class="headerlink" title="一些其他可能占用空间的地方"></a>一些其他可能占用空间的地方</h3><ul>
<li>机器上镜像太多，可以删掉一些没用的： sudo docker images -q | xargs sudo docker rmi </li>
<li>机器上残留的volume太多，删：sudo docker volume ls -q | xargs sudo docker volume rm</li>
<li>物理文件被删了，但是还有进程占用这个文件句柄，导致文件对应的磁盘空间没有释放，检查： lsof |　grep deleted  如果这个文件非常大的话，只能通过重启这个进程来真正释放磁盘空间</li>
</ul>
<hr>
<h4 id="检查是否restart能支持只重启deamon，容器还能正常运行："><a href="#检查是否restart能支持只重启deamon，容器还能正常运行：" class="headerlink" title="检查是否restart能支持只重启deamon，容器还能正常运行："></a>检查是否restart能支持只重启deamon，容器还能正常运行：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$sudo docker info | grep Restore</span><br><span class="line">Live Restore Enabled: true</span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/01/14/%E9%80%9A%E8%BF%87%E5%88%86%E6%9E%90tcp%E5%8C%85%E6%9D%A5%E7%A1%AE%E8%AE%A4%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E7%9A%84%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/01/14/%E9%80%9A%E8%BF%87%E5%88%86%E6%9E%90tcp%E5%8C%85%E6%9D%A5%E7%A1%AE%E8%AE%A4%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E7%9A%84%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4/" class="post-title-link" itemprop="url">通过分析tcp包来确认服务调用的响应时间</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-01-14 10:30:03" itemprop="dateCreated datePublished" datetime="2017-01-14T10:30:03+08:00">2017-01-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TCP/" itemprop="url" rel="index"><span itemprop="name">TCP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="通过分析tcp包来确认服务调用的响应时间"><a href="#通过分析tcp包来确认服务调用的响应时间" class="headerlink" title="通过分析tcp包来确认服务调用的响应时间"></a>通过分析tcp包来确认服务调用的响应时间</h1><h2 id="不需要在应用中打点，不限定于具体语言（php、cpp、java都可以）-分析服务调用的响应时间"><a href="#不需要在应用中打点，不限定于具体语言（php、cpp、java都可以）-分析服务调用的响应时间" class="headerlink" title="不需要在应用中打点，不限定于具体语言（php、cpp、java都可以）, 分析服务调用的响应时间"></a>不需要在应用中打点，不限定于具体语言（php、cpp、java都可以）, 分析服务调用的响应时间</h2><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当时的问题，客户现场不管怎么样增加应用机器，tps就是上不去，同时增加应用机器后，增加的机器CPU还都能被用完，但是tps没有变化（这点比较奇怪，也就是cpu用的更多了，tps没变化），客户感觉 整体服务调用慢，数据库没有慢查询，不知道到具体时间花在哪里，各个环节都尝试过增加服务器（或提升配置），但是问题一直得不到解决</span><br></pre></td></tr></table></figure>

<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><h3 id="数据库服务器网卡中断瓶颈导致rtt非常高，进一步导致每个Query的ResponseTime非常高（图中左边都是出问题、右边都是问题解决后的响应时间）"><a href="#数据库服务器网卡中断瓶颈导致rtt非常高，进一步导致每个Query的ResponseTime非常高（图中左边都是出问题、右边都是问题解决后的响应时间）" class="headerlink" title="数据库服务器网卡中断瓶颈导致rtt非常高，进一步导致每个Query的ResponseTime非常高（图中左边都是出问题、右边都是问题解决后的响应时间）"></a>数据库服务器网卡中断瓶颈导致rtt非常高，进一步导致每个Query的ResponseTime非常高（图中左边都是出问题、右边都是问题解决后的响应时间）</h3><blockquote>
<p>通过程序把每个请求、响应时间等数据分析出来并存入数据库中（缺一个图形展示界面，有图形展示界面后会更直观）</p>
</blockquote>
<blockquote>
<p>图一中是每一秒中的平均 rtt 时间（round trip time）</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20220524155218723.png" alt="image"></p>
<h4 id="问题修复后数据库每个查询的平均响应时间从47毫秒下降到了4-5毫秒"><a href="#问题修复后数据库每个查询的平均响应时间从47毫秒下降到了4-5毫秒" class="headerlink" title="问题修复后数据库每个查询的平均响应时间从47毫秒下降到了4.5毫秒"></a>问题修复后数据库每个查询的平均响应时间从47毫秒下降到了4.5毫秒</h4><blockquote>
<p>图中的每一行都是是一个查询的数据库执行时间</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20220524155221182.png" alt="image"></p>
<h4 id="从wireshark中也可以看到类似的rtt不正常（超过150ms的比较多）"><a href="#从wireshark中也可以看到类似的rtt不正常（超过150ms的比较多）" class="headerlink" title="从wireshark中也可以看到类似的rtt不正常（超过150ms的比较多）"></a>从wireshark中也可以看到类似的rtt不正常（超过150ms的比较多）</h4><p><img src="/images/951413iMgBlog/image.png" alt="image"></p>
<h4 id="从wireshark中也可以看到类似的rtt正常-99-都在10ms以内）"><a href="#从wireshark中也可以看到类似的rtt正常-99-都在10ms以内）" class="headerlink" title="从wireshark中也可以看到类似的rtt正常(99%都在10ms以内）"></a>从wireshark中也可以看到类似的rtt正常(99%都在10ms以内）</h4><p><img src="/images/951413iMgBlog/image-20220524155217000.png" alt="image"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote>
<p>实际上通过抓包发现所有发往后面的SQL查询(请求链路：app -&gt; slb -&gt; drds -&gt; slb -&gt;rds) ，在app上抓包发现每个请求发出去到收到结果平均需要差不多100ms（无论SQL复杂与否），通过统计网络往返时间（rtt）发现rtt非常高，好多都是50ms以上。<br>降低压力比较rtt，发现rtt降到了20ms以内，同时SQL响应时间也相应地减短了。<br>已经排除了drds到rds响应慢的问题，问题应该在slb或者drds上，进一步发现drds（16Core 16GMem）绑定网卡中断的cpu用到了95%以上，尝试绑定到多个cpu内核，似乎ecs不支持，接下来将配置，增加多个低配置的drds来解决问题。</p>
</blockquote>
<p><strong>简单来说ecs默认网卡中断只能用到一个核，如果ecs配置太高，网卡中断会成为瓶颈，导致rtt变高、不稳定</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2017/01/01/top_linux_commands/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/01/01/top_linux_commands/" class="post-title-link" itemprop="url">最牛B的Linux Shell命令</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-01-01 17:30:03" itemprop="dateCreated datePublished" datetime="2017-01-01T17:30:03+08:00">2017-01-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="最牛B的Linux-Shell命令"><a href="#最牛B的Linux-Shell命令" class="headerlink" title="最牛B的Linux Shell命令"></a>最牛B的Linux Shell命令</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>Shell作为Unix系操作系统当中最有魅力且不可或缺的组件，经过数十载的洗礼不仅没有被淘汰，而且愈加变得成熟稳健，究其原因，大概因为它是个非常稳固的粘合剂，能够把大量功能强大的组件任意配搭，总能很好很快地完成用户的任务。</p>
<p>本文的一些命令很可能看起来是“雕虫小技”，我们只好仰慕一下Shell大牛了，但是有些细节我会稍加发掘加以说明，遇到有趣的地方希望能博您一笑了。</p>
<h2 id="1-以sudo运行上条命令"><a href="#1-以sudo运行上条命令" class="headerlink" title="1.以sudo运行上条命令"></a>1.以sudo运行上条命令</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ <strong>sudo</strong> <strong>!!</strong></th>
</tr>
</thead>
</table>
<p>大家应该都知sudo，不解释。但通常出现的情况是，敲完命令执行后报错才发现忘了sudo。这时候，新手用户就会：按上箭头，按左箭头，盯着光标回到开始处，输入sudo，回车；高手用户就蛋定多了，按Ctrl-p，按Ctrl-a，输入sudo，回车。</p>
<p>这里介绍这个是天外飞仙级别的，对，就直接sudo !!。</p>
<p>当然这几种解决方式效果是完全一样的，只是款不一样，嗯，不解释。</p>
<p>两个感叹号其实是bash的一个特性，称为事件引用符（event designators）。!!其实相当于!-1，引用前一条命令，当然也可以!-2，!-50。默认情况下bash会在~&#x2F;.bash_history文件内记录用户执行的最近500条命令，history命令可以显示这些命令。</p>
<p>关于事件引用符的更多用法可以深入阅读<a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/the-definitive-guide-to-bash-command-line-history/">The Definitive Guide to Bash Command Line History</a>。</p>
<h2 id="2-以HTTP方式共享当前文件夹的文件"><a href="#2-以HTTP方式共享当前文件夹的文件" class="headerlink" title="2.以HTTP方式共享当前文件夹的文件"></a>2.以HTTP方式共享当前文件夹的文件</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ python -m  SimpleHTTPServer 8080</th>
</tr>
</thead>
</table>
<p>这命令启动了Python的SimpleHTTPServer模块，考虑到Python在绝大多数的Linux发行版当中都默认安装，所以这个命令很可能是最简单的跨平台传文件的方法。</p>
<p>命令执行后将在本机8000端口开放HTTP服务，在其他能访问本机的机器的浏览器打开ttp:&#x2F;&#x2F;ip:8000即打开一个目录列表，点击即可下载。</p>
<p>python3的话</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m http.server 8080</span><br></pre></td></tr></table></figure>

<h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#最近一天修改的md文档</span><br><span class="line">find . -maxdepth 1 -type f -mtime -1 -name &quot;*.md&quot; -not -name &quot;template.md&quot; -not -name &quot;temp.md&quot; -exec ls -lh &quot;&#123;&#125;&quot; \;</span><br><span class="line"></span><br><span class="line">find . -size 0  -type f -exec ls -lh &quot;&#123;&#125;&quot; \;</span><br><span class="line"></span><br><span class="line">find . -maxdepth 1 -type f -mtime -2 -name &quot;*margin*&quot; -exec mv &quot;&#123;&#125;&quot; /tmp/img/ \;</span><br><span class="line"></span><br><span class="line">#clean the big file, but exclude spill dir</span><br><span class="line">sudo find /home/admin/ -not -path &quot;*/spill/*&quot; -type f -size +3G -exec cp /dev/null &#123;&#125; \;</span><br><span class="line">sudo find /home/admin/ -type f -name &quot;*.hprof&quot; -mtime +1 -exec rm -f &#123;&#125; \;</span><br><span class="line">#clean the spill temp file which before 7 days ago</span><br><span class="line">sudo find /home/admin/ -type f -mtime +7 -exec cp /dev/null &#123;&#125; \;</span><br><span class="line">sudo find /home/admin/logs/ -type f -mtime +7 -exec rm -f &#123;&#125; \;</span><br><span class="line">sudo find /var/log/ -type f -size +500M -exec cp /dev/null &#123;&#125; \;</span><br><span class="line"></span><br><span class="line">// -mindepth 1 可以忽略当前目录的&quot;.&quot; </span><br><span class="line">find . -mindepth 1 -maxdepth 1 -type d -mtime -50</span><br><span class="line"></span><br><span class="line">#备份匹配的文件</span><br><span class="line">find . -name &#x27;*.ibd&#x27; | grep tpcc1000 | grep -v mysql_global | xargs -I&#123;&#125; cp --path &#123;&#125; /tmp/bak/</span><br><span class="line"></span><br><span class="line">#将yaml 备份，保留目录结构</span><br><span class="line">find . -name &#x27;*.yaml&#x27; | xargs -I&#123;&#125; cp --path &#123;&#125; /tmp/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">find $srcDir -maxdepth 1 -type f -mtime -$1 -name &quot;*.md&quot; -not -name &quot;template.md&quot; -not -name &quot;temp.md&quot; -exec ls -lh &quot;&#123;&#125;&quot; \;</span><br><span class="line"></span><br><span class="line">find $srcDir -maxdepth 1 -type f -mtime -$1 -name &quot;*.md&quot; -not -name &quot;template.md&quot; -not -name &quot;temp.md&quot; -exec cp &quot;&#123;&#125;&quot; ./source/_posts/ \;</span><br><span class="line"></span><br><span class="line">#sudo find /media/sf_D_DRIVE/case/ -maxdepth 1 -type f -mtime -$1 -name &quot;*.md&quot; -not -name &quot;template.md&quot; -print -exec cp &quot;&#123;&#125;&quot; ./source/_posts/ \;</span><br><span class="line"></span><br><span class="line">cat的时候输出文件名：</span><br><span class="line">find . -type f -print -exec cat &#123;&#125; \;</span><br></pre></td></tr></table></figure>

<p>xargs 参数：</p>
<blockquote>
<p>-I [replace-str]：将xargs的输出每一项参数，单独赋值给后面的命令，参数需要用指定的代替字符串replace-str代替，也就是说replace-str不可缺省，必须显示指明，可以使用{} $ @等符号，其主要作用是<strong>当xargs command后有多个参数时，调整参数位置</strong></p>
</blockquote>
<h2 id="top"><a href="#top" class="headerlink" title="top"></a>top</h2><p>默认配置文件：<del>&#x2F;.toprc （on Ubuntu, it is *</del>&#x2F;.config&#x2F;procps&#x2F;toprc*）</p>
<p>增加列：f (此时可以调整用 → 选择列并调整位置， 此时也有4个窗口可以选择)</p>
<p>按node展示cpu：2(3 选择需要展示的node)</p>
<p>按core展示cpu: 1</p>
<p>切换颜色：z (有4个窗口可以选择，按 g 可以选择1-4)</p>
<p>配置颜色: Z </p>
<p><strong>V</strong> 切换成森林视图，也就是展示进程父子关系</p>
<p>保存配置: W</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dG9wJ3MgQ29uZmlnIEZpbGUgKExpbnV4IHByb2Nlc3NlcyB3aXRoIHdpbmRvd3MpCklkOmksIE1vZGVfYWx0c2NyPTAsIE1vZGVfaXJpeHBzPTEsIERlbGF5X3RpbWU9My4wLCBDdXJ3aW49MApDcHUJZmllbGRzY3VyPaWmqLWztLu9wMS3urg5xScpKissLS4vMDEyNjw+P0FCQ0ZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWoKCXdpbmZsYWdzPTE5NTM4MCwgc29ydGluZHg9MTgsIG1heHRhc2tzPTAsIGdyYXBoX2NwdXM9MCwgZ3JhcGhfbWVtcz0wCglzdW1tY2xyPTQsIG1zZ3NjbHI9MSwgaGVhZGNscj0zLCB0YXNrY2xyPTQKTWVtCWZpZWxkc2N1cj2lu73AvMPBws3OJjk3uigzNEQnxSkqKywtLi8wMTI1Njg+P0ZHSElKS0xPUFFSU1RVVldYWVpbXF1eX2BhYmNkZWZnaGlqCgl3aW5mbGFncz0xOTUzODAsIHNvcnRpbmR4PTIxLCBtYXh0YXNrcz0wLCBncmFwaF9jcHVzPTAsIGdyYXBoX21lbXM9MAoJc3VtbWNscj02LCBtc2dzY2xyPTYsIGhlYWRjbHI9MywgdGFza2Nscj02ClNjaAlmaWVsZHNjdXI9pTo7PD0+P0BBTUJOQ7WztMfEtre5xcYmJygpKissLS4vMDEyOEhJSktMT1BRUlNUVVZXWFlaW1xdXl9gYWJjZGVmZ2hpagoJd2luZmxhZ3M9MTk0ODY4LCBzb3J0aW5keD0wLCBtYXh0YXNrcz0wLCBncmFwaF9jcHVzPTAsIGdyYXBoX21lbXM9MAoJc3VtbWNscj01LCBtc2dzY2xyPTUsIGhlYWRjbHI9MywgdGFza2Nscj01CkNncAlmaWVsZHNjdXI9paanqCowOTc6RCkrLC0uLzEyMzQ1Njg7PD0+P0BBQkNGR8hJSktMTU5P0NHS09TVxVZXWFlaW1xdXl9gYWJjZGVmZ2hpagoJd2luZmxhZ3M9MTk0ODY4LCBzb3J0aW5keD0wLCBtYXh0YXNrcz0wLCBncmFwaF9jcHVzPTAsIGdyYXBoX21lbXM9MAoJc3VtbWNscj0yLCBtc2dzY2xyPTMsIGhlYWRjbHI9MywgdGFza2Nscj0yCkZpeGVkX3dpZGVzdD0wLCBTdW1tX21zY2FsZT0wLCBUYXNrX21zY2FsZT0wLCBaZXJvX3N1cHByZXNzPTAKCnBpcGUJTmV0RmlsZXMJbHNvZiAtYSAtbCAtbiAtUCAtaTQgLXAgJWQgMj4mMQpwaXBlCU9wZW5GaWxlcwlsc29mIC1hIC1sIC1uIC1QIC1wICVkIDI+JjEKZmlsZQlOVU1BSW5mbwkvcHJvYy8lZC9udW1hX21hcHMK</span><br></pre></td></tr></table></figure>



<h2 id="xargs-传参数"><a href="#xargs-传参数" class="headerlink" title="xargs 传参数"></a>xargs 传参数</h2><blockquote>
<p>ls &#x2F;xx | xargs -t -I{}  cp {} &#x2F;tmp&#x2F;{}</p>
</blockquote>
<p>-t ： 打印内容，去掉\n之后的字符串</p>
<p>-I :  后面定义占位符，上例子是{}  ，后面命令行中可以多次使用占位符</p>
<p>挂载多台苹果的例子</p>
<blockquote>
<p> idevice_id -l|xargs -t -I{} mkdir {};idevice_id -l |xargs -t -I{} ifuse {} {}</p>
</blockquote>
<p>批量执行docker exec</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible -i host.ini all -m shell -a &quot;docker ps -a | grep tpcc | grep dn | cut -d &#x27; &#x27; -f 1 | xargs  -I&#123;&#125; docker exec &#123;&#125; bash -c \&quot;myc -e &#x27;shutdown&#x27;\&quot;&quot;</span><br></pre></td></tr></table></figure>

<p>批量推送镜像</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images |grep &quot;docker.io:5000&quot; | awk &#x27;&#123; print $1&quot;:&quot;$2 &#125;&#x27; | xargs -I &#123;&#125; docker push &#123;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="非贪婪匹配"><a href="#非贪婪匹配" class="headerlink" title="非贪婪匹配"></a>非贪婪匹配</h2><p>vim中默认匹配：abc.*d 是贪婪匹配，也就是尽可能长地匹配，改用 abc.{-}d 匹配到第一个 d字符就结束</p>
<blockquote>
<p>贪婪模式是: .*</p>
<p>非贪婪模式是: .\{-}</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\&#123;n,m&#125; Matches n to m of the preceding atom, as many as possible</span><br><span class="line">\&#123;n&#125; Matches n of the preceding atom</span><br><span class="line">\&#123;n,&#125; Matches at least n of the preceding atom, as many as possible</span><br><span class="line">\&#123;,m&#125; Matches 0 to m of the preceding atom, as many as possible</span><br><span class="line">\&#123;&#125; Matches 0 or more of the preceding atom, as many as possible (like *)</span><br><span class="line">*/\&#123;-*</span><br><span class="line">\&#123;-n,m&#125; matches n to m of the preceding atom, as few as possible</span><br><span class="line">\&#123;-n&#125; matches n of the preceding atom</span><br><span class="line">\&#123;-n,&#125; matches at least n of the preceding atom, as few as possible</span><br><span class="line">\&#123;-,m&#125; matches 0 to m of the preceding atom, as few as possible</span><br><span class="line">\&#123;-&#125; matches 0 or more of the preceding atom, as few as possibles</span><br></pre></td></tr></table></figure>

<p>grep 非贪婪匹配</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep --color -P &quot;agHost.*?,&quot; test.table  //匹配 agHost后带有多个任意字符直到第一个 逗号 结束，-P表示用 perl 的匹配语法，而perl默认是不支持贪婪的</span><br><span class="line"></span><br><span class="line">grep --color -o -P &quot;agHost.*?,&quot; test.table  //-o 只打印匹配部分</span><br></pre></td></tr></table></figure>

<p>匹配数字至少4次</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -E &quot;,rows=[0-9]&#123;4,&#125;&quot;</span><br><span class="line">grep -E &quot;[0-9]&#123;4,&#125;ms&quot; mongod.log</span><br></pre></td></tr></table></figure>



<h2 id="macOS-sed-删除行"><a href="#macOS-sed-删除行" class="headerlink" title="macOS sed 删除行"></a>macOS sed 删除行</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//查找匹配的行：|      |                               |</span><br><span class="line">grep -E &quot;\| [[:space:]]*\| [[:space:]]*\|&quot; top_linux_commands.md -B3</span><br><span class="line"></span><br><span class="line">//删除行 -i &quot;.bak&quot;是直接操作文件并添加.bak作为备份文件名称，如果不需要备份文件，则使用-i &quot;&quot;</span><br><span class="line">sed -i &#x27;&#x27; -e  &#x27;/\| [[:space:]]*\| [[:space:]]*\|/d&#x27;  top_linux_commands.md</span><br><span class="line"></span><br><span class="line">//先备份文件为.bak, 再删除行 -i &quot;.bak&quot;是添加.bak作为备份文件名称</span><br><span class="line">sed -i &#x27;.bak&#x27; &#x27;s/\| [[:space:]]*\| [[:space:]]*\|/d&#x27;  top_linux_commands.md</span><br></pre></td></tr></table></figure>

<h2 id="ps-查看进程"><a href="#ps-查看进程" class="headerlink" title="ps 查看进程"></a>ps 查看进程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -Tfp pid // -T 展开进程下的线程 -f full -p pid</span><br></pre></td></tr></table></figure>



<h2 id="循环按行处理"><a href="#循环按行处理" class="headerlink" title="循环按行处理"></a>循环按行处理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">while  read i ; do echo $i ; done &lt;./prometheus.list</span><br></pre></td></tr></table></figure>



<h2 id="3-在以普通用户打开的vim当中保存一个root用户文件"><a href="#3-在以普通用户打开的vim当中保存一个root用户文件" class="headerlink" title="3.在以普通用户打开的vim当中保存一个root用户文件"></a>3.在以普通用户打开的vim当中保存一个root用户文件</h2><table>
<thead>
<tr>
<th>1</th>
<th>:<strong>w</strong> <strong>!sudo</strong> <strong>tee</strong> <strong>%</strong></th>
</tr>
</thead>
</table>
<p>这题目读起来纠结，其实是很常见的，常常忘记了sudo就直接用vim编辑&#x2F;etc内的文件，（不过也不一定，vim发现保存的文件无法保存时候会提示）等编辑好了，保存时候才发现没权限。曲线方法是先保存个临时文件，退出后再sudo cp回去。不过实际上在vim里面可以直接完成这个过程的，命令就是如此。</p>
<p>查阅vim的文档（输入:help :w），会提到命令:w!{cmd}，让vim执行一个外部命令{cmd}，然后把当前缓冲区的内容从stdin传入。</p>
<p>tee是一个把stdin保存到文件的小工具。</p>
<p>而%，是vim当中一个只读寄存器的名字，总保存着当前编辑文件的文件路径。</p>
<p>所以执行这个命令，就相当于从vim外部修改了当前编辑的文件，好完工。</p>
<h2 id="4-切换回上一个目录"><a href="#4-切换回上一个目录" class="headerlink" title="4.切换回上一个目录"></a>4.切换回上一个目录</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ <strong>cd</strong> -</th>
</tr>
</thead>
</table>
<p>应该不少人都知道这个，横杆-代表上一个目录的路径。</p>
<p>实际上cd -就是cd $OLDPWD的简写，bash的固定变量$OLDPWD总保存着之前一个目录的路径。</p>
<p>相对地，$PWD总保存着当前目录的路径。这些变量在编写shell脚本时候相当有用。</p>
<h2 id="5-替换上一条命令中的一个短语"><a href="#5-替换上一条命令中的一个短语" class="headerlink" title="5.替换上一条命令中的一个短语"></a>5.替换上一条命令中的一个短语</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ ^foo^bar^</th>
</tr>
</thead>
</table>
<p>又是另外一个事件引用符（event designator），可以把上一条命令当中的foo替换成bar。</p>
<p>在需要重复运行调试一道长长的命令，需要测试某个参数时候，用这个命令会比较实用；但多数人会首先选择按上箭头提出上道命令，再移动光标去修改某参数，这样更直观，但效率上就不够使用引用符高，而且在脚本中用这个方法可以简化很多。</p>
<p>这道命令的原始样式应该是这样的:</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>!!</strong>:s**&#x2F;<strong>foo</strong>&#x2F;<strong>bar</strong>&#x2F;**</th>
</tr>
</thead>
</table>
<p>本文一开始介绍过!!，后面的一段大家应该很熟悉，vim、sed的替换操作都是这样的语法。</p>
<p>关于事件引用符的更多用法可以深入阅读<a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/the-definitive-guide-to-bash-command-line-history/">The Definitive Guide to Bash Command Line History</a></p>
<h2 id="6-快速备份一个文件"><a href="#6-快速备份一个文件" class="headerlink" title="6.快速备份一个文件"></a>6.快速备份一个文件</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ <strong>cp</strong>  filename**{<strong>,.bak</strong>}**</th>
</tr>
</thead>
</table>
<p>这道命令把filename文件拷贝成filename.bak，大家应该在一些比较复杂的安装教程里面见过这样的用法。其原理就在于bash对大括号的展开操作，filename{,.bak}这一段会被展开成filename filename.bak再传给cp，于是就有了备份的命令了。</p>
<p>大括号在bash里面是一个排列的意义，可以试试这个：</p>
<table>
<thead>
<tr>
<th>1</th>
<th>$ <strong>echo</strong> <strong>{<strong>a,b,c</strong>}{<strong>a,b,c</strong>}{<strong>a,b,c</strong>}</strong></th>
</tr>
</thead>
</table>
<p>将输出三个集合的全排列:</p>
<p>aaa aab aac aba abb abc aca acb acc</p>
<p>baa bab bac bba bbb bbc bca bcb bcc</p>
<p>caa cab cac cba cbb cbc cca ccb ccc</p>
<p>关于shell当中的集合操作，可深入阅读<a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/set-operations-in-unix-shell/">“Set Operations in the Unix Shell”</a></p>
<h2 id="7-免密码ssh登录主机"><a href="#7-免密码ssh登录主机" class="headerlink" title="7.免密码ssh登录主机"></a>7.免密码ssh登录主机</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ ssh-copy-id remote-machine</th>
</tr>
</thead>
</table>
<p>这个命令把当前用户的公钥串写入到远程主机的~&#x2F;.ssh&#x2F;authorized_keys内，这样下次使用ssh登录的时候，远程主机就直接根据这串密钥完成身份校验，不再询问密码了。前提是你当前用户有生成了公钥，默认是没有的，先执行ssh-keygen试试吧！</p>
<p>这个命令如果用手工完成，是这样的：</p>
<table>
<thead>
<tr>
<th>1  2  3</th>
<th>your-machine$ scp  ~&#x2F;.ssh&#x2F;identity.pub  remote-machine:  your-machine$ ssh  remote-machine  remote-machine$ cat  identity.pub &gt;&gt; ~&#x2F;.ssh&#x2F;authorized_keys</th>
</tr>
</thead>
</table>
<p>如果你想删掉远程主机上的密钥，直接打开authorized_keys，搜索你的用户名，删除那行，即可。</p>
<h2 id="8-抓取Linux桌面的视频"><a href="#8-抓取Linux桌面的视频" class="headerlink" title="8.抓取Linux桌面的视频"></a>8.抓取Linux桌面的视频</h2><table>
<thead>
<tr>
<th>1</th>
<th>$ <strong>ffmpeg</strong> -f x11grab -s  wxga -r 25  -i :0.0 -sameq **&#x2F;<strong>tmp</strong>&#x2F;**out.mpg</th>
</tr>
</thead>
</table>
<p>我们在一些视频网站上看到别人的3D桌面怎么怎么酷的视频，通常就是这么来的，ffmpeg可以直接解码X11的图形，并转换到相应输出格式。</p>
<p>ffmpeg的通常用法是，根据一堆参数，输出一个文件，输出文件通常放最后，下面解析下几个参数：</p>
<p>-f x11grab 指定输入类型。因为x11的缓冲区不是普通的视频文件可以侦测格式，必须指定后ffmpeg才知道如何获得输入。</p>
<p>-s wxga 设置抓取区域的大小。wxga是1366*768的标准说法，也可以换成-s 800×600的写法。</p>
<p>-r 25 设置帧率，即每秒抓取的画面数。</p>
<p>-i :0.0 设置输入源，本地X默认在0.0</p>
<p>-sameq 保持跟输入流一样的图像质量，以用来后期处理。</p>
<p>至于其他ffmpeg的用法，可以参考下面两篇文章：</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/how-to-extract-audio-tracks-from-youtube-videos/">How to Extract Audio Tracks from YouTube Videos</a></p>
<p>·    <a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/converting-youtube-flvs-to-a-better-format-with-ffmpeg">Converting YouTube Flash Videos to a Better Format with ffmpeg</a></p>
<p>后记</p>
<p>说Shell是一种编程语言，可能有些尴尬，虽然很多人每天都在用Shell，但从来没见它荣登TIOBE编程语言排行榜之类的，可以说毫无名分，因为很多用户没意识到它是一种语言，只当做这是一个能够很好完成任务的工具，基本得理所当然，就好像GUI程序的菜单、按钮一样。</p>
<p>掌握Shell，通常能够让任务在数秒钟内完成，这就让Shell跟C、Perl、Python这些语言区别开来，没人否认后者更能胜任更多的任务，但是他们是在不同的层面上去做，Shell依赖大量的系统组件黏合调用，而后者依赖各种库，各所擅长不同的应用领域，比喻就是，Shell是混凝土，可以很方便地粘合一些建筑组件而成为稳固的高楼大厦；但同样是粘合剂，粘玻璃窗、粘书报、粘皮鞋，混凝土是绝对不合适的，Shell并不擅长一些细致操作，比如它连浮点运算都不支持，更别提什么图形运算什么的。但这并不妨碍Shell来帮我们完成很多粗重任务。</p>
<p>Shell的工作方式，大多数入门用户会觉得枯燥难学，而所谓的经典教材也离不开《Advanced Bash-Scripting》、《Bash Guide for Beginners》，但类似本文这样的一些“雕虫小技”因为难登大雅之堂绝不会收录进去。这情况如果象国外一些unix用户比较多的地方会有很好改善，即使是新手，偶尔看看别人的操作都能“偷师”一手，我编译本系列文章其实也就希望稍微改善一下这个状况。</p>
<h2 id="1-用你最喜欢的编辑器来敲命令"><a href="#1-用你最喜欢的编辑器来敲命令" class="headerlink" title="1.用你最喜欢的编辑器来敲命令"></a>1.用你最喜欢的编辑器来敲命令</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>command</strong> <strong>&lt;**CTRL-x  CTRL-e**&gt;</strong></th>
</tr>
</thead>
</table>
<p>在已经敲完的命令后按<CTRL-x CTRL-e>，会打开一个你指定的编辑器（比如vim，通过环境变量$EDITOR指定），里面就是你刚输入的命令，然后爱怎么编辑就怎么编辑吧，特别是那些参数异常复杂的程序，比如mencoder&#x2F;ffmpeg，一个命令动辄3、4行的，要修改其中的参数，这个方法最合适不过了，保存退出后自动执行这个程序。</p>
<p>实际上这是<a target="_blank" rel="noopener" href="http://tiswww.case.edu/php/chet/readline/rltop.html">readline库</a>的功能，在默认情况下，bash使用的是emacs模式的命令行操作方式，<CTRL-x CTRL-e>是调用这个功能的一个绑定。如果你习惯使用vi模式，按<ESC v>可以实现同样功能。</p>
<p>如果你喜欢别的编辑器，可以在~&#x2F;.bashrc里面放上比如export EDITOR&#x3D;nano的命令。</p>
<p>另外一个修改命令的方法是使用fc命令（Fix Command），在编辑器里面打开上一句命令。我们的<a target="_blank" rel="noopener" href="http://www.isspy.com/most_useful_linux_commands_1/">第一辑连载</a>提过一个^foo^bar^命令可以用fc来实现：fc -s foo&#x3D;bar。</p>
<h2 id="2-清空或创建一个文件"><a href="#2-清空或创建一个文件" class="headerlink" title="2.清空或创建一个文件"></a>2.清空或创建一个文件</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>&gt;</strong> file.txt</th>
</tr>
</thead>
</table>
<p>&gt;在shell里面是标准输出重定向符，即把（前部个命令的）命令行输出转往一个文件内，但这里没有“前部命令”，输出为空，于是就覆盖（或创建）成一个空文件了。</p>
<p>有些脚本的写法是:&gt;file.txt，因为:是bash默认存在的空函数。</p>
<p>单纯创建文件也可以用$touch file.txt，touch本来是用作修改文件的时间戳，但如果文件不存在，就自动创建了。</p>
<h2 id="3-用ssh创建端口转发通道"><a href="#3-用ssh创建端口转发通道" class="headerlink" title="3.用ssh创建端口转发通道"></a>3.用ssh创建端口转发通道</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>ssh</strong> -N  -L2001:remotehost:80 user**@**somemachine</th>
</tr>
</thead>
</table>
<p>这个命令在本机打开了2001端口，对本机2001端口的请求通过somemachine作为跳板，转到remotehost的80端口上。</p>
<p>实现效果跟术语反向代理是相似的，实际上就是端口转发，注意上面的描述涉及了3台主机，但当然somemachine可以变成localhost。</p>
<p>这个命令比较抽象，但有时候是很有用的，比如因为众所周知的原因国内的IP的80端口无法使用，又或者公司的防火墙只给外网开了ssh端口，需要访问内部服务器一个web应用，以及需要访问某些限定了来源IP的服务，就可以用上这个方法了。</p>
<p>举一个具体例子，运行：</p>
<table>
<thead>
<tr>
<th>1  2</th>
<th><strong>ssh</strong> -f -N -L  0.0.0.0:443:twitter.com:443 shell.cjb.net  <strong>ssh</strong> -f -N -L  0.0.0.0:80:twitter.com:80 shell.cjb.net</th>
</tr>
</thead>
</table>
<p>然后在&#x2F;etc&#x2F;hosts里面添加127.0.0.1 twitter.com，好吧剩下的你懂的。</p>
<p>当然通常做这个功能的反向代理，应该要用squid、nginx之类，ssh就算是轻量级的尝试吧！</p>
<h2 id="4-重置终端"><a href="#4-重置终端" class="headerlink" title="4.重置终端"></a>4.重置终端</h2><table>
<thead>
<tr>
<th>1</th>
<th>reset</th>
</tr>
</thead>
</table>
<p>如果你试过不小心cat了某个二进制文件，很可能整个终端就傻掉了，可能不会换行，没法回显，大堆乱码之类的，这时候敲入reset回车，不管命令有没有显示，就能回复正常了。</p>
<p>实际上reset命令只是输出了一些特殊字符，我们看BusyBox里面最简单的reset程序的实现：</p>
<table>
<thead>
<tr>
<th>1</th>
<th>printf(“<strong>\033</strong>c**\033**(K**\033**[J**\033**[0m**\033**[?25h”);</th>
</tr>
</thead>
</table>
<p>输出的这些字符对Shell是有特殊意义的：</p>
<p>·    \033c: “ESC c” – 发送重置命令;</p>
<p>·    \033(K: “ESC ( K” – 重载终端的字符映射;</p>
<p>·    \033[J: “ESC [ J” – 清空终端内容;</p>
<p>·    \033[0m: “ESC [ 0 m” – 初始化字符显示属性;</p>
<p>·    \033[?25h: “ESC [ ? 25 h” – 让光标可见;</p>
<p>其中<em>字符显示属性</em>经常用来设定打印字符的颜色等，可参考<a target="_blank" rel="noopener" href="http://linuxshellaccount.blogspot.com/2008/03/using-color-in-linux-or-unix-shell.html">这个博文</a>。</p>
<h2 id="5-在午夜的时候执行某命令"><a href="#5-在午夜的时候执行某命令" class="headerlink" title="5.在午夜的时候执行某命令"></a>5.在午夜的时候执行某命令</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>echo</strong> cmd <strong>|</strong> at  midnight</th>
</tr>
</thead>
</table>
<p>说的就是at这个组件，通常跟cron相提并论，不过at主要用于定时一次性任务，而cron定时周期性任务。</p>
<p>at的参数比较人性化，跟英语语法一样，可以tomorrow, next week之类的，详细的查看手册man at。</p>
<h2 id="6-远程传送麦克风语音"><a href="#6-远程传送麦克风语音" class="headerlink" title="6.远程传送麦克风语音"></a>6.远程传送麦克风语音</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>dd</strong> if&#x3D;**&#x2F;<strong>dev</strong>&#x2F;<strong>dsp  <strong>|</strong> <strong>ssh</strong>  username</strong>@<strong>host <strong>dd</strong> of&#x3D;</strong>&#x2F;<strong>dev</strong>&#x2F;**dsp</th>
</tr>
</thead>
</table>
<p>没错就是实现一个喊话器的功能。</p>
<p>&#x2F;dev&#x2F;dsp是Linux下声卡的文件映射（Digital Signal Proccessor），从其中读数据就是录音，往里面写数据就是播放，相当简单！</p>
<p>dd是常用的数据拷贝程序，如果不同时指定if、of，就直接使用stdin&#x2F;stdout来传输。</p>
<p>如果你没有远程主机，可以试试这样：</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>dd</strong> if&#x3D;**&#x2F;<strong>dev</strong>&#x2F;<strong>dsp  of&#x3D;</strong>&#x2F;<strong>dev</strong>&#x2F;**dsp</th>
</tr>
</thead>
</table>
<p>直接回放麦克风的声音，只是有一点延时。</p>
<p>但是如果有别的程序正在使用声卡，这个方法就不凑效了，因为一般的声卡都不允许多个音频流同时处理，可以借用alsa组件的工具，arecord跟aplay:</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>arecord</strong> <strong>|</strong> <strong>ssh</strong> username**@**host  <strong>aplay</strong></th>
</tr>
</thead>
</table>
<p>本地回放就是：</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>arecord</strong> <strong>|</strong> <strong>aplay</strong></th>
</tr>
</thead>
</table>
<p>如果你想吓吓别人：</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>cat</strong> **&#x2F;<strong>dev</strong>&#x2F;<strong>urandom <strong>|</strong>  <strong>ssh</strong> username</strong>@**host <strong>aplay</strong></th>
</tr>
</thead>
</table>
<h2 id="7-映射一个内存目录"><a href="#7-映射一个内存目录" class="headerlink" title="7.映射一个内存目录"></a>7.映射一个内存目录</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>mount</strong> -t tmpfs -o size&#x3D;1024m  tmpfs **&#x2F;<strong>mnt</strong>&#x2F;**ram</th>
</tr>
</thead>
</table>
<p>这个命令开了一块1G内存来当目录用。不过放心，如果里面没文件，是不会占用内存的，用多少占多少。</p>
<p>不过一般来说没必要手动挂载，因为多数发行版都会在fstab内预留了一个内存目录，挂载在&#x2F;dev&#x2F;shm，直接使用即可；</p>
<p>最常见的用途是用内存空间来放Firefox的配置，可以让慢吞吞的FF快很多，参见Shellex的博文：<a target="_blank" rel="noopener" href="http://shellex.info/speeding-up-firefox-with-tmpfs/">用tmpfs让Firefox在内存中飞驰</a>，以及后来的改进：<a target="_blank" rel="noopener" href="http://shellex.info/speeding-up-firefox-with-tmpfs-ii/">用tmpfs让Firefox在内存中飞驰II</a>，其中提到的脚本来自<a target="_blank" rel="noopener" href="http://www.linuxized.com/2009/05/speeding-up-firefox-with-tmpfs-and-automatic-rsync/">speeding up firefox with tmpfs and automatic rsync</a>。</p>
<p>那个破烂LinuxQQ也可以用这个方法，减少因为大量磁盘IO导致的问题。</p>
<h2 id="8-用diff对比远程文件跟本地文件"><a href="#8-用diff对比远程文件跟本地文件" class="headerlink" title="8.用diff对比远程文件跟本地文件"></a>8.用diff对比远程文件跟本地文件</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>ssh</strong> user**@**host <strong>cat</strong> **&#x2F;<strong>path</strong>&#x2F;<strong>to</strong>&#x2F;**remotefile  <strong>|</strong> <strong>diff</strong>  **&#x2F;<strong>path</strong>&#x2F;<strong>to</strong>&#x2F;**localfile -</th>
</tr>
</thead>
</table>
<p>diff通常的用法是从参数读入两个文件，而命令里面的-则是指从stdin读入了。</p>
<p>善用ssh可以让web开发减少很多繁琐，还有比如sshfs，可以从<strong>编辑</strong>**-<strong><strong>上传</strong></strong>-<strong><strong>编辑</strong></strong>-**<strong>上传</strong>的人工循环里面解脱出来。</p>
<h2 id="9-查看系统中占用端口的进程"><a href="#9-查看系统中占用端口的进程" class="headerlink" title="9.查看系统中占用端口的进程"></a>9.查看系统中占用端口的进程</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>netstat</strong> -tulnp</th>
</tr>
</thead>
</table>
<p>Netstat是很常用的用来查看Linux网络系统的工具之一，这个参数可以背下来：</p>
<p>·    -t: 显示TCP链接信息</p>
<p>·    -u: 显示UDP链接信息</p>
<p>·    -l: 显示监听状态的端口</p>
<p>·    -n: 直接显示ip，不做名称转换</p>
<p>·    -p: 显示相应的进程PID以及名称（要root权限）</p>
<p>如果要查看关于sockets更详细占用信息等，可以使用lsof工具。</p>
<h2 id="1-更友好的显示当前挂载的文件系统"><a href="#1-更友好的显示当前挂载的文件系统" class="headerlink" title="1. 更友好的显示当前挂载的文件系统"></a>1. 更友好的显示当前挂载的文件系统</h2><p>| <code>1</code>  | <code>**mount** **|** column -t</code> |<br>| —- | ————————— |</p>
<p>这条命令适用于任何文件系统，column 用于把输出结果进行列表格式化操作，这里最主要的目的是让大家熟悉一下 columnt 的用法。 下面是单单使用 mount 命令的结果：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5</code></th>
<th><code>$ **mount**`` ``**/**dev**/**root on **/** **type** ext3 **(**rw**)**``**/**proc on **/**proc **type** proc **(**rw**)**``**/**dev**/**mapper**/**lvmraid-home on **/**home **type** ext3 **(**rw,noatime**)**</code></th>
</tr>
</thead>
</table>
<p>而加了 column -t 命令后就成为这样了：</p>
<p>| <code>1``2``3``4``5</code> | <code>$ **mount** **|** column -t`` ``**/**dev**/**root on **/** **type** ext3 **(**rw**)**``**/**proc on **/**proc **type** proc **(**rw**)**``**/**dev**/**mapper**/**lvmraid-home on **/**home **type** ext3 **(**rw,noatime**)**</code> |<br>| ————— | ———————————————————— |</p>
<p>另外你可加上列名称来改善输出结果</p>
<p>| <code>1``2``3``4``5``6</code> | <code>$ **(echo** &quot;DEVICE - PATH - TYPE FLAGS&quot; **&amp;&amp;** **mount)** **|** column -t`` ``DEVICE          -  PATH  -   TYPE  FLAGS``**/**dev**/**root         on **/**   **type** ext3  **(**rw**)**``**/**proc           on **/**proc **type** proc  **(**rw**)**``**/**dev**/**mapper**/**lvmraid-home on **/**home **type** ext3  **(**rw,noatime**)**</code> |<br>| —————— | ———————————————————— |</p>
<p>列2和列4并不是很友好，我们可以用 awk 来再处理一下</p>
<p>| <code>1``2``3``4``5``6</code> | <code>$ **(echo** &quot;DEVICE PATH TYPE FLAGS&quot; **&amp;&amp;** **mount** **|** **awk** &#39;$2=$4=&quot;&quot;;1&#39;**)** **|** column -t`` ``DEVICE          PATH  TYPE  FLAGS``**/**dev**/**root         **/**   ext3  **(**rw**)**``**/**proc           **/**proc proc  **(**rw**)**``**/**dev**/**mapper**/**lvmraid-home **/**home ext3  **(**rw,noatime**)**</code> |<br>| —————— | ———————————————————— |</p>
<p>最后我们可以设置一个别名，为 nicemount</p>
<p>| <code>1</code>  | <code>$ nicemount**()** **{** **(echo** &quot;DEVICE PATH TYPE FLAGS&quot; **&amp;&amp;** **mount** **|** **awk** &#39;$2=$4=&quot;&quot;;1&#39;**)** **|** column -t; **}**</code> |<br>| —- | ———————————————————— |</p>
<p>试一下</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5``6</code></th>
<th><code>$ nicemount`` ``DEVICE          PATH  TYPE  FLAGS``**/**dev**/**root         **/**   ext3  **(**rw**)**``**/**proc           **/**proc proc  **(**rw**)**``**/**dev**/**mapper**/**lvmraid-home **/**home ext3  **(**rw,noatime**)**</code></th>
</tr>
</thead>
</table>
<h2 id="2-运行前一个-Shell-命令，同时用-“bar”-替换掉命令行中的每一个-“foo”"><a href="#2-运行前一个-Shell-命令，同时用-“bar”-替换掉命令行中的每一个-“foo”" class="headerlink" title="2. 运行前一个 Shell 命令，同时用 “bar” 替换掉命令行中的每一个 “foo”"></a>2. 运行前一个 Shell 命令，同时用 “bar” 替换掉命令行中的每一个 “foo”</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>**!!**:gs**/**foo**/**bar</code></th>
</tr>
</thead>
</table>
<p><code>!!</code> 表示重复执行上一条命令，并用 <code>:gs/foo/bar</code> 进行替换操作。 关于 <code>!!</code> 这个用法在<a target="_blank" rel="noopener" href="http://www.isspy.com/most_useful_linux_commands_1/">前一篇文章中</a>已有详细的介绍。</p>
<h2 id="3-实时某个目录下查看最新改动过的文件"><a href="#3-实时某个目录下查看最新改动过的文件" class="headerlink" title="3. 实时某个目录下查看最新改动过的文件"></a>3. 实时某个目录下查看最新改动过的文件</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>**watch** -d -n 1 &#39;df; ls -FlAt /path&#39;</code></th>
</tr>
</thead>
</table>
<p>watch 是实时监控工具，-d 参数会高亮显示变化的区域，-n 1 参数表示刷新间隔为 1 秒。 df; ls -FlAt &#x2F;path 运行了两条命令，df 是输出磁盘使用情况，<code>ls -FlAt</code> 则列出 &#x2F;path 下面的所有文件。 ls -FlAt 的参数详解：</p>
<p>·    -F 在文件后面加一个文件符号表示文件类型，共有 <em>&#x2F;&#x3D;&gt;@|</em> <em>这几种类型，</em> 表示可执行文件，&#x2F; 表示目录，&#x3D; 表示接口( sockets) ，&gt; 表示门， @ 表示符号链接， | 表示管道。</p>
<p>·    -l 以列表方式显示</p>
<p>·    -A 显示 <code>.</code> 和 <code>..</code></p>
<p>·    -t 根据时间排序文件</p>
<h2 id="4-通过-SSH-挂载远程主机上的文件夹"><a href="#4-通过-SSH-挂载远程主机上的文件夹" class="headerlink" title="4. 通过 SSH 挂载远程主机上的文件夹"></a>4. 通过 SSH 挂载远程主机上的文件夹</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>sshfs name**@**server:**/**path**/**to**/**folder **/**path**/**to**/**mount**/**point</code></th>
</tr>
</thead>
</table>
<p>这条命令可以让你通过 SSH 加载远程主机上的文件系统为本地磁盘，前提是你需要安装 FUSE 及 sshfs 这两个软件。 <strong>译者注</strong>：关于 sshfs 实际上我之前写过一篇文章介绍过，详见<a target="_blank" rel="noopener" href="http://wowubuntu.com/sshfs.html">在 Ubuntu 上使用 sshfs 映射远程 ssh 文件系统为本地磁盘</a>。 卸载的话使用 fusermount 或 umount 命令：</p>
<table>
<thead>
<tr>
<th><code>1``2</code></th>
<th><code>$ fusermount -u **/**path**/**to**/**mount**/**point``*# umount /path/to/mount/point*</code></th>
</tr>
</thead>
</table>
<h2 id="5-通过-DNS-来读取-Wikipedia-的词条"><a href="#5-通过-DNS-来读取-Wikipedia-的词条" class="headerlink" title="5. 通过 DNS 来读取 Wikipedia 的词条"></a>5. 通过 DNS 来读取 Wikipedia 的词条</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>**dig** +short txt .wp.dg.cx</code></th>
</tr>
</thead>
</table>
<p>这也许是最有趣的一条技巧了，David Leadbeater 创建了一个 <a target="_blank" rel="noopener" href="https://dgl.cx/wikipedia-dns">DNS 服务器</a>，通过它当你查询一个 TXT 记录类型时，会返回一条来自于 Wikipedia 的简短的词条文字，这是<a target="_blank" rel="noopener" href="https://dgl.cx/2008/11/wpdns-pres/">他的介绍</a>。 这里有一个样例，来查询 “hacker” 的含义：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5``6``7``8</code></th>
<th><code>$ **dig** +short txt hacker.wp.dg.cx`` ``&quot;Hacker may refer to: Hacker (computer security), someone involved``in computer security/insecurity, Hacker (programmer subculture), a``programmer subculture originating in the US academia in the 1960s,``which is nowadays mainly notable for the free software/” “open``source movement, Hacker (hobbyist), an enthusiastic home computer``hobbyist http://a.vu/w:Hacker&quot;</code></th>
</tr>
</thead>
</table>
<p>这里使用了 dig 命令，这是标准的用来查询 DNS 的系统管理工具，+short 参数是让其仅仅返回文字响应，txt 则是指定查询 TXT 记录类型。 更简单的做法是你可以为这个技巧创建一个函数：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5</code></th>
<th><code>wiki**()** **{** **dig** +short txt $1.wp.dg.cx; **}**``*#**然后试试吧：*``wiki hacker`` ``&quot;Hacker may refer to: Hacker (computer security), …&quot;</code></th>
</tr>
</thead>
</table>
<p>如果你不想用 dig ，也可以用 host 命令：</p>
<table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>host -t txt hacker.wp.dg.cx</code></th>
</tr>
</thead>
</table>
<p>另外在Twitter上看过某人的创意，用普通的dns来作为程序版本更新的查询服务器：设定域名<code>software-version-check.example.com</code>的A记录为<code>1.2.40.3</code>，对比自己的版本号，嗯，有更新了！</p>
<h2 id="6-用-Wget-的递归方式下载整个网站"><a href="#6-用-Wget-的递归方式下载整个网站" class="headerlink" title="6. 用 Wget 的递归方式下载整个网站"></a>6. 用 Wget 的递归方式下载整个网站</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup wget --random-wait -nc -q -r -l 0 --reject=html -np -e robots=off -U Mozilla www.example.com &amp;</span><br></pre></td></tr></table></figure>

<p>参数解释： <em>–random-wait</em> <em>等待</em> <em>0.5</em> <em>到</em> <em>1.5</em> <em>秒的时间来进行下一次请求</em> -r 开启递归检索 <em>-e robots&#x3D;off</em> <em>忽略</em> <em>robots.txt</em> -U Mozilla 设置 User-Agent 头为 Mozilla 其它一些有用的参数：</p>
<p>·    –limit-rate&#x3D;20K 限制下载速度为 20K</p>
<p>·    -o logfile.txt 记录下载日志</p>
<p>·    -l 0 删除深度（默认为5）</p>
<p>·    -wait&#x3D;1h 每下载一个文件后等待1小时</p>
<p>-np 不下载父目录 </p>
<p>–reject&#x3D;html 不下载html</p>
<p>-nc 本地已有的不再下载</p>
<h2 id="7-复制最后使用的命令中的参数"><a href="#7-复制最后使用的命令中的参数" class="headerlink" title="7. 复制最后使用的命令中的参数"></a>7. 复制最后使用的命令中的参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ctrl + . or ESC + . </span><br><span class="line">command + . //macOS</span><br></pre></td></tr></table></figure>

<p>这个快捷键只能工作于 shell 的 emacs 编辑模式，它可以从最后使用的命令行中复制参数到当前命令行中，下面是一个样例：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5</code></th>
<th><code>$ **echo** a b c``a b c`` ``$ **echo**``$ **echo** c</code></th>
</tr>
</thead>
</table>
<p>你可以重复执行该快捷键，以便获取自已需要的参数， 以下是样例：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5``6``7``8``9``10</code></th>
<th><code>$ **echo** 1 2 3``1 2 3``$ **echo** a b c``a b c`` ``$ **echo**``$ **echo** c`` ``$ **echo** again``$ **echo** 3</code></th>
</tr>
</thead>
</table>
<p>另外，假如你想指定第1个或第2个，或者是第 n 个参数的话，可以按 ALT + 1 (或 ESC + 1) 或 ALT + 2 (或 ESC +2) 这样形式的快捷键。 以下是样例：</p>
<table>
<thead>
<tr>
<th><code>1``2``3``4``5``6``7``8``9``10</code></th>
<th><code>$ **echo** a b c``a b c`` ``$ **echo**``$ **echo** a``a`` ``$ **echo**``$ **echo** b``b</code></th>
</tr>
</thead>
</table>
<p>查看<a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/bash-emacs-editing-mode-cheat-sheet/">Emacs Editing Mode Keyboard Shortcuts</a>一文获取更多类似的快捷键。</p>
<h2 id="8-执行一条命令但不保存到-history-中"><a href="#8-执行一条命令但不保存到-history-中" class="headerlink" title="8. 执行一条命令但不保存到 history 中"></a>8. 执行一条命令但不保存到 history 中</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>$ **command**</code></th>
</tr>
</thead>
</table>
<p>这条命令可运行于最新的 Bash shell 里，在其它 shell 中没测试过。 通过在命令行前面添加一个空格，就可以阻止这条命令被保存到 bash history (~&#x2F;.bash_history) 文件中，这个行为可以通过 $HISTIGNORE shell 变量来控制。我的设置是 HISTIGNORE&#x3D;”&amp;:[ ]*” ，表示不保存重复的命令到 history 中，并且不保存以空格开头的命令行。$HISTIGNORE 中的值以冒号分隔。 如果你的命令内包含密码，比如<code>mysqladmin</code>，不把它记录在历史当中是好主义。 深入了解的话，可进一步看此文<a target="_blank" rel="noopener" href="http://www.catonmat.net/blog/the-definitive-guide-to-bash-command-line-history/">The Definitive Guide to Bash Command Line History</a></p>
<h2 id="9-显示当前目录中所有子目录的大小-du"><a href="#9-显示当前目录中所有子目录的大小-du" class="headerlink" title="9. 显示当前目录中所有子目录的大小 du"></a>9. 显示当前目录中所有子目录的大小 du</h2><table>
<thead>
<tr>
<th>sudo du –max-depth&#x3D;1 -BG &#x2F;&#x2F;单位 block-size G;  or  -BM MB</th>
<th>du -h –max-depth&#x3D;1</th>
</tr>
</thead>
</table>
<p>–max-depth&#x3D;1 参数可以让 du 命令显示当前目录下 1 级子目录的统计信息，当然你也可以把 1 改为 2 ，进一步显示 2 级子目录的统计信息，可以灵活运用。而 -h 参数则是以 Mb 、G 这样的单位来显示大小。 <strong>译者注</strong>：在此推荐一个小工具 ncdu ，可以更方便的达到此效果。</p>
<p> 按单位大小排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#du -sh * | sort -hr | head</span><br><span class="line">1.8T	anolis_yum</span><br><span class="line">1.6T	u02</span><br><span class="line">1.5T	os</span><br><span class="line">45G	drds_image</span><br><span class="line">23G	polarx</span><br><span class="line">8.3G	src</span><br><span class="line">7.9G	drds.pcap</span><br><span class="line">7.8G	root</span><br><span class="line">4.3G	core.24086</span><br><span class="line">3.5G	core.112462</span><br></pre></td></tr></table></figure>



<h2 id="10-显示消耗内存最多的-10-个运行中的进程，以内存使用量排序"><a href="#10-显示消耗内存最多的-10-个运行中的进程，以内存使用量排序" class="headerlink" title="10. 显示消耗内存最多的 10 个运行中的进程，以内存使用量排序"></a>10. 显示消耗内存最多的 10 个运行中的进程，以内存使用量排序</h2><p>| <code>1</code>  | <code>**ps** aux **|** **sort** -nk +4 **|** **tail**</code> |<br>| —- | ————————————————- |</p>
<p>显然这并不是最好的方法，但它确实用起还不错。 这是一个典型的管道应用，通过 ps aux 来输出到 sort 命令，并用 sort 排序列出 4 栏，再进一步转到 tail 命令，最终输出 10 行显示使用内存最多的进程情况。 假如想要发现哪个进程使用了大量内存的话，我通常会使用 htop 或 top 而非 ps 。</p>
<h2 id="11-用-python-快速开启一个-SMTP-服务"><a href="#11-用-python-快速开启一个-SMTP-服务" class="headerlink" title="11. 用 python 快速开启一个 SMTP 服务"></a>11. 用 python 快速开启一个 SMTP 服务</h2><table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>python -m smtpd -n -c DebuggingServer localhost:1025</code></th>
</tr>
</thead>
</table>
<p>这是一个用 Python 标准库 smtpd （用 -m smtpd 指定) 实现在简易 SMTP 服务，运行于 1025 端口 。 另外三个参数的解释： <em>-n</em> <em>参数让</em> <em>Python</em> <em>不要进行</em> <em>setuid (</em> <em>改变用户）为</em> <em>“nobody”</em> <em>，也就是说直接用你的帐号来运行</em> -c DebuggingServer 参数是让 Python 运行时在屏幕上输出调试及运行信息 * localhost:1025 参数则是让 Python 在本地的 1025 端口上开启 SMTP 服务 另外，假如你想让程序运行于标准的 25 的端口上的话，你必须使用 sudo 命令，因为只有 root 才能在 1-1024 端口上开启服务。如下：</p>
<table>
<thead>
<tr>
<th><code>1</code></th>
<th><code>**sudo** python -m smtpd -n -c DebuggingServer localhost:25</code></th>
</tr>
</thead>
</table>
<p>1.查看ascii码表</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>man</strong> 7 ascii</th>
</tr>
</thead>
</table>
<p>很多人初学编程都会接触到ascii码的概念，有时候为了查某个符号的ascii值，可能还得翻箱倒柜找出当年的课本？<a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/">Linux Manpage</a>里面其实包含了很多类似的实用资料，上述命令就能很详细的方式解释ascii编码，<a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/ascii.7.html">当然这里还有在线版</a>。</p>
<p>man命令的第二个参数是区域码，用来区分索引词的范围，比如printf，在C标准库里面的printf跟bash当中的printf是不同的，前者的查询是man 3 printf，后者是man 1 printf。如果这个区域码省略，就会从1开始搜索，直到找到为止。</p>
<p>命令man man可以<a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/man-pages.7.html">看到详细的解释</a>。</p>
<p>manpages里面还有一些有趣而且实用的资料，可能鲜为人知：</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man1/intro.1.html">man 1 intro </a>– 一篇对从未接触过Linux的用户的简明教程。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man2/syscalls.2.html">man 2 syscalls </a>– 内核系统请求的列表，按内核版本注释分类，系统编程必备。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man2/select_tut.2.html">man 2 select_tut </a>– 关于select()系统请求的教程。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man3/string.3.html">man 3 string </a>– 在头文件内的所有函数。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man3/stdio.3.html">man 3 stdio </a>– 关于头文件的使用，标准输入&#x2F;输出库的说明。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man3/errno.3.html">man 3 errno </a>– 所有errorno的取值及说明。（C语言内类似其他语言的异常告知机制）</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man4/console_codes.4.html">man 4 console_codes </a>– Linux的终端控制码及其使用解释。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man4/full.4.html">man 4 full </a>– 介绍&#x2F;dev&#x2F;full这个总是处于“满”状态的磁盘。（对应&#x2F;dev&#x2F;null这个总是空的设备）</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man5/proc.5.html">man 5 proc </a>– 介绍&#x2F;proc下的文件系统。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man5/filesystems.5.html">man 5 filesystems </a>– 各种Linux文件系统。</p>
<p>第7区里面的资料通常最酷：</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/bootparam.7.html">man 7 bootparam </a>– 详细解释内核启动参数。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/charsets.7.html">man 7 charsets </a>– 解释各种语言的编码集。（gbk，gb2312等）</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/glob.7.html">man 7 glob </a>– 解释glob文件名管理机制的工作过程。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/hier.7.html">man 7 hier </a>– 解释Linux文件系统结构各个部分的作用。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/operator.7.html">man 7 operator </a>– C语言的运算符的列表。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/regex.7.html">man 7 regex </a>– 介绍正则表达式。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/suffixes.7.html">man 7 suffixes </a>– 常见文件后缀名的列表跟解释。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/time.7.html">man 7 time </a>– Linux的时钟机制解释。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/units.7.html">man 7 units </a>– 数值单位及其数值的解释。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/utf8.7.html">man 7 utf8 </a>– 描述UTF-8编码。</p>
<p>·    <a target="_blank" rel="noopener" href="http://www.kernel.org/doc/man-pages/online/pages/man7/url.7.html">man 7 url </a>– 解释URL、URI、URN等的标准。</p>
<p>2.简易计时器</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>time</strong> <strong>read</strong></th>
</tr>
</thead>
</table>
<p>运行命令开始算起，到结束时按一下Enter，就显示出整个过程的时间，精确到ms级别。</p>
<p>time是用来计算一个进程在运行到结束过程耗费多少时间的程序，它的输出通常有三项：</p>
<table>
<thead>
<tr>
<th>1  2  3  4  5</th>
<th>$ time ls &#x2F;opt  …  real    0m0.008s  user    0m0.003s  sys    0m0.007s</th>
</tr>
</thead>
</table>
<p>real指整个程序对真实世界而言运行所需时间，user指程序在用户空间运行的时间，sys指程序对系统调用锁占用时间。</p>
<p>read本来是一个读取用户输入的命令，常见用法是read LINE，用户输入并回车后，键入的内容就被保存到$LINE变量内，但在键入回车前，这个命令是一直阻塞的。</p>
<p>可见time read这命令灵活地利用了操作系统的阻塞。用这个命令来测试一壶水多久煮滚应该是不错的。</p>
<p>3.远程关掉一台Windows机器</p>
<table>
<thead>
<tr>
<th>1</th>
<th>net rpc shutdown -I  IP_ADDRESS -U username**%**password</th>
</tr>
</thead>
</table>
<p>Windows平台上的net命令是比较强大的，因为其后台是一个RPC类的系统服务，大家应该看过win下用net use \ip\ipc$ *这样一个命令建立IPC空连接，入侵主机的事情。</p>
<p>Linux下的net命令是samba组件的程序，通常包含在smbclient内，可以跟windows主机的文件、打印机共享等服务进行通讯，但是也支持rpc命令。</p>
<p>上述命令就是在远程Windows主机上执行了shutdown命令。当然这不一定成功，关系到win主机上面的安全设置。net命令能够控制到win主机就是了。</p>
<h2 id="4-在一个子shell中运行一个命令"><a href="#4-在一个子shell中运行一个命令" class="headerlink" title="4.在一个子shell中运行一个命令"></a>4.在一个子shell中运行一个命令</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>(cd</strong> **&#x2F;**tmp <strong>&amp;&amp;</strong> <strong>ls)</strong></th>
</tr>
</thead>
</table>
<p>当然这只是演示，要查看目录当然可以ls &#x2F;tmp。</p>
<p>好处就是不会改变当前shell的目录，以及如果命令中设计环境变量，也不会对当前shell有任何修改。</p>
<p>在Shell编程中还有很多使用上引号来括住一个命令：<code>ls /tmp</code>，这也是子shell过程。可是上引号的方法无法嵌套，而使用小括号的方法可以，一个比较纠结的例子是：</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>echo</strong> $<strong>(echo</strong> -e \x$<strong>(printf</strong>  “%x” 65**))**</th>
</tr>
</thead>
</table>
<p>5.利用中间管道嵌套使用SSH</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>ssh</strong> -t host_A <strong>ssh</strong> host_B</th>
</tr>
</thead>
</table>
<p>如果目标机器host_B处于比较复杂的网络环境，本机无法直接访问，但另外一台host_A能够访问到host_B，而且也能被本机访问到，那上述命令就解决了方便登录host_B的问题。</p>
<p>但理论上这个过程是可以无限嵌套的，比如：</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>ssh</strong> -t host1 <strong>ssh</strong> -t  host2 <strong>ssh</strong> -t  host3 <strong>ssh</strong> -t  host4 …</th>
</tr>
</thead>
</table>
<p>嗯那神马FBI CIA的，有本事来捉我吧～</p>
<p>6.清空屏幕</p>
<table>
<thead>
<tr>
<th>1</th>
<th><strong>&lt;**CTRL+l**&gt;</strong>;</th>
</tr>
</thead>
</table>
<p>这个跟之前介绍的reset命令重置终端的作用有些类似，其实都只是发送一段控制序列，让终端的显示复位。</p>
<p>还可以这样运行：</p>
<table>
<thead>
<tr>
<th>1</th>
<th>tput <strong>clear</strong></th>
</tr>
</thead>
</table>
<p>tput是专门用来控制终端的一个小工具，也挺强大的，详细信息运行man tput查看。</p>
<h2 id="7-我想知道一台服务器什么时候重启完"><a href="#7-我想知道一台服务器什么时候重启完" class="headerlink" title="7.我想知道一台服务器什么时候重启完"></a>7.我想知道一台服务器什么时候重启完</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>ping</strong> -a IP</th>
</tr>
</thead>
</table>
<p>系统管理员最常做的事情是重启系统。但是服务器的重启过程往往得花上好几分钟，什么你的服务器4个scsi卡？16个硬盘？系统是Redhat？还完全安装所有组件？好吧，它重启的时间都够你吃顿饭了，所以我很想知道它什么时候回来。</p>
<p>ping命令有个audible ping参数，-a，当它终于ping通你的服务器时会让小喇叭叫起来。</p>
<h2 id="8-列出你最常用的10条命令"><a href="#8-列出你最常用的10条命令" class="headerlink" title="8.列出你最常用的10条命令"></a>8.列出你最常用的10条命令</h2><table>
<thead>
<tr>
<th>1</th>
<th><strong>history</strong> <strong>|</strong> <strong>awk</strong> ‘{a[$2]++}END{for(i  in a){print a[i] “ “ i}}’ <strong>|</strong>  <strong>sort</strong> -rn  <strong>|</strong> <strong>head</strong></th>
</tr>
</thead>
</table>
<p>这行命令组合得很妙：</p>
<p>history输出用户了命令历史；awk统计并输出列表；sort排序；head截出前10行。</p>
<h2 id="9-检查Gmail新邮件"><a href="#9-检查Gmail新邮件" class="headerlink" title="9.检查Gmail新邮件"></a>9.检查Gmail新邮件</h2><table>
<thead>
<tr>
<th>1  2  3  4  5  6</th>
<th>curl -u you**@**gmail.com –silent  “<a target="_blank" rel="noopener" href="https://mail.google.com/mail/feed/atom">https://mail.google.com/mail/feed/atom</a>“  <strong>|</strong>   <strong>perl</strong> -ne  \   ‘      print “Subject: $1 “ if &#x2F;<title>(.+?)&lt;/title&gt;&#x2F;  &amp;&amp; $title++;      print “(from $1)\n” if &#x2F;<email>(.+?)&lt;/email&gt;&#x2F;;   ‘</th>
</tr>
</thead>
</table>
<p>Gmail的一个特色是支持Atom feed输出邮件列表，所以总是见到很多Gmail邮件提醒器之类的，因为开发特简单，atom很方便。</p>
<p>这里只是利用了perl的正则来解析atom（sed&#x2F;awk也能做到）。</p>
<h2 id="10-用Telnet看《星球大战》"><a href="#10-用Telnet看《星球大战》" class="headerlink" title="10.用Telnet看《星球大战》"></a>10.用Telnet看《星球大战》</h2><table>
<thead>
<tr>
<th>1</th>
<th>telnet towel.blinkenlights.nl</th>
</tr>
</thead>
</table>
<p>没什么好解释的，就是ASCII艺术之一。如果你有ipv6连接，还能看到彩色版的。牛吧？</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2016/10/12/ss%E7%94%A8%E6%B3%95%E5%A4%A7%E5%85%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2016/10/12/ss%E7%94%A8%E6%B3%95%E5%A4%A7%E5%85%A8/" class="post-title-link" itemprop="url">就是要你懂网络监控--ss用法大全</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2016-10-12 15:30:03" itemprop="dateCreated datePublished" datetime="2016-10-12T15:30:03+08:00">2016-10-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/network/" itemprop="url" rel="index"><span itemprop="name">network</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="就是要你懂网络监控–ss用法大全"><a href="#就是要你懂网络监控–ss用法大全" class="headerlink" title="就是要你懂网络监控–ss用法大全"></a>就是要你懂网络监控–ss用法大全</h1><p>ss是Socket Statistics的缩写。</p>
<p>netstat命令大家肯定已经很熟悉了，但是在2001年的时候netstat 1.42版本之后就没更新了，之后取代的工具是ss命令，是iproute2 package的一员。</p>
<blockquote>
<p>​	rpm -ql iproute | grep ss<br>​	&#x2F;usr&#x2F;sbin&#x2F;ss</p>
</blockquote>
<p>netstat的替代工具是nstat，当然netstat的大部分功能ss也可以替代</p>
<p>ss可以显示跟netstat类似的信息，但是速度却比netstat快很多，netstat是基于&#x2F;proc&#x2F;net&#x2F;tcp获取 TCP socket 的相关统计信息，用strace跟踪一下netstat查询tcp的连接，会看到他open的是&#x2F;proc&#x2F;net&#x2F;tcp的信息。ss快的秘密就在于它利用的是TCP协议的tcp_diag模块，而且是从内核直接读取信息，<strong>当内核不支持  tcp_diag 内核模块时，会回退到 &#x2F;proc&#x2F;net&#x2F;tcp 模式</strong>。</p>
<p>&#x2F;proc&#x2F;net&#x2F;snmp 存放的是系统启动以来的累加值，netstat -s 读取它<br>&#x2F;proc&#x2F;net&#x2F;tcp  是存放目前活跃的tcp连接的统计值，连接断开统计值清空， ss -it 读取它</p>
<h2 id="ss-查看Buffer窗口"><a href="#ss-查看Buffer窗口" class="headerlink" title="ss 查看Buffer窗口"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/discussions/3624151">ss 查看Buffer窗口</a></h2><p>ss参数说明<a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man8/ss.8.html">权威参考</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">-m, --memory  //查看每个连接的buffer使用情况</span><br><span class="line">              Show socket memory usage. The output format is:</span><br><span class="line"></span><br><span class="line">              skmem:(r&lt;rmem_alloc&gt;,rb&lt;rcv_buf&gt;,t&lt;wmem_alloc&gt;,tb&lt;snd_buf&gt;,</span><br><span class="line">                            f&lt;fwd_alloc&gt;,w&lt;wmem_queued&gt;,o&lt;opt_mem&gt;,</span><br><span class="line">                            bl&lt;back_log&gt;,d&lt;sock_drop&gt;)</span><br><span class="line"></span><br><span class="line">              &lt;rmem_alloc&gt;</span><br><span class="line">                     the memory allocated for receiving packet</span><br><span class="line"></span><br><span class="line">              &lt;rcv_buf&gt;</span><br><span class="line">                     the total memory can be allocated for receiving</span><br><span class="line">                     packet</span><br><span class="line"></span><br><span class="line">              &lt;wmem_alloc&gt;</span><br><span class="line">                     the memory used for sending packet (which has been</span><br><span class="line">                     sent to layer 3)</span><br><span class="line"></span><br><span class="line">              &lt;snd_buf&gt;</span><br><span class="line">                     the total memory can be allocated for sending</span><br><span class="line">                     packet</span><br><span class="line"></span><br><span class="line">              &lt;fwd_alloc&gt;</span><br><span class="line">                     the memory allocated by the socket as cache, but</span><br><span class="line">                     not used for receiving/sending packet yet. If need</span><br><span class="line">                     memory to send/receive packet, the memory in this</span><br><span class="line">                     cache will be used before allocate additional</span><br><span class="line">                     memory.</span><br><span class="line"></span><br><span class="line">              &lt;wmem_queued&gt;</span><br><span class="line">                     The memory allocated for sending packet (which has</span><br><span class="line">                     not been sent to layer 3)</span><br><span class="line"></span><br><span class="line">              &lt;ropt_mem&gt;</span><br><span class="line">                     The memory used for storing socket option, e.g.,</span><br><span class="line">                     the key for TCP MD5 signature</span><br><span class="line"></span><br><span class="line">              &lt;back_log&gt;</span><br><span class="line">                     The memory used for the sk backlog queue. On a</span><br><span class="line">                     process context, if the process is receiving</span><br><span class="line">                     packet, and a new packet is received, it will be</span><br><span class="line">                     put into the sk backlog queue, so it can be</span><br><span class="line">                     received by the process immediately</span><br><span class="line"></span><br><span class="line">              &lt;sock_drop&gt;</span><br><span class="line">                     the number of packets dropped before they are de-</span><br><span class="line">                     multiplexed into the socket</span><br></pre></td></tr></table></figure>

<p>The entire print format of <code>ss -m</code> is given in the source:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">      printf(&quot; skmem:(r%u,rb%u,t%u,tb%u,f%u,w%u,o%u&quot;,</span><br><span class="line">               skmeminfo[SK_MEMINFO_RMEM_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_RCVBUF],</span><br><span class="line">               skmeminfo[SK_MEMINFO_WMEM_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_SNDBUF],</span><br><span class="line">               skmeminfo[SK_MEMINFO_FWD_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_WMEM_QUEUED],</span><br><span class="line">               skmeminfo[SK_MEMINFO_OPTMEM]);</span><br><span class="line"></span><br><span class="line">        if (RTA_PAYLOAD(tb[attrtype]) &gt;=</span><br><span class="line">                (SK_MEMINFO_BACKLOG + 1) * sizeof(__u32))</span><br><span class="line">                printf(&quot;,bl%u&quot;, skmeminfo[SK_MEMINFO_BACKLOG]);</span><br><span class="line"></span><br><span class="line">        if (RTA_PAYLOAD(tb[attrtype]) &gt;=</span><br><span class="line">                (SK_MEMINFO_DROPS + 1) * sizeof(__u32))</span><br><span class="line">                printf(&quot;,d%u&quot;, skmeminfo[SK_MEMINFO_DROPS]);</span><br><span class="line"></span><br><span class="line">        printf(&quot;)&quot;);</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">net/core/sock.c line:3095</span><br><span class="line">void sk_get_meminfo(const struct sock *sk, u32 *mem)</span><br><span class="line">&#123;</span><br><span class="line">	memset(mem, 0, sizeof(*mem) * SK_MEMINFO_VARS);</span><br><span class="line"></span><br><span class="line">	mem[SK_MEMINFO_RMEM_ALLOC] = sk_rmem_alloc_get(sk);</span><br><span class="line">	mem[SK_MEMINFO_RCVBUF] = sk-&gt;sk_rcvbuf;</span><br><span class="line">	mem[SK_MEMINFO_WMEM_ALLOC] = sk_wmem_alloc_get(sk);</span><br><span class="line">	mem[SK_MEMINFO_SNDBUF] = sk-&gt;sk_sndbuf;</span><br><span class="line">	mem[SK_MEMINFO_FWD_ALLOC] = sk-&gt;sk_forward_alloc;</span><br><span class="line">	mem[SK_MEMINFO_WMEM_QUEUED] = sk-&gt;sk_wmem_queued;</span><br><span class="line">	mem[SK_MEMINFO_OPTMEM] = atomic_read(&amp;sk-&gt;sk_omem_alloc);</span><br><span class="line">	mem[SK_MEMINFO_BACKLOG] = sk-&gt;sk_backlog.len;</span><br><span class="line">	mem[SK_MEMINFO_DROPS] = atomic_read(&amp;sk-&gt;sk_drops);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/image-20210604120011898.png" alt="image-20210604120011898"></p>
<p>–memory&#x2F;-m ： 展示buffer窗口的大小</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#ss -m | xargs -L 1 | grep &quot;ESTAB&quot; | awk &#x27;&#123; if($3&gt;0 || $4&gt;0) print $0 &#125;&#x27;</span><br><span class="line">tcp ESTAB 0 31 10.97.137.1:7764 10.97.137.2:41019 skmem:(r0,rb7160692,t0,tb87040,f1792,w2304,o0,bl0)</span><br><span class="line">tcp ESTAB 0 193 ::ffff:10.97.137.1:sdo-tls ::ffff:10.97.137.2:55545 skmem:(r0,rb369280,t0,tb87040,f1792,w2304,o0,bl0)</span><br><span class="line">tcp ESTAB 0 65 ::ffff:10.97.137.1:splitlock ::ffff:10.97.137.2:47796 skmem:(r0,rb369280,t0,tb87040,f1792,w2304,o0,bl0)</span><br><span class="line">tcp ESTAB 0 80 ::ffff:10.97.137.1:informer ::ffff:10.97.137.3:49279 skmem:(r0,rb369280,t0,tb87040,f1792,w2304,o0,bl0)</span><br><span class="line">tcp ESTAB 0 11 ::ffff:10.97.137.1:acp-policy ::ffff:10.97.137.2:41607 skmem:(r0,rb369280,t0,tb87040,f1792,w2304,o0,bl0)</span><br><span class="line"></span><br><span class="line">#ss -m -n | xargs -L 1 | grep &quot;tcp EST&quot; | grep &quot;t[1-9]&quot;</span><br><span class="line">tcp ESTAB 0 281 10.97.169.173:32866 10.97.170.220:3306 skmem:(r0,rb4619516,t2304,tb87552,f1792,w2304,o0,bl0)</span><br></pre></td></tr></table></figure>

<p><img src="/images/oss/4a09503e6c6e84c25e026248a1b3ebb6.png" alt="image.png"></p>
<p>如上图，tb指可分配的发送buffer大小，不够还可以动态调整（应用没有写死的话），w[The memory allocated for sending packet (which has not been sent to layer 3)]已经预分配好了的size，t[the memory used for sending packet (which has been sent to layer 3)] , 似乎 w总是等于大于t？</p>
<p>example:</p>
<p><img src="/images/oss/4ed3d8aab6ef3ee45decda75e534baab.png" alt="image.png"></p>
<p>对172.16.210.17和172.16.160.1之间的带宽限速50MB后观察(带宽限制后，发送buffer就很容易被撑满了）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">ss -m | xargs -L 1 | grep <span class="string">&quot;tcp EST&quot;</span> | awk <span class="string">&#x27;&#123; if($3&gt;0 || $4&gt;0) print $0 &#125;&#x27;</span></span></span><br><span class="line">Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port</span><br><span class="line">tcp ESTAB 1431028 0 172.16.210.17:30082 172.16.160.1:4847 skmem:(r2066432,rb2135508,t0,tb46080,f2048,w0,o0,bl0,d72)</span><br><span class="line">tcp ESTAB 1195628 0 172.16.210.17:30086 172.16.160.1:4847 skmem:(r1742848,rb1915632,t8,tb46080,f190464,w0,o0,bl0,d187)</span><br><span class="line">tcp ESTAB 86416 0 172.16.210.17:40470 172.16.160.1:4847 skmem:(r127232,rb131072,t0,tb46080,f3840,w0,o0,bl0,d16)</span><br><span class="line">tcp ESTAB 1909826 0 172.16.210.17:40476 172.16.160.1:4847 skmem:(r2861568,rb2933688,t2,tb46080,f26112,w0,o0,bl0,d15)</span><br><span class="line">tcp ESTAB 758312 0 172.16.210.17:40286 172.16.160.1:4847 skmem:(r1124864,rb1177692,t0,tb46080,f1536,w0,o0,bl0,d17)</span><br><span class="line">tcp ESTAB 2238720 0 172.16.210.17:40310 172.16.160.1:4847 skmem:(r3265280,rb3334284,t0,tb46080,f3328,w0,o0,bl0,d30)</span><br><span class="line">tcp ESTAB 88172 0 172.16.210.17:40508 172.16.160.1:4847 skmem:(r128000,rb131072,t0,tb46080,f3072,w0,o0,bl0,d16)</span><br><span class="line">tcp ESTAB 87700 0 172.16.210.17:41572 172.16.160.1:4847 skmem:(r130560,rb131072,t0,tb46080,f512,w0,o0,bl0,d10)</span><br><span class="line">tcp ESTAB 4147293 0 172.16.210.17:40572 172.16.160.1:4847 skmem:(r6064896,rb6291456,t2,tb46080,f75008,w0,o0,bl0,d27)</span><br><span class="line">tcp ESTAB 1610940 0 172.16.210.17:30100 172.16.160.1:4847 skmem:(r2358784,rb2533092,t6,tb46080,f82432,w0,o0,bl0,d304)</span><br><span class="line">tcp ESTAB 4216156 0 172.16.210.17:30068 172.16.160.1:4847 skmem:(r6091008,rb6291456,t0,tb46080,f3840,w0,o0,bl0,d112)</span><br><span class="line">tcp ESTAB 87468 0 172.16.210.17:40564 172.16.160.1:4847 skmem:(r127232,rb131072,t0,tb46080,f3840,w0,o0,bl0,d16)</span><br><span class="line">tcp ESTAB 0 84608 172.16.210.17:3306 10.100.7.27:43114 skmem:(r0,rb65536,t8352,tb131072,f75648,w92288,o0,bl0,d0)</span><br><span class="line">tcp ESTAB 4141872 0 172.16.210.17:40584 172.16.160.1:4847 skmem:(r6050560,rb6291456,t2,tb46080,f19712,w0,o0,bl0,d14)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">ss -itn</span></span><br><span class="line">State       Recv-Q Send-Q   Local Address:Port                  Peer Address:Port</span><br><span class="line">ESTAB       965824 0        172.16.210.17:19310                 172.16.160.1:4847</span><br><span class="line">         cubic wscale:9,7 rto:215 rtt:14.405/0.346 ato:160 mss:1440 rcvmss:1460 advmss:1460 cwnd:10 bytes_acked:1324584 bytes_received:2073688144 segs_out:91806 segs_in:1461520 data_segs_out:4824 data_segs_in:1456130 send 8.0Mbps lastsnd:545583 lastrcv:545276 lastack:13173 pacing_rate 16.0Mbps delivery_rate 8.9Mbps app_limited busy:9071ms rcv_rtt:1.303 rcv_space:164245 minrtt:1.293</span><br><span class="line">ESTAB       0      84371    172.16.210.17:3306                  10.100.7.147:59664</span><br><span class="line">         cubic wscale:7,7 rto:217 rtt:16.662/0.581 ato:40 mss:1448 rcvmss:976 advmss:1448 cwnd:375 ssthresh:19 bytes_acked:5087795046 bytes_received:1647 segs_out:3589314 segs_in:358086 data_segs_out:3589313 data_segs_in:8 send 260.7Mbps lastsnd:6 lastrcv:1177745 lastack:4 pacing_rate 312.8Mbps delivery_rate 32.9Mbps busy:1176476ms rwnd_limited:1717ms(0.1%) sndbuf_limited:159867ms(13.6%) unacked:37 retrans:0/214 rcv_space:14600 notsent:32055 minrtt:7.945</span><br><span class="line">ESTAB       0      83002    172.16.210.17:3306                   10.100.7.28:34066</span><br><span class="line">         cubic wscale:7,7 rto:215 rtt:14.635/0.432 ato:40 mss:1448 rcvmss:976 advmss:1448 cwnd:144 ssthresh:144 bytes_acked:972464708 bytes_received:1466 segs_out:671667 segs_in:94369 data_segs_out:671666 data_segs_in:8 send 114.0Mbps lastsnd:1 lastrcv:453365 lastack:1 pacing_rate 136.8Mbps delivery_rate 24.0Mbps busy:453493ms sndbuf_limited:200ms(0.0%) unacked:23 rcv_space:14600 notsent:49698 minrtt:9.937</span><br><span class="line">ESTAB       1239616 0        172.16.210.17:41592                 172.16.160.1:4847</span><br><span class="line">         cubic wscale:9,7 rto:216 rtt:15.754/0.775 ato:144 mss:1440 rcvmss:1460 advmss:1460 cwnd:10 bytes_acked:20321 bytes_received:1351071 segs_out:269 segs_in:1091 data_segs_out:76 data_segs_in:988 send 7.3Mbps lastsnd:339339 lastrcv:337401 lastack:10100 pacing_rate 14.6Mbps delivery_rate 1.0Mbps app_limited busy:1214ms rcv_rtt:227.156 rcv_space:55581 minrtt:11.38</span><br><span class="line">ESTAB       3415748 0        172.16.210.17:30090                 172.16.160.1:4847</span><br><span class="line">         cubic wscale:9,7 rto:202 rtt:1.667/0.011 ato:80 mss:1440 rcvmss:1460 advmss:1460 cwnd:10 bytes_acked:398583 bytes_received:613824362 segs_out:28630 segs_in:437621 data_segs_out:1495 data_segs_in:435792 send 69.1Mbps lastsnd:1179931 lastrcv:1179306 lastack:12149 pacing_rate 138.2Mbps delivery_rate 7.2Mbps app_limited busy:2520ms rcv_rtt:1.664 rcv_space:212976 minrtt:1.601</span><br><span class="line">ESTAB       86480  0        172.16.210.17:41482                 172.16.160.1:4847</span><br><span class="line">         cubic wscale:9,7 rto:215 rtt:14.945/1.83 ato:94 mss:1440 rcvmss:1460 advmss:1460 cwnd:10 bytes_acked:3899 bytes_received:93744 segs_out:73 segs_in:136 data_segs_out:20 data_segs_in:83 send 7.7Mbps lastsnd:449541 lastrcv:449145 lastack:19314 pacing_rate 15.4Mbps delivery_rate 964.2Kbps app_limited busy:296ms rcv_rtt:8561.27 rcv_space:14600 minrtt:11.948</span><br><span class="line">ESTAB       89136  0        172.16.210.17:40480                 172.16.160.1:4847</span><br><span class="line">         cubic wscale:9,7 rto:213 rtt:12.11/0.79 ato:196 mss:1440 rcvmss:1460 advmss:1460 cwnd:10 bytes_acked:2510 bytes_received:95652 segs_out:102 segs_in:168 data_segs_out:16 data_segs_in:81send 9.5Mbps lastsnd:1099067 lastrcv:1098659 lastack:13686 pacing_rate 19.0Mbps delivery_rate 1.0Mbps app_limited busy:199ms rcv_rtt:2438.63 rcv_space:14600 minrtt:11.178</span><br><span class="line">ESTAB       0      84288    172.16.210.17:3306                   10.100.7.26:51160</span><br><span class="line">         cubic wscale:7,7 rto:216 rtt:15.129/0.314 ato:40 mss:1448 rcvmss:976 advmss:1448 cwnd:157 ssthresh:157 bytes_acked:2954689465 bytes_received:1393 segs_out:2041403 segs_in:237797 data_segs_out:2041402 data_segs_in:8 send 120.2Mbps lastsnd:11 lastrcv:1103462 lastack:10 pacing_rate 144.2Mbps delivery_rate 31.3Mbps busy:1103503ms sndbuf_limited:3398ms(0.3%) unacked:24 retrans:0/7rcv_space:14600 notsent:49536 minrtt:9.551</span><br></pre></td></tr></table></figure>

<p>推荐 -m -i 一起查看状态，比如 rcv_space 表示buffer达到过的最大水位</p>
<blockquote>
<p><strong>rcv_space</strong> is the high water mark of the rate of the local application reading from the receive buffer during any RTT. This is used internally within the kernel to adjust sk_rcvbuf.</p>
</blockquote>
<h2 id="ss-查看拥塞窗口、RTO"><a href="#ss-查看拥塞窗口、RTO" class="headerlink" title="ss 查看拥塞窗口、RTO"></a>ss 查看拥塞窗口、RTO</h2><blockquote>
<p>&#x2F;&#x2F;rto的定义，不让修改，每个ip的rt都不一样，必须通过rtt计算所得, HZ 一般是1秒<br>#define TCP_RTO_MAX     ((unsigned)(120*HZ))<br>#define TCP_RTO_MIN     ((unsigned)(HZ&#x2F;5)) &#x2F;&#x2F;在rt很小的环境中计算下来RTO基本等于TCP_RTO_MIN</p>
</blockquote>
<p>下面看到的rto和rtt单位都是毫秒，一般rto最小为200ms、最大为120秒</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#ss -itn |egrep &quot;cwnd|rto&quot;	</span><br><span class="line">ESTAB       0      165      [::ffff:192.168.0.174]:48074                [::ffff:192.168.0.173]:3306</span><br><span class="line">	cubic wscale:7,7 rto:201 rtt:0.24/0.112 ato:40 mss:1448 rcvmss:1448 advmss:1448 cwnd:10 bytes_acked:1910206449 bytes_received:8847784416 segs_out:11273005 segs_in:22997562 data_segs_out:9818729 data_segs_in:13341573 send 482.7Mbps lastsnd:1 lastrcv:1 pacing_rate 963.8Mbps delivery_rate 163.2Mbps app_limited busy:2676463ms retrans:0/183 rcv_rtt:1.001 rcv_space:35904 minrtt:0.135</span><br><span class="line"></span><br><span class="line">ESTAB       0      0        [::ffff:192.168.0.174]:48082                [::ffff:192.168.0.173]:3306</span><br><span class="line">	 cubic wscale:7,7 rto:201 rtt:0.262/0.112 ato:40 mss:1448 rcvmss:1448 advmss:1448 cwnd:10 bytes_acked:1852907381 bytes_received:8346503207 segs_out:10913962 segs_in:22169704 data_segs_out:9531411 data_segs_in:12796151 send 442.1Mbps lastsnd:2 lastack:2 pacing_rate 881.3Mbps delivery_rate 164.3Mbps app_limited busy:2736500ms retrans:0/260 rcv_rtt:1.042 rcv_space:31874 minrtt:0.133</span><br><span class="line">	 </span><br><span class="line">	 -----</span><br><span class="line">	 skmem:(r0,rb131072,t0,tb133632,f0,w0,o0,bl0,d0) cubic wscale:8,7 rto:233 rtt:32.489/2.99 ato:40 mss:1380 rcvmss:536 advmss:1460 cwnd:11 ssthresh:8 bytes_acked:99862366 bytes_received:2943 segs_out:78933 segs_in:23388 data_segs_out:78925 data_segs_in:81 send 3.7Mbps lastsnd:1735288 lastrcv:1735252 lastack:1735252 pacing_rate 4.5Mbps delivery_rate 2.9Mbps busy:370994ms retrans:0/6479 reordering:5 rcv_space:14600 minrtt:27.984</span><br></pre></td></tr></table></figure>

<h3 id="RTO计算算法"><a href="#RTO计算算法" class="headerlink" title="RTO计算算法"></a>RTO计算算法</h3><p>RTO的计算依赖于RTT值，或者说一系列RTT值。rto&#x3D;f(rtt)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1.1. 在没有任何rtt sample的时候，RTO &lt;- TCP_TIMEOUT_INIT (1s)</span><br><span class="line">   多次重传时同样适用指数回避算法(backoff)增加RTO  </span><br><span class="line"></span><br><span class="line">1.2. 获得第一个RTT sample后，</span><br><span class="line">    SRTT &lt;- RTT</span><br><span class="line">    RTTVAR &lt;- RTT/2</span><br><span class="line">    RTO &lt;- SRTT + max(G, K * RTTVAR)</span><br><span class="line">其中K=4, G表示timestamp的粒度(在CONFIG_HZ=1000时，粒度为1ms)</span><br><span class="line"></span><br><span class="line">1.3. 后续获得更多RTT sample后，</span><br><span class="line">    RTTVAR &lt;- (1 - beta) * RTTVAR + beta * |SRTT - R|</span><br><span class="line">    SRTT &lt;- (1 - alpha) * SRTT + alpha * R</span><br><span class="line">其中beta = 1/4, alpha = 1/8</span><br><span class="line"></span><br><span class="line">1.4. Whenever RTO is computed, if it is less than 1 second, then the</span><br><span class="line">   RTO SHOULD be rounder up to 1 second.</span><br><span class="line"></span><br><span class="line">1.5. A maximum value MAY be placed on RTO provided it is at least 60 seconds.</span><br></pre></td></tr></table></figure>

<p>RTTVAR表示的是平滑过的平均偏差，SRTT表示的平滑过的RTT。这两个值的具体含义会在后面介绍<br>具体实现的时候进一步的解释。<br>以上是计算一个初始RTO值的过程，当连续出现RTO超时后，<br>RTO值会用一个叫做指数回避的策略进行调整，下面来具体介绍。</p>
<h2 id="从系统cache中查看-tcp-metrics-item"><a href="#从系统cache中查看-tcp-metrics-item" class="headerlink" title="从系统cache中查看 tcp_metrics item"></a>从系统cache中查看 tcp_metrics item</h2><pre><code>$sudo ip tcp_metrics show | grep  100.118.58.7
100.118.58.7 age 1457674.290sec tw_ts 3195267888/5752641sec ago rtt 1000us rttvar 1000us ssthresh 361 cwnd 40 ----这两个值对传输性能很重要

192.168.1.100 age 1051050.859sec ssthresh 4 cwnd 2 rtt 4805us rttvar 4805us source 192.168.0.174 ---这条记录有问题，缓存的ssthresh 4 cwnd 2都太小，传输速度一定慢 

清除 tcp_metrics, sudo ip tcp_metrics flush all 
关闭 tcp_metrics 功能，net.ipv4.tcp_no_metrics_save = 1
sudo ip tcp_metrics delete 100.118.58.7
</code></pre>
<p>每个连接的ssthresh默认是个无穷大的值，但是内核会cache对端ip上次的ssthresh（大部分时候两个ip之间的拥塞窗口大小不会变），这样大概率到达ssthresh之后就基本拥塞了，然后进入cwnd的慢增长阶段。</p>
<h2 id="ss-过滤地址和端口号，类似tcpdump的用法"><a href="#ss-过滤地址和端口号，类似tcpdump的用法" class="headerlink" title="ss 过滤地址和端口号，类似tcpdump的用法"></a>ss 过滤地址和端口号，类似tcpdump的用法</h2><p>过滤目标端口是80的或者源端口是1723的连接，dst后面要跟空格然后加“：”：</p>
<pre><code># ss -ant dst :80 or src :1723 
State      Recv-Q Send-Q   Local Address:Port Peer Address:Port 
LISTEN     0      3        *:1723              *:*     
TIME-WAIT  0      0                                                     172.31.23.95:37269                                              111.161.68.235:80    
TIME-WAIT  0      0                                                     172.31.23.95:37263                                              111.161.68.235:80    
TIME-WAIT  0      0                                                     172.31.23.95:37267 
</code></pre>
<p>or：</p>
<pre><code>ss -ant dport = :80 or sport = :1723
</code></pre>
<p>地址筛选，目标地址是111.161.68.235的连接</p>
<pre><code>ss -ant dst 111.161.68.235
</code></pre>
<p>端口大小筛选，源端口大于1024的端口：</p>
<pre><code>ss sport gt 1024
</code></pre>
<p>How Do I Compare Local and&#x2F;or Remote Port To A Number?<br>Use the following syntax:</p>
<pre><code>## Compares remote port to a number ##
ss dport OP PORT
 
## Compares local port to a number ##
sport OP PORT
</code></pre>
<p>Where OP can be one of the following:</p>
<pre><code>&lt;= or le : Less than or equal to port
&gt;= or ge : Greater than or equal to port
== or eq : Equal to port
!= or ne : Not equal to port
&lt; or gt : Less than to port
&gt; or lt : Greater than to port
Note: le, gt, eq, ne etc. are use in unix shell and are accepted as well.

###################################################################################
### Do not forget to escape special characters when typing them in command line ###
###################################################################################
 
ss  sport = :http
ss  dport = :http
ss  dport \&gt; :1024
ss  sport \&gt; :1024
ss sport \&lt; :32000
ss  sport eq :22
ss  dport != :22
ss  state connected sport = :http
ss \( sport = :http or sport = :https \)
ss -o state fin-wait-1 \( sport = :http or sport = :https \) dst 192.168.1/24
</code></pre>
<h2 id="ss-查看-timer-状态"><a href="#ss-查看-timer-状态" class="headerlink" title="ss 查看 timer 状态"></a>ss 查看 timer 状态</h2><p>ss -atonp</p>
<h2 id="按连接状态过滤"><a href="#按连接状态过滤" class="headerlink" title="按连接状态过滤"></a>按连接状态过滤</h2><p>Display All Established HTTP Connections</p>
<pre><code>ss -o state established &#39;( dport = :http or sport = :http )&#39;
</code></pre>
<p>List all the TCP sockets in state -FIN-WAIT-1 for our httpd to network 202.54.1&#x2F;24 and look at their timers:<br>	ss -o state fin-wait-1 ‘( sport &#x3D; :http or sport &#x3D; :https )’ dst 202.54.1&#x2F;24</p>
<p>Filter Sockets Using TCP States</p>
<pre><code>ss -4 state FILTER-NAME-HERE
</code></pre>
<p>Where FILTER-NAME-HERE can be any one of the following,</p>
<pre><code>established
syn-sent
syn-recv
fin-wait-1
fin-wait-2
time-wait
closed
close-wait
last-ack
listen
closing
all : All of the above states
connected : All the states except for listen and closed
synchronized : All the connected states except for syn-sent
bucket : Show states, which are maintained as minisockets, i.e. time-wait and syn-recv.
big : Opposite to bucket state.
</code></pre>
<h2 id="ss分析重传的包数量"><a href="#ss分析重传的包数量" class="headerlink" title="ss分析重传的包数量"></a>ss分析重传的包数量</h2><p>通过抓取ss命令，可以分析出来重传的包数量，然后将重传的流的数量和重传的包的数量按照对端IP:port的维度分段聚合，参考命令：</p>
<pre><code>ss -itn |grep -v &quot;Address:Port&quot; | xargs -L 1  | grep retrans | awk &#39;{gsub(&quot;retrans:.*/&quot;, &quot;&quot;,$21); print $5, $21}&#39; | awk &#39;{arr[$1]+=$2} END {for (i in arr) {print i,arr[i]}}&#39; | sort -rnk 2 
</code></pre>
<p>xargs <strong>-L 1</strong>  每一行处理一次，但是这个行如果是空格、tab结尾，那么会被认为是连续行，跟下一行合并</p>
<p>高版本Linux内核的话，可以用systemtap或者bcc来获取每个连接的重传包以及发生重传的阶段</p>
<h2 id="当前和最大全连接队列确认"><a href="#当前和最大全连接队列确认" class="headerlink" title="当前和最大全连接队列确认"></a>当前和最大全连接队列确认</h2><pre><code>$ss -lt
State      Recv-Q Send-Q Local Address:Port                 Peer Address:Port         
LISTEN     0      128    127.0.0.1:10248                       *:*                   
LISTEN     0      128           *:2376                        *:*                    
LISTEN     0      128    127.0.0.1:10249                       *:*                   
LISTEN     0      128           *:7337                        *:*                    
LISTEN     0      128           *:10250                       *:*                    
LISTEN     0      128    11.163.187.44:7946                        *:*               
LISTEN     0      128    127.0.0.1:55631                       *:*                   
LISTEN     0      128           *:10256                       *:*                    
LISTEN     0      10            *:6640                        *:*                    
LISTEN     0      128    127.0.0.1:vmware-fdm                  *:*                   
LISTEN     0      128    11.163.187.44:vmware-fdm                  *:*               
LISTEN     0      128           *:ssh                         *:*                    
LISTEN     0      10     127.0.0.1:15772                       *:*                   
LISTEN     0      10     127.0.0.1:15776                       *:*                   
LISTEN     0      10     127.0.0.1:19777                       *:*                   
LISTEN     0      10     11.163.187.44:15778                       *:*               
LISTEN     0      128           *:tr-rsrb-p2                  *:*
</code></pre>
<h2 id="ss-s"><a href="#ss-s" class="headerlink" title="ss -s"></a>ss -s</h2><p>统计所有连接的状态</p>
<h2 id="nstat"><a href="#nstat" class="headerlink" title="nstat"></a>nstat</h2><p>nstat -z -t 1 类似 netstat -s  (ss –info 展示rto、拥塞算法等更详细信息； netstat -ant -o 展示keepalive是否)</p>
<p>netstat<a target="_blank" rel="noopener" href="http://perthcharles.github.io/2015/11/10/wiki-netstat-proc/">参考</a></p>
<p>比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#nstat -az TcpExtTCPRcvCollapsed TcpExtTCPRcvCoalesce TcpExtTCPRcvQDrop</span><br><span class="line">#kernel</span><br><span class="line">TcpExtTCPRcvCollapsed           0                  0.0  //类似对内存进行垃圾回收，慢</span><br><span class="line">TcpExtTCPRcvCoalesce            403679             0.0  //合并整理，较快</span><br><span class="line">TcpExtTCPRcvQDrop               0                  0.0</span><br></pre></td></tr></table></figure>

<p>参考 <a target="_blank" rel="noopener" href="https://blog.cloudflare.com/when-the-window-is-not-fully-open-your-tcp-stack-is-doing-more-than-you-think">cloudflare 博客</a>：</p>
<p><img src="/images/951413iMgBlog/image5-13.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/image8-4.png" alt="img"></p>
<h2 id="knetstat"><a href="#knetstat" class="headerlink" title="knetstat"></a>knetstat</h2><p>最后给出的一个工具，knetstat（需要单独安装），也可以查看tcp的状态下的各种参数，需要单独安装</p>
<p>example(3306是本地server，4192是后端MySQL）：</p>
<pre><code>Recv-Q Send-Q Local Address           Foreign Address         Stat Diag Options
 0      0 0.0.0.0:3306            0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 0.0.0.0:3406            0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 127.0.0.1:8182          0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 10.0.186.73:8182        0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 0.0.0.0:22              0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 0.0.0.0:8188            0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0
 0      0 127.0.0.1:15778         0.0.0.0:*               LSTN      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=0,TCP_NODELAY=0,TCP_FASTOPEN=0,TCP_DEFER_ACCEPT=0 
 0    138 10.0.186.73:51756       10.0.160.1:4192         ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0      0 10.0.186.73:3306        10.0.186.70:37428       ESTB      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVBUF=32768,SO_SNDBUF=65536,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0    138 10.0.186.73:51476       10.0.160.1:4192         ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0      0 10.0.186.73:3306        10.0.186.70:37304       ESTB      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVBUF=32768,SO_SNDBUF=65536,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0      0 10.0.186.73:51842       10.0.160.1:4192         ESTB      SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
44      0 10.0.186.73:3306        10.0.186.70:36238       ESTB      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVBUF=32768,SO_SNDBUF=65536,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
44      0 10.0.186.73:3306        10.0.186.70:36160       ESTB      SO_REUSEADDR=1,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVBUF=32768,SO_SNDBUF=65536,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
0      0 10.0.186.73:19030       10.0.171.188:8000       TIMW
</code></pre>
<p>3306对应的client上：</p>
<pre><code>Recv-Q Send-Q Local Address           Foreign Address         Stat Diag Options
 0     44 10.0.186.70:42428       10.0.186.73:3306        ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVTIMEO=31536000000ms,SO_SNDTIMEO=31536000000ms,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0     44 10.0.186.70:42298       10.0.186.73:3306        ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVTIMEO=31536000000ms,SO_SNDTIMEO=31536000000ms,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0     44 10.0.186.70:42296       10.0.186.73:3306        ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVTIMEO=31536000000ms,SO_SNDTIMEO=31536000000ms,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
 0     44 10.0.186.70:42322       10.0.186.73:3306        ESTB &gt;#   SO_REUSEADDR=0,SO_REUSEPORT=0,SO_KEEPALIVE=1,SO_RCVTIMEO=31536000000ms,SO_SNDTIMEO=31536000000ms,TCP_NODELAY=1,TCP_DEFER_ACCEPT=0
</code></pre>
<p>Diag列的说明	<br>	Indicator		Meaning<br>	  &gt;|	         The sender window (i.e. the window advertised by the remote endpoint) is 0. No data can be sent to the peer.<br>	    &gt;|&lt;	         The receiver window (i.e. the window advertised by the local endpoint) is 0. No data can be received from the peer.<br>	  &gt;<br>	  &gt;#	         There are unacknowledged packets and the last ACK was received more than one second ago. This may be an indication that there are network problems or that the peer crashed.</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://www.cyberciti.biz/tips/linux-investigate-sockets-network-connections.html">https://www.cyberciti.biz/tips/linux-investigate-sockets-network-connections.html</a></p>
<p><a target="_blank" rel="noopener" href="http://perthcharles.github.io/2015/11/10/wiki-netstat-proc/">http://perthcharles.github.io/2015/11/10/wiki-netstat-proc/</a></p>
<p>源代码：<a target="_blank" rel="noopener" href="https://github.com/sivasankariit/iproute2/blob/master/misc/ss.c">https://github.com/sivasankariit/iproute2/blob/master/misc/ss.c</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/veithen/knetstat/tree/master">https://github.com/veithen/knetstat/tree/master</a></p>
<p><a target="_blank" rel="noopener" href="https://access.redhat.com/discussions/782343">https://access.redhat.com/discussions/782343</a></p>
<p><a target="_blank" rel="noopener" href="https://perthcharles.github.io/2015/09/06/wiki-rtt-estimator/">RTO的计算方法(基于RFC6298和Linux 3.10)</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/17/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><span class="page-number current">18</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/19/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
