<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>LoadBalance - 标签 - plantegg</title>
        <link>https://plantegg.github.io/tags/loadbalance/</link>
        <description>LoadBalance - 标签 - plantegg</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-Hans</language><lastBuildDate>Fri, 19 Jul 2019 15:30:03 &#43;0000</lastBuildDate><atom:link href="https://plantegg.github.io/tags/loadbalance/" rel="self" type="application/rss+xml" /><item>
    <title>LVS 20倍的负载不均衡，原来是内核的这个Bug</title>
    <link>https://plantegg.github.io/posts/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/</link>
    <pubDate>Fri, 19 Jul 2019 15:30:03 &#43;0000</pubDate><author>
        <name>作者</name>
    </author><guid>https://plantegg.github.io/posts/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/</guid>
    <description><![CDATA[<h1 id="lvs-20倍的负载不均衡原来是内核的这个bug" class="headerLink">
    <a href="#lvs-20%e5%80%8d%e7%9a%84%e8%b4%9f%e8%bd%bd%e4%b8%8d%e5%9d%87%e8%a1%a1%e5%8e%9f%e6%9d%a5%e6%98%af%e5%86%85%e6%a0%b8%e7%9a%84%e8%bf%99%e4%b8%aabug" class="header-mark"></a>LVS 20倍的负载不均衡，原来是内核的这个Bug</h1><p>姊妹篇：<a href="https://plantegg.github.io/2019/06/20/%e5%b0%b1%e6%98%af%e8%a6%81%e4%bd%a0%e6%87%82%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1--lvs%e5%92%8c%e8%bd%ac%e5%8f%91%e6%a8%a1%e5%bc%8f/" target="_blank" rel="noopener noreferrer">就是要你懂负载均衡&ndash;lvs和转发模式</a></p>
<h2 id="问题由来" class="headerLink">
    <a href="#%e9%97%ae%e9%a2%98%e7%94%b1%e6%9d%a5" class="header-mark"></a>问题由来</h2><p>最近用 sysbench 做压测的时候，sysbench每次创建100个长连接，lvs后面两台RS（通过wlc来均衡），发现每次都是其中一台差不多95个连接，另外一台大概5个连接，不均衡得太离谱了，并且稳定重现，所以想要搞清楚为什么会出现20倍的不均衡。</p>
<p>前面是啰嗦的基础知识部分，<a href="#bug" rel="">bug直达文章末尾</a></p>
<h2 id="几个术语和缩写" class="headerLink">
    <a href="#%e5%87%a0%e4%b8%aa%e6%9c%af%e8%af%ad%e5%92%8c%e7%bc%a9%e5%86%99" class="header-mark"></a>几个术语和缩写</h2><pre><code>vip：Virtual IP，LVS实例IP
RS: Real Server 后端真正提供服务的机器
LB： Load Balance 负载均衡器
LVS： Linux Virtual Server
</code></pre>
<h2 id="负载均衡调度算法" class="headerLink">
    <a href="#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e8%b0%83%e5%ba%a6%e7%ae%97%e6%b3%95" class="header-mark"></a>负载均衡调度算法</h2><p>LVS的负载调度算法有10种，其它不常用的就不说了，凑数没有意义。基本常用的如下四种，这四种又可以分成两大种：rr轮询调度和lc最小连接调度。</p>
<h3 id="rr轮询调度round-robin-scheduling" class="headerLink">
    <a href="#rr%e8%bd%ae%e8%af%a2%e8%b0%83%e5%ba%a6round-robin-scheduling" class="header-mark"></a>rr轮询调度(Round-Robin Scheduling)</h3><p>轮询调度（Round Robin Scheduling）算法就是以轮询的方式依次将请求调度到不同的服务器，即每次调度执行i = (i + 1) mod n，并选出第i台服务器。算法的优点是其简洁性，它无需记录当前所有连接的状态，不管服务器上实际的连接数和系统负载，所以它是一种无状态调度。</p>
<h3 id="wrr加权轮询调度weighted-round-robin-scheduling" class="headerLink">
    <a href="#wrr%e5%8a%a0%e6%9d%83%e8%bd%ae%e8%af%a2%e8%b0%83%e5%ba%a6weighted-round-robin-scheduling" class="header-mark"></a>wrr加权轮询调度(Weighted Round-Robin Scheduling)</h3><p>加权轮询调度（Weighted Round-Robin Scheduling）算法可以解决服务器间性能不一的情况，它用相应的权值表示服务器的处理性能，服务器的缺省权值为1。假设服务器A的权值为1，B的权值为2，则表示服务器B的处理性能是A的两倍。加权轮叫调度算法是按权值的高低和轮叫方式分配请求到各服务器。权值高的服务器先收到的连接，权值高的服务器比权值低的服务器处理更多的连接，相同权值的服务器处理相同数目的连接数。</p>
<h3 id="lc最小连接调度least-connection-scheduling" class="headerLink">
    <a href="#lc%e6%9c%80%e5%b0%8f%e8%bf%9e%e6%8e%a5%e8%b0%83%e5%ba%a6least-connection-scheduling" class="header-mark"></a>lc最小连接调度(Least-Connection Scheduling)</h3><p>最小连接调度（Least-Connection Scheduling）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态调度算法，它通过服务器当前所活跃的连接数来估计服务器的负载情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中止或超时，其连接数减一。</p>
<p>如果集群系统的真实服务器具有相近的系统性能，采用”最小连接”调度算法可以较好地均衡负载。</p>
<p><strong>特别注意：这种调度算法还需要考虑active（权重*256）和inactive连接的状态，这个实现考量实际会带来严重的不均衡问题。</strong></p>
<h3 id="wlc加权最小连接调度weighted-least-connection-scheduling" class="headerLink">
    <a href="#wlc%e5%8a%a0%e6%9d%83%e6%9c%80%e5%b0%8f%e8%bf%9e%e6%8e%a5%e8%b0%83%e5%ba%a6weighted-least-connection-scheduling" class="header-mark"></a>wlc加权最小连接调度(Weighted Least-Connection Scheduling)</h3><p>加权最小连接调度（Weighted Least-Connection Scheduling）算法是最小连接调度的超集，各个服务器用相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。</p>
<p>调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。</p>
<p>其中wlc和lc可以看成一种，wrr和rr可以看成另外一种。下面只重点说wrr和wlc为什么不均衡</p>
<h2 id="为什么会不均衡" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bc%9a%e4%b8%8d%e5%9d%87%e8%a1%a1" class="header-mark"></a>为什么会不均衡</h2><h3 id="wrr算法" class="headerLink">
    <a href="#wrr%e7%ae%97%e6%b3%95" class="header-mark"></a>wrr算法</h3><p>非常简单，来了新连接向各个RS转发就行，比如一段时间内创建100个连接，那这100个连接能基本均匀分布在后端所有RS上。</p>
<h4 id="长连接" class="headerLink">
    <a href="#%e9%95%bf%e8%bf%9e%e6%8e%a5" class="header-mark"></a>长连接</h4><p>如果所有请求都是长连接，如果后端有RS重启（宕机、OOM服务不响应、日常性重启等等），那么其上面的连接一般会重建，重建的新连接会均匀分布到其它RS上，当重启的RS正常加入到LVS后，它上面的连接是最少的，即使后面大批量建新的连接，也只是新连接在这些RS上均匀分布，重新加入的RS没法感知到历史已经存在的老连接所以容易导致负载不均衡。</p>
<p>批量重启所有RS（升级等，多个RS进入服务状态肯定有先后），第一个起来的RS最容易获取到更多的连接，压力明显比其它RS要大，这肯定也是不符合预期的。</p>
<p><strong>总之wrr/rr算法因为不考虑已存在的连接问题，在长连接的情况下对RS重启、扩容（增加新的RS）十分不友好，容易导致长连接的不均衡。</strong></p>
<p>当然对于短连接不存在这个问题，所以可以考虑让应用端的连接不要那么长，比如几个小时候断开重新连接一下。升级的时候等所有RS都启动好后再让LVS开始工作等</p>
<h4 id="lvs-集群下不均衡" class="headerLink">
    <a href="#lvs-%e9%9b%86%e7%be%a4%e4%b8%8b%e4%b8%8d%e5%9d%87%e8%a1%a1" class="header-mark"></a>LVS 集群下不均衡</h4><p>一般一个负载均衡由多个（4个）LVS 机器组成。</p>
<p>假设每批请求发来四个新连接，经过4台负载均衡机器每个机器一个连接，这一个连接都打到了 RS 的第一个节点上。主要是4台负载均衡机器之间没有协商机制，互相没有同步信息。</p>
<p>可以的解决方案：LVS 机器加入随机因子，让每个LVS 认为的第一个节点不一样</p>
<h5 id="权值相等的wrr算法是否与rr算法等效" class="headerLink">
    <a href="#%e6%9d%83%e5%80%bc%e7%9b%b8%e7%ad%89%e7%9a%84wrr%e7%ae%97%e6%b3%95%e6%98%af%e5%90%a6%e4%b8%8err%e7%ae%97%e6%b3%95%e7%ad%89%e6%95%88" class="header-mark"></a>权值相等的WRR算法是否与RR算法等效？</h5><p>不等效。原因是由于RR调试算法加入了<strong>初始随机因子</strong>，而WRR由于算法的限制没有此功能。因此在新建连接数少，同时并发连接少，也没有预热的情况下，RR算法会有更好的均衡性表现。</p>
<p>WRR在每一次健康检查抖动的时候，会重置调度器，从头开始WRR的逻辑，因此可能会导致调度部分调度不均匀。</p>
<h3 id="案例" class="headerLink">
    <a href="#%e6%a1%88%e4%be%8b" class="header-mark"></a>案例</h3><p>比如如下这个负载不均衡，因为第一个RS CPU特别忙，QPS的不均衡大致能说明工作连接的差异</p>
<p><img class="tw-inline" loading="lazy" src=https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210422171244718.png   alt="image-20210422171244718"  ></p>
<ol>
<li>连接数差距大有一部分是因为机器忙，断开慢。lvs监控的累积连接数是200:250的差距, 流量差距是1:2</li>
<li>wrr会经常重置调度逻辑，经常从第一台开始轮询，导致第一台压力更大</li>
</ol>
<p>和lvs负载监控数据对比来看是一致的：</p>
<p><img class="tw-inline" loading="lazy" src=https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210422171155401.png   alt="image-20210422171155401"  ></p>
<h3 id="wlc算法" class="headerLink">
    <a href="#wlc%e7%ae%97%e6%b3%95" class="header-mark"></a>wlc算法</h3><p>针对wrr对长连接的上述不均衡，所以wlc算法考虑当前已存在的连接数，尽量把新连接发送到连接数较少的RS上，看起来比较完美地修复了wrr的上述不均衡问题。</p>
<p>wlc将连接分成active（ESTABLISHED）和inactive(syn/fin等其它状态），收到syn包后LVS按照如下算法判定该将syn发给哪个RS</p>
<pre><code>static inline int
ip_vs_dest_conn_overhead(struct ip_vs_dest *dest)
{
        /* We think the overhead of processing active connections is 256
         * times higher than that of inactive connections in average. (This
         * 256 times might not be accurate, we will change it later) We
         * use the following formula to estimate the overhead now:
         *                dest-&gt;activeconns*256 + dest-&gt;inactconns
         */
        return (atomic_read(&amp;dest-&gt;activeconns) &lt;&lt; 8) +
                atomic_read(&amp;dest-&gt;inactconns);
}
</code></pre>
<p>也就是一个active状态的连接权重是256，一个inactive权重是1，然后将syn发给总连接负载最轻的RS。</p>
<p>这里会导致不均衡过程: 短时间内有一批syn冲过来（同时并发创建一批连接），必然有一个RS（假如这里总共两个RS）先建立第一个active的连接，在第二个RS也建立第一个active连接之前，后面的syn都会发给第二个RS，那么最终会看到第二个RS的连接远大于第一个RS，这样就导致了最终连接数的负载不均衡。</p>
<p>主要是因为这里对inactive 连接的判定比较糙，active连接的权重直接<em>256就更糙了（作者都说了是拍脑袋的）。实际握手阶段的连接直接都判定为active比较妥当，挥手阶段的连接判定为inactive是可以的，但是active的权重取</em>4或者8就够了，256有点夸张。</p>
<p>这个不均衡场景可以通过 sysbench 稳定重现，<strong>如果两个RS的rt差异大一点会更明显</strong>。</p>
<p>RS到LVS之间的时延差异会放大这个不均衡，这个差异必然会存在，再就是vpc网络环境下首包延时很大（因为overlay之类的网络，连接的首包都会去网关拉取路由信息，所以首包都很慢），差异会更明显，因为这些都会影响第一个active连接的建立。</p>
<h4 id="what-is-an-activeconninactconn-activeinactive-connnection" class="headerLink">
    <a href="#what-is-an-activeconninactconn-activeinactive-connnection" class="header-mark"></a>What is an ActiveConn/InActConn (Active/Inactive) connnection?</h4><ul>
<li>ActiveConn in ESTABLISHED state</li>
<li>InActConn any other state</li>
</ul>
<p>只对NAT模式下有效：</p>
<p>With LVS-NAT, the director sees all the packets between the client and the realserver, so always knows the state of tcp connections and the listing from ipvsadm is accurate. However for LVS-DR, LVS-Tun, the director does not see the packets from the realserver to the client.</p>
<p>Example with my Apache Web server.</p>
<pre><code>Client  	    &lt;---&gt; Server

A client request an object on the web server on port 80 :

SYN REQUEST     ----&gt;
SYN ACK 	    &lt;----
ACK             ----&gt; *** ActiveConn=1 and 1 ESTABLISHED socket on realserver.
HTTP get        ----&gt; *** The client request the object
HTTP response   &lt;---- *** The server sends the object
APACHE closes the socket : *** ActiveConn=1 and 0 ESTABLISHED socket on realserver
The CLIENT receives the object. (took 15 seconds in my test)
ACK-FIN         ----&gt; *** ActiveConn=0 and 0 ESTABLISHED socket on realserver
</code></pre>
<h4 id="slb下的wlc" class="headerLink">
    <a href="#slb%e4%b8%8b%e7%9a%84wlc" class="header-mark"></a>slb下的wlc</h4><p>阿里slb集群下多台LVS服务器之间是开启的session同步功能，因此WLC在计算后端RS的连接权重时会将其它LVS服务器同步的连接计算进来，所以说实际上是一个准全局的调度算法，因此它的调度均衡性最好</p>
<p>WLC由于要计算所有连接的权重，因此消耗的CPU最多，性能最差。由于Session同步不是实时的，同时WLC算法对完成三次握手连接与半开连接的计算权重不同，因此WLC算法不适合突发新建连接的场景。</p>
<h3 id="sysbench验证wlc均衡逻辑" class="headerLink">
    <a href="#sysbench%e9%aa%8c%e8%af%81wlc%e5%9d%87%e8%a1%a1%e9%80%bb%e8%be%91" class="header-mark"></a>sysbench验证wlc均衡逻辑</h3><p>lvs（多个LVS节点的集群）后面总共两个RS，如果<strong>一次性同时</strong>创建100个连接，那么基本上这个100个连接都在第一个RS上，如果先创建50个，这时这50个基本在第一个RS上，休息几秒钟，再创建50个，那么第二批的50个基本落在第二个RS上。</p>
<p>如果先创建50个，这时这50个基本在第一个RS上，休息几秒钟，再创建100个，那么第二批的100个中前50个基本落在第二个RS上，后面50个又都跑到第一个RS上了。</p>
<h3 id="session-persistence-导致的负载不均衡" class="headerLink">
    <a href="#session-persistence-%e5%af%bc%e8%87%b4%e7%9a%84%e8%b4%9f%e8%bd%bd%e4%b8%8d%e5%9d%87%e8%a1%a1" class="header-mark"></a>Session Persistence 导致的负载不均衡</h3><p>LB 上开启了“会话保持”（Session Persistence），会将会话黏在某个RS上，如果刚好某个请求端访问量大，就会导致这个RS访问量大，从而不均衡</p>
<p>LVS的会话保持有这两种</p>
<ol>
<li>
<p>把同一个client的请求信息记录到lvs的hash表里，保存时间使用persistence_timeout控制，单位为秒。 persistence_granularity 参数是配合persistence_timeout的，在某些情况特别有用，他的值是子网掩码，表示持久连接的粒度，默认是 255.255.255.255，也就是单独的client ip，如果改成，255.255.255.0就是client ip一个网段的都会被分配到同一个real server。</p>
</li>
<li>
<p>一个连接创建后空闲时的超时时间，这个时间为3种</p>
<ul>
<li>
<p>tcp的空闲超时时间</p>
</li>
<li>
<p>lvs收到客户端tcp fin的超时时间</p>
</li>
<li>
<p>udp的超时时间</p>
</li>
</ul>
</li>
</ol>
<h2 id="总结" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93" class="header-mark"></a>总结</h2><ul>
<li>wrr/rr在长连接下，RS比较害怕动态扩容、重启机器、升级应用等场景</li>
<li>wrr会因为没有随机因子在小流量、探活失败重置场景下导致第一个RS 压力大，总的来说推荐rr而不是wrr</li>
<li>wlc/lc在长连接下，如果同时创建的大量连接（比如sysbench压测），因为内核的lvs逻辑对active和inactive判定不太合理导致了这种场景下连接会严重不均衡。</li>
<li>如果是druid这种连接池一个个创建的连接在wlc/lc算法是不会触发不均衡</li>
<li>如果lvs到两个RS的rt差异越大会加剧wlc/lc的不平衡（rt差异肯定是会存在的）</li>
</ul>
<h2 id="参考文章" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83%e6%96%87%e7%ab%a0" class="header-mark"></a>参考文章</h2><p><a href="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.ipvsadm.html#ActiveConn" target="_blank" rel="noopener noreferrer">What is an ActiveConn/InActConn (Active/Inactive) connnection?</a></p>
]]></description>
</item><item>
    <title>就是要你懂负载均衡--lvs和转发模式</title>
    <link>https://plantegg.github.io/posts/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/</link>
    <pubDate>Thu, 20 Jun 2019 15:30:03 &#43;0000</pubDate><author>
        <name>作者</name>
    </author><guid>https://plantegg.github.io/posts/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/</guid>
    <description><![CDATA[<h1 id="基础知识的力量--lvs和转发模式" class="headerLink">
    <a href="#%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86%e7%9a%84%e5%8a%9b%e9%87%8f--lvs%e5%92%8c%e8%bd%ac%e5%8f%91%e6%a8%a1%e5%bc%8f" class="header-mark"></a>基础知识的力量&ndash;lvs和转发模式</h1><blockquote>
  <p>本文希望阐述清楚LVS的各种转发模式，以及他们的工作流程和优缺点，同时从网络包的流转原理上解释清楚优缺点的来由，并结合阿里云的slb来说明优缺点。</p>

</blockquote><p>大家都背过LVS的几种转发模式，DR模式性能最好但是部署不灵活；NAT性能差部署灵活多了…… 实际都是没理解好这几个模式背后代表的网络连通性的原理和网络包路由原理，导致大多时候都是死背那几个概念。</p>
<p>如果我们能从网络包背后流转的流程和原理来看LVS的转发模式，那么那些优缺点简直就太直白了，这就是基础知识的力量。</p>
<p>如果对网络包是怎么流转的不太清楚，推荐先看这篇基础：<a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/" target="_blank" rel="noopener noreferrer">程序员的网络知识 &ndash; 一个网络包的旅程</a> ，对后面理解LVS的各个转发模式非常有帮助。</p>
<h2 id="几个术语和缩写" class="headerLink">
    <a href="#%e5%87%a0%e4%b8%aa%e6%9c%af%e8%af%ad%e5%92%8c%e7%bc%a9%e5%86%99" class="header-mark"></a>几个术语和缩写</h2><pre><code>cip：Client IP，客户端地址
vip：Virtual IP，LVS实例IP
rip：Real IP，后端RS地址
RS: Real Server 后端真正提供服务的机器
LB： Load Balance 负载均衡器
LVS： Linux Virtual Server
sip： source ip
dip： destination
</code></pre>
<h2 id="lvs的几种转发模式" class="headerLink">
    <a href="#lvs%e7%9a%84%e5%87%a0%e7%a7%8d%e8%bd%ac%e5%8f%91%e6%a8%a1%e5%bc%8f" class="header-mark"></a>LVS的几种转发模式</h2><ul>
<li>DR模型 &ndash; (Director Routing-直接路由)</li>
<li>NAT模型 &ndash; (NetWork Address Translation-网络地址转换)</li>
<li>fullNAT &ndash; (full NAT)</li>
<li>ENAT &ndash; (enhence NAT 或者叫三角模式/DNAT，阿里云提供)</li>
<li>IP TUN模型 &ndash; (IP Tunneling - IP隧道)</li>
</ul>
<h2 id="dr模型director-routing--直接路由" class="headerLink">
    <a href="#dr%e6%a8%a1%e5%9e%8bdirector-routing--%e7%9b%b4%e6%8e%a5%e8%b7%af%e7%94%b1" class="header-mark"></a>DR模型(Director Routing&ndash;直接路由)</h2><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/574a12e18ebbf0bafcfc97b1984305b5.png   alt="image.png"  ></p>
<p>如上图所示基本流程(假设 cip 是200.200.200.2， vip是200.200.200.1)：</p>
<ol>
<li>请求流量(sip 200.200.200.2, dip 200.200.200.1) 先到达 LVS(图中Director)</li>
<li>然后LVS，根据负载策略挑选众多 RS中的一个，然后将这个网络包的MAC地址修改成这个选中的RS的MAC</li>
<li>然后丢给Director，Director将这个包丢给选中的RS</li>
<li>选中的RS看到MAC地址是自己的、dip也是自己的，愉快地收下并处理、回复</li>
<li>回复包(sip 200.200.200.1， dip 200.200.200.2)</li>
<li>经过交换机直接回复给client了(不再走LVS)</li>
</ol>
<p>我们看到上面流程，请求包到达LVS后，LVS只对包的目的MAC地址作了修改，回复包直接回给了client。</p>
<p>同时<strong>要求多个RS和LVS(Director)都配置的是同一个IP地址，但是用的不同的MA</strong>C。这就要求所有RS和LVS在同一个子网，在二层路由不需要IP，他们又在同一个子网，所以这里联通性没问题。</p>
<p>RS上会将vip配置在lo回环网卡上，同时route中添加相应的规则，这样在第四步收到的包能被os正常处理。</p>
<p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/739447baddd120ca23c68ac85c0ea36d.png   alt="image.png"  ></p>
<p>优点：</p>
<ul>
<li>DR模式是性能最好的一种模式，入站请求走LVS，回复报文绕过LVS直接发给Client</li>
</ul>
<p>缺点：</p>
<ul>
<li>要求LVS和rs在同一个子网，扩展性不够好；</li>
<li>RS需要配置vip同时特殊处理arp；</li>
<li>配置比较复杂；</li>
<li>不支持端口映射。</li>
</ul>
<h3 id="为什么要求lvs和rs在同一个vlan或者说同一个二层网络里" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e6%b1%82lvs%e5%92%8crs%e5%9c%a8%e5%90%8c%e4%b8%80%e4%b8%aavlan%e6%88%96%e8%80%85%e8%af%b4%e5%90%8c%e4%b8%80%e4%b8%aa%e4%ba%8c%e5%b1%82%e7%bd%91%e7%bb%9c%e9%87%8c" class="header-mark"></a>为什么要求LVS和RS在同一个vlan(或者说同一个二层网络里)</h3><p>因为DR模式依赖多个RS和LVS共用同一个VIP，然后依据MAC地址来在LVS和多个RS之间路由，所以LVS和RS必须在一个vlan或者说同一个二层网络里</p>
<h3 id="dr-模式为什么性能最好" class="headerLink">
    <a href="#dr-%e6%a8%a1%e5%bc%8f%e4%b8%ba%e4%bb%80%e4%b9%88%e6%80%a7%e8%83%bd%e6%9c%80%e5%a5%bd" class="header-mark"></a>DR 模式为什么性能最好</h3><p>因为回复包不走LVS了，大部分情况下都是请求包小，回复包大，LVS很容易成为流量瓶颈，同时LVS只需要修改进来的包的MAC地址。</p>
<h3 id="dr-模式为什么回包不需要走lvs了" class="headerLink">
    <a href="#dr-%e6%a8%a1%e5%bc%8f%e4%b8%ba%e4%bb%80%e4%b9%88%e5%9b%9e%e5%8c%85%e4%b8%8d%e9%9c%80%e8%a6%81%e8%b5%b0lvs%e4%ba%86" class="header-mark"></a>DR 模式为什么回包不需要走LVS了</h3><p>因为RS和LVS共享同一个vip，回复的时候RS能正确地填好sip为vip，不再需要LVS来多修改一次(后面讲的NAT、Full NAT都需要)</p>
<h3 id="总结下-dr的结构" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93%e4%b8%8b-dr%e7%9a%84%e7%bb%93%e6%9e%84" class="header-mark"></a>总结下 DR的结构</h3><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/bb209bc08a21a28e99703e700acc82e4.png   alt="image.png"  ></p>
<p>绿色是请求包进来，红色是修改过MAC的请求包，SW是一个交换机。</p>
<h2 id="nat模型network-address-translation---网络地址转换" class="headerLink">
    <a href="#nat%e6%a8%a1%e5%9e%8bnetwork-address-translation---%e7%bd%91%e7%bb%9c%e5%9c%b0%e5%9d%80%e8%bd%ac%e6%8d%a2" class="header-mark"></a>NAT模型(NetWork Address Translation - 网络地址转换)</h2><p>nat模式的结构图如下：</p>
<p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/b806e1615d99f6a018c537a18addc464.png   alt="image.png"  ></p>
<p>基本流程：</p>
<ol>
<li>client发出请求(sip 200.200.200.2，dip 200.200.200.1)</li>
<li>请求包到达LVS(图中Director)，LVS修改请求包为(sip 200.200.200.2， dip rip)</li>
<li>请求包到达rs， rs回复(sip rip，dip 200.200.200.2)</li>
<li>这个回复包不能直接给client，因为rip不是VIP会被reset掉(client看到的连接是vip，突然来一个rip就reset)</li>
<li>但是因为lvs是网关，所以这个回复包先走到网关，网关有机会修改sip</li>
<li>网关修改sip为VIP，修改后的回复包(sip 200.200.200.1，dip 200.200.200.2)发给client</li>
</ol>
<p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/bd311051c55f08c8d0add3cb329b87bf.png   alt="image.png"  ></p>
<p>优点：</p>
<ul>
<li>配置简单</li>
<li>支持端口映射(看名字就知道)</li>
<li>RIP一般是私有地址，主要用户LVS和RS之间通信</li>
</ul>
<p>缺点：</p>
<ul>
<li>LVS和所有RS必须在同一个vlan</li>
<li>进出流量都要走LVS转发</li>
<li>LVS容易成为瓶颈</li>
<li>一般而言需要将VIP配置成RS的网关</li>
</ul>
<h3 id="为什么nat要求lvs和rs在同一个vlan" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88nat%e8%a6%81%e6%b1%82lvs%e5%92%8crs%e5%9c%a8%e5%90%8c%e4%b8%80%e4%b8%aavlan" class="header-mark"></a>为什么NAT要求lvs和RS在同一个vlan</h3><p>因为<strong>回复包必须经过lvs再次修改sip为vip，client才认</strong>，如果回复包的sip不是client包请求的dip(也就是vip)，那么这个连接会被reset掉。如果LVS不是网关，因为回复包的dip是cip，那么可能从其它路由就走了，LVS没有机会修改回复包的sip</p>
<h3 id="总结下nat结构" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93%e4%b8%8bnat%e7%bb%93%e6%9e%84" class="header-mark"></a>总结下NAT结构</h3><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/51b694409882318d5acd6a1422afce03.png   alt="image.png"  ></p>
<p>注意这里LVS修改进出包的(sip, dip)的时候只改了其中一个，所以才有接下来的full NAT。当然NAT最大的缺点是要求LVS和RS必须在同一个vlan，这样限制了LVS集群和RS集群的部署灵活性，尤其是在阿里云这种对外售卖的公有云环境下，NAT基本不实用。</p>
<h2 id="full-nat模型full-network-address-translation-全部网络地址转换" class="headerLink">
    <a href="#full-nat%e6%a8%a1%e5%9e%8bfull-network-address-translation-%e5%85%a8%e9%83%a8%e7%bd%91%e7%bb%9c%e5%9c%b0%e5%9d%80%e8%bd%ac%e6%8d%a2" class="header-mark"></a>full NAT模型(full NetWork Address Translation-全部网络地址转换)</h2><p>基本流程(类似NAT)：</p>
<ol>
<li>client发出请求(sip 200.200.200.2 dip 200.200.200.1)</li>
<li>请求包到达lvs，lvs修改请求包为**(sip 200.200.200.1， dip rip)** 注意这里sip/dip都被修改了</li>
<li>请求包到达rs， rs回复(sip rip，dip 200.200.200.1)</li>
<li>这个回复包的目的IP是VIP(不像NAT中是 cip)，所以LVS和RS不在一个vlan通过IP路由也能到达lvs</li>
<li>lvs修改sip为vip， dip为cip，修改后的回复包(sip 200.200.200.1，dip 200.200.200.2)发给client</li>
</ol>
<p>优点：</p>
<ul>
<li>解决了NAT对LVS和RS要求在同一个vlan的问题，适用更复杂的部署形式</li>
</ul>
<p>缺点：</p>
<ul>
<li>RS看不到cip(NAT模式下可以看到)</li>
<li>进出流量还是都走的lvs，容易成为瓶颈(跟NAT一样都有这个问题)</li>
</ul>
<h3 id="为什么full-nat解决了nat中要求的lvs和rs必须在同一个vlan的问题" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88full-nat%e8%a7%a3%e5%86%b3%e4%ba%86nat%e4%b8%ad%e8%a6%81%e6%b1%82%e7%9a%84lvs%e5%92%8crs%e5%bf%85%e9%a1%bb%e5%9c%a8%e5%90%8c%e4%b8%80%e4%b8%aavlan%e7%9a%84%e9%97%ae%e9%a2%98" class="header-mark"></a>为什么full NAT解决了NAT中要求的LVS和RS必须在同一个vlan的问题</h3><p>因为LVS修改进来的包的时候把(sip, dip)都修改了(这也是full的主要含义吧)，RS的回复包目的地址是vip(NAT中是cip)，所以只要vip和rs之间三层可通就行，这样LVS和RS可以在不同的vlan了，也就是LVS不再要求是网关，从而LVS和RS可以在更复杂的网络环境下部署。</p>
<h3 id="为什么full-nat后rs看不见cip了" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88full-nat%e5%90%8ers%e7%9c%8b%e4%b8%8d%e8%a7%81cip%e4%ba%86" class="header-mark"></a>为什么full NAT后RS看不见cip了</h3><p>因为cip被修改掉了，RS只能看到LVS的vip，在阿里内部会将cip放入TCP包的Option中传递给RS，RS上一般部署自己写的 toa(Tcp Option as Address)模块来从Options中读取的cip，这样RS能看到cip了, 当然这不是一个开源的通用方案。</p>
<h3 id="总结下full-nat的结构" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93%e4%b8%8bfull-nat%e7%9a%84%e7%bb%93%e6%9e%84" class="header-mark"></a>总结下full NAT的结构</h3><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/94d55b926b5bb1573c4cab8353428712.png   alt="image.png"  ></p>
<p><strong>注意上图中绿色的进包和红色的出包他们的地址变化</strong></p>
<p>那么到现在full NAT解决了NAT的同vlan的要求，<strong>基本上可以用于公有云了</strong>，但是还是没解决进出流量都走LVS的问题(LVS要修改进出的包)。</p>
<h3 id="比较下nat和full-nat" class="headerLink">
    <a href="#%e6%af%94%e8%be%83%e4%b8%8bnat%e5%92%8cfull-nat" class="header-mark"></a>比较下NAT和Full NAT</h3><p>两者进出都要走LVS，NAT必须要求vip是RS的网关，这个限制在公有云这种应用场景下不能忍，于是Full NAT通过修改请求包的source ip，将原来的source ip从cip改成vip，这样RS回复的时候回复包的目标IP也是vip，所以LVS和RS之间不再要求是同一vlan的关系了。当然带来了新的问题，RS看不见cip了(这个可以通过自定义的vtoa模块来复原)</p>
<p>那么有没有一个方案能够像full NAT一样不限制lvs和RS之间的网络关系，同时出去的流量跟DR模式一样也不走LVS呢？</p>
<h3 id="比较下drnat和full-nat" class="headerLink">
    <a href="#%e6%af%94%e8%be%83%e4%b8%8bdrnat%e5%92%8cfull-nat" class="header-mark"></a>比较下DR、NAT和Full NAT</h3><p>DR只修改目标Mac地址；
NAT只修改目标IP，LVS做网关得到修改回包的机会，RS能看到client ip；
Full-NAT同时修改 源ip和 目标ip， LVS通过三层路由和RS相通，RS看到的源ip是LVS IP。</p>
<h2 id="阿里云的enat模式enhence-nat-或者叫-三角模式" class="headerLink">
    <a href="#%e9%98%bf%e9%87%8c%e4%ba%91%e7%9a%84enat%e6%a8%a1%e5%bc%8fenhence-nat-%e6%88%96%e8%80%85%e5%8f%ab-%e4%b8%89%e8%a7%92%e6%a8%a1%e5%bc%8f" class="header-mark"></a>阿里云的ENAT模式(enhence NAT) 或者叫 三角模式</h2><p>前后端都是经典类型，属于NAT模式的特例，LVS转发给RS报文的源地址是客户端的源地址。</p>
<p>与NAT模式的差异在于 RS响应客户端的报文不再经过LVS机器，而是直接发送给客户端(源地址是VIP的地址, 后端RS需要加载一个ctk模块， lsmod | grep ctk 确认 ，主要是数据库产品使用)</p>
<p>优点：</p>
<ul>
<li>不要求LVS和RS在同一个vlan</li>
<li>出去的流量不需要走LVS，性能好</li>
</ul>
<p>缺点：</p>
<ul>
<li>阿里集团内部实现的自定义方案，需要在所有RS上安装ctk组件(类似full NAT中的vtoa)</li>
</ul>
<p>基本流程：</p>
<ol>
<li>client发出请求(cip，vip)</li>
<li>请求包到达lvs，lvs修改请求包为(vip，rip)，并将cip放入TCP Option中</li>
<li>请求包根据ip路由到达rs， ctk模块读取TCP Option中的cip</li>
<li>回复包(RIP, vip)被ctk模块截获，并将回复包改写为(vip, cip)</li>
<li>因为回复包的目的地址是cip所以不需要经过lvs，可以直接发给client</li>
</ol>
<p>ENAT模式在内部也会被称为 三角模式或者DNAT/SNAT模式</p>
<h3 id="为什么enat的回复包不需要走回lvs了" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88enat%e7%9a%84%e5%9b%9e%e5%a4%8d%e5%8c%85%e4%b8%8d%e9%9c%80%e8%a6%81%e8%b5%b0%e5%9b%9elvs%e4%ba%86" class="header-mark"></a>为什么ENAT的回复包不需要走回LVS了</h3><p>因为之前full NAT模式下要走回去是需要LVS 再次改写回复包的IP，而ENAT模式下，这件事情在RS上被ctk模块提前做掉了</p>
<h3 id="为什么enat的lvs和rs可以在不同的vlan" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88enat%e7%9a%84lvs%e5%92%8crs%e5%8f%af%e4%bb%a5%e5%9c%a8%e4%b8%8d%e5%90%8c%e7%9a%84vlan" class="header-mark"></a>为什么ENAT的LVS和RS可以在不同的vlan</h3><p>跟full NAT一样</p>
<h3 id="总结下-enat的结构" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93%e4%b8%8b-enat%e7%9a%84%e7%bb%93%e6%9e%84" class="header-mark"></a>总结下 ENAT的结构</h3><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/5b498ed88c3233977a592f924affc43a.png   alt="image.png"  ></p>
<p>最后说一下不太常用的 TUN模型</p>
<h2 id="ip-tun模型ip-tunneling---ip隧道" class="headerLink">
    <a href="#ip-tun%e6%a8%a1%e5%9e%8bip-tunneling---ip%e9%9a%a7%e9%81%93" class="header-mark"></a>IP TUN模型(IP Tunneling - IP隧道)</h2><p>基本流程：</p>
<ol>
<li>请求包到达LVS后，LVS将请求包封装成一个新的IP报文</li>
<li>新的IP包的目的IP是某一RS的IP，然后转发给RS</li>
<li>RS收到报文后IPIP内核模块解封装，取出用户的请求报文</li>
<li>发现目的IP是VIP，而自己的tunl0网卡上配置了这个IP，从而愉快地处理请求并将结果直接发送给客户</li>
</ol>
<p>优点：</p>
<ul>
<li>集群节点可以跨vlan</li>
<li>跟DR一样，响应报文直接发给client</li>
</ul>
<p>缺点：</p>
<ul>
<li>RS上必须安装运行IPIP模块</li>
<li>多增加了一个IP头</li>
<li>LVS和RS上的tunl0虚拟网卡上配置同一个VIP(类似DR)</li>
</ul>
<p><strong>DR模式中LVS修改的是目的MAC</strong></p>
<h3 id="为什么ip-tun不要求同一个vlan" class="headerLink">
    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88ip-tun%e4%b8%8d%e8%a6%81%e6%b1%82%e5%90%8c%e4%b8%80%e4%b8%aavlan" class="header-mark"></a>为什么IP TUN不要求同一个vlan</h3><p>因为IP TUN中不是修改MAC来路由，所以不要求同一个vlan，只要求lvs和rs之间ip能通就行。DR模式要求的是lvs和RS之间广播能通</p>
<h3 id="ip-tun性能" class="headerLink">
    <a href="#ip-tun%e6%80%a7%e8%83%bd" class="header-mark"></a>IP TUN性能</h3><p>回包不走LVS，但是多做了一次封包解包，不如DR好</p>
<h3 id="总结下-ip-tun的结构" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93%e4%b8%8b-ip-tun%e7%9a%84%e7%bb%93%e6%9e%84" class="header-mark"></a>总结下 IP TUN的结构</h3><p><img class="tw-inline" loading="lazy" src=https://plantegg.github.io/Users/ren/case/ossimg/218e93e6fa37b6f04dae9669de0e3fe3.png   alt="image.png"  ></p>
<p>图中红线是再次封装过的包，ipip是操作系统的一个内核模块。</p>
<p>DR可能在小公司用的比较多，IP TUN用的少一些，相对而言NAT、FullNAT、ENAT这三种在集团内部比较类似，用的也比较多，他们之间的可比较性很强，所以放在一块了。</p>
<h2 id="阿里云-slb-的-fnat" class="headerLink">
    <a href="#%e9%98%bf%e9%87%8c%e4%ba%91-slb-%e7%9a%84-fnat" class="header-mark"></a>阿里云 SLB 的 FNAT</h2><p>本质就是前面所讲的 fullnat模式，为了解决RS看不到真正的client ip问题，在阿里云公网上的物理机/宿主机默认都会帮你将source-ip(本来是lvs ip)替换成真正的client ip，这样当包进到ecs的时候source ip已经是client ip了，所以slb默认的fnat模式会让你直接能拿到client ip。回包依然会经过lvs(虽然理论上可以不需要了，但是要考虑rs和client不能直接通，以及管理方便等)</p>
<p>这个进出的替换过程在物理机/宿主机上是avs来做，如果没有avs就得安装slb的toa模块来做了。</p>
<p>这就是为什么slb比直接用lvs要方便些，也就是云服务商提供这种云产品的价值所在。</p>
<p>但是进出流量都走lvs，导致lvs流量过大，大象流容易打挂单core（目前限制单流不超过5GB），时延有所增加</p>
<p>所以推出NGLB来解决这个问题</p>
<h2 id="阿里云的nglb" class="headerLink">
    <a href="#%e9%98%bf%e9%87%8c%e4%ba%91%e7%9a%84nglb" class="header-mark"></a>阿里云的NGLB</h2><p>下一代负载均衡，只有首包经过slb节点，后续client和RS直接通信，只支持RS是物理机的场景。这个模块slb基本没有负载，性能最好。</p>
<p><img class="tw-inline" loading="lazy" src=https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/9726056d2a630cbe0f7ff67b23596452.png   alt="NGLB_pic.png"  ></p>
<h3 id="slb模块简介" class="headerLink">
    <a href="#slb%e6%a8%a1%e5%9d%97%e7%ae%80%e4%bb%8b" class="header-mark"></a>SLB模块简介</h3><ol>
<li>toa模块主要用在Classic网络SLB/ALB的FNAT场景下后端RS（NC）获取实际Client端的真实地址和端口（FNAT模式下SLB/ALB发送给后端RS的报文中源IP已经被替换为SLB/ALB的localIP，将ClientIP[后续简写为cip]通过tcp option携带到RS），用户通过特定getpeername接口获取cip。toa模块已经内置到ali内核版本中，无需再单独安装（见/lib/modules/<code>uname -r</code>/kernel/net/toa/toa.ko）。</li>
<li>vtoa模块属于增强版toa，同时支持VPC网络和Classic网络SLB/ALB的FNAT场景下后端RS获取实际客户端的真实地址和端口（FNAT模式下SLB/ALB发送给后端RS的报文中源IP已经被替换为SLB/ALB的localIP，将cip通过tcp option携带到RS），用户通过特定getsockopt接口获取vid:vip:vport和cip:cport，兼容toa接口。</li>
<li>ctk: 包括ALB_ctk_debugfs.ko，ALB_ctk_session.ko，ALB_ctk_proxy.ko模块。ctk是一个NAT模块，对于ENAT场景，从ALB过来的带tcp option的tcp流量（cip:cport&lt;-&gt;rip:rport带vip:vport opt）做了DNAT和反向DNAT转换，使得到上层应用层时看到的流被恢复为原始形态（cip:cport&lt;-&gt;vip:vport）</li>
<li>vctk:VPC NGLB模式下，只有建立TCP连接的首包（SYN包）经过ALB转发,后端vctk做Local的SNAT（避免VPC间地址冲突）和DNAT, 返回包做反向SNAT和DNAT转换，再做VXLAN封装，直接返回Source NC。</li>
</ol>
<p>!！注意：一般来说，ctk与toa/vtoa模块不同时使用，toa和vtoa不同时使用:</p>
<blockquote>
  <p>vtoa模块的功能是toa模块的超集，也就是说toa提供的功能在vtoa模块中都是提供的，并且接口，功能都是保持不变的。所以加载了vtoa之后，就不需要加载toa模块，如果加载了vtoa后再加载toa，获取vpcid以及cip/vip可能失败。</p>
<p>当toa/vtoa单独工作时，toa/vtoa模块工作在tcp层，通过修改内核把tcp opt中的cip，rip保存在sock结构中，并通过getpeername/getsockname系统接口给用户提供服务。</p>
<p>如果同时加载ctk和toa/vtoa模块，FNAT场景下ctk不起作用；ENAT场景下, 因ctk工作在IP层(NAT)，tcp opt先被ctk处理并去除并保存在session中，vtoa接口依赖ctk的session获取toa/vtoa信息。</p>

</blockquote><h2 id="阿里云-slb-的双机房高可用" class="headerLink">
    <a href="#%e9%98%bf%e9%87%8c%e4%ba%91-slb-%e7%9a%84%e5%8f%8c%e6%9c%ba%e6%88%bf%e9%ab%98%e5%8f%af%e7%94%a8" class="header-mark"></a>阿里云 SLB 的双机房高可用</h2><p>主备模式，备用机房没有流量。</p>
<p>SLB 的双机房容灾主要通过lvs机器和网络设备lsw之间通过动态路由协议（OSPF、ECMP、BGP）发布大小段路由实现主备机房容灾。10G集群采用ospf协议，40G集群采用bgp协议。</p>
<h3 id="案例" class="headerLink">
    <a href="#%e6%a1%88%e4%be%8b" class="header-mark"></a>案例</h3><p>主机房通过bgp协议发送 /27 的路由到lsw，csr，备机房发布 /26 路由到lsw, csr。</p>
<p>正常情况下，如果应用访问192.168.0.2的话，路由器会选择掩码最长的路由为最佳路由，获选进入路由表，也就是会选择192.168.0.1/27这条路由。从而实现流量主要在主机房，备机房冷备的效果。
当主机房发生故障，仅当主机房所有lvs机器都不能提供服务，即ABTN中无法收到主机房的/27明细路由时，流量才会发生主备切换，切换到备机房，实现主备机房容灾。</p>
<p><img class="tw-inline" loading="lazy" src=https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/6021c1f2dafa0e47d437d486f13c243a.png   alt="image.png"  ></p>
<h3 id="lvs节点之间的均衡" class="headerLink">
    <a href="#lvs%e8%8a%82%e7%82%b9%e4%b9%8b%e9%97%b4%e7%9a%84%e5%9d%87%e8%a1%a1" class="header-mark"></a>LVS节点之间的均衡</h3><p>内核版的lvs 最开始就采用集群化的部署，每个group 4台lvs 机器，支持group 级别横向扩展。使用ospf 作为引流方式。每台lvs机器有两块10G 网卡T1、T2口，分别上联lsw1 和 lsw2，通过ospf 动态路由协议与lsw 之间建立邻居关系，四台lvs机器发布相同的network 给lsw，实现流量转发的ecmp。lsw 打开multicast 以支持4台lvs机器之间的session 同步。通过session 同步保证当单台lvs机器宕机或者下线时，长连接 rehash 到其他lvs 机器时能够继续转发而不产生中断。</p>
<h4 id="lvs节点单机高可用" class="headerLink">
    <a href="#lvs%e8%8a%82%e7%82%b9%e5%8d%95%e6%9c%ba%e9%ab%98%e5%8f%af%e7%94%a8" class="header-mark"></a>LVS节点单机高可用</h4><p>每台lvs机器有两块10G网卡，每块网卡上联一台lsw，单机双上联容灾；</p>
<h4 id="lvs-group" class="headerLink">
    <a href="#lvs-group" class="header-mark"></a>LVS Group</h4><p>每个lvs_group 4台lvs 机器，同group机器提供对等服务，同时4台lvs机器之间有实时的session 同步，发生单机宕机的场景，流量会均摊到同组其他lvs机器上，长连接可以保持不断；</p>
<h2 id="一些数据" class="headerLink">
    <a href="#%e4%b8%80%e4%ba%9b%e6%95%b0%e6%8d%ae" class="header-mark"></a>一些数据</h2><p>内核版的lvs只支持10G带宽，采用dpdk后能支持25、40G带宽。</p>
<p>dpdk基于内核的<a href="https://lwn.net/Articles/232575/" target="_blank" rel="noopener noreferrer">uio机制</a>，提供了<a href="http://doc.dpdk.org/guides/prog_guide/poll_mode_drv.html" target="_blank" rel="noopener noreferrer">PMD</a>（Poll Mode Driver）的收包模式，uio旁路了内核，主动轮询去掉硬中断，DPDK从而可以在用户态做收发包处理。带来Zero Copy、无系统调用的好处，同步处理减少上下文切换带来的Cache Miss。</p>
<p>另外dpdk也采用了<a href="https://yq.aliyun.com/articles/90383" target="_blank" rel="noopener noreferrer">hugepage</a>，LVS使用单页内存1G，基本上避免了TLB MISS，对于LVS这种内存大户来说，对性能提升非常有利。并且dpdk提供了一系列高质量的基础库比如内存池（Mempool）、MBuf、无锁环（Ring），便于开发者迅速构建自己的包转发平台。</p>
<h3 id="性能优化" class="headerLink">
    <a href="#%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96" class="header-mark"></a>性能优化</h3><p>LVS侧针对内存的访问所做的优化如下：</p>
<p>1.session/svc 数据结构调整 热点字段聚集到同个cache line</p>
<p>2.结合性能测试数据，调整session的prefecth</p>
<p>3.消除false sharing。</p>
<p>目前LVS 40G机型，单机4块 40G网卡。</p>
<p>平均包长1k的情况下能跑满4个网口(160G)</p>
<p>64bytes小包的转发pps为4200W，kernel版本为1000W。</p>
<h4 id="限流对性能的影响" class="headerLink">
    <a href="#%e9%99%90%e6%b5%81%e5%af%b9%e6%80%a7%e8%83%bd%e7%9a%84%e5%bd%b1%e5%93%8d" class="header-mark"></a>限流对性能的影响</h4><p>通过令牌桶限流的话令牌桶加锁就是瓶颈</p>
<p>lvs的优化方案为大小桶算法：</p>
<p>per core维护一个小的令牌桶，当小桶中的令牌取完之后，才会加锁从大桶中获取，如果大桶中也拿不到令牌，本周期(令牌更新间隔)内也不会再次访问大桶。</p>
<p>从而去除每包必须加锁访问令牌桶，降低中心化限速对性能的影响。</p>
<h4 id="单流瓶颈" class="headerLink">
    <a href="#%e5%8d%95%e6%b5%81%e7%93%b6%e9%a2%88" class="header-mark"></a>单流瓶颈</h4><p>四层负载均衡lvs作为阿里云的核心产品已经走过了10个年头，在这期间lvs不断的进行技术的革新和演进，从最初的单机10g内核版本、10g用户态到现在主流的线上40g的版本，机器的带宽越来越大，cpu核数越来越多处理能力也越来越强，但存在一个问题一直没有解，对于同一条流会hash分到同一个cpu上，如果是单流的流量比较大超过lvs单核的处理能力，就会导致lvs的单cpu使用率飙高从而导致丢包。mellnex cx5 100g网卡平台提供了流offload的能力，lvs基于该硬件的特性开发了offload的功能，可以将大象流offload到网卡中防止单流消耗cpu的性能。</p>
<p>经测试offload后最高性能单卡单流可以达到2800wpps，具备应对大象流的能力。</p>
<p>经过十年来的不断演进，目前SLB四层监听的单LVS集群，已经可以达到PPS 4亿，网卡单向带宽1.6T，单集群新建连接8000w，并发13.4亿以及Offload单流2800万PPS的处理能力。</p>
<h2 id="参考资料" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99" class="header-mark"></a>参考资料</h2><p><a href="https://plantegg.github.io/2019/07/19/%e5%b0%b1%e6%98%af%e8%a6%81%e4%bd%a0%e6%87%82%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1--%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e8%b0%83%e5%ba%a6%e7%ae%97%e6%b3%95%e5%92%8c%e4%b8%ba%e4%bb%80%e4%b9%88%e4%b8%8d%e5%9d%87%e8%a1%a1/" target="_blank" rel="noopener noreferrer">LVS 20倍的负载不均衡，原来是内核的这个Bug</a></p>
<p><a href="https://yq.aliyun.com/articles/52752" target="_blank" rel="noopener noreferrer">章文嵩(正明)博士和他背后的负载均衡(LOAD BANLANCER)帝国</a></p>
<p><a href="https://yizhi.ren/2019/05/03/lvs/" target="_blank" rel="noopener noreferrer">https://yizhi.ren/2019/05/03/lvs/</a></p>
]]></description>
</item></channel>
</rss>
