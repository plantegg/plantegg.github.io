<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Linux,network,">





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1">






<meta name="description" content="网络硬件相关知识程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下 光纤和普通网线的性能差异以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：  光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M. 光纤接口：   单模光纤和多模光纤">
<meta name="keywords" content="Linux,network">
<meta property="og:type" content="article">
<meta property="og:title" content="网络硬件相关知识">
<meta property="og:url" content="https://plantegg.github.io/2021/01/01/网络相关知识/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="网络硬件相关知识程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下 光纤和普通网线的性能差异以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：  光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M. 光纤接口：   单模光纤和多模光纤">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/553e1c5fff2dd04a668434f0da4f9d90.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/b67715de1b8e143f6fc17ba574bcf0c4.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20230227152302800.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210831211315077.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221125190002856.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/640-20221114141014713.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/d718966f8f1fa1375e4437842fc759c2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220614171759153.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220614173416775.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613803162582-ce09e9cc-36e4-4805-b968-98d8dd601f52-5197629.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613982679299-d6832373-6a5f-4b54-9440-fd16606b8341.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613814089563-fb1de2e7-46d4-4bb7-9162-356e39c19a4c.png">
<meta property="og:updated_time" content="2024-11-25T12:25:31.903Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="网络硬件相关知识">
<meta name="twitter:description" content="网络硬件相关知识程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下 光纤和普通网线的性能差异以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：  光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M. 光纤接口：   单模光纤和多模光纤">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/553e1c5fff2dd04a668434f0da4f9d90.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/2021/01/01/网络相关知识/">





  <title>网络硬件相关知识 | plantegg</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/01/网络相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">网络硬件相关知识</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T17:30:03+08:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/network/" itemprop="url" rel="index">
                    <span itemprop="name">network</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="网络硬件相关知识"><a href="#网络硬件相关知识" class="headerlink" title="网络硬件相关知识"></a>网络硬件相关知识</h1><p>程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下</p>
<h2 id="光纤和普通网线的性能差异"><a href="#光纤和普通网线的性能差异" class="headerlink" title="光纤和普通网线的性能差异"></a>光纤和普通网线的性能差异</h2><p>以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/553e1c5fff2dd04a668434f0da4f9d90.png" alt="image.png"></p>
<p>光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M.</p>
<p>光纤接口：</p>
<img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/oss/b67715de1b8e143f6fc17ba574bcf0c4.png" alt="image.png" style="zoom:60%;">

<h3 id="单模光纤和多模光纤"><a href="#单模光纤和多模光纤" class="headerlink" title="单模光纤和多模光纤"></a>单模光纤和多模光纤</h3><p>下图绿色是多模光纤(Multi Mode Fiber),黄色是单模光纤(Single Mode Fiber), 因为光纤最好能和光模块匹配, 我们测试用的光模块都是多模的, 单模光纤线便宜,但是对应的光模块贵多了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20230227152302800.png" alt="image-20230227152302800"></p>
<p>多模光模块工作波长为850nm，单模光模块工作波长为1310nm或1550nm, 从成本上来看，单模光模块所使用的设备多出多模光模块两倍，总体成本远高于多模光模块，但单模光模块的传输距离也要长于多模光模块，单模光模块最远传输距离为100km，多模光模块最远传输距离为2km。因单模光纤的传输原理为使光纤直射到中心，所以主要用作远距离数据传输，而多模光纤则为多通路传播模式，所以主要用于短距离数据传输。单模光模块适用于对距离和传输速率要求较高的大型网络中，多模光模块主要用于短途网路。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210831211315077.png" alt="image-20210831211315077"></p>
<p>ping结果比较:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[aliyun@uos15 11:00 /home/aliyun]  以下88都是光口、89都是电口。</span><br><span class="line"><span class="meta">$</span><span class="bash">ping -c 10 10.88.88.16 //光纤</span></span><br><span class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=1 ttl=64 time=0.058 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=2 ttl=64 time=0.049 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=3 ttl=64 time=0.053 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=4 ttl=64 time=0.040 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=5 ttl=64 time=0.053 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=6 ttl=64 time=0.043 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=7 ttl=64 time=0.038 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=8 ttl=64 time=0.050 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=9 ttl=64 time=0.043 ms</span><br><span class="line">64 bytes from 10.88.88.16: icmp_seq=10 ttl=64 time=0.064 ms</span><br><span class="line"></span><br><span class="line">--- 10.88.88.16 ping statistics ---</span><br><span class="line">10 packets transmitted, 10 received, 0% packet loss, time 159ms</span><br><span class="line">rtt min/avg/max/mdev = 0.038/0.049/0.064/0.008 ms</span><br><span class="line"></span><br><span class="line">[aliyun@uos15 11:01 /home/aliyun]</span><br><span class="line"><span class="meta">$</span><span class="bash">ping -c 10 10.88.89.16 //电口</span></span><br><span class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=1 ttl=64 time=0.087 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=2 ttl=64 time=0.053 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=3 ttl=64 time=0.095 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=4 ttl=64 time=0.391 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=5 ttl=64 time=0.051 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=6 ttl=64 time=0.343 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=7 ttl=64 time=0.045 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=8 ttl=64 time=0.341 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=9 ttl=64 time=0.054 ms</span><br><span class="line">64 bytes from 10.88.89.16: icmp_seq=10 ttl=64 time=0.066 ms</span><br><span class="line"></span><br><span class="line">--- 10.88.89.16 ping statistics ---</span><br><span class="line">10 packets transmitted, 10 received, 0% packet loss, time 149ms</span><br><span class="line">rtt min/avg/max/mdev = 0.045/0.152/0.391/0.136 ms</span><br><span class="line"></span><br><span class="line">[aliyun@uos15 11:02 /u01]</span><br><span class="line"><span class="meta">$</span><span class="bash">scp uos.tar aliyun@10.88.89.16:/tmp/</span></span><br><span class="line">uos.tar                                  100% 3743MB 111.8MB/s   00:33    </span><br><span class="line"></span><br><span class="line">[aliyun@uos15 11:03 /u01]</span><br><span class="line"><span class="meta">$</span><span class="bash">scp uos.tar aliyun@10.88.88.16:/tmp/</span></span><br><span class="line">uos.tar                                   100% 3743MB 178.7MB/s   00:20    </span><br><span class="line"></span><br><span class="line">[aliyun@uos15 11:07 /u01]</span><br><span class="line"><span class="meta">$</span><span class="bash">sudo ping -f 10.88.89.16</span></span><br><span class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</span><br><span class="line">--- 10.88.89.16 ping statistics ---</span><br><span class="line">284504 packets transmitted, 284504 received, 0% packet loss, time 702ms</span><br><span class="line">rtt min/avg/max/mdev = 0.019/0.040/1.014/0.013 ms, ipg/ewma 0.048/0.042 ms</span><br><span class="line"></span><br><span class="line">[aliyun@uos15 11:07 /u01]</span><br><span class="line"><span class="meta">$</span><span class="bash">sudo ping -f 10.88.88.16</span></span><br><span class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</span><br><span class="line">--- 10.88.88.16 ping statistics ---</span><br><span class="line">299748 packets transmitted, 299748 received, 0% packet loss, time 242ms</span><br><span class="line">rtt min/avg/max/mdev = 0.012/0.016/0.406/0.006 ms, pipe 2, ipg/ewma 0.034/0.014 ms</span><br></pre></td></tr></table></figure>

<p>另外还要考虑网卡和光模块的带宽匹配，一般万兆网卡插上2.5万兆的光模块是无法联通的</p>
<h2 id="多网卡bonding"><a href="#多网卡bonding" class="headerlink" title="多网卡bonding"></a>多网卡bonding</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">cat ifcfg-bond0</span></span><br><span class="line">DEVICE=bond0</span><br><span class="line">TYPE=Bond</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=10.176.7.11</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">cat /etc/sysconfig/network-scripts/ifcfg-eth0</span></span><br><span class="line">DEVICE=eth0</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">MASTER=bond0</span><br><span class="line">SLAVE=yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">cat /etc/sysconfig/network-scripts/ifcfg-eth1</span></span><br><span class="line">DEVICE=eth1</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">MASTER=bond0</span><br><span class="line">SLAVE=yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">cat /proc/net/bonding/bond0</span></span><br><span class="line"></span><br><span class="line">----加载内核bonding模块, mode=0 是RR负载均衡模式</span><br><span class="line"><span class="meta">#</span><span class="bash">cat /etc/modprobe.d/bonding.conf</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> modprobe bonding</span></span><br><span class="line">alias bond0 bonding</span><br><span class="line">options bond0 mode=0 miimon=100  //这一行也可以放到bond0配置文件中,比如:BONDING_OPTS="miimon=100 mode=4 xmit_hash_policy=layer3+4" 用iperf 多连接测试bonding后的带宽发现，发送端能用上两张网卡，但是接收队列只能使用一张物理网卡</span><br></pre></td></tr></table></figure>

<p>网卡绑定mode共有七种(0~6) bond0、bond1、bond2、bond3、bond4、bond5、bond6</p>
<p>常用的有三种</p>
<ul>
<li><p>mode&#x3D;0：平衡负载模式 **(balance-rr)**，有自动备援，两块物理网卡和bond网卡使用同一个mac地址，但需要”Switch”支援及设定。</p>
</li>
<li><p>mode&#x3D;1：自动备援模式 **(balance-backup)**，其中一条线若断线，其他线路将会自动备援。</p>
</li>
<li><p>mode&#x3D;6：平衡负载模式**(balance-alb)**，有自动备援，不必”Switch”支援及设定，两块网卡是使用不同的MAC地址</p>
</li>
<li><p><strong>Mode 4 (802.3ad)</strong>: This mode creates aggregation groups that share the same speed and duplex settings, and it requires a switch that supports an IEEE 802.3ad dynamic link. Mode 4 uses all interfaces in the active aggregation group. For example, you can aggregate three 1 GB per second (GBPS) ports into a 3 GBPS trunk port. This is equivalent to having one interface with 3 GBPS speed. It provides fault tolerance and load balancing.</p>
</li>
</ul>
<p>需要说明的是如果想做成mode 0的负载均衡,仅仅设置这里options bond0 miimon&#x3D;100 mode&#x3D;0是不够的,与网卡相连的交换机必须做特殊配置（这两个端口应该采取聚合方式），因为做bonding的这两块网卡是使用同一个MAC地址.从原理分析一下（bond运行在mode 0下）：</p>
<p>mode 0下bond所绑定的网卡的IP都被修改成相同的mac地址，如果这些网卡都被接在同一个交换机，那么交换机的arp表里这个mac地址对应的端口就有多 个，那么交换机接受到发往这个mac地址的包应该往哪个端口转发呢？正常情况下mac地址是全球唯一的，一个mac地址对应多个端口肯定使交换机迷惑了。所以 mode0下的bond如果连接到交换机，交换机这几个端口应该采取聚合方式（cisco称为 ethernetchannel，foundry称为portgroup），因为交换机做了聚合后，聚合下的几个端口也被捆绑成一个mac地址.我们的解决办法是，两个网卡接入不同的交换机即可。</p>
<p>mode6模式下无需配置交换机，因为做bonding的这两块网卡是使用不同的MAC地址。</p>
<p>mod&#x3D;5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡）</p>
<p>特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。</p>
<p>该模式的必要条件：ethtool支持获取每个slave的速率.</p>
<p>案例，两块万兆bonding后带宽翻倍</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">#ethtool bond0</span><br><span class="line">Settings for bond0:</span><br><span class="line">	Supported ports: [ ]</span><br><span class="line">	Supported link modes:   Not reported</span><br><span class="line">	Supported pause frame use: No</span><br><span class="line">	Supports auto-negotiation: No</span><br><span class="line">	Advertised link modes:  Not reported</span><br><span class="line">	Advertised pause frame use: No</span><br><span class="line">	Advertised auto-negotiation: No</span><br><span class="line">	Speed: 20000Mb/s</span><br><span class="line">	Duplex: Full</span><br><span class="line">	Port: Other</span><br><span class="line">	PHYAD: 0</span><br><span class="line">	Transceiver: internal</span><br><span class="line">	Auto-negotiation: off</span><br><span class="line">	Link detected: yes</span><br><span class="line"></span><br><span class="line">[root@phy 16:55 /root]</span><br><span class="line">#cat /etc/sysconfig/network-scripts/ifcfg-bond0</span><br><span class="line">DEVICE=bond0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">TYPE=&quot;ethernet&quot;</span><br><span class="line">IPADDR=100.1.1.2</span><br><span class="line">NETMASK=255.255.255.192</span><br><span class="line">ONBOOT=yes</span><br><span class="line">USERCTL=no</span><br><span class="line">PEERDNS=no</span><br><span class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</span><br><span class="line"></span><br><span class="line">#cat /etc/modprobe.d/bonding.conf</span><br><span class="line">alias netdev-bond0 bonding</span><br><span class="line"></span><br><span class="line">#lsmod |grep bond</span><br><span class="line">bonding               137339  0</span><br><span class="line"></span><br><span class="line">#cat ifcfg-bond0</span><br><span class="line">DEVICE=bond0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">TYPE=&quot;ethernet&quot;</span><br><span class="line">IPADDR=100.81.131.221</span><br><span class="line">NETMASK=255.255.255.192</span><br><span class="line">ONBOOT=yes</span><br><span class="line">USERCTL=no</span><br><span class="line">PEERDNS=no</span><br><span class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</span><br><span class="line"></span><br><span class="line">#cat ifcfg-eth1</span><br><span class="line">DEVICE=eth1</span><br><span class="line">TYPE=&quot;Ethernet&quot;</span><br><span class="line">HWADDR=7C:D3:0A:E0:F7:81</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">ONBOOT=yes</span><br><span class="line">MASTER=bond0</span><br><span class="line">SLAVE=yes</span><br><span class="line">PEERDNS=no</span><br><span class="line">RX_MAX=`ethtool -g &quot;$DEVICE&quot; | grep &apos;Pre-set&apos; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</span><br><span class="line">RX_CURRENT=`ethtool -g &quot;$DEVICE&quot; | grep &quot;Current&quot; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</span><br><span class="line">[[ &quot;$RX_CURRENT&quot; -lt &quot;$RX_MAX&quot; ]] &amp;&amp; ethtool -G &quot;$DEVICE&quot; rx &quot;$RX_MAX&quot;</span><br></pre></td></tr></table></figure>

<h2 id="网络中断和绑核"><a href="#网络中断和绑核" class="headerlink" title="网络中断和绑核"></a>网络中断和绑核</h2><p>网络包的描述符的内存（RingBuffer）跟着设备走（设备在哪个Die&#x2F;Node上，就近分配内存）， 数据缓冲区（Data Buffer–存放网络包）内存跟着队列(中断)走， 如果队列绑定到DIE0， 而设备在die1上，这样在做DMA通信时， <a href="https://ata.alibaba-inc.com/articles/230545" target="_blank" rel="noopener">会产生跨die的交织访问</a>。</p>
<p>不管设备插在哪一个die上， 只要描述符申请的内存和数据缓冲区的内存都在同一个die上（需要修改驱动源代码–非常规），就能避免跨die内存交织， 性能能保持一致。</p>
<p><strong>irqbalance服务不会将中断进行跨node迁移，只会在同一numa node中进行优化。</strong></p>
<h3 id="ethtool"><a href="#ethtool" class="headerlink" title="ethtool"></a>ethtool</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">ethtool -i p1p1   //查询网卡bus-info</span></span><br><span class="line">driver: mlx5_core</span><br><span class="line">version: 5.0-0</span><br><span class="line">firmware-version: 14.27.1016 (MT_2420110004)</span><br><span class="line">expansion-rom-version:</span><br><span class="line">bus-info: 0000:21:00.0</span><br><span class="line">supports-statistics: yes</span><br><span class="line">supports-test: yes</span><br><span class="line">supports-eeprom-access: no</span><br><span class="line">supports-register-dump: no</span><br><span class="line">supports-priv-flags: yes</span><br><span class="line"></span><br><span class="line">//根据bus-info找到中断id</span><br><span class="line"><span class="meta">#</span><span class="bash">cat /proc/interrupts | grep 0000:21:00.0 | awk -F: <span class="string">'&#123;print $1&#125;'</span> | wc -l</span></span><br><span class="line"></span><br><span class="line">//修改网卡队列数</span><br><span class="line">sudo ethtool -L eth0  combined 2 （不能超过网卡最大队列数）</span><br><span class="line"></span><br><span class="line">然后检查是否生效了(不需要重启应用和机器，实时生效)：</span><br><span class="line">sudo ethtool -l eth0</span><br></pre></td></tr></table></figure>

<p>根据网卡bus-info可以找到对应的irq id</p>
<p>手工绑核脚本:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">irq_list=(`cat /proc/interrupts | grep enp131s0 | awk -F: <span class="string">'&#123;print $1&#125;'</span>`)</span></span><br><span class="line">intf=$1</span><br><span class="line">irq_list=(cat /proc/interrupts | grep `ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'` | awk -F: '&#123;print $1&#125;')</span><br><span class="line">cpunum=48  # 修改为所在node的第一个Core</span><br><span class="line">for irq in $&#123;irq_list[@]&#125;</span><br><span class="line">do</span><br><span class="line">echo $cpunum &gt; /proc/irq/$irq/smp_affinity_list</span><br><span class="line">echo `cat /proc/irq/$irq/smp_affinity_list`</span><br><span class="line">(( cpunum+=1 ))</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>检查绑定结果: sh irqCheck.sh enp131s0</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 网卡名</span></span><br><span class="line">intf=$1</span><br><span class="line">irqID=`ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'`</span><br><span class="line">log=irqSet-`date "+%Y%m%d-%H%M%S"`.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可用的CPU数</span></span><br><span class="line">cpuNum=$(cat /proc/cpuinfo |grep processor -c)</span><br><span class="line"><span class="meta">#</span><span class="bash"> RX TX中断列表</span></span><br><span class="line">irqListRx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</span><br><span class="line">irqListTx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</span><br><span class="line"><span class="meta">#</span><span class="bash"> 绑定接收中断rx irq</span></span><br><span class="line">for irqRX in $&#123;irqListRx[@]&#125;</span><br><span class="line">do</span><br><span class="line">cat /proc/irq/$&#123;irqRX&#125;/smp_affinity_list</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span><span class="bash"> 绑定发送中断tx irq</span></span><br><span class="line">for irqTX in $&#123;irqListTx[@]&#125;</span><br><span class="line">do</span><br><span class="line">cat /proc/irq/$&#123;irqTX&#125;/smp_affinity_list</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="中断联合（Coalescing）"><a href="#中断联合（Coalescing）" class="headerlink" title="中断联合（Coalescing）"></a>中断联合（Coalescing）</h3><p>中断联合可供我们推迟向内核通告新事件的操作，将多个事件汇总在一个中断中通知内核。该功能的当前设置可通过<code>ethtool -c</code>查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -c eth0</span><br><span class="line">Coalesce parameters for eth0:</span><br><span class="line">...</span><br><span class="line">rx-usecs: 50</span><br><span class="line">tx-usecs: 50</span><br></pre></td></tr></table></figure>

<p>此处可以设置固定上限，对每内核每秒处理中断数量的最大值进行硬性限制，或针对特定硬件根据吞吐率<a href="https://community.mellanox.com/docs/DOC-2511" target="_blank" rel="noopener">自动调整中断速率</a>。</p>
<p>启用联合（使用<code> -C</code>）会增大延迟并可能导致丢包，因此对延迟敏感的工作可能需要避免这样做。另外，彻底禁用该功能可能导致中断受到节流限制，进而影响性能。</p>
<p>多次在nginx场景下测试未发现这个值对TPS有什么明显的改善</p>
<p><a href="https://blog.cloudflare.com/how-to-achieve-low-latency/" target="_blank" rel="noopener">How to achieve low latency with 10Gbps Ethernet</a> 中有提到 Linux 3.11 added support for the <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/open-source-kernel-enhancements-paper.pdf" target="_blank" rel="noopener"><code>SO_BUSY_POLL</code> socket option</a>.  也有类似的作用</p>
<h3 id="irqbalance"><a href="#irqbalance" class="headerlink" title="irqbalance"></a><a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/performance_tuning_guide/appe-red_hat_enterprise_linux-performance_tuning_guide-tool_reference" target="_blank" rel="noopener">irqbalance</a></h3><p><strong>irqbalance</strong> 是一个命令行工具，在处理器中分配硬件中断以提高系统性能。默认设置下在后台程序运行，但只可通过 <code>--oneshot</code> 选项运行一次。</p>
<p>以下参数可用于提高性能。</p>
<ul>
<li><p>–powerthresh</p>
<p>CPU 进入节能模式之前，设定可空闲的 CPU 数量。如果有大于阀值数量的 CPU 是大于一个标准的偏差，该差值低于平均软中断工作负载，以及没有 CPU 是大于一个标准偏差，且该偏差高出平均，并有多于一个的 irq 分配给它们，一个 CPU 将处于节能模式。在节能模式中，CPU 不是 irqbalance 的一部分，所以它在有必要时才会被唤醒。</p>
</li>
<li><p>–hintpolicy</p>
<p>决定如何解决 irq 内核关联提示。有效值为 <code>exact</code>（总是应用 irq 关联提示）、<code>subset</code> （irq 是平衡的，但分配的对象是关联提示的子集）、或者 <code>ignore</code>（irq 完全被忽略）。</p>
</li>
<li><p>–policyscript</p>
<p>通过设备路径、当作参数的irq号码以及 <strong>irqbalance</strong> 预期的零退出代码，定义脚本位置以执行每个中断请求。定义的脚本能指定零或多键值对来指导管理传递的 irq 中 <strong>irqbalance</strong>。下列是为效键值对：ban有效值为 <code>true</code>（从平衡中排除传递的 irq）或 <code>false</code>（该 irq 表现平衡）。balance_level允许用户重写传递的 irq 平衡度。默认设置下，平衡度基于拥有 irq 设备的 PCI 设备种类。有效值为 <code>none</code>、<code>package</code>、<code>cache</code>、或 <code>core</code>。numa_node允许用户重写视作为本地传送 irq 的 NUMA 节点。如果本地节点的信息没有限定于 ACPI ，则设备被视作与所有节点距离相等。有效值为识别特定 NUMA 节点的整数（从0开始）和 <code>-1</code>，规定 irq 应被视作与所有节点距离相等。</p>
</li>
<li><p>–banirq</p>
<p>将带有指定中断请求号码的中断添加至禁止中断的列表。</p>
</li>
</ul>
<p>也可以使用 <em><code>IRQBALANCE_BANNED_CPUS</code></em> 环境变量来指定被 <strong>irqbalance</strong> 忽略的 CPU 掩码。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//默认irqbalance绑定一个numa, -1指定多个numa</span><br><span class="line">echo -1 &gt;/sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'`/numa_node ; </span><br><span class="line">// 目录 /sys/class/net/p1p1/ link到了 /sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'` </span><br><span class="line"></span><br><span class="line">执行 irqbalance --debug 进行调试</span><br></pre></td></tr></table></figure>

<h4 id="irqbalance指定core"><a href="#irqbalance指定core" class="headerlink" title="irqbalance指定core"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/interrupt_and_process_binding" target="_blank" rel="noopener">irqbalance指定core</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/sysconfig/irqbalance</span><br><span class="line"># IRQBALANCE_BANNED_CPUS</span><br><span class="line"># 64 bit bitmask which allows you to indicate which cpu&apos;s should</span><br><span class="line"># be skipped when reblancing irqs. Cpu numbers which have their</span><br><span class="line"># corresponding bits set to one in this mask will not have any</span><br><span class="line"># irq&apos;s assigned to them on rebalance</span><br><span class="line">#绑定软中断到8-15core, 每位表示4core</span><br><span class="line">#IRQBALANCE_BANNED_CPUS=ffffffff,ffff00ff</span><br><span class="line">#绑定软中断到8-15core和第65core</span><br><span class="line">IRQBALANCE_BANNED_CPUS=ffffffff,fffffdff,ffffffff,ffff00ff</span><br><span class="line"></span><br><span class="line">#96core 鲲鹏920下绑前16core</span><br><span class="line">IRQBALANCE_BANNED_CPUS=ffffffff,ffffffff,ffff0000</span><br></pre></td></tr></table></figure>

<h4 id="irqbalance的流程"><a href="#irqbalance的流程" class="headerlink" title="irqbalance的流程"></a><a href="https://blog.csdn.net/whrszzc/article/details/50533866" target="_blank" rel="noopener">irqbalance的流程</a></h4><p>初始化的过程只是建立链表的过程，暂不描述，只考虑正常运行状态时的流程<br>-处理间隔是10s<br>-清除所有中断的负载值<br>-&#x2F;proc&#x2F;interrupts读取中断，并记录中断数<br>-&#x2F;proc&#x2F;stat读取每个cpu的负载，并依次计算每个层次每个节点的负载以及每个中断的负载<br>-通过平衡算法找出需要重新分配的中断<br>-把需要重新分配的中断加入到新的节点中<br>-配置smp_affinity使处理生效</p>
<p><strong>irqbalance服务不会将中断进行跨node迁移，只会在同一numa node中进行优化。</strong></p>
<h3 id="网卡软中断以及内存远近的测试结论"><a href="#网卡软中断以及内存远近的测试结论" class="headerlink" title="网卡软中断以及内存远近的测试结论"></a><a href="https://ata.alibaba-inc.com/articles/230545" target="_blank" rel="noopener">网卡软中断以及内存远近</a>的测试结论</h3><p>一般网卡中断会占用一些CPU，如果把网卡中断挪到其它node的core上，在鲲鹏920上测试（网卡插在node0上），业务跑在node3，网卡中断分别在node0和node3，QPS分别是：179000 VS 175000</p>
<p>如果将业务跑在node0上，网卡中断分别在node0和node1上得到的QPS分别是：204000 VS 212000 </p>
<p>以上测试的时候业务进程分配的内存全限制在node0上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#/root/numa-maps-summary.pl &lt;/proc/123853/numa_maps</span><br><span class="line">N0        :      5085548 ( 19.40 GB)</span><br><span class="line">N1        :         4479 (  0.02 GB)</span><br><span class="line">N2        :            1 (  0.00 GB)</span><br><span class="line">active    :            0 (  0.00 GB)</span><br><span class="line">anon      :      5085455 ( 19.40 GB)</span><br><span class="line">dirty     :      5085455 ( 19.40 GB)</span><br><span class="line">kernelpagesize_kB:         2176 (  0.01 GB)</span><br><span class="line">mapmax    :          348 (  0.00 GB)</span><br><span class="line">mapped    :         4626 (  0.02 GB)</span><br></pre></td></tr></table></figure>

<p>从以上测试数据可以看到在这个内存分布场景下，如果就近访问内存性能有20%以上的提升</p>
<p>一般默认申请的data buffer也都在设备所在的numa节点上<strong>， 如果将队列的中断绑定到其他cpu上， 那么</strong>队列申请的data buffer的节点也会跟着中断迁移。</p>
<h3 id="阿里云绑核脚本"><a href="#阿里云绑核脚本" class="headerlink" title="阿里云绑核脚本"></a>阿里云绑核脚本</h3><p>通常情况下，Linux的网卡中断是由一个CPU核心来处理的，当承担高流量的场景下，会出现一些诡异的情况（网卡尚未达到瓶颈，但是却出现丢包的情况）</p>
<p>这种时候，我们最好看下网卡中断是不是缺少调优。</p>
<p>优化3要点：网卡多队列+irq affinity亲缘性设置+关闭irqbalance (systemctl stop irqbalance)</p>
<p>目前阿里云官方提供的centos和ubuntu镜像里面，已经自带了优化脚本，内容如下:</p>
<p><strong>centos7的脚本路径在 &#x2F;usr&#x2F;sbin&#x2F;ecs_mq_rps_rfs 具体内容如下：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the default setting of networking multiqueue and irq affinity</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. <span class="built_in">enable</span> multiqueue <span class="keyword">if</span> available</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. irq affinity optimization</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. stop irqbalance service</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> and check multiqueue</span></span><br><span class="line"></span><br><span class="line">function set_check_multiqueue()</span><br><span class="line">&#123;</span><br><span class="line">    eth=$1</span><br><span class="line">    log_file=$2</span><br><span class="line">    queue_num=$(ethtool -l $eth | grep -ia5 'pre-set' | grep -i combined | awk &#123;'print $2'&#125;)</span><br><span class="line">    if [ $queue_num -gt 1 ]; then</span><br><span class="line">        # set multiqueue</span><br><span class="line">        ethtool -L $eth combined $queue_num</span><br><span class="line">        # check multiqueue setting</span><br><span class="line">        cur_q_num=$(ethtool -l $eth | grep -iA5 current | grep -i combined | awk &#123;'print $2'&#125;)</span><br><span class="line">        if [ "X$queue_num" != "X$cur_q_num" ]; then</span><br><span class="line">            echo "Failed to set $eth queue size to $queue_num" &gt;&gt; $log_file</span><br><span class="line">            echo "after setting, pre-set queue num: $queue_num , current: $cur_q_num" &gt;&gt; $log_file</span><br><span class="line">            return 1</span><br><span class="line">        else</span><br><span class="line">            echo "OK. set $eth queue size to $queue_num" &gt;&gt; $log_file</span><br><span class="line">        fi</span><br><span class="line">    else</span><br><span class="line">        echo "only support $queue_num queue; no need to enable multiqueue on $eth" &gt;&gt; $log_file</span><br><span class="line">    fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">set</span> irq affinity</span></span><br><span class="line">function set_irq_smpaffinity()</span><br><span class="line">&#123;</span><br><span class="line">    log_file=$1</span><br><span class="line">    node_dir=/sys/devices/system/node</span><br><span class="line">    for i in $(ls -d $node_dir/node*); do</span><br><span class="line">        i=$&#123;i/*node/&#125;</span><br><span class="line">    done</span><br><span class="line">    </span><br><span class="line">    echo "max node :$i" &gt;&gt; $log_file</span><br><span class="line">    node_cpumax=$(cat /sys/devices/system/node/node$&#123;i&#125;/cpulist |awk -F- '&#123;print $NF&#125;')</span><br><span class="line">    irqs=($(cat /proc/interrupts |grep virtio |grep put | awk -F: '&#123;print $1&#125;'))</span><br><span class="line">    core=0</span><br><span class="line">    for irq in $&#123;irqs[@]&#125;;do</span><br><span class="line">        VEC=$core</span><br><span class="line">        if [ $VEC -ge 32 ];then</span><br><span class="line">            let "IDX = $VEC / 32"</span><br><span class="line">            MASK_FILL=""</span><br><span class="line">            MASK_ZERO="00000000"</span><br><span class="line">            for ((i=1; i&lt;=$IDX;i++))</span><br><span class="line">                do</span><br><span class="line">                    MASK_FILL="$&#123;MASK_FILL&#125;,$&#123;MASK_ZERO&#125;"</span><br><span class="line">                done</span><br><span class="line">            let "VEC -= 32 * $IDX"</span><br><span class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</span><br><span class="line">            MASK=$(printf "%X%s" $MASK_TMP $MASK_FILL)</span><br><span class="line">        else</span><br><span class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</span><br><span class="line">            MASK=$(printf "%X" $MASK_TMP)</span><br><span class="line">        fi</span><br><span class="line">        echo $MASK &gt; /proc/irq/$irq/smp_affinity</span><br><span class="line">        echo "mask:$MASK, irq:$irq" &gt;&gt; $log_file</span><br><span class="line">        core=$(((core+1)%(node_cpumax+1)))</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> stop irqbalance service</span></span><br><span class="line">function stop_irqblance()</span><br><span class="line">&#123;</span><br><span class="line">    log_file=$1</span><br><span class="line">    ret=0</span><br><span class="line">    if [ "X" != "X$(ps -ef | grep irqbalance | grep -v grep)" ]; then</span><br><span class="line">        if which systemctl;then</span><br><span class="line">            systemctl stop irqbalance</span><br><span class="line">        else</span><br><span class="line">            service irqbalance stop</span><br><span class="line">        fi</span><br><span class="line">        if [ $? -ne 0 ]; then</span><br><span class="line">            echo "Failed to stop irqbalance" &gt;&gt; $log_file</span><br><span class="line">            ret=1</span><br><span class="line">        fi</span><br><span class="line">    else</span><br><span class="line">       echo "OK. irqbalance stoped." &gt;&gt; $log_file</span><br><span class="line">    fi</span><br><span class="line">    return $ret</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> main logic</span></span><br><span class="line">function main()</span><br><span class="line">&#123;</span><br><span class="line">    ecs_network_log=/var/log/ecs_network_optimization.log</span><br><span class="line">    ret_value=0</span><br><span class="line">    echo "running $0" &gt; $ecs_network_log</span><br><span class="line">    echo "========  ECS network setting starts $(date +'%Y-%m-%d %H:%M:%S') ========" &gt;&gt; $ecs_network_log</span><br><span class="line">    # we assume your NIC interface(s) is/are like eth*</span><br><span class="line">    eth_dirs=$(ls -d /sys/class/net/eth*)</span><br><span class="line">    if [ "X$eth_dirs" = "X" ]; then</span><br><span class="line">        echo "ERROR! can not find any ethX in /sys/class/net/ dir." &gt;&gt; $ecs_network_log</span><br><span class="line">        ret_value=1</span><br><span class="line">    fi</span><br><span class="line">    for i in $eth_dirs</span><br><span class="line">    do</span><br><span class="line">        cur_eth=$(basename $i)</span><br><span class="line">        echo "optimize network performance: current device $cur_eth" &gt;&gt; $ecs_network_log</span><br><span class="line">        # only optimize virtio_net device</span><br><span class="line">        driver=$(basename $(readlink $i/device/driver))</span><br><span class="line">        if ! echo $driver | grep -q virtio; then</span><br><span class="line">            echo "ignore device $cur_eth with driver $driver" &gt;&gt; $ecs_network_log</span><br><span class="line">            continue</span><br><span class="line">        fi</span><br><span class="line">        echo "set and check multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</span><br><span class="line">        set_check_multiqueue $cur_eth $ecs_network_log</span><br><span class="line">        if [ $? -ne 0 ]; then</span><br><span class="line">            echo "Failed to set multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</span><br><span class="line">            ret_value=1</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">    stop_irqblance  $ecs_network_log</span><br><span class="line">    set_irq_smpaffinity $ecs_network_log</span><br><span class="line">    echo "========  ECS network setting END $(date +'%Y-%m-%d %H:%M:%S')  ========" &gt;&gt; $ecs_network_log</span><br><span class="line">    return $ret_value</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> program starts here</span></span><br><span class="line">main</span><br><span class="line">exit $?</span><br></pre></td></tr></table></figure>

<p>查询的rps绑定情况的脚本 get_rps.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取当前rps情况</span></span><br><span class="line">for i in $(ls /sys/class/net/eth0/queues/rx-*/rps_cpus); do </span><br><span class="line">  echo $i</span><br><span class="line">  cat $i</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="RSS-和-RPS"><a href="#RSS-和-RPS" class="headerlink" title="RSS 和 RPS"></a>RSS 和 RPS</h2><ul>
<li>RSS：即receive side steering,利用网卡的多队列特性，将每个核分别跟网卡的一个首发队列绑定，以达到网卡硬中断和软中断均衡的负载在各个CPU上。他要求网卡必须要支持多队列特性。</li>
<li>RPS：receive packet steering，他把收到的packet依据一定的hash规则给hash到不同的CPU上去，以达到各个CPU负载均衡的目的。他只是把软中断做负载均衡，不去改变硬中断。因而对网卡没有任何要求。</li>
<li>RFS：receive flow steering，RFS需要依赖于RPS，他跟RPS不同的是不再简单的依据packet来做hash，而是根据flow的特性，即application在哪个核上来运行去做hash，从而使得有更好的数据局部性。</li>
</ul>
<p>RSS</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20221125190002856.png" alt="image-20221125190002856"></p>
<p>设置 RPS，首先内核要开启<strong>CONFIG_RPS</strong>编译选项，然后设置需要将中断分配到哪些CPU：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#cat /sys/class/net/eth3/queues/rx-[0-7]/rps_cpus</span><br><span class="line">#cat /sys/class/net/eth3/queues/tx-[0-7]/xps_cpus</span><br></pre></td></tr></table></figure>

<p>我们可以看到很多案例，使用这些特性后提醒了网络包的处理能力，从而提升QPS，降低RT。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/640-20221114141014713.png" alt="Image"></p>
<p>如上图所示，数据包在进入内核IP&#x2F;TCP协议栈之前，经历了这些步骤：</p>
<ol>
<li>网口（NIC）收到packets</li>
<li>网口通过DMA（Direct memeory access）将数据写入到内存（RAM）中。</li>
<li>网口通过RSS（网卡多队列）将收到的数据包分发给某个rx队列，并触发该队列所绑定核上的CPU中断。</li>
<li>收到中断的核，调用该核所在的内核软中断线程（softirqd）进行后续处理。</li>
<li>softirqd负责将数据包从RAM中取到内核中。</li>
<li>如果开启了RPS，RPS会选择一个目标cpu核来处理该包，如果目标核非当前正在运行的核，则会触发目标核的IPI（处理器之间中断），并将数据包放在目标核的backlog队列中。</li>
<li>软中断线程将数据包（数据包可能来源于第5步、或第6步），通过gro(generic receive offload，如果开启的话)等处理后，送往IP协议栈，及之后的TCP&#x2F;UDP等协议栈。</li>
</ol>
<h2 id="查看网卡和numa的关系"><a href="#查看网卡和numa的关系" class="headerlink" title="查看网卡和numa的关系"></a>查看网卡和numa的关系</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#yum install lshw -y</span><br><span class="line">#lshw -C network -short</span><br><span class="line">H/W path               Device          Class      Description</span><br><span class="line">=============================================================</span><br><span class="line">/0/100/0/9/0           eth0            network    MT27710 Family [ConnectX-4 Lx]</span><br><span class="line">/0/100/0/9/0.1         eth1            network    MT27710 Family [ConnectX-4 Lx]</span><br><span class="line">/1                     e41358fae4ee_h  network    Ethernet interface</span><br><span class="line">/2                     86b0637ef1e1_h  network    Ethernet interface</span><br><span class="line">/3                     a6706e785f53_h  network    Ethernet interface</span><br><span class="line">/4                     d351290e50a0_h  network    Ethernet interface</span><br><span class="line">/5                     1a9e5df98dd1_h  network    Ethernet interface</span><br><span class="line">/6                     766ec0dab599_h  network    Ethernet interface</span><br><span class="line">/7                     bond0.11        network    Ethernet interface</span><br><span class="line">/8                     ea004888c217_h  network    Ethernet interface</span><br></pre></td></tr></table></figure>

<p>以及：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lscpu | grep -i numa</span><br><span class="line">numactl --hardware</span><br><span class="line">cat /proc/interrupts | egrep -i &quot;CPU|rx&quot;</span><br></pre></td></tr></table></figure>

<p><a href="https://ixnfo.com/en/how-to-find-out-on-which-numa-node-network-interfaces.html" target="_blank" rel="noopener">Check if the network interfaces are tied to Numa</a> (if -1 means not tied, if 0, then to numa0):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/class/net/eth0/device/numa_node</span><br></pre></td></tr></table></figure>

<p>You can see which NAMA the network card belongs to, for example, using lstopo:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line">yum install hwloc -y</span><br><span class="line">lstopo</span><br><span class="line">lstopo --logical</span><br><span class="line">lstopo --logical --output-format png &gt; lstopo.png</span><br><span class="line"></span><br><span class="line">--</span><br><span class="line">[root@hygon3 10:58 /root]  //hygon 7280 CPU</span><br><span class="line">#lstopo --logical</span><br><span class="line">Machine (503GB total)               //总内存大小</span><br><span class="line">  NUMANode L#0 (P#0 252GB)          //socket0、numa0 的内存大小</span><br><span class="line">    Package L#0</span><br><span class="line">      L3 L#0 (8192KB)               //L3 cache，对应4个物理core，8个HT</span><br><span class="line">        L2 L#0 (512KB) + L1d L#0 (32KB) + L1i L#0 (64KB) + Core L#0 // L1/L2</span><br><span class="line">          PU L#0 (P#0)</span><br><span class="line">          PU L#1 (P#64)</span><br><span class="line">        L2 L#1 (512KB) + L1d L#1 (32KB) + L1i L#1 (64KB) + Core L#1</span><br><span class="line">          PU L#2 (P#1)</span><br><span class="line">          PU L#3 (P#65)</span><br><span class="line">        L2 L#2 (512KB) + L1d L#2 (32KB) + L1i L#2 (64KB) + Core L#2</span><br><span class="line">          PU L#4 (P#2)</span><br><span class="line">          PU L#5 (P#66)</span><br><span class="line">        L2 L#3 (512KB) + L1d L#3 (32KB) + L1i L#3 (64KB) + Core L#3</span><br><span class="line">          PU L#6 (P#3)</span><br><span class="line">          PU L#7 (P#67)</span><br><span class="line">      L3 L#1 (8192KB)</span><br><span class="line">      L3 L#2 (8192KB)</span><br><span class="line">      L3 L#3 (8192KB)</span><br><span class="line">      L3 L#4 (8192KB)</span><br><span class="line">      L3 L#5 (8192KB)</span><br><span class="line">      L3 L#6 (8192KB)</span><br><span class="line">      L3 L#7 (8192KB)</span><br><span class="line">    HostBridge L#0</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 1a03:2000</span><br><span class="line">            GPU L#0 &quot;controlD64&quot;</span><br><span class="line">            GPU L#1 &quot;card0&quot;</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 1d94:7901</span><br><span class="line">          Block(Disk) L#2 &quot;sdm&quot;   //ssd系统盘，接在Node0上，绑核有优势</span><br><span class="line">    HostBridge L#4</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 1000:0097</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 1c5f:000d</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 1c5f:000d</span><br><span class="line">    HostBridge L#8</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 15b3:1015</span><br><span class="line">          Net L#3 &quot;p1p1&quot;      //万兆网卡接在Node0上</span><br><span class="line">        PCI 15b3:1015</span><br><span class="line">          Net L#4 &quot;p1p2&quot;</span><br><span class="line">    HostBridge L#10</span><br><span class="line">      PCIBridge</span><br><span class="line">        PCI 8086:1521</span><br><span class="line">          Net L#5 &quot;em1&quot;       //千兆网卡接在Node0上</span><br><span class="line">        PCI 8086:1521</span><br><span class="line">          Net L#6 &quot;em2&quot;</span><br><span class="line">  NUMANode L#1 (P#1 251GB)    //另外一个socket</span><br><span class="line">    Package L#1</span><br><span class="line">      L3 L#8 (8192KB)</span><br><span class="line">        L2 L#32 (512KB) + L1d L#32 (32KB) + L1i L#32 (64KB) + Core L#32</span><br><span class="line">        </span><br><span class="line">----------- FT2500 两路共128core</span><br><span class="line">#lstopo-no-graphics --logical</span><br><span class="line">Machine (503GB total)</span><br><span class="line">  Package L#0 + L3 L#0 (64MB)</span><br><span class="line">    NUMANode L#0 (P#0 31GB)</span><br><span class="line">      L2 L#0 (2048KB)         //4个物理core共享2M </span><br><span class="line">        L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 + PU L#0 (P#0)</span><br><span class="line">        L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 + PU L#1 (P#1)</span><br><span class="line">        L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 + PU L#2 (P#2)</span><br><span class="line">        L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 + PU L#3 (P#3)</span><br><span class="line">      L2 L#1 (2048KB)</span><br><span class="line">        L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 + PU L#4 (P#4)</span><br><span class="line">        L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 + PU L#5 (P#5)</span><br><span class="line">        L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6 + PU L#6 (P#6)</span><br><span class="line">        L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7 + PU L#7 (P#7)</span><br><span class="line">      HostBridge L#0</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCIBridge</span><br><span class="line">            PCIBridge</span><br><span class="line">              PCI 1000:00ac</span><br><span class="line">                Block(Disk) L#0 &quot;sdh&quot;</span><br><span class="line">                Block(Disk) L#1 &quot;sdf&quot;  // 磁盘挂在Node0上</span><br><span class="line">            PCIBridge</span><br><span class="line">              PCI 8086:1521</span><br><span class="line">                Net L#13 &quot;eth0&quot;</span><br><span class="line">              PCI 8086:1521</span><br><span class="line">                Net L#14 &quot;eth1&quot;       //网卡挂在node0上</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCIBridge</span><br><span class="line">            PCI 1a03:2000</span><br><span class="line">              GPU L#15 &quot;controlD64&quot;</span><br><span class="line">              GPU L#16 &quot;card0&quot;</span><br><span class="line">    NUMANode L#1 (P#1 31GB)</span><br><span class="line">    NUMANode L#2 (P#2 31GB)</span><br><span class="line">    NUMANode L#3 (P#3 31GB)</span><br><span class="line">    NUMANode L#4 (P#4 31GB)</span><br><span class="line">    NUMANode L#5 (P#5 31GB)</span><br><span class="line">    NUMANode L#6 (P#6 31GB)</span><br><span class="line">    NUMANode L#7 (P#7 31GB)</span><br><span class="line">      L2 L#14 (2048KB)</span><br><span class="line">        L1d L#56 (32KB) + L1i L#56 (32KB) + Core L#56 + PU L#56 (P#56)</span><br><span class="line">        L1d L#57 (32KB) + L1i L#57 (32KB) + Core L#57 + PU L#57 (P#57)</span><br><span class="line">        L1d L#58 (32KB) + L1i L#58 (32KB) + Core L#58 + PU L#58 (P#58)</span><br><span class="line">        L1d L#59 (32KB) + L1i L#59 (32KB) + Core L#59 + PU L#59 (P#59)</span><br><span class="line">      L2 L#15 (2048KB)</span><br><span class="line">        L1d L#60 (32KB) + L1i L#60 (32KB) + Core L#60 + PU L#60 (P#60)</span><br><span class="line">        L1d L#61 (32KB) + L1i L#61 (32KB) + Core L#61 + PU L#61 (P#61)</span><br><span class="line">        L1d L#62 (32KB) + L1i L#62 (32KB) + Core L#62 + PU L#62 (P#62)</span><br><span class="line">        L1d L#63 (32KB) + L1i L#63 (32KB) + Core L#63 + PU L#63 (P#63)</span><br><span class="line">  Package L#1 + L3 L#1 (64MB)   //socket2</span><br><span class="line">    NUMANode L#8 (P#8 31GB)</span><br><span class="line">      L2 L#16 (2048KB)</span><br><span class="line">        L1d L#64 (32KB) + L1i L#64 (32KB) + Core L#64 + PU L#64 (P#64)</span><br><span class="line">        L1d L#65 (32KB) + L1i L#65 (32KB) + Core L#65 + PU L#65 (P#65)</span><br><span class="line">        L1d L#66 (32KB) + L1i L#66 (32KB) + Core L#66 + PU L#66 (P#66)</span><br><span class="line">        L1d L#67 (32KB) + L1i L#67 (32KB) + Core L#67 + PU L#67 (P#67)</span><br><span class="line">      L2 L#17 (2048KB)</span><br><span class="line">        L1d L#68 (32KB) + L1i L#68 (32KB) + Core L#68 + PU L#68 (P#68)</span><br><span class="line">        L1d L#69 (32KB) + L1i L#69 (32KB) + Core L#69 + PU L#69 (P#69)</span><br><span class="line">        L1d L#70 (32KB) + L1i L#70 (32KB) + Core L#70 + PU L#70 (P#70)</span><br><span class="line">        L1d L#71 (32KB) + L1i L#71 (32KB) + Core L#71 + PU L#71 (P#71)</span><br><span class="line">      HostBridge L#7</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCIBridge</span><br><span class="line">            PCIBridge</span><br><span class="line">              PCI 15b3:1015</span><br><span class="line">                Net L#17 &quot;eth2&quot;   //node8 上的网卡，eth2、eth3做了bonding</span><br><span class="line">              PCI 15b3:1015</span><br><span class="line">                Net L#18 &quot;eth3&quot;</span><br><span class="line">            PCIBridge</span><br><span class="line">              PCI 144d:a808</span><br><span class="line">            PCIBridge</span><br><span class="line">              PCI 144d:a808</span><br><span class="line">              </span><br><span class="line"> ---鲲鹏920 每路48core 2路共4node，网卡插在node0，磁盘插在node2</span><br><span class="line"> #lstopo-no-graphics</span><br><span class="line">Machine (755GB total)</span><br><span class="line">  Package L#0</span><br><span class="line">    NUMANode L#0 (P#0 188GB)</span><br><span class="line">      L3 L#0 (24MB)</span><br><span class="line">        L2 L#0 (512KB) + L1d L#0 (64KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</span><br><span class="line">        L2 L#1 (512KB) + L1d L#1 (64KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</span><br><span class="line">        L2 L#22 (512KB) + L1d L#22 (64KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</span><br><span class="line">        L2 L#23 (512KB) + L1d L#23 (64KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</span><br><span class="line">      HostBridge L#0</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 15b3:1017</span><br><span class="line">            Net L#0 &quot;enp2s0f0&quot;</span><br><span class="line">          PCI 15b3:1017</span><br><span class="line">            Net L#1 &quot;eth1&quot;</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:1711</span><br><span class="line">            GPU L#2 &quot;controlD64&quot;</span><br><span class="line">            GPU L#3 &quot;card0&quot;</span><br><span class="line">      HostBridge L#3</span><br><span class="line">        2 x &#123; PCI 19e5:a230 &#125;</span><br><span class="line">        PCI 19e5:a235</span><br><span class="line">          Block(Disk) L#4 &quot;sda&quot;</span><br><span class="line">      HostBridge L#4</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:a222</span><br><span class="line">            Net L#5 &quot;enp125s0f0&quot;</span><br><span class="line">          PCI 19e5:a221</span><br><span class="line">            Net L#6 &quot;enp125s0f1&quot;</span><br><span class="line">          PCI 19e5:a222</span><br><span class="line">            Net L#7 &quot;enp125s0f2&quot;</span><br><span class="line">          PCI 19e5:a221</span><br><span class="line">            Net L#8 &quot;enp125s0f3&quot;</span><br><span class="line">    NUMANode L#1 (P#1 189GB) + L3 L#1 (24MB)</span><br><span class="line">      L2 L#24 (512KB) + L1d L#24 (64KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</span><br><span class="line">  Package L#1</span><br><span class="line">    NUMANode L#2 (P#2 189GB)</span><br><span class="line">      L3 L#2 (24MB)</span><br><span class="line">        L2 L#48 (512KB) + L1d L#48 (64KB) + L1i L#48 (64KB) + Core L#48 + PU L#48 (P#48)</span><br><span class="line">      HostBridge L#6</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:3714</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:3714</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:3714</span><br><span class="line">        PCIBridge</span><br><span class="line">          PCI 19e5:3714</span><br><span class="line">      HostBridge L#11</span><br><span class="line">        PCI 19e5:a230</span><br><span class="line">        PCI 19e5:a235</span><br><span class="line">        PCI 19e5:a230</span><br><span class="line">    NUMANode L#3 (P#3 189GB) + L3 L#3 (24MB)</span><br><span class="line">      L2 L#72 (512KB) + L1d L#72 (64KB) + L1i L#72 (64KB) + Core L#72 + PU L#72 (P#72)</span><br><span class="line">  Misc(MemoryModule)</span><br></pre></td></tr></table></figure>

<p>如果cpu core太多, interrupts 没法看的话，通过cut只看其中一部分core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/interrupts | grep -i &apos;eth4\|CPU&apos; | cut -c -8,865-995,1425-</span><br></pre></td></tr></table></figure>

<h2 id="lspci"><a href="#lspci" class="headerlink" title="lspci"></a>lspci</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">lspci -s 21:00.0 -vvv</span></span><br><span class="line">21:00.0 Ethernet controller: Mellanox Technologies MT27710 Family [ConnectX-4 Lx]</span><br><span class="line">	Subsystem: Mellanox Technologies ConnectX-4 Lx Stand-up dual-port 10GbE MCX4121A-XCAT</span><br><span class="line">	Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+</span><br><span class="line">	Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx-</span><br><span class="line">	Latency: 0, Cache Line Size: 64 bytes</span><br><span class="line">	Interrupt: pin A routed to IRQ 105</span><br><span class="line">	Region 0: Memory at 3249c000000 (64-bit, prefetchable) [size=32M]</span><br><span class="line">	Expansion ROM at db300000 [disabled] [size=1M]</span><br><span class="line">	Capabilities: [60] Express (v2) Endpoint, MSI 00</span><br><span class="line">		DevCap:	MaxPayload 512 bytes, PhantFunc 0, Latency L0s unlimited, L1 unlimited</span><br><span class="line">			ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset+ SlotPowerLimit 0.000W</span><br><span class="line">		DevCtl:	CorrErr+ NonFatalErr+ FatalErr+ UnsupReq-</span><br><span class="line">			RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ FLReset-</span><br><span class="line">			MaxPayload 512 bytes, MaxReadReq 512 bytes</span><br><span class="line">		DevSta:	CorrErr+ NonFatalErr- FatalErr- UnsupReq+ AuxPwr- TransPend-</span><br><span class="line">		LnkCap:	Port #0, Speed 8GT/s, Width x8, ASPM not supported</span><br><span class="line">			ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp+</span><br><span class="line">		LnkCtl:	ASPM Disabled; RCB 64 bytes Disabled- CommClk+</span><br><span class="line">			ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt-</span><br><span class="line">		LnkSta:	Speed 8GT/s (ok), Width x8 (ok)</span><br><span class="line">			TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">		DevCap2: Completion Timeout: Range ABC, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">			 AtomicOpsCap: 32bit- 64bit- 128bitCAS-</span><br><span class="line">		DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">			 AtomicOpsCtl: ReqEn-</span><br><span class="line">		LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-</span><br><span class="line">			 Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS-</span><br><span class="line">			 Compliance De-emphasis: -6dB</span><br><span class="line">		LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete+, EqualizationPhase1+</span><br><span class="line">			 EqualizationPhase2+, EqualizationPhase3+, LinkEqualizationRequest-</span><br><span class="line">	Capabilities: [48] Vital Product Data</span><br><span class="line">		Product Name: CX4121A - ConnectX-4 LX SFP28</span><br><span class="line">		Read-only fields:</span><br><span class="line">			[PN] Part number: MCX4121A-XCAT</span><br><span class="line">			[EC] Engineering changes: AJ</span><br><span class="line">			[SN] Serial number: MT2031J09199</span><br><span class="line">			[V0] Vendor specific: PCIeGen3 x8</span><br><span class="line">			[RV] Reserved: checksum good, 0 byte(s) reserved</span><br><span class="line">		End</span><br><span class="line">	Capabilities: [9c] MSI-X: Enable+ Count=64 Masked-</span><br><span class="line">		Vector table: BAR=0 offset=00002000</span><br><span class="line">		PBA: BAR=0 offset=00003000</span><br><span class="line">	Capabilities: [c0] Vendor Specific Information: Len=18 &lt;?&gt;</span><br><span class="line">	Capabilities: [40] Power Management version 3</span><br><span class="line">		Flags: PMEClk- DSI- D1- D2- AuxCurrent=375mA PME(D0-,D1-,D2-,D3hot-,D3cold+)</span><br><span class="line">		Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME-</span><br><span class="line">	Capabilities: [100 v1] Advanced Error Reporting</span><br><span class="line">		UESta:	DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-</span><br><span class="line">		UEMsk:	DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-</span><br><span class="line">		UESvrt:	DLP+ SDES- TLP- FCP+ CmpltTO- CmpltAbrt- UnxCmplt- RxOF+ MalfTLP+ ECRC+ UnsupReq- ACSViol-</span><br><span class="line">		CESta:	RxErr- BadTLP- BadDLLP- Rollover- Timeout- AdvNonFatalErr-</span><br><span class="line">		CEMsk:	RxErr- BadTLP- BadDLLP- Rollover- Timeout- AdvNonFatalErr+</span><br><span class="line">		AERCap:	First Error Pointer: 04, ECRCGenCap+ ECRCGenEn+ ECRCChkCap+ ECRCChkEn+</span><br><span class="line">			MultHdrRecCap- MultHdrRecEn- TLPPfxPres- HdrLogCap-</span><br><span class="line">		HeaderLog: 00000000 00000000 00000000 00000000</span><br><span class="line">	Capabilities: [150 v1] Alternative Routing-ID Interpretation (ARI)</span><br><span class="line">		ARICap:	MFVC- ACS-, Next Function: 1</span><br><span class="line">		ARICtl:	MFVC- ACS-, Function Group: 0</span><br><span class="line">	Capabilities: [180 v1] Single Root I/O Virtualization (SR-IOV)</span><br><span class="line">		IOVCap:	Migration-, Interrupt Message Number: 000</span><br><span class="line">		IOVCtl:	Enable- Migration- Interrupt- MSE- ARIHierarchy+</span><br><span class="line">		IOVSta:	Migration-</span><br><span class="line">		Initial VFs: 8, Total VFs: 8, Number of VFs: 0, Function Dependency Link: 00</span><br><span class="line">		VF offset: 2, stride: 1, Device ID: 1016</span><br><span class="line">		Supported Page Size: 000007ff, System Page Size: 00000001</span><br><span class="line">		Region 0: Memory at 000003249e800000 (64-bit, prefetchable)</span><br><span class="line">		VF Migration: offset: 00000000, BIR: 0</span><br><span class="line">	Capabilities: [1c0 v1] Secondary PCI Express &lt;?&gt;</span><br><span class="line">	Capabilities: [230 v1] Access Control Services</span><br><span class="line">		ACSCap:	SrcValid- TransBlk- ReqRedir- CmpltRedir- UpstreamFwd- EgressCtrl- DirectTrans-</span><br><span class="line">		ACSCtl:	SrcValid- TransBlk- ReqRedir- CmpltRedir- UpstreamFwd- EgressCtrl- DirectTrans-</span><br><span class="line">	Kernel driver in use: mlx5_core</span><br><span class="line">	Kernel modules: mlx5_core</span><br></pre></td></tr></table></figure>

<p>如果有多个高速设备争夺带宽（例如将高速网络连接到高速存储），那么 PCIe 也可能成为瓶颈，因此可能需要从物理上将 PCIe 设备划分给不同 CPU，以获得最高吞吐率。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/d718966f8f1fa1375e4437842fc759c2.png" alt="img"></p>
<p>数据来源：<a href="https://en.wikipedia.org/wiki/PCI_Express#History_and_revisions" target="_blank" rel="noopener"> https://en.wikipedia.org/wiki/PCI_Express#History_and_revisions</a></p>
<p>Intel 认为，有时候 PCIe 电源管理（ASPM）可能导致延迟提高，因进而导致丢包率增高。因此也可以为内核命令行参数添加<code>pcie_aspm=off</code>将其禁用。</p>
<h2 id="Default-路由持久化"><a href="#Default-路由持久化" class="headerlink" title="Default 路由持久化"></a>Default 路由持久化</h2><p>通过 ip route 可以添加默认路由，但是reboot就丢失了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add default dev bond0</span><br></pre></td></tr></table></figure>

<p>如果要持久化，在centos下可以创建 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;route-bond0 文件，内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">default dev bond0    ---默认路由，后面的可以省略</span><br><span class="line">10.0.0.0/8 via 11.158.239.247 dev bond0</span><br><span class="line">11.0.0.0/8 via 11.158.239.247 dev bond0</span><br><span class="line">30.0.0.0/8 via 11.158.239.247 dev bond0</span><br><span class="line">172.16.0.0/12 via 11.158.239.247 dev bond0</span><br><span class="line">192.168.0.0/16 via 11.158.239.247 dev bond0</span><br><span class="line">100.64.0.0/10 via 11.158.239.247 dev bond0</span><br><span class="line">33.0.0.0/8 via 11.158.239.247 dev bond0</span><br></pre></td></tr></table></figure>

<p>或者用sed在文件第一行添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i &apos;/default /d&apos;  /etc/sysconfig/network-scripts/route-bond0   //先删除默认路由（如果有）</span><br><span class="line">sed -i &apos;1 i\default dev bond0&apos; /etc/sysconfig/network-scripts/route-bond0   //添加</span><br></pre></td></tr></table></figure>

<p>Centos 7的话需要在 &#x2F;etc&#x2F;sysconfig&#x2F;network 中添加创建默认路由的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/sysconfig/network</span><br><span class="line"># Created by anaconda</span><br><span class="line">ip route add default dev eth0</span><br></pre></td></tr></table></figure>

<h2 id="内核态启动并加载网卡的逻辑"><a href="#内核态启动并加载网卡的逻辑" class="headerlink" title="内核态启动并加载网卡的逻辑"></a>内核态启动并加载网卡的逻辑</h2><ol>
<li><p>运行Linux的机器在BIOS阶段之后，机器的boot loader根据我们预先定义好的配置文件，将intrd和linux kernel加载到内存。这个包含initrd和linux kernel的配置文件通常在&#x2F;boot分区（从grub.conf中读取参数）</p>
</li>
<li><p>内核启动，运行当前根目录下面的init进程，init进程再运行其他必要的进程，其中跟网卡PCI设备相关的一个进程，就是udevd进程，udevd负责根据内核pci scan的pci设备，从initrd这个临时的根文件系统中加载内核模块，对于网卡来说，就是网卡驱动。(对应systemd-udevd 服务)</p>
</li>
<li><p>udevd，根据内核pci device scan出来的pci device，通过netlink消息机制通知udevd加载相应的内核驱动，其中，网卡驱动就是在这个阶段加载，如果initrd临时文件系统里面有这个网卡的驱动文件。通常upstream到linux内核的驱动，比如ixgbe，或者和内核一起编译的网卡驱动，会默认包含在initrd文件系统中。这些跟内核一起ship的网卡驱动会在这个阶段加载</p>
</li>
<li><p>udevd除了负责网卡驱动加载之外，还要负责为网卡命名。udevd在为网卡命名的时候，会首先check “&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;“下的rule，如果hit到相应的rule，就会通过rule里面指定的binary为网卡命名。如果&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;没有命名成功网卡，那么udevd会使用&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rule.d下面的rule，为网卡重命名。其中rule的文件经常以数字开头，数字越小，表示改rule的优先级越高。intrd init不会初始化network服务，所以&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts下面的诸如bond0，route的配置都不会生效。（内核启动先是 intrd init，然后执行一次真正的init）</p>
</li>
<li><p>在完成网卡driver load和name命名之后，initrd里面的init进程，会重启其他用户态进程，如udevd等，并且重新mount真正的根文件系统，启动network service。</p>
</li>
<li><p>重启udevd，会触发一次kernel的rescan device。这样第三方安装的网卡driver，由于其driver模块没有在initrd里面，会在这个阶段由udevd触发加载。同时，也会根据“&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;”和“&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rule.d”的rule，重命名网卡设备。–用户态修改网卡名字的机会</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kernel: ixgbe 0000:3b:00.1 eth1: renamed from enp59s0f1</span><br><span class="line">kernel: i40e 0000:88:00.0 eth7: renamed from enp136s0</span><br></pre></td></tr></table></figure>
</li>
<li><p>同时network service 会启动，进而遍历etc&#x2F;sysconfig&#x2F;network-scripts下面的脚本，我们配置的bond0， 默认路由，通常会在这个阶段运行，创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kernel: bond0: Enslaving eth0 as a backup interface with a down link</span><br><span class="line">kernel: ixgbe 0000:3b:00.0 eth0: detected SFP+: 5</span><br><span class="line">kernel: power_meter ACPI000D:00: Found ACPI power meter.</span><br><span class="line">kernel: power_meter ACPI000D:00: Ignoring unsafe software power cap!</span><br><span class="line">kernel: ixgbe 0000:3b:00.1: registered PHC device on eth1</span><br><span class="line">kernel: ixgbe 0000:3b:00.0 eth0: NIC Link is Up 10 Gbps, Flow Control: RX/TX</span><br><span class="line">kernel: bond0: Enslaving eth1 as a backup interface with a down link</span><br><span class="line">kernel: bond0: Warning: No 802.3ad response from the link partner for any adapters in the bond</span><br><span class="line">kernel: bond0: link status definitely up for interface eth0, 10000 Mbps full duplex</span><br><span class="line">kernel: bond0: first active interface up!</span><br></pre></td></tr></table></figure></li>
</ol>
<p>由于我们系统的初始化有两个阶段，udevd会运行两次，所以内核态网卡driver的加载，网卡命名也有两次机会。</p>
<p>第一次网卡driver的加载和命名是在initrd运行阶段，这个阶段由于initrd文件系统比较小，只包括和kernel一起ship的内核module，所以这个阶段只能加载initrd里面有的内核模块。网卡的重命名也只能重命名加载了驱动的网卡。</p>
<p>第二个网卡driver的加载和命名，是在真正根文件系统加载后，内核再一次pci scan，这个时候，由于真的根文件系统包含了所有的driver，第一个阶段无法probe的网卡会在这个阶段probe，重命名也会在这个阶段进行。</p>
<blockquote>
<p>内核默认命名规则有一定的局限性，往往不一定准确对应网卡接口的物理顺序，而且每次启动只根据内核发现网卡的顺序进行命名，因此并不固定；所以目前一般情况下会在用户态启用其他的方式去更改网卡名称，原则就是在内核命名ethx后将其在根据用户态的规则rename为其他的名字，这种规则往往是根据网卡的Mac地址以及其他能够唯一代表一块网卡的参数去命名，因此会一一对应；</p>
</blockquote>
<p>内核自带的网卡驱动在initrd中的内核模块中。对于第三方网卡，我们通常通过rpm包的方式安装。这种第三方安装的rpm，通常不会在initrd里面，只存在disk上。这样这种内核模块就只会在第二次udevd启动的时候被加载。</p>
<p>不论第一次重命名还是第二次重命名，其都遵循一样的逻辑，也就是先check &#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;的rule，然后check &#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rule.d中的rule，其中rule的优先级etc下最高，然后是usr下面。并且，rule的文件名中的数字表示该rule在同一文件夹中的优先级，数字越低，优先级越高。</p>
<p>network.service 根据network-script里面的脚本创建bond0，下发路由。这个过程和网卡重命名是同步进行，一般网卡重命名会超级快，单极端情况下重命名可能在network.service后会导致创建bond0失败（依赖网卡名来bonding），这里会依赖network.service retry机制来反复尝试确保network服务能启动成功</p>
<p>要想解决网卡加载慢的问题，可以考虑把安装后的网卡集成到initrd中。Linux系统提供的dracut可以做到这一点，我们只需要在安装完第三方网卡驱动后，执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dracut --forace</span><br><span class="line"></span><br><span class="line">查看</span><br><span class="line">udevadm info -q all -a /dev/nvme0</span><br></pre></td></tr></table></figure>

<p>就可以解决这个问题，该命令会根据最新的内存中的module，重新下刷initrd。</p>
<p>其实在多数第三方网卡的rpm spec或者makefile里面通常也会加入这种强制重刷的逻辑，确保内核驱动在initrd里面，从而加快网卡驱动的加载。</p>
<h3 id="用户态命名网卡流程"><a href="#用户态命名网卡流程" class="headerlink" title="用户态命名网卡流程"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-understanding_the_device_renaming_procedure" target="_blank" rel="noopener">用户态命名网卡流程</a></h3><p><a href="https://blog.csdn.net/biaotai/article/details/120710966" target="_blank" rel="noopener">CentOS 7提供了在网络接口中使用一致且可预期的网络设备命名方法， 目前默认使用的是net.ifnames规则</a>。The device name procedure in detail is as follows:</p>
<ol>
<li>A rule in <code>/usr/lib/udev/rules.d/60-net.rules</code> instructs the <strong>udev</strong> helper utility, <strong>&#x2F;lib&#x2F;udev&#x2F;rename_device</strong>, to look into all <code>/etc/sysconfig/network-scripts/ifcfg-*suffix*</code> files. If it finds an <code>ifcfg</code> file with a <code>HWADDR</code> entry matching the MAC address of an interface it renames the interface to the name given in the <code>ifcfg</code> file by the <code>DEVICE</code> directive.（根据提前定义好的ifcfg-网卡名来命名网卡–依赖mac匹配，如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡）</li>
<li>A rule in <code>/usr/lib/udev/rules.d/71-biosdevname.rules</code> instructs <strong>biosdevname</strong> to rename the interface according to its naming policy, provided that it was not renamed in a previous step, <strong>biosdevname</strong> is installed, and <code>biosdevname=0</code> was not given as a kernel command on the boot command line.</li>
<li>A rule in <code>/lib/udev/rules.d/75-net-description.rules</code> instructs <strong>udev</strong> to fill in the internal <strong>udev</strong> device property values ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH, ID_NET_NAME_MAC by examining the network interface device. Note, that some device properties might be undefined.</li>
<li>A rule in <code>/usr/lib/udev/rules.d/80-net-name-slot.rules</code> instructs <strong>udev</strong> to rename the interface, provided that it was not renamed in step 1 or 2, and the kernel parameter <code>net.ifnames=0</code> was not given, according to the following priority: ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH. It falls through to the next in the list, if one is unset. If none of these are set, then the interface will not be renamed.</li>
</ol>
<p>Steps 3 and 4 are implementing the naming schemes 1, 2, 3, and optionally 4, described in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/ch-Consistent_Network_Device_Naming#sec-Naming_Schemes_Hierarchy" target="_blank" rel="noopener">Section 11.1, “Naming Schemes Hierarchy”</a>. Step 2 is explained in more detail in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-Consistent_Network_Device_Naming_Using_biosdevname" target="_blank" rel="noopener">Section 11.6, “Consistent Network Device Naming Using biosdevname”</a>.</p>
<p>以上重命名简要概述就是对于CentOS系统，一般有下面几个rule在&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rule.d来重命名网卡：</p>
<ol>
<li>&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;60-net.rules 文件中的规则会让 udev 帮助工具&#x2F;lib&#x2F;udev&#x2F;rename_device 查看所有 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-* 文件。如果发现包含 HWADDR 条目的 ifcfg 文件与某个接口的 MAC 地址匹配，它会将该接口重命名为ifcfg 文件中由 DEVICE 指令给出的名称。rename条件：如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡；</li>
<li>&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;71-biosdevname.rules 中的规则让 biosdevname 根据其命名策略重命名该接口，即在上一步中没有重命名该接口、安装biosdevname、且在 boot 命令行中将biosdevname&#x3D;0 作为内核命令给出。（bisodevname规则，从CentOS 7 开始默认不使用，所以该条规则在不配置的情况下失效，直接去执行3；默认在cmdline中bisodevname&#x3D;0，如果需要启用，则需要设置bisodevname&#x3D;1）</li>
<li>&#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;75-net-description.rules 中的规则让 udev 通过检查网络接口设备，填写内部 udev 设备属性值 ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH、ID_NET_NAME_MAC。注：有些设备属性可能处于未定义状态。 –没有修改网卡名，只是取到了命名需要的一些属性值。查看：udevadm info -p &#x2F;sys&#x2F;class&#x2F;net&#x2F;enp125s0f0</li>
<li>&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;80-net-name-slot.rules 中的规则让 udev 重命名该接口，优先顺序如下：ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH。并提供如下信息：没有在步骤 1 或 2 中重命名该接口，同时未给出内核参数 net.ifnames&#x3D;0。如果一个参数未设定，则会按列表的顺序设定下一个。如果没有设定任何参数，则不会重命名该接口 —- 目前主流CentOS流都是这个命名方式</li>
<li>network service起来后会遍历&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts下的脚本，配置bond0、默认路由、其它网卡等</li>
</ol>
<p>其中60 rule会调用rename_device根据ifcfg-xxx脚本来命名，rule 71调用biosdevname来命名网卡。以上规则数字越小优先级越高，高优先级生效后跳过低优先级</p>
<p>总的来说网卡命名规则：grub启动参数 -&gt; &#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;的rule -&gt; &#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rule.d</p>
<p><a href="https://opensource.com/article/22/8/network-configuration-files?continueFlag=0e1c90589c7c691ec44a1aaecdcba76e" target="_blank" rel="noopener">参考</a>：</p>
<p>The following is an excerpt from Chapter 11 of the RHEL 7 “Networking Guide”:</p>
<ul>
<li>Scheme 1: Names incorporating Firmware or BIOS provided index numbers for on-board devices (example: eno1), are applied if that information from the firmware or BIOS is applicable and available, else falling back to scheme 2.</li>
<li>Scheme 2: Names incorporating Firmware or BIOS provided PCI Express hotplug slot index numbers (example: ens1) are applied if that information from the firmware or BIOS is applicable and available, else falling back to scheme 3.</li>
<li>Scheme 3: Names incorporating physical location of the connector of the hardware (example: enp2s0), are applied if applicable, else falling directly back to scheme 5 in all other cases.</li>
<li>Scheme 4: Names incorporating interface’s MAC address (example: enx78e7d1ea46da), is not used by default, but is available if the user chooses.</li>
<li>Scheme 5: The traditional unpredictable kernel naming scheme, is used if all other methods fail (example: eth0).</li>
</ul>
<h3 id="网卡命名"><a href="#网卡命名" class="headerlink" title="网卡命名"></a>网卡命名</h3><p>最开始Linux对网卡的命名规范是 eth* , 后来随着PCIe插槽的普及开始有 eno&#x2F;enp等命名</p>
<ol>
<li>eno1: 代表由主板bios内置的网卡</li>
<li>Ens: 代表有主板bios内置的PCI-E网卡</li>
<li>Enp2s0: PCI-E独立网卡</li>
<li>Eth0: 如果以上都不使用回到默认的网卡名</li>
</ol>
<p>En  代笔：ethernet </p>
<p>第3个字符根据设备类型选择 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">o&lt;index&gt;           on-board device index number</span><br><span class="line">s&lt;slot&gt;            hotplug slot index number</span><br><span class="line">x&lt;MAC&gt;             MAC address</span><br><span class="line">p&lt;bus&gt;s&lt;slot&gt;      PCI geographical location</span><br><span class="line">p&lt;bus&gt;s&lt;slot&gt;      USB port number chain</span><br></pre></td></tr></table></figure>

<p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-consistent_network_device_naming_using_biosdevname" target="_blank" rel="noopener">默认安装网卡所在位置来命名（enp131s0 等）</a>，按位置命名实例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//name example  ---默认方式，按照 /usr/lib/udev/rules.d/80-net-name-slot.rules 来命名</span><br><span class="line">enp4s10f1                        pci 0000:04:0a.1</span><br><span class="line">| | |  |                                |  |  | |</span><br><span class="line">| | |  |                   domain &lt;- 0000  |  | |</span><br><span class="line">| | |  |                                   |  | |</span><br><span class="line">en| |  |  --&gt; ethernet                     |  | |</span><br><span class="line">  | |  |                                   |  | |</span><br><span class="line">  p4|  |  --&gt; prefix/bus number (4)   &lt;-- 04  | |</span><br><span class="line">    |  |                                      | |</span><br><span class="line">    s10|  --&gt; slot/device number (10) &lt;--    10 |</span><br><span class="line">       |                                        |</span><br><span class="line">       f1 --&gt; function number (1)     &lt;--       1</span><br></pre></td></tr></table></figure>

<p>可以<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-disabling_consistent_network_device_naming" target="_blank" rel="noopener">关掉这种按位置命名的方式</a>，在grub参数中添加： net.ifnames&#x3D;0 biosdevname&#x3D;0，关闭后默认命名方式是eth**，开启biosdevname&#x3D;1后，默认网卡命名方式是p1p1&#x2F;p1p2(麒麟默认开启；alios默认关闭，然后以eth来命名)</p>
<blockquote>
<p>You have two options (<a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/sec-Disabling_Consistent_Network_Device_Naming.html" target="_blank" rel="noopener">as described in the new RHEL 7 Networking Guide</a>) to disable the <a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/ch-Consistent_Network_Device_Naming.html#sec-Understanding_the_Predictable_Network_Interface_Device_Names" target="_blank" rel="noopener">new naming scheme</a>:</p>
<ul>
<li>Run once: <code>ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules</code></li>
</ul>
<p>or</p>
<ul>
<li>Run once: <code>echo &#39;GRUB_CMDLINE_LINUX=&quot;net.ifnames=0&quot;&#39; &gt;&gt;/etc/default/grub</code></li>
</ul>
<p>Note that the <strong>biosdevname</strong> package is not installed by default, so unless it gets installed, you don’t need to add <code>biosdevname=0</code> as a kernel argument.</p>
</blockquote>
<p>也可以添加命名规则在 &#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F; 下(这种优先级挺高），比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/udev/rules.d/70-persistent-net.rules</span><br><span class="line"># PCI device 21:00.0 (ixgbe)</span><br><span class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;d4:5d:64:bb:06:32&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</span><br><span class="line"># PCI device 0x8086:0x105e (e1000e)</span><br><span class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;b8:59:9f:2d:48:2b&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth1&quot;</span><br></pre></td></tr></table></figure>

<p>但是以上规则在麒麟下没有生效</p>
<p>网卡重命名方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sbin/ip link set eth1 name eth123</span><br></pre></td></tr></table></figure>

<h2 id="校验"><a href="#校验" class="headerlink" title="校验"></a><a href="https://www.kernel.org/doc/html/latest/networking/checksum-offloads.html" target="_blank" rel="noopener">校验</a></h2><p>比如如下结构下因为通过xdp redirect来联通veth0、veth1，两边能ping通，但是TCP、UDP 都不通</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220614171759153.png" alt="image-20220614171759153"></p>
<p>正常走bridge ping&#x2F;tcp&#x2F;udp是不会有问题的, 这也是docker下常见用法</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220614173416775.png" alt="image-20220614173416775"></p>
<p>当前主流的网卡（包括虚拟网卡，如veth&#x2F;tap）都支持一个叫做RX&#x2F;TX Checksum Offload（RX和TX对应接收和发送两个方向）的特性，用于将传输层协议的校验和计算卸载到网卡硬件中（IP头的检验和会被操作系统用软件方式正确计算）。对于经过启用该功能的网卡的报文，操作系统不会对该报文进行校验和的计算，从而减少对系统CPU资源的占用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613803162582-ce09e9cc-36e4-4805-b968-98d8dd601f52-5197629.png" alt="1613803162582-ce09e9cc-36e4-4805-b968-98d8dd601f52"></p>
<p>对于没有挂载XDP程序的且开启Checksum Offload功能的Veth设备，在接收到数据包时，会将<code>ip_summed</code>置为<code>CHECKSUM_UNNECESSARY</code>，因此上层L4协议栈在收到该数据包的时候不会再检查校验和，即使是数据包的校验和不正确也会正常被处理。但是若我们在veth设备上挂载了XDP程序，XDP程序运行时将网卡接收队列中的数据转换为结构<code>struct xdp_buff</code>时会丢失掉<code>ip_summed</code>信息，这就导致数据包被L4协议栈接收后由于校验和错误而被丢弃。</p>
<p>如上图因为veth挂载了XDP程序，导致包没有校验信息而丢掉，如果在同样环境下ping是可以通的，因为ping包提前计算好了正确的校验和</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613982679299-d6832373-6a5f-4b54-9440-fd16606b8341.png" alt="img"></p>
<p>这种丢包可以通过 <code>/proc/net/snmp</code> 看到</p>
<p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1613814089563-fb1de2e7-46d4-4bb7-9162-356e39c19a4c.png" alt="img"></p>
<p>通过命令<code>ethtool -K &lt;nic-name&gt; tx off</code>工具关闭Checksum Offload特性，强行让操作系统用软件方式计算校验和。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="noopener">网卡日志打开</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.conf.all.log_martians=1 //所有网卡</span><br><span class="line">sysctl -w net.ipv4.conf.p1p1.log_martians=1 //特定网卡</span><br><span class="line"></span><br><span class="line">/proc/sys/net/ipv4/conf/eth0.9/log_martians</span><br></pre></td></tr></table></figure>

<p>&#x2F;var&#x2F;log&#x2F;messages中：</p>
<p>messages-20120101:Dec 31 09:25:45 nixcraft-router kernel: martian source 74.xx.47.yy from 10.13.106.25, on dev eth1</p>
<h2 id="修改mac地址"><a href="#修改mac地址" class="headerlink" title="修改mac地址"></a>修改mac地址</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ip link set dev eth1 down</span><br><span class="line">sudo ip link set dev eth1 address e8:61:1f:33:c5:fd</span><br><span class="line">sudo ip link set dev eth1 up</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.modb.pro/db/29135" target="_blank" rel="noopener">高斯在鲲鹏下跑TPCC的优化</a></p>
<p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="noopener">https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/</a></p>
<p><a href="https://www.hikunpeng.com/document/detail/zh/kunpenggrf/tuningtip/kunpengtuning_12_0025.html" target="_blank" rel="noopener">鲲鹏性能优化十板斧</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Linux/" rel="tag"># Linux</a>
          
            <a href="/tags/network/" rel="tag"># network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/01/01/如何用1分钱建站来秒杀搜狐新浪等三大门户网站/" rel="next" title="如何用1分钱建站速度秒杀三大门户网站站">
                <i class="fa fa-chevron-left"></i> 如何用1分钱建站速度秒杀三大门户网站站
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/01/03/mac路由和DSN相关知识/" rel="prev" title="mac 路由和DSN相关知识">
                mac 路由和DSN相关知识 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="twitter @plantegg">
          <p class="site-author-name" itemprop="name">twitter @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">191</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">282</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#网络硬件相关知识"><span class="nav-number">1.</span> <span class="nav-text">网络硬件相关知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#光纤和普通网线的性能差异"><span class="nav-number">1.1.</span> <span class="nav-text">光纤和普通网线的性能差异</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#单模光纤和多模光纤"><span class="nav-number">1.1.1.</span> <span class="nav-text">单模光纤和多模光纤</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多网卡bonding"><span class="nav-number">1.2.</span> <span class="nav-text">多网卡bonding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络中断和绑核"><span class="nav-number">1.3.</span> <span class="nav-text">网络中断和绑核</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ethtool"><span class="nav-number">1.3.1.</span> <span class="nav-text">ethtool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断联合（Coalescing）"><span class="nav-number">1.3.2.</span> <span class="nav-text">中断联合（Coalescing）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#irqbalance"><span class="nav-number">1.3.3.</span> <span class="nav-text">irqbalance</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#irqbalance指定core"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">irqbalance指定core</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#irqbalance的流程"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">irqbalance的流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网卡软中断以及内存远近的测试结论"><span class="nav-number">1.3.4.</span> <span class="nav-text">网卡软中断以及内存远近的测试结论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#阿里云绑核脚本"><span class="nav-number">1.3.5.</span> <span class="nav-text">阿里云绑核脚本</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RSS-和-RPS"><span class="nav-number">1.4.</span> <span class="nav-text">RSS 和 RPS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查看网卡和numa的关系"><span class="nav-number">1.5.</span> <span class="nav-text">查看网卡和numa的关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lspci"><span class="nav-number">1.6.</span> <span class="nav-text">lspci</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Default-路由持久化"><span class="nav-number">1.7.</span> <span class="nav-text">Default 路由持久化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#内核态启动并加载网卡的逻辑"><span class="nav-number">1.8.</span> <span class="nav-text">内核态启动并加载网卡的逻辑</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#用户态命名网卡流程"><span class="nav-number">1.8.1.</span> <span class="nav-text">用户态命名网卡流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网卡命名"><span class="nav-number">1.8.2.</span> <span class="nav-text">网卡命名</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#校验"><span class="nav-number">1.9.</span> <span class="nav-text">校验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#日志"><span class="nav-number">1.10.</span> <span class="nav-text">日志</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#修改mac地址"><span class="nav-number">1.11.</span> <span class="nav-text">修改mac地址</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">1.12.</span> <span class="nav-text">参考资料</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
