<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"plantegg.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="CPU性能和CACHE为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。 这次让我们从最底层的沙子开始用8篇文章来回答各种疑">
<meta property="og:type" content="article">
<meta property="og:title" content="CPU性能和CACHE">
<meta property="og:url" content="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="CPU性能和CACHE为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。 这次让我们从最底层的沙子开始用8篇文章来回答各种疑">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210802161558248.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/476909_1_En_15_Fig3_HTML.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20211110174606037.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/42gg2.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/eAvLK.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/4Z1nU.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20211110174810752.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/cache.architecture.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220304104859770.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220304152056740.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/bb29ac99-3645-4482-8473-c55b190af777.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210719102039296.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210719102112331.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210716102624566.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/141f4ccd-37ce-41e5-b404-101e6b9acf5d.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/mem-litmus.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/mem-sc.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/mem-tso.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/mem-weak.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/latency.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/cycle_times.jpg">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/1460000039103606.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/cache-hierarchy-1.jpg">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/0d31418e-78e9-46ac-ac8e-0fcc295f1050.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220321172431647.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210613123006681.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/ad19b92ccc97763aa7f78d8d1d514c84.jpg">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/58286da947132f269cb26ff3eda25c68.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210511160107225.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/f5728a2afb29c653a3e1bf21f4d56056.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/d39b0f2b3962d646133d450541fb75a6.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210603114550646.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220730161825538.png">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/maxresdefault.jpg">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20220607154156826.png">
<meta property="article:published_time" content="2021-07-19T04:30:03.000Z">
<meta property="article:modified_time" content="2025-11-16T11:58:49.512Z">
<meta property="article:author" content="twitter @plantegg">
<meta property="article:tag" content="CPU">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="cache">
<meta property="article:tag" content="performance">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://plantegg.github.io/images/951413iMgBlog/image-20210802161558248.png">


<link rel="canonical" href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/","path":"2021/07/19/CPU性能和CACHE/","title":"CPU性能和CACHE"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CPU性能和CACHE | plantegg</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">plantegg</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE"><span class="nav-number">1.</span> <span class="nav-text">CPU性能和CACHE</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0"><span class="nav-number">1.1.</span> <span class="nav-text">系列文章</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU%E4%B8%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81L1-L2%E7%AD%89%E5%90%84%E7%BA%A7cache"><span class="nav-number">1.2.</span> <span class="nav-text">CPU中为什么要L1&#x2F;L2等各级cache</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU%E4%B8%AD%E7%9A%84cache%E5%8F%98%E8%BF%81%E5%8E%86%E5%8F%B2"><span class="nav-number">1.3.</span> <span class="nav-text">CPU中的cache变迁历史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E5%9E%8B%E5%8F%B7CPU%E7%9A%84cache%E3%80%81%E5%86%85%E5%AD%98%E6%97%B6%E5%BB%B6"><span class="nav-number">1.4.</span> <span class="nav-text">不同型号CPU的cache、内存时延</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E6%A1%88%E4%BE%8B"><span class="nav-number">1.5.</span> <span class="nav-text">矩阵乘法案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cache%E5%AF%B9CPU%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">1.6.</span> <span class="nav-text">cache对CPU性能的影响</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E5%AF%B9Oceanbase-%EF%BC%8CMySQL-ODPS%E7%9A%84%E6%80%A7%E8%83%BD%E5%BD%B1%E5%93%8D"><span class="nav-number">1.6.1.</span> <span class="nav-text">缓存对Oceanbase ，MySQL, ODPS的性能影响</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-L2-Last-Level-Cache-LLC-%E7%BC%93%E5%AD%98%E7%9A%84%E6%BC%94%E5%8F%98"><span class="nav-number">1.6.2.</span> <span class="nav-text">CPU L2, Last Level Cache (LLC) 缓存的演变</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cache%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">1.7.</span> <span class="nav-text">Cache的缺点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hardware-Memory-Models-%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">1.8.</span> <span class="nav-text">Hardware Memory Models 顺序一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#x86-Total-Store-Order-x86-TSO-%E6%80%BB%E5%AD%98%E5%82%A8%E6%9C%89%E5%BA%8F"><span class="nav-number">1.8.1.</span> <span class="nav-text">x86 Total Store Order (x86-TSO) 总存储有序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ARM-POWER-Relaxed-Memory-Model"><span class="nav-number">1.8.2.</span> <span class="nav-text">ARM&#x2F;POWER Relaxed Memory Model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%84%E7%BA%A7IO%E5%BB%B6%E8%BF%9F%E6%95%B0%E5%AD%97"><span class="nav-number">1.9.</span> <span class="nav-text">各级IO延迟数字</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cache%E3%80%81%E5%86%85%E5%AD%98%E3%80%81%E7%A3%81%E7%9B%98%E3%80%81%E7%BD%91%E7%BB%9C%E7%9A%84%E5%BB%B6%E8%BF%9F%E6%AF%94%E8%BE%83"><span class="nav-number">1.9.1.</span> <span class="nav-text">Cache、内存、磁盘、网络的延迟比较</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E5%92%8Ccache%E7%9A%84latency%E5%AF%B9%E6%AF%94"><span class="nav-number">1.10.</span> <span class="nav-text">内存和cache的latency对比</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L1C%E3%80%81L2C%E3%80%81L3C%E3%80%81DDR-%E7%9A%84Latency%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE"><span class="nav-number">1.10.1.</span> <span class="nav-text">L1C、L2C、L3C、DDR 的Latency测试数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95memory-latency"><span class="nav-number">1.11.</span> <span class="nav-text">测试memory latency</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88CACHE%E6%AF%94%E5%86%85%E5%AD%98%E5%BF%AB%EF%BC%9F"><span class="nav-number">1.12.</span> <span class="nav-text">为什么CACHE比内存快？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SRAM%EF%BC%88Static-Random-Access-Memory%EF%BC%8C%E9%9D%99%E6%80%81%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8%EF%BC%89%E7%9A%84%E8%8A%AF%E7%89%87"><span class="nav-number">1.12.1.</span> <span class="nav-text">SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DRAM%EF%BC%88Dynamic-Random-Access-Memory%EF%BC%8C%E5%8A%A8%E6%80%81%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8%EF%BC%89%E7%9A%84%E8%8A%AF%E7%89%87"><span class="nav-number">1.12.2.</span> <span class="nav-text">DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SRAM%E5%92%8CDRAM%E5%8E%9F%E7%90%86%E6%AF%94%E8%BE%83"><span class="nav-number">1.12.3.</span> <span class="nav-text">SRAM和DRAM原理比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DRAM-%E5%88%B7%E6%96%B0"><span class="nav-number">1.12.4.</span> <span class="nav-text">DRAM 刷新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DRAM-%E9%A2%91%E7%8E%87"><span class="nav-number">1.12.5.</span> <span class="nav-text">DRAM 频率</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Persistence-memory"><span class="nav-number">1.13.</span> <span class="nav-text">Persistence memory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0-1"><span class="nav-number">1.14.</span> <span class="nav-text">系列文章</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">1.15.</span> <span class="nav-text">参考资料</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twitter @plantegg</p>
  <div class="site-description" itemprop="description">java mysql tcp performance network docker Linux</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">185</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">274</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/07/19/CPU%E6%80%A7%E8%83%BD%E5%92%8CCACHE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twitter @plantegg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
      <meta itemprop="description" content="java mysql tcp performance network docker Linux">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CPU性能和CACHE | plantegg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CPU性能和CACHE
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-19 12:30:03" itemprop="dateCreated datePublished" datetime="2021-07-19T12:30:03+08:00">2021-07-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-16 19:58:49" itemprop="dateModified" datetime="2025-11-16T19:58:49+08:00">2025-11-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CPU/" itemprop="url" rel="index"><span itemprop="name">CPU</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a>CPU性能和CACHE</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87-FT2500%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="/images/951413iMgBlog/image-20210802161558248.png" alt="image-20210802161558248"></p>
<h2 id="CPU中为什么要L1-L2等各级cache"><a href="#CPU中为什么要L1-L2等各级cache" class="headerlink" title="CPU中为什么要L1&#x2F;L2等各级cache"></a>CPU中为什么要L1&#x2F;L2等各级cache</h2><p>因为CPU的速度和访问内存速度差异太大，导致CPU在计算的时候90%以上的时间花在等待从内存中取数据、写数据而此时CPU处于闲置状态，也就导致了所谓的 <strong>内存墙</strong></p>
<p>cpu的速度大概50-60%每年的增长率，内存只有7%每年增长率：</p>
<p><img src="/images/951413iMgBlog/476909_1_En_15_Fig3_HTML.png" alt="A 1000× Improvement of the Processor-Memory Gap | SpringerLink"></p>
<p>CPU访问内存慢的案例参考：<a target="_blank" rel="noopener" href="http://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects</a></p>
<p>在数据使用前加载到CPU内更快的缓存中，最快的一级缓存等待时间是1~3个时钟周期。限制在于对于不在缓存中的数据，还是要等待数十上百个周期——按50周期算的话，不考虑并发和指令执行时间，缓存命中率达到98%，才能发挥一半的理论性能。然而实际情况中，大部分应用都无法达到这个命中率。</p>
<p><img src="/images/951413iMgBlog/image-20211110174606037.png" alt="image-20211110174606037"></p>
<h2 id="CPU中的cache变迁历史"><a href="#CPU中的cache变迁历史" class="headerlink" title="CPU中的cache变迁历史"></a>CPU中的cache变迁历史</h2><p>80486(1989), 8K的L1 cache第一次被集成在CPU中:</p>
<p><img src="/images/951413iMgBlog/42gg2.png" alt="486 motherboard with CPU location and 2nd level cache marked"></p>
<p><strong>80686</strong>(1995) ，<a target="_blank" rel="noopener" href="https://superuser.com/questions/196143/where-exactly-l1-l2-and-l3-caches-located-in-computer">L2被放入到CPU的Package</a>上，但是是一个独立的Die，可以看到L2大小和一个Die差不多:</p>
<p><img src="/images/951413iMgBlog/eAvLK.png" alt="Picture of a pentium Pro CPU, 256KB cache model"></p>
<p>以酷睿为例，现在的CPU集成了L1&#x2F;L2&#x2F;L3等各级CACHE，<strong>CACHE面积能占到CPU的一半</strong>:</p>
<p><img src="/images/951413iMgBlog/4Z1nU.png" alt="modernCPUwithL3.png"></p>
<p>从上图可以看到L3的大小快到die的一半，L1&#x2F;L2由每个core独享，L3是所有core共享，3级CACHE总面积跟所有core差不多大了。</p>
<p><img src="/images/951413iMgBlog/image-20211110174810752.png" alt="image-20211110174810752"></p>
<p>下图是目前一个主流的Die中CACHE的构成：</p>
<p><img src="/images/951413iMgBlog/cache.architecture.png" alt="img"></p>
<p>cache对速度的影响：</p>
<ul>
<li>一个方面是物理速度，如果要更大的容量就需要更多的晶体管，除了芯片的体积会变大，更重要的是大量的晶体管会导致速度下降，因为访问速度和要访问的晶体管所在的位置成反比，也就是当信号路径变长时，通信速度会变慢。这部分是物理问题。</li>
<li>另外一个问题是，多核技术中，数据的状态需要在多个CPU中进行同步，并且，我们可以看到，cache和RAM的速度差距太大，所以，多级不同尺寸的缓存有利于提高整体的性能。</li>
</ul>
<p>cache 大小查看</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bugu88 cpu0]# cd /sys/devices/system/</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index0/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index1/size</span><br><span class="line">32K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index2/size</span><br><span class="line">512K</span><br><span class="line">[root@bugu88 cpu0]# cat cache/index3/size</span><br><span class="line">32768K</span><br></pre></td></tr></table></figure>



<h2 id="不同型号CPU的cache、内存时延"><a href="#不同型号CPU的cache、内存时延" class="headerlink" title="不同型号CPU的cache、内存时延"></a>不同型号CPU的cache、内存时延</h2><p>测试命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl --membind=0 --cpunodebind=0 ./bin/lat_mem_rd 2000 64 //从结果看L3/memory latency不符合常识</span><br></pre></td></tr></table></figure>

<p><img src="/images/951413iMgBlog/image-20220304104859770.png" alt="image-20220304104859770"></p>
<p>调整测试参数，增加 -t 参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl -C 0 -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 2000M</span><br></pre></td></tr></table></figure>

<blockquote>
<p>内存基准测试命令 lat_mem_rd 的 -t 参数指定测试集以制造 TLB miss, Cache miss的压力场景，以测试 TLB miss,Cache miss对内存访问延迟的影响</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20220304152056740.png" alt="image-20220304152056740"></p>
<p>从上图可以看到的一些测试结论</p>
<ul>
<li>添加 -t 后(第二组测试)，L2和L3的延时比较正常了</li>
<li>倒数第三图hygon 7280 2node VS 8node(橙色) , 可以看到8node 内存延时降低了25%</li>
<li>飞腾没开numa内存延时抖动非常大（倒数图二，灰色线），基本不可用，整体延时也比其它CPU高很多</li>
<li>hygon L3大小比较特殊，一个socket下多个Die之间没有共享</li>
<li>intel E5时延表现很优秀，intel E5 CPU开启numa后内存延时有30%以上的减少（图三）</li>
<li>鲲鹏数据比较中规中矩，接近intel</li>
<li>stride参数、-t参数对整体数据影响比较大，x86、arm不同参数下也不一样</li>
</ul>
<p>E5机器内存速度为2133 MT&#x2F;S, 8163和8269则是2666 MT&#x2F;S, 所以说E5的时延表现很优秀</p>
<h2 id="矩阵乘法案例"><a href="#矩阵乘法案例" class="headerlink" title="矩阵乘法案例"></a><a target="_blank" rel="noopener" href="https://quick-bench.com/q/mmCA_YqPBiGsE8vY8POpSvYzwCo">矩阵乘法案例</a></h2><p>不做任何处理，最直白的矩阵乘法运算，在Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz 运行情况 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#cat simple.c</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;emmintrin.h&gt;</span><br><span class="line">#define N 2000</span><br><span class="line">double res[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul1[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul2[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">#define SM (CLS / sizeof (double))</span><br><span class="line"></span><br><span class="line">//compile:gcc -o simd -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ./simd.c</span><br><span class="line">//</span><br><span class="line">int main (void)</span><br><span class="line">&#123;</span><br><span class="line">  // ... Initialize mul1 and mul2</span><br><span class="line">  int i, i2, j, j2, k, k2;</span><br><span class="line"></span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	  for (j = 0; j &lt; N; ++j)</span><br><span class="line">		  for (k = 0; k &lt; N; ++k)</span><br><span class="line">			  res[i][j] += mul1[i][k] * mul2[k][j]; //mul2[k][j]是先列后行，对cache不友好；</span><br><span class="line"></span><br><span class="line">  // ... use res matrix</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果现将矩阵转置一下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;emmintrin.h&gt;</span><br><span class="line">#define N 2000</span><br><span class="line">double res[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul1[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double mul2[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">double tmp[N][N] __attribute__ ((aligned (64)));</span><br><span class="line">#define SM (CLS / sizeof (double))</span><br><span class="line"></span><br><span class="line">//compile:gcc -o simd -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ./simd.c</span><br><span class="line">//</span><br><span class="line">int main (void)</span><br><span class="line">&#123;</span><br><span class="line">  // ... Initialize mul1 and mul2</span><br><span class="line">  int i, i2, j, j2, k, k2;</span><br><span class="line"></span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	    for (j = 0; j &lt; N; ++j)</span><br><span class="line">			    tmp[i][j] = mul2[j][i]; //先转置</span><br><span class="line">  for (i = 0; i &lt; N; ++i)</span><br><span class="line">	    for (j = 0; j &lt; N; ++j)</span><br><span class="line">			    for (k = 0; k &lt; N; ++k)</span><br><span class="line">					      res[i][j] += mul1[i][k] * tmp[j][k]; //转置后按行访问，对内存友好</span><br><span class="line"></span><br><span class="line">  // ... use res matrix</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">//未做任何优化，直接矩阵乘法</span><br><span class="line">#taskset -c 1 perf stat ./simple</span><br><span class="line">      47192.640339      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">                88      context-switches          #    0.002 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,392      page-faults               #    0.665 K/sec</span><br><span class="line">   117,866,224,774      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   264,254,238,724      instructions              #    2.24  insns per cycle</span><br><span class="line">     8,052,145,218      branches                  #  170.623 M/sec</span><br><span class="line">         4,573,572      branch-misses             #    0.06% of all branches</span><br><span class="line"></span><br><span class="line">      47.151498977 seconds time elapsed</span><br><span class="line">      </span><br><span class="line">//转置后都是按行取数据，但是需要额外的空间</span><br><span class="line">#taskset -c 0 perf stat ./simp2</span><br><span class="line">      30457.259168      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               137      context-switches          #    0.004 K/sec</span><br><span class="line">                 7      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            86,081      page-faults               #    0.003 M/sec</span><br><span class="line">    76,068,232,551      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   264,385,818,470      instructions              #    3.48  insns per cycle</span><br><span class="line">     8,072,001,639      branches                  #  265.027 M/sec</span><br><span class="line">         4,414,867      branch-misses             #    0.05% of all branches</span><br><span class="line"></span><br><span class="line">      30.437018792 seconds time elapsed</span><br><span class="line"></span><br><span class="line">//按cache line 运算</span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">      29767.847109      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">                41      context-switches          #    0.001 K/sec</span><br><span class="line">                 1      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,454      page-faults               #    0.001 M/sec</span><br><span class="line">    74,346,857,277      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   253,099,702,393      instructions              #    3.40  insns per cycle</span><br><span class="line">    11,450,804,877      branches                  #  384.670 M/sec</span><br><span class="line">        16,043,642      branch-misses             #    0.14% of all branches</span><br><span class="line"></span><br><span class="line">      29.742025067 seconds time elapsed   </span><br><span class="line"></span><br><span class="line">//使用simd指令，按理应该最快，实际效果很差 :( </span><br><span class="line">#taskset -c 1 perf stat ./simd</span><br><span class="line">     140224.550539      task-clock (msec)         #    1.001 CPUs utilized</span><br><span class="line">               243      context-switches          #    0.002 K/sec</span><br><span class="line">                 2      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            70,569      page-faults               #    0.503 K/sec</span><br><span class="line">   350,218,614,852      cycles                    #    2.498 GHz</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-frontend</span><br><span class="line">   &lt;not supported&gt;      stalled-cycles-backend</span><br><span class="line">   717,191,577,191      instructions              #    2.05  insns per cycle</span><br><span class="line">    25,161,922,136      branches                  #  179.440 M/sec</span><br><span class="line">        54,411,349      branch-misses             #    0.22% of all branches</span><br><span class="line"></span><br><span class="line">     140.101635085 seconds time elapsed      </span><br></pre></td></tr></table></figure>

<p>On ARM Kunpeng 920-4826:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#taskset -c 1 perf stat ./simple</span><br><span class="line">        150,242.52 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               943      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.208 K/sec</span><br><span class="line">   390,626,613,178      cycles                    #    2.600 GHz</span><br><span class="line">   432,396,482,134      instructions              #    1.11  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">        11,348,599      branch-misses</span><br><span class="line"></span><br><span class="line">     150.249408485 seconds time elapsed</span><br><span class="line">     </span><br><span class="line">#taskset -c 1 perf stat ./simp2</span><br><span class="line">         69,008.66 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               426      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            39,104      page-faults               #    0.567 K/sec</span><br><span class="line">   179,417,225,187      cycles                    #    2.600 GHz</span><br><span class="line">   432,409,078,894      instructions              #    2.41  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">        11,122,131      branch-misses</span><br><span class="line"></span><br><span class="line">      69.014491453 seconds time elapsed     </span><br><span class="line">      </span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">			   50,251.34 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               315      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.623 K/sec</span><br><span class="line">   130,652,187,736      cycles                    #    2.600 GHz</span><br><span class="line">   291,261,746,765      instructions              #    2.23  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">       160,585,583      branch-misses</span><br><span class="line"></span><br><span class="line">      50.254025852 seconds time elapsed      </span><br></pre></td></tr></table></figure>

<p>如果在aarch编译开启gcc -O3 优化选项：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">//aarch gcc -O3 on</span><br><span class="line">#taskset -c 1 perf stat ./simple //开O3后 优化器走了simd指令</span><br><span class="line">         67,897.93 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">               414      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.461 K/sec</span><br><span class="line">   176,532,812,062      cycles                    #    2.600 GHz</span><br><span class="line">    28,214,139,367      instructions              #    0.16  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         3,250,598      branch-misses</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">#perf stat ./s2 //s2代码直接按行访问mul2,不考虑结果对错，运算量一样，相当于整体转置</span><br><span class="line">         15,963.30 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">                20      context-switches          #    0.001 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,288      page-faults               #    0.002 M/sec</span><br><span class="line">    41,504,239,031      cycles                    #    2.600 GHz</span><br><span class="line">    56,108,176,644      instructions              #    1.35  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         4,586,197      branch-misses</span><br><span class="line">     </span><br><span class="line">      </span><br><span class="line">#taskset -c 1 perf stat ./s3</span><br><span class="line">          5,695.85 msec task-clock                #    1.000 CPUs utilized</span><br><span class="line">                35      context-switches          #    0.006 K/sec</span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec</span><br><span class="line">            31,289      page-faults               #    0.005 M/sec</span><br><span class="line">    14,808,977,314      cycles                    #    2.600 GHz</span><br><span class="line">    24,281,358,553      instructions              #    1.64  insn per cycle</span><br><span class="line">   &lt;not supported&gt;      branches</span><br><span class="line">         2,006,221      branch-misses</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line">s3.c反编译后的汇编：</span><br><span class="line">  bc:	913a0060 	add	x0, x3, #0xe80</span><br><span class="line">  c0:	eb04001f 	cmp	x0, x4</span><br><span class="line">  c4:	1f584010 	fmadd	d16, d0, d24, d16</span><br><span class="line">  c8:	1f571c07 	fmadd	d7, d0, d23, d7 //参数 d7-精度，d0 </span><br><span class="line">  cc:	1f561806 	fmadd	d6, d0, d22, d6</span><br><span class="line">  d0:	1f551405 	fmadd	d5, d0, d21, d5</span><br><span class="line">  d4:	1f541004 	fmadd	d4, d0, d20, d4</span><br><span class="line">  d8:	1f530c03 	fmadd	d3, d0, d19, d3</span><br><span class="line">  dc:	1f520802 	fmadd	d2, d0, d18, d2</span><br><span class="line">  e0:	1f510401 	fmadd	d1, d0, d17, d1</span><br><span class="line">  e4:	54fffd81 	b.ne	94 &lt;main+0x94&gt;</span><br><span class="line">  e8:	91400c22 	add	x2, x1, #0x3, lsl #12</span><br><span class="line">  ec:	fd000030 	str	d16, [x1]</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/ddi0596/2021-12/SIMD-FP-Instructions/FMADD--Floating-point-fused-Multiply-Add--scalar--">FMADD指令</a></p>
<blockquote>
<p>Floating-point fused Multiply-Add (scalar). This instruction multiplies the values of the first two SIMD&amp;FP source registers, adds the product to the value of the third SIMD&amp;FP source register, and writes the result to the SIMD&amp;FP destination register.</p>
</blockquote>
<p>一些对比解释：</p>
<blockquote>
<p>编译优化选项设置-O2 级别及以上时，Kunpeng 处理器将对连续的浮点数乘法、加法融 合为乘加运算，以提升性能和精度。在-O2 级以上编译选项，x86 处理器不会将乘法和 加法做融合乘加运算，因此两种处理器在连续的浮点数乘法、加法运算后，小数点后 16 位存在差异。</p>
</blockquote>
<h2 id="cache对CPU性能的影响"><a href="#cache对CPU性能的影响" class="headerlink" title="cache对CPU性能的影响"></a>cache对CPU性能的影响</h2><p>CPU访问内存是非常慢的，所以我们在CPU中增加了多级缓存来<strong>匹配</strong>CPU和内存的速度。主频这20年基本都没怎么做高了，但是工艺提升了两个数量级，也就是集成的晶体管数量提升了2个数量级，工艺提升的能力主要给了cache，从而整体CPU性能提升了很多。</p>
<h3 id="缓存对Oceanbase-，MySQL-ODPS的性能影响"><a href="#缓存对Oceanbase-，MySQL-ODPS的性能影响" class="headerlink" title="缓存对Oceanbase ，MySQL, ODPS的性能影响"></a>缓存对Oceanbase ，MySQL, ODPS的性能影响</h3><p>以下测试数据主要来源于真实的业务场景：OB&#x2F;MySQL&#x2F;ODPS</p>
<p><img src="/images/951413iMgBlog/bb29ac99-3645-4482-8473-c55b190af777.png" alt="img"></p>
<p>x86 Skylake之前，L1 I&#x2F;D 32KB, L2 256KB, L3 2.5MB&#x2F;core， 2.5MB&#x2F;core的L3（LLC）芯片面积相当于1&#x2F;2 CPU core 的尺寸</p>
<ol>
<li>关闭L3（2.5MB），关闭L2（256KB），此时性能CPI（越小越好）是4.25</li>
<li>关闭L3，打开L2（256KB），此时性能CPI为2.23</li>
<li>关闭L3，打开L2同时增加256KB，L2尺寸到512KB，性能CPI为1.38</li>
<li>打开L3（2.5MB），打开L2（256KB），性能为1.28 ，该状态就是intel CPU出厂的状态</li>
<li>打开L3，增加到16MB，打开L2（256KB），性能为1.25</li>
</ol>
<p>上面的数据显示当L3关闭之后，从case 3 开始，L2仅仅增加256KB，L2芯片面积相对于CPU core 增加 5%(0.5 &#x2F;2.5M * 025M)，性能相对于case 2 提升1.61倍（2.23&#x2F;1.38），而使用case 4 ,L3 2.5MB打开，相对于case 3，增加2.3MB（2.5MB - 256KB）,芯片面积相对于CPU core 增加 46%（0.5&#x2F;2.5M * 2.3M）， 而性能仅仅提升 1.07倍（1.38&#x2F;1.28），所以14年给Intel提议需要增加L2尺寸降低L3尺寸，这些数据促使Intel开始重新考虑对于数据中心缓存新的设计。</p>
<p>2014年的 Broadwell 的第五代智能酷睿处理器，是 Haswell 的 14nm 升级版（$1745.00 - $1749.00）：</p>
<p><img src="/images/951413iMgBlog/image-20210719102039296.png" alt="image-20210719102039296"></p>
<p>E5一个Die有16个物理core（上面截图是两个Socket, 每个Socket一个Die，每个物理core两个超线程），所以每core的L3大小：40M&#x2F;16&#x3D;2.5M&#x2F;core</p>
<p>2015年则推出 SkyLake 架构的Platinum 8269CY（$4702.00）, 每core的L3大小：36M&#x2F;26&#x3D;1.38M&#x2F;core：</p>
<p><img src="/images/951413iMgBlog/image-20210719102112331.png" alt="image-20210719102112331"></p>
<p>Intel 2015年 发表论文<a target="_blank" rel="noopener" href="https://people.csail.mit.edu/emer/papers/2015.02.hpca.cache_hierarchy.pdf">《High Performing Cache Hierarchies for Server Workloads》</a>证明了阿里提出的建议的正确性，从Skylake架构开始将L2 cache 由 256KB 升级到 1MB， L3由2.5MB &#x2F;core 压缩到 1.375MB &#x2F; core， Intel之所以没有完全去掉L3的原因是希望这样设计的CPU对于 使用 CPU2006的workload性能仍然能够做到不受影响。</p>
<p><img src="/images/951413iMgBlog/image-20210716102624566.png" alt="image-20210716102624566"></p>
<p>上图是不同业务场景下，CPI 随cache大小的变化，可以看到随着cache增加性能基本不增加了。</p>
<h3 id="CPU-L2-Last-Level-Cache-LLC-缓存的演变"><a href="#CPU-L2-Last-Level-Cache-LLC-缓存的演变" class="headerlink" title="CPU L2, Last Level Cache (LLC) 缓存的演变"></a>CPU L2, Last Level Cache (LLC) 缓存的演变</h3><p>Last Level Cache(L3) 在2016年之前都是2MB&#x2F;core 或者 2.5MB&#x2F;core, 这个原因取决于在此之前行业都是使用CPU2006作为设计CPU的benchmark，如下图所示：</p>
<p><img src="/images/951413iMgBlog/141f4ccd-37ce-41e5-b404-101e6b9acf5d.png" alt="img"></p>
<p>根据上图中CPU2006的MPKI数据显示如果LLC在4MB的时候非常好，LLC在2.5MB之后MKPI提升10%性能只有1～3%的提升，2.5MB LLC cache是 CPU core 1&#x2F;2 的芯片面积，因此若将LLC 由2.5MB升级到4MB，换算成CPU core的芯片面积是增长30%（1&#x2F;2 * 1.5M&#x2F;2.5M），但性能仅仅提升最多3%，这就是为什么基于CPU2006的benchmark条件下，intel将LLC设定为2~2.5MB的原因。</p>
<h2 id="Cache的缺点"><a href="#Cache的缺点" class="headerlink" title="Cache的缺点"></a>Cache的缺点</h2><p>缓存有两大缺点：</p>
<ul>
<li>当数据集非常大的时候，时间空间局部性较低时缓存的工作效率很低；</li>
<li>当缓存工作效率高的时候，局部性非常高，这意味着，根据定义，大多数缓存在大多数时间都处于空闲状态。</li>
</ul>
<h2 id="Hardware-Memory-Models-顺序一致性"><a href="#Hardware-Memory-Models-顺序一致性" class="headerlink" title="Hardware Memory Models 顺序一致性"></a><a target="_blank" rel="noopener" href="https://colobu.com/2021/06/30/hwmm/">Hardware Memory Models 顺序一致性</a></h2><blockquote>
<p>对存储在内存中数据更改的可见性和一致性，所以这个契约被称为内存一致性模型（<code>memory consistency model</code>）或仅仅是内存模型(<code>memory model</code>)</p>
</blockquote>
<p>r1&#x2F;r2是线程本地变量，如下代码的可能结果是哪些？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Litmus Test: Message Passing</span><br><span class="line">Can this program see r1 = 1, r2 = 0?</span><br><span class="line"></span><br><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 r1 = y</span><br><span class="line">y = 1                 r2 = x</span><br></pre></td></tr></table></figure>

<p>如果该<code>litmus test</code>的执行顺序一致，则只有六种可能的交替:</p>
<p><a target="_blank" rel="noopener" href="https://colobu.com/2021/06/30/hwmm/mem-litmus.png"><img src="/images/951413iMgBlog/mem-litmus.png" alt="img"></a></p>
<p>因为没有交替执行的结果会产生<code>r1 = 1, r2 = 0</code>,所以这个结果是不允许的。也就是说，在顺序执行的硬件上，litmus test执行结果出现<code>r1 = 1, r2 = 0</code>是不可能的。</p>
<p>顺序一致性的一个很好的思维模型是想象所有处理器直接连接到同一个共享内存，它可以一次处理一个线程的读或写请求。 不涉及缓存，因此每次处理器需要读取或写入内存时，该请求都会转到共享内存。 一次使用一次的共享内存对所有内存访问的执行施加了顺序顺序：顺序一致性。</p>
<p><a target="_blank" rel="noopener" href="https://colobu.com/2021/06/30/hwmm/mem-sc.png"><img src="/images/951413iMgBlog/mem-sc.png" alt="img"></a></p>
<h3 id="x86-Total-Store-Order-x86-TSO-总存储有序"><a href="#x86-Total-Store-Order-x86-TSO-总存储有序" class="headerlink" title="x86 Total Store Order (x86-TSO) 总存储有序"></a><a target="_blank" rel="noopener" href="https://research.swtch.com/hwmm#x86">x86 Total Store Order (x86-TSO) 总存储有序</a></h3><p>所有处理器仍然连接到一个共享内存，但是每个处理器都将对该内存的写入(<code>write</code>)放入到本地写入队列中。处理器继续执行新指令，同时写操作(<code>write</code>)会更新到这个共享内存。一个处理器上的内存读取在查询主内存之前会查询本地写队列，但它看不到其他处理器上的写队列。其效果就是当前处理器比其他处理器会先看到自己的写操作。但是——这一点非常重要——&#x3D;&#x3D;所有处理器都保证写入(存储<code>store</code>)到共享内存的(总)顺序，所以给这个模型起了个名字:总存储有序，或<code>TSO</code>&#x3D;&#x3D;。当一个写操作到达共享内存时，任何处理器上的任何未来读操作都将看到它并使用该值(直到它被以后的写操作覆盖，或者可能被另一个处理器的缓冲写操作覆盖)。</p>
<p><img src="/images/951413iMgBlog/mem-tso.png" alt="img"></p>
<p>针对前文的litmus test案例，写队列保证线程1在y之前将x写入内存，关于内存写入顺序(总存储有序)的系统级协议保证线程2在读y的新值之前读x的新值。因此，<code>r1 = y</code>在<code>r2 = x</code>看不到新的x之前不可能看到新的y。存储顺序至关重要:线程1在写入y之前先写入x，因此线程2在看到x的写入之前不可能看到y的写入。</p>
<p>但是对于TSO系统下，以下case能看到r1 &#x3D; 0, r2 &#x3D; 0, 如果在顺序一致性的协议下这是不可能发生的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Litmus Test: Write Queue (also called Store Buffer)</span><br><span class="line">Can this program see r1 = 0, r2 = 0?</span><br><span class="line"></span><br><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 y = 1</span><br><span class="line">r1 = y                r2 = x</span><br><span class="line">On sequentially consistent hardware: no.</span><br><span class="line">On x86 (or other TSO): yes!</span><br></pre></td></tr></table></figure>

<p>为了让TSO和顺序一致性协议保持一致，我们需要依赖于更强的内存排序，非顺序一致的硬件提供了称为内存屏障(或栅栏)的显式指令，可用于控制排序。我们可以添加一个内存屏障，以确保每个线程在开始读取之前都会刷新其先前对内存的写入:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Thread 1           // Thread 2</span><br><span class="line">x = 1                 y = 1</span><br><span class="line">barrier               barrier</span><br><span class="line">r1 = y                r2 = x</span><br></pre></td></tr></table></figure>

<p>加上正确的障碍，<code>r1 = 0，r2 = 0</code>也是不可能的了。内存屏障有很多种，它的存在给了程序员或语言实现者一种在程序的关键时刻强制顺序一致行为的方法。</p>
<h3 id="ARM-POWER-Relaxed-Memory-Model"><a href="#ARM-POWER-Relaxed-Memory-Model" class="headerlink" title="ARM&#x2F;POWER Relaxed Memory Model"></a><a target="_blank" rel="noopener" href="https://research.swtch.com/hwmm#relaxed">ARM&#x2F;POWER Relaxed Memory Model</a></h3><p>ARM和POWER系统的概念模型是，每个处理器从其自己的完整内存副本中读取和向其写入，每个写入独立地传播到其他处理器，随着写入的传播，允许重新排序。</p>
<p><img src="/images/951413iMgBlog/mem-weak.png" alt="img"></p>
<p>这里没有总存储顺序。虽然没有描述，但是每个处理器都被允许推迟读取(<code>read</code>)，直到它等到它需要结果:读取(<code>read</code>)可以被延迟到稍后的写入(<code>write</code>)之后。在这个宽松的(<code>relaxed</code>)模型中，我们迄今为止所看到的每一个litmus test的答案都是“yes，这真的可能发生。”</p>
<p>在这个内存模型下，对于前文中的 Litmus Test: Message Passing case是可以看到r1&#x3D;1,r2&#x3D;0的（TSO保证不会），但是可以保证 Litmus Test: Store Buffering case 和TSO一致。</p>
<p>最后再附加几个Latency数据，让大家比较起来更有体感一些</p>
<h2 id="各级IO延迟数字"><a href="#各级IO延迟数字" class="headerlink" title="各级IO延迟数字"></a>各级IO延迟数字</h2><h3 id="Cache、内存、磁盘、网络的延迟比较"><a href="#Cache、内存、磁盘、网络的延迟比较" class="headerlink" title="Cache、内存、磁盘、网络的延迟比较"></a>Cache、内存、磁盘、网络的延迟比较</h3><p><a target="_blank" rel="noopener" href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network">假设主频2.6G的CPU，每个指令只需要 0.38ns</a> </p>
<p>每次内存寻址需要 100ns </p>
<p>一次 CPU 上下文切换（系统调用）需要大约 1500ns，也就是 1.5us（这个数字参考了<a target="_blank" rel="noopener" href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html">这篇文章</a>，采用的是单核 CPU 线程平均时间）</p>
<p>SSD 随机读取耗时为 150us</p>
<p>从内存中读取 1MB 的连续数据，耗时大约为 250us</p>
<p>同一个数据中心网络上跑一个来回需要 0.5ms</p>
<p>从 SSD 读取 1MB 的顺序数据，大约需要 1ms （是内存速度的四分之一）</p>
<p>磁盘寻址时间为 10ms</p>
<p>从磁盘读取 1MB 连续数据需要 20ms</p>
<p>如果 CPU 访问 L1 缓存需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<h2 id="内存和cache的latency对比"><a href="#内存和cache的latency对比" class="headerlink" title="内存和cache的latency对比"></a>内存和cache的latency对比</h2><p><img src="/images/951413iMgBlog/latency.png" alt="latency"></p>
<p><a target="_blank" rel="noopener" href="http://www.webstersystems.co.uk/threads.htm">各级cache的Latency</a>：</p>
<p><img src="/images/951413iMgBlog/cycle_times.jpg" alt="Cycle times"></p>
<p><strong>2012 年延迟数字对比表：</strong></p>
<table>
<thead>
<tr>
<th>Work</th>
<th>Latency</th>
</tr>
</thead>
<tbody><tr>
<td>L1 cache reference</td>
<td>0.5 ns</td>
</tr>
<tr>
<td>Branch mispredict</td>
<td>5 ns</td>
</tr>
<tr>
<td>L2 cache reference</td>
<td>7 ns</td>
</tr>
<tr>
<td>Mutex lock&#x2F;unlock</td>
<td>25 ns</td>
</tr>
<tr>
<td>Main memory reference</td>
<td>100 ns</td>
</tr>
<tr>
<td>持久内存</td>
<td>300 ns</td>
</tr>
<tr>
<td>Compress 1K bytes with Zippy</td>
<td>3,000 ns</td>
</tr>
<tr>
<td>Send 1K bytes over 1 Gbps network</td>
<td>10,000 ns</td>
</tr>
<tr>
<td>Read 4K randomly from SSD*</td>
<td>150,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from memory</td>
<td>250,000 ns</td>
</tr>
<tr>
<td>Round trip within same datacenter</td>
<td>500,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from SSD*</td>
<td>1,000,000 ns</td>
</tr>
<tr>
<td>Disk seek</td>
<td>10,000,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from disk</td>
<td>20,000,000 ns</td>
</tr>
<tr>
<td>Send packet CA-&gt;Netherlands-&gt;CA</td>
<td>150,000,000 ns</td>
</tr>
</tbody></table>
<p>一个比较有体感的比较：如果 CPU 访问 寄存器需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<p><img src="/images/951413iMgBlog/1460000039103606.png" alt="img"></p>
<p>当然更古老一点的年代给出来的数据可能又不一样一点，但是基本比例差异还是差不多的：</p>
<p><img src="/images/951413iMgBlog/cache-hierarchy-1.jpg" alt="Memory Hierarchy"></p>
<p><img src="/images/951413iMgBlog/0d31418e-78e9-46ac-ac8e-0fcc295f1050.png" alt="img"></p>
<p>测试Inte E5 L1 、L2、L3的cache延时图来加深印象，可以看到在每级cache大小附近时延有个跳跃(纵坐标是纳秒，横坐标是大小 M)：</p>
<p><img src="/images/951413iMgBlog/image-20220321172431647.png" alt="image-20220321172431647"></p>
<p><a target="_blank" rel="noopener" href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">推荐从这里看延时，拖动时间轴可以看到随着技术、工艺的改变Latency每一年的变化</a></p>
<p><img src="/images/951413iMgBlog/image-20210613123006681.png" alt="image-20210613123006681"></p>
<p>查看cpu cache数据</p>
<pre><code>cat /proc/cpuinfo |grep -i cache
</code></pre>
<img src="/images/951413iMgBlog/ad19b92ccc97763aa7f78d8d1d514c84.jpg" alt="image.png" style="zoom:50%;" />

<h3 id="L1C、L2C、L3C、DDR-的Latency测试数据"><a href="#L1C、L2C、L3C、DDR-的Latency测试数据" class="headerlink" title="L1C、L2C、L3C、DDR 的Latency测试数据"></a>L1C、L2C、L3C、DDR 的Latency测试数据</h3><p><a target="_blank" rel="noopener" href="https://topic.atatech.org/articles/100065">下图从左至右响应时间分别是L1C、L2C、L3C、DDR</a>，可以看出这四个Latency变化还是非常明显的，泾渭分明。</p>
<p><img src="/images/951413iMgBlog/58286da947132f269cb26ff3eda25c68.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/image-20210511160107225.png" alt="image-20210511160107225"></p>
<p><img src="/images/951413iMgBlog/f5728a2afb29c653a3e1bf21f4d56056.png" alt="image.png"></p>
<h2 id="测试memory-latency"><a href="#测试memory-latency" class="headerlink" title="测试memory latency"></a>测试memory latency</h2><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw">memory latency逻辑</a>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;sys/mman.h&gt;</span><br><span class="line">#include &lt;sys/time.h&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line"></span><br><span class="line">#define ONE p = (char **)*p;</span><br><span class="line">#define FIVE    ONE ONE ONE ONE ONE</span><br><span class="line">#define TEN FIVE FIVE</span><br><span class="line">#define FIFTY   TEN TEN TEN TEN TEN</span><br><span class="line">#define HUNDRED FIFTY FIFTY</span><br><span class="line"></span><br><span class="line">static void usage()</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;Usage: ./mem-lat -b xxx -n xxx -s xxx\n&quot;);</span><br><span class="line">    printf(&quot;   -b buffer size in KB\n&quot;);</span><br><span class="line">    printf(&quot;   -n number of read\n\n&quot;);</span><br><span class="line">    printf(&quot;   -s stride skipped before the next access\n\n&quot;);</span><br><span class="line">    printf(&quot;Please don&#x27;t use non-decimal based number\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[])</span><br><span class="line">&#123;</span><br><span class="line">  unsigned long i, j, size, tmp;</span><br><span class="line">    unsigned long memsize = 0x800000; /* 1/4 LLC size of skylake, 1/5 of broadwell */</span><br><span class="line">    unsigned long count = 1048576; /* memsize / 64 * 8 */</span><br><span class="line">    unsigned int stride = 64; /* skipped amount of memory before the next access */</span><br><span class="line">    unsigned long sec, usec;</span><br><span class="line">    struct timeval tv1, tv2;</span><br><span class="line">    struct timezone tz;</span><br><span class="line">    unsigned int *indices;</span><br><span class="line"></span><br><span class="line">    while (argc-- &gt; 0) &#123;</span><br><span class="line">        if ((*argv)[0] == &#x27;-&#x27;) &#123;  /* look at first char of next */</span><br><span class="line">            switch ((*argv)[1]) &#123;   /* look at second */</span><br><span class="line">                case &#x27;b&#x27;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    memsize = atoi(*argv) * 1024;</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                case &#x27;n&#x27;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    count = atoi(*argv);</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                case &#x27;s&#x27;:</span><br><span class="line">                    argv++;</span><br><span class="line">                    argc--;</span><br><span class="line">                    stride = atoi(*argv);</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">                default:</span><br><span class="line">                    usage();</span><br><span class="line">                    exit(1);</span><br><span class="line">                    break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        argv++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  char* mem = mmap(NULL, memsize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);</span><br><span class="line">    // trick3: init pointer chasing, per stride=8 byte</span><br><span class="line">    size = memsize / stride;</span><br><span class="line">    indices = malloc(size * sizeof(int));</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; size; i++)</span><br><span class="line">        indices[i] = i;</span><br><span class="line"></span><br><span class="line">    // trick 2: fill mem with pointer references</span><br><span class="line">    for (i = 0; i &lt; size - 1; i++)</span><br><span class="line">        *(char **)&amp;mem[indices[i]*stride]= (char*)&amp;mem[indices[i+1]*stride];</span><br><span class="line">    *(char **)&amp;mem[indices[size-1]*stride]= (char*)&amp;mem[indices[0]*stride];</span><br><span class="line"></span><br><span class="line">    register char **p = (char **) mem;</span><br><span class="line">    //char **p = (char **) mem;</span><br><span class="line">    tmp = count / 100;</span><br><span class="line"></span><br><span class="line">    gettimeofday (&amp;tv1, &amp;tz);</span><br><span class="line">    for (i = 0; i &lt; tmp; ++i) &#123;</span><br><span class="line">        HUNDRED;  //trick 1</span><br><span class="line">    &#125;</span><br><span class="line">    gettimeofday (&amp;tv2, &amp;tz);</span><br><span class="line">    char **touch = p;</span><br><span class="line">    if (tv2.tv_usec &lt; tv1.tv_usec) &#123;</span><br><span class="line">        usec = 1000000 + tv2.tv_usec - tv1.tv_usec;</span><br><span class="line">        sec = tv2.tv_sec - tv1.tv_sec - 1;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        usec = tv2.tv_usec - tv1.tv_usec;</span><br><span class="line">        sec = tv2.tv_sec - tv1.tv_sec;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printf(&quot;Buffer size: %ld KB, stride %d, time %d.%06d s, latency %.2f ns\n&quot;,</span><br><span class="line">            memsize/1024, stride, sec, usec, (sec * 1000000  + usec) * 1000.0 / (tmp *100));</span><br><span class="line">    munmap(mem, memsize);</span><br><span class="line">    free(indices);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分别在intel 8163和arm 鲲鹏920上执行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">$cat run_mem_lat.sh</span><br><span class="line">#!/bin/sh</span><br><span class="line">#set -x</span><br><span class="line"></span><br><span class="line">work=./mem-lat</span><br><span class="line">buffer_size=1</span><br><span class="line">node=$1</span><br><span class="line">mem=$2</span><br><span class="line"></span><br><span class="line">for i in `seq 1 15`; do</span><br><span class="line">    #echo $i</span><br><span class="line">        #echo $buffer_size</span><br><span class="line">    taskset -ac 1 $work -b $buffer_size -s 64</span><br><span class="line">    buffer_size=$(($buffer_size*2))</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#sh run_mem_lat.sh</span><br><span class="line">Buffer size: 1 KB, stride 64, time 0.001682 s, latency 1.60 ns</span><br><span class="line">Buffer size: 2 KB, stride 64, time 0.001685 s, latency 1.61 ns</span><br><span class="line">Buffer size: 4 KB, stride 64, time 0.001687 s, latency 1.61 ns</span><br><span class="line">Buffer size: 8 KB, stride 64, time 0.001682 s, latency 1.60 ns</span><br><span class="line">Buffer size: 16 KB, stride 64, time 0.001688 s, latency 1.61 ns</span><br><span class="line">Buffer size: 32 KB, stride 64, time 0.001817 s, latency 1.73 ns</span><br><span class="line">Buffer size: 64 KB, stride 64, time 0.005842 s, latency 5.57 ns</span><br><span class="line">Buffer size: 128 KB, stride 64, time 0.005838 s, latency 5.57 ns</span><br><span class="line">Buffer size: 256 KB, stride 64, time 0.005838 s, latency 5.57 ns</span><br><span class="line">Buffer size: 512 KB, stride 64, time 0.005841 s, latency 5.57 ns</span><br><span class="line">Buffer size: 1024 KB, stride 64, time 0.006056 s, latency 5.78 ns</span><br><span class="line">Buffer size: 2048 KB, stride 64, time 0.006175 s, latency 5.89 ns</span><br><span class="line">Buffer size: 4096 KB, stride 64, time 0.006203 s, latency 5.92 ns</span><br><span class="line">Buffer size: 8192 KB, stride 64, time 0.006383 s, latency 6.09 ns</span><br><span class="line">Buffer size: 16384 KB, stride 64, time 0.007345 s, latency 7.01 ns</span><br><span class="line"></span><br><span class="line">[root@x86.170 /root]</span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    24</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          1</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2500.390</span><br><span class="line">CPU max MHz:           3100.0000</span><br><span class="line">CPU min MHz:           1000.0000</span><br><span class="line">BogoMIPS:              4998.87</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              33792K</span><br><span class="line">NUMA node0 CPU(s):     0-95</span><br><span class="line"></span><br><span class="line">//鲲鹏920</span><br><span class="line">#sh run_mem_lat.sh</span><br><span class="line">Buffer size: 1 KB, stride 64, time 0.001628 s, latency 1.55 ns</span><br><span class="line">Buffer size: 2 KB, stride 64, time 0.001623 s, latency 1.55 ns</span><br><span class="line">Buffer size: 4 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 8 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 16 KB, stride 64, time 0.001622 s, latency 1.55 ns</span><br><span class="line">Buffer size: 32 KB, stride 64, time 0.001613 s, latency 1.54 ns</span><br><span class="line">Buffer size: 64 KB, stride 64, time 0.001637 s, latency 1.56 ns</span><br><span class="line">Buffer size: 128 KB, stride 64, time 0.003749 s, latency 3.58 ns</span><br><span class="line">Buffer size: 256 KB, stride 64, time 0.003320 s, latency 3.17 ns</span><br><span class="line">Buffer size: 512 KB, stride 64, time 0.003779 s, latency 3.60 ns</span><br><span class="line">Buffer size: 1024 KB, stride 64, time 0.004310 s, latency 4.11 ns</span><br><span class="line">Buffer size: 2048 KB, stride 64, time 0.004655 s, latency 4.44 ns</span><br><span class="line">Buffer size: 4096 KB, stride 64, time 0.005032 s, latency 4.80 ns</span><br><span class="line">Buffer size: 8192 KB, stride 64, time 0.005721 s, latency 5.46 ns</span><br><span class="line">Buffer size: 16384 KB, stride 64, time 0.006470 s, latency 6.17 ns</span><br><span class="line"></span><br><span class="line">[root@ARM 15:58 /root]</span><br><span class="line">#lscpu</span><br><span class="line">Architecture:          aarch64</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                96</span><br><span class="line">On-line CPU(s) list:   0-95</span><br><span class="line">Thread(s) per core:    1</span><br><span class="line">Core(s) per socket:    48</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          4</span><br><span class="line">Model:                 0</span><br><span class="line">CPU max MHz:           2600.0000</span><br><span class="line">CPU min MHz:           200.0000</span><br><span class="line">BogoMIPS:              200.00</span><br><span class="line">L1d cache:             64K</span><br><span class="line">L1i cache:             64K</span><br><span class="line">L2 cache:              512K</span><br><span class="line">L3 cache:              24576K</span><br><span class="line">NUMA node0 CPU(s):     0-23</span><br><span class="line">NUMA node1 CPU(s):     24-47</span><br><span class="line">NUMA node2 CPU(s):     48-71</span><br><span class="line">NUMA node3 CPU(s):     72-95</span><br></pre></td></tr></table></figure>



<h2 id="为什么CACHE比内存快？"><a href="#为什么CACHE比内存快？" class="headerlink" title="为什么CACHE比内存快？"></a>为什么CACHE比内存快？</h2><p>首先肯定是距离的原因，另外这两种存储结构的制造工艺不同导致的速度差异也很大，从上面可以看到一块4000刀的CPU有一半的面积是cache，也就是40M CACHE花了2000刀，如果用来买内存条能卖一大堆吧。</p>
<p>接下来说下CACHE（SRAM) 和内存（DRAM）制造的工艺差异</p>
<h3 id="SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片"><a href="#SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片" class="headerlink" title="SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片"></a>SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片</h3><p>CPU Cache 用的是一种叫作 SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片。</p>
<p>SRAM 之所以被称为”静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。在 SRAM 里面，一个比特的数据，需要 6～8 个晶体管。所以 SRAM 的存储密度不高。同样的物理空间下，能够存储的数据有限。不过，因为 SRAM 的电路简单，所以访问速度非常快。</p>
<p>L1和L2一般是SRAM， L1的容量通常比L2小，容量大的SRAM访问时间就越长，同样制程和设计的情况下，<strong>访问延时与容量的开方大致是成正比</strong>的。</p>
<p>另外工作原理不同速度差异也不一样，L1就是讲究快，比如L1是N路组相联，N路阻相联的意思就是N个Cache单元同时读取数据（有点类似RAID0）。</p>
<p>L3用的还是SRAM，但是在考虑换成STT-MRAM，这样容量更大。</p>
<h3 id="DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片"><a href="#DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片" class="headerlink" title="DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片"></a>DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片</h3><p>为磁芯存储器画上句号的是集成电路随机存储器件。1966年，IBM Thomas J. Watson研究中心的Dr. Robert H. Dennard开发出了单个单元的动态随机存储器DRAM，DRAM每个单元包含一个开关晶体管和一个电容，利用电容中的电荷存储数据。因为电容中的电荷会泄露，需要每个周期都进行刷新重新补充电量，所以称其为动态随机存储器。</p>
<p>内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。</p>
<p>动态随机存取存储器（DRAM）是一种半导体存储器，主要的作用原理是利用电容内存储电荷的多寡来代表一个二进制比特（bit）是1还是0。由于<strong>在现实中晶体管会有漏电电流的现象</strong>，导致电容上所存储的电荷数量并不足以正确的判别数据，而导致数据毁损。因此对于DRAM来说，周期性地充电是一个无可避免的要件。由于这种需要定时刷新的特性，因此被称为“动态”存储器。相对来说，静态存储器（SRAM）只要存入数据后，纵使不刷新也不会丢失记忆。</p>
<p>DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多，也就是存储的”密度”更大。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。</p>
<p><img src="/images/951413iMgBlog/d39b0f2b3962d646133d450541fb75a6.png" alt="img"></p>
<p>SRAM是比<strong>DRAM</strong>更为昂贵，但更为快速、非常低功耗（特别是在空闲状态）。 因此<strong>SRAM</strong>首选用于带宽要求高，或者功耗要求低，或者二者兼而有之。 <strong>SRAM</strong>比起<strong>DRAM</strong>更为容易控制，也更是随机访问。 由于复杂的内部结构，<strong>SRAM</strong>比<strong>DRAM</strong>的占用面积更大，因而不适合用于更高储存密度低成本的应用，如PC内存。</p>
<h3 id="SRAM和DRAM原理比较"><a href="#SRAM和DRAM原理比较" class="headerlink" title="SRAM和DRAM原理比较"></a>SRAM和DRAM原理比较</h3><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI2NDYwMDAxOQ==&mid=2247483772&idx=1&sn=d7c188247b9851f7985676e2f9dd9a0e&chksm=eaab61c0dddce8d62bdb521de1ada13142264882feae1ff06d6dcd81430a0063377e4b34cedb&scene=178&cur_album_id=1368835510680272898#rd">简单说DRAM只有一个晶体管和一个电容，SRAM就复杂多了，需要6个晶体管</a></p>
<p><img src="/images/951413iMgBlog/image-20210603114550646.png" alt="What is the difference between SRAM and DRAM"></p>
<p>图左边的 DRAM 的状态是保持在电容器C中。晶体管M用来控制访问。如果要读取状态，拉升访问线AL，这时，可能会有电流流到数据线DL上，也可能没有，取决于电容器是否有电。如果要写入状态，先设置DL，然后升起AL一段时间，直到电容器充电或放电完毕。</p>
<p>由于读取状态时需要对电容器放电，所以这一过程不能无限重复，不得不在某个点上对它重新充电。更糟糕的是，为了容纳大量单元(现在一般在单个芯片上容纳109以上的RAM单元)，电容器的容量必须很小(0.000000000000001法拉以下)。这样，完整充电后大约持有几万个电子。即使电容器的电阻很大(若干兆欧姆)，仍然只需很短的时间就会耗光电荷，称为「泄漏」。</p>
<p>这种泄露就是现在的大部分DRAM芯片每隔64ms就必须进行一次刷新的原因。在刷新期间，对于该芯片的访问是不可能的，这甚至会造成半数任务的延宕。（相关内容请察看【highperfdram】一章）</p>
<p>这个问题的另一个后果就是无法直接读取芯片单元中的信息，而必须通过信号放大器将0和1两种信号间的电势差增大，才能分辨出来。</p>
<p>DRAM 主要靠电容充放电来识别0和1，<strong>但是充放电是一个持续过程，需要耗时，这也是导致内存延时大的主要原因</strong></p>
<p><img src="/images/951413iMgBlog/image-20220730161825538.png" alt="image-20220730161825538"></p>
<p>不像SRAM可以即刻读取数据，当要读取DRAM的时候，必须花一点时间来等待电容的冲放电完全。这一点点的时间最终限制了DRAM的速度。</p>
<p>SRAM 需要注意以下问题:</p>
<ul>
<li>一个单元需要6个晶体管。也有采用4个晶体管的SRAM，体积大、贵、结构复杂。</li>
<li>维持状态需要恒定的电源。</li>
<li>升起WL后<strong>立即可以读取状态</strong>。信号与其它晶体管控制的信号一样，是直角的(快速在两个状态间变化)。</li>
<li>状态稳定，不需要刷新循环。</li>
</ul>
<p>SRAM也有其它形式，不那么费电，但比较慢。由于我们需要的是快速RAM，因此不在关注范围内。这些较慢的SRAM的主要优点在于接口简单，比动态RAM更容易使用。</p>
<p>详细比较：</p>
<p><img src="/images/951413iMgBlog/maxresdefault.jpg" alt="Difference Between SRAM and DRAM - YouTube"></p>
<p>SRAM 也有其它形式，不那么费电，但比较慢。由于我们需要的是快速RAM，因此其它形式的 SRAM 不在关注范围内。这些较慢的SRAM的主要优点在于接口简单，比动态RAM更容易使用。CPU cache用的是快速 SRAM，本文提到的 SRAM 都是指快速 SRAM</p>
<h3 id="DRAM-刷新"><a href="#DRAM-刷新" class="headerlink" title="DRAM 刷新"></a>DRAM 刷新</h3><p>DRAM内存内部使用电容来存储数据，由于电容有漏电现象，经过一段时间电荷会泄放，导致数据不能长时间存储。因此需要不断充电，这个充电的动作叫做刷新。自动刷新是以“行”为单位进行刷新，刷新操作与读写访问无法同时进行，即刷新时会对内存的性能造成影响。同时温度越高电容泄放越快，器件手册通常要求芯片表面温度在0℃-85℃时，内存需要按照64ms的周期刷新数据，在85℃~95℃时，按照32ms的周期刷新数据。</p>
<p>BIOS中内存刷新速率选项提供了auto选项，可以根据工作温度自动调节内存刷新速率。相比默认32ms配置可以提升内存性能，同时确保工作温度在85℃~95℃时内存数据的可靠性。</p>
<h3 id="DRAM-频率"><a href="#DRAM-频率" class="headerlink" title="DRAM 频率"></a>DRAM 频率</h3><p>内存实际有3种频率：</p>
<ul>
<li>核心频率</li>
<li>时钟频率(IO控制器频率）</li>
<li>等效频率（有效数据传输频率）</li>
</ul>
<p>核心频率就是内存的Cell阵列（内存电容）的刷新频率，只与内存本身物理特性有关，目前频率基本都在133MHz~200MH之间</p>
<p>我们俗称DDR4-2666实际指的是等效频率，是通过上升下降沿进行数据预取放大后的实际数据传输频率，DDR4 prefetch是8，通过bank group提升到核心频率的16倍，所以DDR4的最低起频是133.333MHz*16&#x3D;2133MHz。DDR(Double Data Rate)因为是在一个时钟周期的上升沿和下降沿个执行预取，所以时钟频率&#x3D;等效频率&#x2F;2</p>
<h2 id="Persistence-memory"><a href="#Persistence-memory" class="headerlink" title="Persistence memory"></a>Persistence memory</h2><p>左边是在32G物理内存的基础上挂了128G pmem, 然后系统通过free能看到 154G内存，用 <code>lat_mem_rd</code> 实际测试速度可以看到左边的机器抖动比较大</p>
<p><img src="/images/951413iMgBlog/image-20220607154156826.png" alt="image-20220607154156826"></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">CPU的制造和概念</a></p>
<p>[CPU 性能和Cache Line](&#x2F;2021&#x2F;05&#x2F;16&#x2F;CPU Cache Line 和性能&#x2F;)</p>
<p>[Perf IPC以及CPU性能](&#x2F;2021&#x2F;05&#x2F;16&#x2F;Perf IPC以及CPU利用率&#x2F;)</p>
<p><a href="/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><a href="/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/">一次海光物理机资源竞争压测的记录</a></p>
<p>[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](&#x2F;2019&#x2F;12&#x2F;16&#x2F;Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的&#x2F;)</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="http://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects</a></p>
<p><a target="_blank" rel="noopener" href="https://coolshell.cn/articles/10249.html">7个示例科普CPU CACHE</a></p>
<p><a target="_blank" rel="noopener" href="https://coolshell.cn/articles/20793.html">与程序员相关的CPU缓存知识</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/ftp/arxiv/papers/1803/1803.00254.pdf">45-year CPU evolution: one law and two equations</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw">揭秘 cache 访问延迟背后的计算机原理</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/FC-bPwHUT7EpTydxDk5btQ">业务与芯片垂直整合的一点思考</a></p>
<p> <a target="_blank" rel="noopener" href="http://www.akkadia.org/drepper/cpumemory.pdf">What Every Programmer Should Know About Main Memory</a> by Ulrich Drepper  中文版：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/611133924">https://zhuanlan.zhihu.com/p/611133924</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/performance/" rel="tag"># performance</a>
              <a href="/tags/CPU/" rel="tag"># CPU</a>
              <a href="/tags/Linux/" rel="tag"># Linux</a>
              <a href="/tags/cache/" rel="tag"># cache</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/06/23/%E5%81%9A%E4%BA%86%E4%B8%80%E9%81%93%E6%95%B0%E5%AD%A6%E5%87%A0%E4%BD%95%E9%A2%98/" rel="prev" title="做了一道数学几何题">
                  <i class="fa fa-angle-left"></i> 做了一道数学几何题
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/08/13/AMD_Zen_CPU%E6%9E%B6%E6%9E%84/" rel="next" title="AMD Zen CPU 架构以及不同CPU性能大PK">
                  AMD Zen CPU 架构以及不同CPU性能大PK <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
